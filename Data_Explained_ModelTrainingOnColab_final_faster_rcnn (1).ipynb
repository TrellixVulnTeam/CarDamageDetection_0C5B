{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_Explained_ModelTrainingOnColab_final_faster_rcnn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3DpsEfckuuU-"},"source":["# Training Models on Colab"]},{"cell_type":"markdown","metadata":{"id":"ywLTsRXITas-"},"source":["Install TensorFlow and Numpy"]},{"cell_type":"code","metadata":{"id":"8WAUDct-2tT5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608054926832,"user_tz":-330,"elapsed":7470,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"4c50bd04-e8be-44f0-81c2-bed4fecd29e0"},"source":["!pip install --upgrade pip\n","!pip install --upgrade protobuf "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.3)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (3.14.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VVGEEyBWuybR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608054936096,"user_tz":-330,"elapsed":8467,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"0ed3802e-dadd-40b9-bc42-735af98696aa"},"source":["%tensorflow_version 1.15\n","import tensorflow as tf\n","\n","!pip install numpy"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.15`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RNyhvzdu9TRC"},"source":["Connect your google drive to google colab\n"]},{"cell_type":"code","metadata":{"id":"x3iBnJUl9qRN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608054955429,"user_tz":-330,"elapsed":18648,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"f1c96bba-b06e-4cd1-a2fc-4ea71902e187"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5Lj5oPsDAFjL"},"source":["Using Github Repository from \n","Edje Electronics Youtube Channel. (https://www.youtube.com/watch?v=Rgpfk6eYxJA&list=LLqBebQMBg4dGl0z37PNveiQ&index=30&t=0s)"]},{"cell_type":"markdown","metadata":{"id":"NoFRJDhgAb3s"},"source":["Do Support his youtube Channel!"]},{"cell_type":"code","metadata":{"id":"g5ygVAQIAHTB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608054961316,"user_tz":-330,"elapsed":4214,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"11c6b18f-67c9-4e62-ec27-4f554fbb979e"},"source":["!wget https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/archive/master.zip\n","!unzip master.zip"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2020-12-15 17:55:59--  https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/archive/master.zip\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://codeload.github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/zip/master [following]\n","--2020-12-15 17:55:59--  https://codeload.github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10/zip/master\n","Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n","Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘master.zip’\n","\n","master.zip              [        <=>         ]  58.73M  25.3MB/s    in 2.3s    \n","\n","2020-12-15 17:56:01 (25.3 MB/s) - ‘master.zip’ saved [61583832]\n","\n","Archive:  master.zip\n","c1645825822622fc75919b6be253779d49678f55\n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/\n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/LICENSE  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/Object_detection_image.py  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/Object_detection_video.py  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/Object_detection_webcam.py  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/README.md  \n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/\n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/C_drive_tensorflow1.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/YouTube video.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/collage.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/detector1.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/detector2.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/jupyter_notebook_dogs.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/labels.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/loss_graph.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/models.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/object_detection_directory.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/rcnn_vs_ssd.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/doc/training.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/generate_tfrecord.py  \n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/\n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/\n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2383.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2383.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2384.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2384.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2387.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2387.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2391.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2391.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2395.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2395.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2403.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2403.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2432.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2432.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2433.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2433.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2435.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2435.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2436.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2436.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2440.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2440.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2461.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2461.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2463.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2463.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2470.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2470.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2476.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2476.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2479.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2479.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2482.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2482.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2485.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2485.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2510.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2510.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2530.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2530.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2531.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2531.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2532.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2532.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2539.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2539.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2540.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2540.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2544.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2544.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2550.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2550.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2551.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2551.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2554.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2554.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2555.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2555.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2557.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2557.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2560.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2560.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2561.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2561.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2564.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2564.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2568.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2568.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2571.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2571.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2573.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2573.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2580.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2580.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2583.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2583.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2585.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2585.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2591.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2591.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2592.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2592.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2594.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2594.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2595.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2595.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2598.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2598.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2600.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2600.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2604.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2604.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2634.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2634.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2636.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2636.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2639.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2639.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2640.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2640.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2647.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2647.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2651.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2651.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2654.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2654.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2656.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2656.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2662.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2662.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2670.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2670.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2675.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2675.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2677.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2677.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2678.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2678.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2686.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/IMG_2686.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image2.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image2.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image4.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image4.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image45.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image45.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image5.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image5.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image6.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image6.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image7.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image7.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image8.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test/cam_image8.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/test_labels.csv  \n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/\n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2385.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2385.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2386.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2386.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2388.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2388.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2389.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2389.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2390.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2390.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2392.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2392.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2393.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2393.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2394.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2394.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2396.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2396.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2397.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2397.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2398.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2398.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2399.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2399.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2400.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2400.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2401.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2401.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2402.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2402.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2404.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2404.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2405.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2405.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2406.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2406.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2407.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2407.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2408.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2408.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2409.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2409.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2410.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2410.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2411.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2411.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2412.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2412.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2413.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2413.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2414.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2414.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2415.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2415.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2416.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2416.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2417.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2417.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2418.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2418.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2419.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2419.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2420.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2420.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2421.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2421.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2422.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2422.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2423.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2423.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2424.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2424.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2425.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2425.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2426.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2426.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2427.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2427.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2428.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2428.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2429.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2429.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2430.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2430.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2431.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2431.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2434.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2434.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2437.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2437.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2439.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2439.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2441.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2441.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2442.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2442.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2443.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2443.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2445.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2445.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2446.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2446.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2447.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2447.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2448.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2448.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2449.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2449.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2450.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2450.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2451.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2451.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2452.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2452.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2453.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2453.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2454.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2454.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2455.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2455.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2456.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2456.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2457.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2457.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2458.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2458.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2459.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2459.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2460.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2460.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2462.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2462.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2464.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2464.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2465.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2465.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2466.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2466.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2467.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2467.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2468.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2468.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2469.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2469.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2471.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2471.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2472.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2472.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2473.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2473.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2474.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2474.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2475.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2475.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2477.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2477.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2478.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2478.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2480.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2480.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2481.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2481.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2483.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2483.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2484.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2484.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2486.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2486.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2487.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2487.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2488.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2488.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2489.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2489.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2490.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2490.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2491.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2491.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2492.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2492.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2493.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2493.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2494.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2494.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2495.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2495.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2496.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2496.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2497.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2497.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2498.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2498.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2499.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2499.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2500.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2500.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2501.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2501.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2502.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2502.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2503.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2503.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2504.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2504.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2505.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2505.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2506.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2506.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2507.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2507.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2508.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2508.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2509.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2509.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2511.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2511.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2512.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2512.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2513.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2513.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2514.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2514.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2515.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2515.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2516.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2516.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2517.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2517.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2518.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2518.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2519.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2519.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2520.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2520.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2521.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2521.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2522.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2522.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2523.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2523.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2524.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2524.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2525.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2525.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2526.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2526.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2527.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2527.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2528.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2528.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2529.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2529.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2533.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2533.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2535.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2535.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2536.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2536.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2537.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2537.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2538.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2538.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2542.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2542.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2543.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2543.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2545.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2545.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2546.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2546.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2548.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2548.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2549.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2549.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2552.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2552.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2553.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2553.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2556.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2556.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2558.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2558.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2559.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2559.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2562.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2562.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2563.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2563.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2565.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2565.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2566.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2566.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2567.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2567.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2569.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2569.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2570.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2570.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2572.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2572.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2574.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2574.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2576.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2576.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2577.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2577.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2578.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2578.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2579.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2579.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2581.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2581.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2582.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2582.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2584.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2584.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2586.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2586.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2587.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2587.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2588.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2588.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2589.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2589.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2590.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2590.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2593.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2593.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2596.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2596.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2597.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2597.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2599.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2599.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2601.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2601.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2602.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2602.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2603.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2603.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2605.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2605.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2607.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2607.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2608.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2608.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2609.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2609.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2610.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2610.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2611.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2611.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2612.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2612.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2613.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2613.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2614.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2614.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2615.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2615.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2616.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2616.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2617.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2617.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2618.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2618.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2619.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2619.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2620.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2620.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2621.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2621.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2622.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2622.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2623.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2623.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2624.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2624.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2626.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2626.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2627.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2627.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2628.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2628.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2629.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2629.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2630.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2630.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2631.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2631.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2632.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2632.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2633.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2633.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2635.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2635.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2637.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2637.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2638.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2638.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2641.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2641.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2642.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2642.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2643.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2643.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2644.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2644.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2645.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2645.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2648.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2648.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2649.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2649.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2650.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2650.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2652.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2652.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2653.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2653.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2655.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2655.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2657.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2657.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2658.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2658.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2659.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2659.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2660.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2660.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2661.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2661.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2663.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2663.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2664.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2664.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2665.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2665.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2666.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2666.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2667.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2667.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2668.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2668.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2669.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2669.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2671.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2671.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2672.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2672.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2673.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2673.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2674.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2674.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2679.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2679.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2680.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2680.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2681.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2681.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2682.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2682.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2683.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2683.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2684.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2684.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2685.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2685.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2687.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2687.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2689.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2689.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2690.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2690.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2691.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2691.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2692.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2692.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2693.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2693.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2694.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2694.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2695.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2695.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2696.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2696.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2697.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2697.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2698.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2698.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2699.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2699.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2700.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2700.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2701.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2701.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2702.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2702.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2703.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2703.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2704.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/IMG_2704.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image1.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image1.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image10.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image10.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image11.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image11.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image12.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image12.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image13.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image13.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image14.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image14.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image15.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image15.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image16.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image16.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image17.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image17.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image18.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image18.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image19.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image19.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image20.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image20.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image21.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image21.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image22.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image22.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image23.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image23.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image24.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image24.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image25.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image25.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image26.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image26.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image27.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image27.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image28.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image28.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image29.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image29.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image3.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image3.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image30.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image30.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image31.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image31.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image32.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image32.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image33.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image33.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image34.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image34.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image35.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image35.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image36.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image36.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image37.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image37.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image38.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image38.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image39.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image39.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image40.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image40.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image41.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image41.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image42.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image42.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image43.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image43.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image44.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image44.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image46.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image46.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image47.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image47.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image48.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image48.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image50.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image50.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image51.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image51.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image52.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image52.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image54.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image54.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image9.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train/cam_image9.xml  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/images/train_labels.csv  \n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/inference_graph/\n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/inference_graph/placeholder.txt  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/resizer.py  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/sizeChecker.py  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/test.mov  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/test1.JPG  \n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/training/\n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/training/faster_rcnn_inception_v2_pets.config  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/training/labelmap.pbtxt  \n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/\n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/README_Chinese.md  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/README_Korean.md  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/README_Vietnamese.md  \n","   creating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/\n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/C_drive_tensorflow1.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/YouTube video.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/collage.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/detector1.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/detector2.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/jupyter_notebook_dogs.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/labels.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/loss_graph.JPG  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/models.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/object_detection_directory.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/rcnn_vs_ssd.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/translate/doc/training.jpg  \n","  inflating: TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/xml_to_csv.py  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oGW487k4rP5M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608054971134,"user_tz":-330,"elapsed":4800,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"d1c25e1f-e64b-40ba-a792-592044416267"},"source":["!wget https://github.com/tensorflow/models/archive/master.zip\n","!unzip /content/master.zip.1"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2020-12-15 17:56:08--  https://github.com/tensorflow/models/archive/master.zip\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://codeload.github.com/tensorflow/models/zip/master [following]\n","--2020-12-15 17:56:08--  https://codeload.github.com/tensorflow/models/zip/master\n","Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n","Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/zip]\n","Saving to: ‘master.zip.1’\n","\n","master.zip.1            [          <=>       ]  31.65M  14.2MB/s    in 2.2s    \n","\n","2020-12-15 17:56:11 (14.2 MB/s) - ‘master.zip.1’ saved [33192261]\n","\n","Archive:  /content/master.zip.1\n","39f98e30e7fb51c8b7ad58b0fc65ee5312829deb\n","   creating: models-master/\n","   creating: models-master/.github/\n","   creating: models-master/.github/ISSUE_TEMPLATE/\n","  inflating: models-master/.github/ISSUE_TEMPLATE/00-official-bug-report-issue.md  \n","  inflating: models-master/.github/ISSUE_TEMPLATE/10-official-documentation-issue.md  \n","  inflating: models-master/.github/ISSUE_TEMPLATE/20-official-feature-request-issue.md  \n","  inflating: models-master/.github/ISSUE_TEMPLATE/30-research-bug-report-issue.md  \n","  inflating: models-master/.github/ISSUE_TEMPLATE/40-research-documentation-issue.md  \n","  inflating: models-master/.github/ISSUE_TEMPLATE/50-research-feature-request-issue.md  \n","  inflating: models-master/.github/ISSUE_TEMPLATE/60-questions-help-issue.md  \n"," extracting: models-master/.github/ISSUE_TEMPLATE/config.yml  \n","  inflating: models-master/.github/PULL_REQUEST_TEMPLATE.md  \n","  inflating: models-master/.github/README_TEMPLATE.md  \n","  inflating: models-master/.github/bot_config.yml  \n","  inflating: models-master/.github/stale.yml  \n","  inflating: models-master/.gitignore  \n","  inflating: models-master/AUTHORS   \n","  inflating: models-master/CODEOWNERS  \n","  inflating: models-master/CONTRIBUTING.md  \n","  inflating: models-master/ISSUES.md  \n","  inflating: models-master/LICENSE   \n","  inflating: models-master/README.md  \n","   creating: models-master/community/\n","  inflating: models-master/community/README.md  \n","   creating: models-master/official/\n","  inflating: models-master/official/LICENSE  \n","  inflating: models-master/official/README-TPU.md  \n","  inflating: models-master/official/README.md  \n"," extracting: models-master/official/__init__.py  \n","   creating: models-master/official/colab/\n","  inflating: models-master/official/colab/fine_tuning_bert.ipynb  \n","   creating: models-master/official/colab/nlp/\n","  inflating: models-master/official/colab/nlp/customize_encoder.ipynb  \n","  inflating: models-master/official/colab/nlp/nlp_modeling_library_intro.ipynb  \n","   creating: models-master/official/common/\n"," extracting: models-master/official/common/__init__.py  \n","  inflating: models-master/official/common/distribute_utils.py  \n","  inflating: models-master/official/common/distribute_utils_test.py  \n","  inflating: models-master/official/common/flags.py  \n","  inflating: models-master/official/common/registry_imports.py  \n","   creating: models-master/official/core/\n"," extracting: models-master/official/core/__init__.py  \n","  inflating: models-master/official/core/base_task.py  \n","  inflating: models-master/official/core/base_trainer.py  \n","  inflating: models-master/official/core/base_trainer_test.py  \n","  inflating: models-master/official/core/config_definitions.py  \n","  inflating: models-master/official/core/exp_factory.py  \n","  inflating: models-master/official/core/input_reader.py  \n","  inflating: models-master/official/core/registry.py  \n","  inflating: models-master/official/core/registry_test.py  \n","  inflating: models-master/official/core/task_factory.py  \n","  inflating: models-master/official/core/train_lib.py  \n","  inflating: models-master/official/core/train_lib_test.py  \n","  inflating: models-master/official/core/train_utils.py  \n","   creating: models-master/official/modeling/\n"," extracting: models-master/official/modeling/__init__.py  \n","   creating: models-master/official/modeling/activations/\n","  inflating: models-master/official/modeling/activations/__init__.py  \n","  inflating: models-master/official/modeling/activations/gelu.py  \n","  inflating: models-master/official/modeling/activations/gelu_test.py  \n","  inflating: models-master/official/modeling/activations/relu.py  \n","  inflating: models-master/official/modeling/activations/relu_test.py  \n","  inflating: models-master/official/modeling/activations/sigmoid.py  \n","  inflating: models-master/official/modeling/activations/sigmoid_test.py  \n","  inflating: models-master/official/modeling/activations/swish.py  \n","  inflating: models-master/official/modeling/activations/swish_test.py  \n","   creating: models-master/official/modeling/hyperparams/\n","  inflating: models-master/official/modeling/hyperparams/__init__.py  \n","  inflating: models-master/official/modeling/hyperparams/base_config.py  \n","  inflating: models-master/official/modeling/hyperparams/base_config_test.py  \n","  inflating: models-master/official/modeling/hyperparams/config_definitions.py  \n","  inflating: models-master/official/modeling/hyperparams/oneof.py  \n","  inflating: models-master/official/modeling/hyperparams/oneof_test.py  \n","  inflating: models-master/official/modeling/hyperparams/params_dict.py  \n","  inflating: models-master/official/modeling/hyperparams/params_dict_test.py  \n","   creating: models-master/official/modeling/optimization/\n","  inflating: models-master/official/modeling/optimization/__init__.py  \n","   creating: models-master/official/modeling/optimization/configs/\n"," extracting: models-master/official/modeling/optimization/configs/__init__.py  \n","  inflating: models-master/official/modeling/optimization/configs/learning_rate_config.py  \n","  inflating: models-master/official/modeling/optimization/configs/optimization_config.py  \n","  inflating: models-master/official/modeling/optimization/configs/optimization_config_test.py  \n","  inflating: models-master/official/modeling/optimization/configs/optimizer_config.py  \n","  inflating: models-master/official/modeling/optimization/ema_optimizer.py  \n","  inflating: models-master/official/modeling/optimization/lr_schedule.py  \n","  inflating: models-master/official/modeling/optimization/optimizer_factory.py  \n","  inflating: models-master/official/modeling/optimization/optimizer_factory_test.py  \n","  inflating: models-master/official/modeling/performance.py  \n","  inflating: models-master/official/modeling/tf_utils.py  \n","   creating: models-master/official/nlp/\n","  inflating: models-master/official/nlp/README.md  \n"," extracting: models-master/official/nlp/__init__.py  \n","   creating: models-master/official/nlp/albert/\n","  inflating: models-master/official/nlp/albert/README.md  \n"," extracting: models-master/official/nlp/albert/__init__.py  \n","  inflating: models-master/official/nlp/albert/configs.py  \n","  inflating: models-master/official/nlp/albert/export_albert_tfhub.py  \n","  inflating: models-master/official/nlp/albert/export_albert_tfhub_test.py  \n","  inflating: models-master/official/nlp/albert/run_classifier.py  \n","  inflating: models-master/official/nlp/albert/run_squad.py  \n","  inflating: models-master/official/nlp/albert/tf2_albert_encoder_checkpoint_converter.py  \n","   creating: models-master/official/nlp/bert/\n","  inflating: models-master/official/nlp/bert/README.md  \n"," extracting: models-master/official/nlp/bert/__init__.py  \n","  inflating: models-master/official/nlp/bert/bert_cloud_tpu.md  \n","  inflating: models-master/official/nlp/bert/bert_models.py  \n","  inflating: models-master/official/nlp/bert/bert_models_test.py  \n","  inflating: models-master/official/nlp/bert/common_flags.py  \n","  inflating: models-master/official/nlp/bert/configs.py  \n","  inflating: models-master/official/nlp/bert/export_tfhub.py  \n","  inflating: models-master/official/nlp/bert/export_tfhub_test.py  \n","  inflating: models-master/official/nlp/bert/input_pipeline.py  \n","  inflating: models-master/official/nlp/bert/model_saving_utils.py  \n","  inflating: models-master/official/nlp/bert/model_training_utils.py  \n","  inflating: models-master/official/nlp/bert/model_training_utils_test.py  \n","  inflating: models-master/official/nlp/bert/run_classifier.py  \n","  inflating: models-master/official/nlp/bert/run_pretraining.py  \n","  inflating: models-master/official/nlp/bert/run_squad.py  \n","  inflating: models-master/official/nlp/bert/run_squad_helper.py  \n","  inflating: models-master/official/nlp/bert/serving.py  \n","  inflating: models-master/official/nlp/bert/squad_evaluate_v1_1.py  \n","  inflating: models-master/official/nlp/bert/squad_evaluate_v2_0.py  \n","  inflating: models-master/official/nlp/bert/tf1_checkpoint_converter_lib.py  \n","  inflating: models-master/official/nlp/bert/tf2_encoder_checkpoint_converter.py  \n","  inflating: models-master/official/nlp/bert/tokenization.py  \n","  inflating: models-master/official/nlp/bert/tokenization_test.py  \n","   creating: models-master/official/nlp/configs/\n"," extracting: models-master/official/nlp/configs/__init__.py  \n","  inflating: models-master/official/nlp/configs/bert.py  \n","  inflating: models-master/official/nlp/configs/electra.py  \n","  inflating: models-master/official/nlp/configs/encoders.py  \n","  inflating: models-master/official/nlp/configs/experiment_configs.py  \n","   creating: models-master/official/nlp/configs/experiments/\n","  inflating: models-master/official/nlp/configs/experiments/glue_mnli_matched.yaml  \n","  inflating: models-master/official/nlp/configs/finetuning_experiments.py  \n","   creating: models-master/official/nlp/configs/models/\n","  inflating: models-master/official/nlp/configs/models/bert_en_uncased_base.yaml  \n","   creating: models-master/official/nlp/data/\n"," extracting: models-master/official/nlp/data/__init__.py  \n","  inflating: models-master/official/nlp/data/classifier_data_lib.py  \n","  inflating: models-master/official/nlp/data/create_finetuning_data.py  \n","  inflating: models-master/official/nlp/data/create_pretraining_data.py  \n","  inflating: models-master/official/nlp/data/create_pretraining_data_test.py  \n","  inflating: models-master/official/nlp/data/create_xlnet_pretraining_data.py  \n","  inflating: models-master/official/nlp/data/create_xlnet_pretraining_data_test.py  \n","  inflating: models-master/official/nlp/data/data_loader.py  \n","  inflating: models-master/official/nlp/data/data_loader_factory.py  \n","  inflating: models-master/official/nlp/data/data_loader_factory_test.py  \n","  inflating: models-master/official/nlp/data/pretrain_dataloader.py  \n","  inflating: models-master/official/nlp/data/pretrain_dataloader_test.py  \n","  inflating: models-master/official/nlp/data/question_answering_dataloader.py  \n","  inflating: models-master/official/nlp/data/question_answering_dataloader_test.py  \n","  inflating: models-master/official/nlp/data/sentence_prediction_dataloader.py  \n","  inflating: models-master/official/nlp/data/sentence_prediction_dataloader_test.py  \n","  inflating: models-master/official/nlp/data/sentence_retrieval_lib.py  \n","  inflating: models-master/official/nlp/data/squad_lib.py  \n","  inflating: models-master/official/nlp/data/squad_lib_sp.py  \n","  inflating: models-master/official/nlp/data/tagging_data_lib.py  \n","  inflating: models-master/official/nlp/data/tagging_data_lib_test.py  \n","  inflating: models-master/official/nlp/data/tagging_dataloader.py  \n","  inflating: models-master/official/nlp/data/tagging_dataloader_test.py  \n","  inflating: models-master/official/nlp/data/train_sentencepiece.py  \n","   creating: models-master/official/nlp/keras_nlp/\n","  inflating: models-master/official/nlp/keras_nlp/README.md  \n","  inflating: models-master/official/nlp/keras_nlp/__init__.py  \n","  inflating: models-master/official/nlp/keras_nlp/contributing.md  \n","   creating: models-master/official/nlp/keras_nlp/encoders/\n","  inflating: models-master/official/nlp/keras_nlp/encoders/__init__.py  \n","  inflating: models-master/official/nlp/keras_nlp/encoders/bert_encoder.py  \n","  inflating: models-master/official/nlp/keras_nlp/encoders/bert_encoder_test.py  \n","   creating: models-master/official/nlp/keras_nlp/layers/\n","  inflating: models-master/official/nlp/keras_nlp/layers/__init__.py  \n","  inflating: models-master/official/nlp/keras_nlp/layers/masked_lm.py  \n","  inflating: models-master/official/nlp/keras_nlp/layers/on_device_embedding.py  \n","  inflating: models-master/official/nlp/keras_nlp/layers/on_device_embedding_test.py  \n","  inflating: models-master/official/nlp/keras_nlp/layers/position_embedding.py  \n","  inflating: models-master/official/nlp/keras_nlp/layers/position_embedding_test.py  \n","  inflating: models-master/official/nlp/keras_nlp/layers/self_attention_mask.py  \n","  inflating: models-master/official/nlp/keras_nlp/layers/transformer_encoder_block.py  \n","  inflating: models-master/official/nlp/keras_nlp/layers/transformer_encoder_block_test.py  \n"," extracting: models-master/official/nlp/keras_nlp/requirements.txt  \n","  inflating: models-master/official/nlp/keras_nlp/setup.py  \n","   creating: models-master/official/nlp/modeling/\n","  inflating: models-master/official/nlp/modeling/README.md  \n"," extracting: models-master/official/nlp/modeling/__init__.py  \n","   creating: models-master/official/nlp/modeling/layers/\n","  inflating: models-master/official/nlp/modeling/layers/README.md  \n","  inflating: models-master/official/nlp/modeling/layers/__init__.py  \n","  inflating: models-master/official/nlp/modeling/layers/attention.py  \n","  inflating: models-master/official/nlp/modeling/layers/attention_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/cls_head.py  \n","  inflating: models-master/official/nlp/modeling/layers/cls_head_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/dense_einsum.py  \n","  inflating: models-master/official/nlp/modeling/layers/dense_einsum_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/gated_feedforward.py  \n","  inflating: models-master/official/nlp/modeling/layers/gated_feedforward_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/masked_lm.py  \n","  inflating: models-master/official/nlp/modeling/layers/masked_lm_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/masked_softmax.py  \n","  inflating: models-master/official/nlp/modeling/layers/masked_softmax_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/mat_mul_with_margin.py  \n","  inflating: models-master/official/nlp/modeling/layers/mat_mul_with_margin_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/mobile_bert_layers.py  \n","  inflating: models-master/official/nlp/modeling/layers/mobile_bert_layers_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/multi_channel_attention.py  \n","  inflating: models-master/official/nlp/modeling/layers/multi_channel_attention_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/on_device_embedding.py  \n","  inflating: models-master/official/nlp/modeling/layers/position_embedding.py  \n","  inflating: models-master/official/nlp/modeling/layers/position_embedding_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/relative_attention.py  \n","  inflating: models-master/official/nlp/modeling/layers/relative_attention_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/rezero_transformer.py  \n","  inflating: models-master/official/nlp/modeling/layers/rezero_transformer_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/self_attention_mask.py  \n","  inflating: models-master/official/nlp/modeling/layers/talking_heads_attention.py  \n","  inflating: models-master/official/nlp/modeling/layers/talking_heads_attention_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/tn_expand_condense.py  \n","  inflating: models-master/official/nlp/modeling/layers/tn_expand_condense_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/tn_transformer_expand_condense.py  \n","  inflating: models-master/official/nlp/modeling/layers/tn_transformer_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/transformer.py  \n","  inflating: models-master/official/nlp/modeling/layers/transformer_scaffold.py  \n","  inflating: models-master/official/nlp/modeling/layers/transformer_scaffold_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/transformer_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/transformer_xl.py  \n","  inflating: models-master/official/nlp/modeling/layers/transformer_xl_test.py  \n","  inflating: models-master/official/nlp/modeling/layers/util.py  \n","   creating: models-master/official/nlp/modeling/losses/\n","  inflating: models-master/official/nlp/modeling/losses/README.md  \n","  inflating: models-master/official/nlp/modeling/losses/__init__.py  \n","  inflating: models-master/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy.py  \n","  inflating: models-master/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy_test.py  \n","   creating: models-master/official/nlp/modeling/models/\n","  inflating: models-master/official/nlp/modeling/models/README.md  \n","  inflating: models-master/official/nlp/modeling/models/__init__.py  \n","  inflating: models-master/official/nlp/modeling/models/bert_classifier.py  \n","  inflating: models-master/official/nlp/modeling/models/bert_classifier_test.py  \n","  inflating: models-master/official/nlp/modeling/models/bert_pretrainer.py  \n","  inflating: models-master/official/nlp/modeling/models/bert_pretrainer_test.py  \n","  inflating: models-master/official/nlp/modeling/models/bert_span_labeler.py  \n","  inflating: models-master/official/nlp/modeling/models/bert_span_labeler_test.py  \n","  inflating: models-master/official/nlp/modeling/models/bert_token_classifier.py  \n","  inflating: models-master/official/nlp/modeling/models/bert_token_classifier_test.py  \n","  inflating: models-master/official/nlp/modeling/models/dual_encoder.py  \n","  inflating: models-master/official/nlp/modeling/models/dual_encoder_test.py  \n","  inflating: models-master/official/nlp/modeling/models/electra_pretrainer.py  \n","  inflating: models-master/official/nlp/modeling/models/electra_pretrainer_test.py  \n","  inflating: models-master/official/nlp/modeling/models/seq2seq_transformer.py  \n","  inflating: models-master/official/nlp/modeling/models/seq2seq_transformer_test.py  \n","  inflating: models-master/official/nlp/modeling/models/xlnet.py  \n","  inflating: models-master/official/nlp/modeling/models/xlnet_test.py  \n","   creating: models-master/official/nlp/modeling/networks/\n","  inflating: models-master/official/nlp/modeling/networks/README.md  \n","  inflating: models-master/official/nlp/modeling/networks/__init__.py  \n","  inflating: models-master/official/nlp/modeling/networks/albert_encoder.py  \n","  inflating: models-master/official/nlp/modeling/networks/albert_encoder_test.py  \n","  inflating: models-master/official/nlp/modeling/networks/bert_encoder.py  \n","  inflating: models-master/official/nlp/modeling/networks/bert_encoder_test.py  \n","  inflating: models-master/official/nlp/modeling/networks/classification.py  \n","  inflating: models-master/official/nlp/modeling/networks/classification_test.py  \n","  inflating: models-master/official/nlp/modeling/networks/encoder_scaffold.py  \n","  inflating: models-master/official/nlp/modeling/networks/encoder_scaffold_test.py  \n","  inflating: models-master/official/nlp/modeling/networks/mobile_bert_encoder.py  \n","  inflating: models-master/official/nlp/modeling/networks/mobile_bert_encoder_test.py  \n","  inflating: models-master/official/nlp/modeling/networks/packed_sequence_embedding.py  \n","  inflating: models-master/official/nlp/modeling/networks/packed_sequence_embedding_test.py  \n","  inflating: models-master/official/nlp/modeling/networks/span_labeling.py  \n","  inflating: models-master/official/nlp/modeling/networks/span_labeling_test.py  \n","  inflating: models-master/official/nlp/modeling/networks/xlnet_base.py  \n","  inflating: models-master/official/nlp/modeling/networks/xlnet_base_test.py  \n","   creating: models-master/official/nlp/modeling/ops/\n"," extracting: models-master/official/nlp/modeling/ops/__init__.py  \n","  inflating: models-master/official/nlp/modeling/ops/beam_search.py  \n","  inflating: models-master/official/nlp/modeling/ops/beam_search_test.py  \n","  inflating: models-master/official/nlp/modeling/ops/decoding_module.py  \n","  inflating: models-master/official/nlp/modeling/ops/decoding_module_test.py  \n","  inflating: models-master/official/nlp/modeling/ops/sampling_module.py  \n","  inflating: models-master/official/nlp/modeling/ops/segment_extractor.py  \n","  inflating: models-master/official/nlp/modeling/ops/segment_extractor_test.py  \n","   creating: models-master/official/nlp/nhnet/\n","  inflating: models-master/official/nlp/nhnet/README.md  \n"," extracting: models-master/official/nlp/nhnet/__init__.py  \n","  inflating: models-master/official/nlp/nhnet/configs.py  \n","  inflating: models-master/official/nlp/nhnet/configs_test.py  \n","  inflating: models-master/official/nlp/nhnet/decoder.py  \n","  inflating: models-master/official/nlp/nhnet/decoder_test.py  \n","  inflating: models-master/official/nlp/nhnet/evaluation.py  \n","  inflating: models-master/official/nlp/nhnet/input_pipeline.py  \n","  inflating: models-master/official/nlp/nhnet/models.py  \n","  inflating: models-master/official/nlp/nhnet/models_test.py  \n","  inflating: models-master/official/nlp/nhnet/optimizer.py  \n","  inflating: models-master/official/nlp/nhnet/raw_data_process.py  \n","  inflating: models-master/official/nlp/nhnet/raw_data_processor.py  \n","   creating: models-master/official/nlp/nhnet/testdata/\n","   creating: models-master/official/nlp/nhnet/testdata/crawled_articles/\n","   creating: models-master/official/nlp/nhnet/testdata/crawled_articles/domain_0.com/\n","  inflating: models-master/official/nlp/nhnet/testdata/crawled_articles/domain_0.com/url_000.html  \n","  inflating: models-master/official/nlp/nhnet/testdata/crawled_articles/domain_0.com/url_000.json  \n","   creating: models-master/official/nlp/nhnet/testdata/crawled_articles/domain_1.com/\n","  inflating: models-master/official/nlp/nhnet/testdata/crawled_articles/domain_1.com/url_001.html  \n","  inflating: models-master/official/nlp/nhnet/testdata/crawled_articles/domain_1.com/url_001.json  \n","  inflating: models-master/official/nlp/nhnet/testdata/stories.json  \n","  inflating: models-master/official/nlp/nhnet/testdata/vocab.txt  \n","  inflating: models-master/official/nlp/nhnet/trainer.py  \n","  inflating: models-master/official/nlp/nhnet/trainer_test.py  \n","  inflating: models-master/official/nlp/nhnet/utils.py  \n","  inflating: models-master/official/nlp/optimization.py  \n","   creating: models-master/official/nlp/projects/\n"," extracting: models-master/official/nlp/projects/__init__.py  \n","   creating: models-master/official/nlp/projects/bigbird/\n"," extracting: models-master/official/nlp/projects/bigbird/__init__.py  \n","  inflating: models-master/official/nlp/projects/bigbird/attention.py  \n","  inflating: models-master/official/nlp/projects/bigbird/attention_test.py  \n","  inflating: models-master/official/nlp/projects/bigbird/encoder.py  \n","  inflating: models-master/official/nlp/projects/bigbird/encoder_test.py  \n","   creating: models-master/official/nlp/projects/triviaqa/\n"," extracting: models-master/official/nlp/projects/triviaqa/__init__.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/dataset.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/download_and_prepare.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/evaluate.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/evaluation.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/inputs.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/modeling.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/predict.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/prediction.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/preprocess.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/sentencepiece_pb2.py  \n","  inflating: models-master/official/nlp/projects/triviaqa/train.py  \n","   creating: models-master/official/nlp/tasks/\n"," extracting: models-master/official/nlp/tasks/__init__.py  \n","  inflating: models-master/official/nlp/tasks/electra_task.py  \n","  inflating: models-master/official/nlp/tasks/electra_task_test.py  \n","  inflating: models-master/official/nlp/tasks/masked_lm.py  \n","  inflating: models-master/official/nlp/tasks/masked_lm_test.py  \n","  inflating: models-master/official/nlp/tasks/question_answering.py  \n","  inflating: models-master/official/nlp/tasks/question_answering_test.py  \n","  inflating: models-master/official/nlp/tasks/sentence_prediction.py  \n","  inflating: models-master/official/nlp/tasks/sentence_prediction_test.py  \n","  inflating: models-master/official/nlp/tasks/tagging.py  \n","  inflating: models-master/official/nlp/tasks/tagging_test.py  \n","  inflating: models-master/official/nlp/tasks/utils.py  \n","  inflating: models-master/official/nlp/train.md  \n","  inflating: models-master/official/nlp/train.py  \n","  inflating: models-master/official/nlp/train_ctl_continuous_finetune.py  \n","  inflating: models-master/official/nlp/train_ctl_continuous_finetune_test.py  \n","   creating: models-master/official/nlp/transformer/\n","  inflating: models-master/official/nlp/transformer/README.md  \n"," extracting: models-master/official/nlp/transformer/__init__.py  \n","  inflating: models-master/official/nlp/transformer/attention_layer.py  \n","  inflating: models-master/official/nlp/transformer/beam_search_v1.py  \n","  inflating: models-master/official/nlp/transformer/compute_bleu.py  \n","  inflating: models-master/official/nlp/transformer/compute_bleu_test.py  \n","  inflating: models-master/official/nlp/transformer/data_download.py  \n","  inflating: models-master/official/nlp/transformer/data_pipeline.py  \n","  inflating: models-master/official/nlp/transformer/embedding_layer.py  \n","  inflating: models-master/official/nlp/transformer/ffn_layer.py  \n","  inflating: models-master/official/nlp/transformer/metrics.py  \n","  inflating: models-master/official/nlp/transformer/misc.py  \n","  inflating: models-master/official/nlp/transformer/model_params.py  \n","  inflating: models-master/official/nlp/transformer/model_utils.py  \n","  inflating: models-master/official/nlp/transformer/model_utils_test.py  \n","  inflating: models-master/official/nlp/transformer/optimizer.py  \n","  inflating: models-master/official/nlp/transformer/transformer.py  \n","  inflating: models-master/official/nlp/transformer/transformer_forward_test.py  \n","  inflating: models-master/official/nlp/transformer/transformer_layers_test.py  \n","  inflating: models-master/official/nlp/transformer/transformer_main.py  \n","  inflating: models-master/official/nlp/transformer/transformer_main_test.py  \n","  inflating: models-master/official/nlp/transformer/transformer_test.py  \n","  inflating: models-master/official/nlp/transformer/translate.py  \n","   creating: models-master/official/nlp/transformer/utils/\n"," extracting: models-master/official/nlp/transformer/utils/__init__.py  \n","  inflating: models-master/official/nlp/transformer/utils/metrics.py  \n","  inflating: models-master/official/nlp/transformer/utils/tokenizer.py  \n","  inflating: models-master/official/nlp/transformer/utils/tokenizer_test.py  \n","   creating: models-master/official/nlp/xlnet/\n","  inflating: models-master/official/nlp/xlnet/README.md  \n"," extracting: models-master/official/nlp/xlnet/__init__.py  \n","  inflating: models-master/official/nlp/xlnet/classifier_utils.py  \n","  inflating: models-master/official/nlp/xlnet/common_flags.py  \n","  inflating: models-master/official/nlp/xlnet/data_utils.py  \n","  inflating: models-master/official/nlp/xlnet/optimization.py  \n","  inflating: models-master/official/nlp/xlnet/preprocess_classification_data.py  \n","  inflating: models-master/official/nlp/xlnet/preprocess_pretrain_data.py  \n","  inflating: models-master/official/nlp/xlnet/preprocess_squad_data.py  \n","  inflating: models-master/official/nlp/xlnet/preprocess_utils.py  \n","  inflating: models-master/official/nlp/xlnet/run_classifier.py  \n","  inflating: models-master/official/nlp/xlnet/run_pretrain.py  \n","  inflating: models-master/official/nlp/xlnet/run_squad.py  \n","  inflating: models-master/official/nlp/xlnet/squad_utils.py  \n","  inflating: models-master/official/nlp/xlnet/training_utils.py  \n","  inflating: models-master/official/nlp/xlnet/xlnet_config.py  \n","  inflating: models-master/official/nlp/xlnet/xlnet_modeling.py  \n","   creating: models-master/official/pip_package/\n","  inflating: models-master/official/pip_package/setup.py  \n","   creating: models-master/official/recommendation/\n","  inflating: models-master/official/recommendation/README.md  \n"," extracting: models-master/official/recommendation/__init__.py  \n","  inflating: models-master/official/recommendation/constants.py  \n","  inflating: models-master/official/recommendation/create_ncf_data.py  \n","  inflating: models-master/official/recommendation/data_pipeline.py  \n","  inflating: models-master/official/recommendation/data_preprocessing.py  \n","  inflating: models-master/official/recommendation/data_test.py  \n","  inflating: models-master/official/recommendation/movielens.py  \n","  inflating: models-master/official/recommendation/ncf_common.py  \n","  inflating: models-master/official/recommendation/ncf_input_pipeline.py  \n","  inflating: models-master/official/recommendation/ncf_keras_main.py  \n","  inflating: models-master/official/recommendation/ncf_test.py  \n","  inflating: models-master/official/recommendation/neumf_model.py  \n","  inflating: models-master/official/recommendation/popen_helper.py  \n","  inflating: models-master/official/recommendation/run.sh  \n","  inflating: models-master/official/recommendation/stat_utils.py  \n","  inflating: models-master/official/requirements.txt  \n","   creating: models-master/official/staging/\n"," extracting: models-master/official/staging/__init__.py  \n","   creating: models-master/official/staging/training/\n","  inflating: models-master/official/staging/training/__init__.py  \n","  inflating: models-master/official/staging/training/grad_utils.py  \n","   creating: models-master/official/utils/\n"," extracting: models-master/official/utils/__init__.py  \n","   creating: models-master/official/utils/flags/\n","  inflating: models-master/official/utils/flags/README.md  \n"," extracting: models-master/official/utils/flags/__init__.py  \n","  inflating: models-master/official/utils/flags/_base.py  \n","  inflating: models-master/official/utils/flags/_benchmark.py  \n","  inflating: models-master/official/utils/flags/_conventions.py  \n","  inflating: models-master/official/utils/flags/_device.py  \n","  inflating: models-master/official/utils/flags/_distribution.py  \n","  inflating: models-master/official/utils/flags/_misc.py  \n","  inflating: models-master/official/utils/flags/_performance.py  \n","  inflating: models-master/official/utils/flags/core.py  \n","  inflating: models-master/official/utils/flags/flags_test.py  \n","  inflating: models-master/official/utils/flags/guidelines.md  \n","  inflating: models-master/official/utils/hyperparams_flags.py  \n","   creating: models-master/official/utils/misc/\n"," extracting: models-master/official/utils/misc/__init__.py  \n","  inflating: models-master/official/utils/misc/callstack_sampler.py  \n","  inflating: models-master/official/utils/misc/distribution_utils.py  \n","  inflating: models-master/official/utils/misc/keras_utils.py  \n","  inflating: models-master/official/utils/misc/model_helpers.py  \n","  inflating: models-master/official/utils/misc/model_helpers_test.py  \n","   creating: models-master/official/utils/testing/\n"," extracting: models-master/official/utils/testing/__init__.py  \n","  inflating: models-master/official/utils/testing/integration.py  \n","  inflating: models-master/official/utils/testing/mock_task.py  \n","  inflating: models-master/official/utils/testing/pylint.rcfile  \n","   creating: models-master/official/utils/testing/scripts/\n","  inflating: models-master/official/utils/testing/scripts/builds_common.sh  \n","  inflating: models-master/official/utils/testing/scripts/ci_sanity.sh  \n","  inflating: models-master/official/utils/testing/scripts/presubmit.sh  \n","   creating: models-master/official/vision/\n"," extracting: models-master/official/vision/__init__.py  \n","   creating: models-master/official/vision/beta/\n","  inflating: models-master/official/vision/beta/MODEL_GARDEN.md  \n","  inflating: models-master/official/vision/beta/README.md  \n","  inflating: models-master/official/vision/beta/__init__.py  \n","   creating: models-master/official/vision/beta/configs/\n","  inflating: models-master/official/vision/beta/configs/__init__.py  \n","  inflating: models-master/official/vision/beta/configs/backbones.py  \n","  inflating: models-master/official/vision/beta/configs/backbones_3d.py  \n","  inflating: models-master/official/vision/beta/configs/common.py  \n","  inflating: models-master/official/vision/beta/configs/decoders.py  \n","   creating: models-master/official/vision/beta/configs/experiments/\n","   creating: models-master/official/vision/beta/configs/experiments/image_classification/\n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_mobilenetv2_gpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_mobilenetv2_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet101_deeplab_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet101_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet152_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet200_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet300_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet350_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_deeplab_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_gpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_tpu.yaml  \n","   creating: models-master/official/vision/beta/configs/experiments/maskrcnn/\n","  inflating: models-master/official/vision/beta/configs/experiments/maskrcnn/r50fpn_640_coco_scratch_tpu4x4.yaml  \n","   creating: models-master/official/vision/beta/configs/experiments/retinanet/\n","  inflating: models-master/official/vision/beta/configs/experiments/retinanet/coco_spinenet143_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/retinanet/coco_spinenet190_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/retinanet/coco_spinenet49_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/retinanet/coco_spinenet96_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/retinanet/resnet50fpn_coco_tpu4x4_benchmark.yaml  \n","   creating: models-master/official/vision/beta/configs/experiments/video_classification/\n","  inflating: models-master/official/vision/beta/configs/experiments/video_classification/k400_3d-resnet50_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/experiments/video_classification/k400_slowonly8x8_tpu.yaml  \n","  inflating: models-master/official/vision/beta/configs/image_classification.py  \n","  inflating: models-master/official/vision/beta/configs/image_classification_test.py  \n","  inflating: models-master/official/vision/beta/configs/maskrcnn.py  \n","  inflating: models-master/official/vision/beta/configs/retinanet.py  \n","  inflating: models-master/official/vision/beta/configs/semantic_segmentation.py  \n","  inflating: models-master/official/vision/beta/configs/semantic_segmentation_test.py  \n","  inflating: models-master/official/vision/beta/configs/video_classification.py  \n","  inflating: models-master/official/vision/beta/configs/video_classification_test.py  \n","   creating: models-master/official/vision/beta/data/\n","  inflating: models-master/official/vision/beta/data/create_coco_tf_record.py  \n","  inflating: models-master/official/vision/beta/data/tfrecord_lib.py  \n","  inflating: models-master/official/vision/beta/data/tfrecord_lib_test.py  \n","   creating: models-master/official/vision/beta/dataloaders/\n","  inflating: models-master/official/vision/beta/dataloaders/classification_input.py  \n","  inflating: models-master/official/vision/beta/dataloaders/decoder.py  \n","  inflating: models-master/official/vision/beta/dataloaders/maskrcnn_input.py  \n","  inflating: models-master/official/vision/beta/dataloaders/parser.py  \n","  inflating: models-master/official/vision/beta/dataloaders/retinanet_input.py  \n","  inflating: models-master/official/vision/beta/dataloaders/segmentation_input.py  \n","  inflating: models-master/official/vision/beta/dataloaders/tf_example_decoder.py  \n","  inflating: models-master/official/vision/beta/dataloaders/tf_example_decoder_test.py  \n","  inflating: models-master/official/vision/beta/dataloaders/tf_example_label_map_decoder.py  \n","  inflating: models-master/official/vision/beta/dataloaders/tf_example_label_map_decoder_test.py  \n","  inflating: models-master/official/vision/beta/dataloaders/utils.py  \n","  inflating: models-master/official/vision/beta/dataloaders/video_input.py  \n","  inflating: models-master/official/vision/beta/dataloaders/video_input_test.py  \n","   creating: models-master/official/vision/beta/evaluation/\n","  inflating: models-master/official/vision/beta/evaluation/coco_evaluator.py  \n","  inflating: models-master/official/vision/beta/evaluation/coco_utils.py  \n","  inflating: models-master/official/vision/beta/evaluation/segmentation_metrics.py  \n","   creating: models-master/official/vision/beta/losses/\n","  inflating: models-master/official/vision/beta/losses/maskrcnn_losses.py  \n","  inflating: models-master/official/vision/beta/losses/retinanet_losses.py  \n","  inflating: models-master/official/vision/beta/losses/segmentation_losses.py  \n","   creating: models-master/official/vision/beta/modeling/\n","   creating: models-master/official/vision/beta/modeling/backbones/\n","  inflating: models-master/official/vision/beta/modeling/backbones/__init__.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/efficientnet.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/efficientnet_test.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/factory.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/factory_test.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/mobilenet.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/mobilenet_test.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/resnet.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/resnet_3d.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/resnet_3d_test.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/resnet_deeplab.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/resnet_deeplab_test.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/resnet_test.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/revnet.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/revnet_test.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/spinenet.py  \n","  inflating: models-master/official/vision/beta/modeling/backbones/spinenet_test.py  \n","  inflating: models-master/official/vision/beta/modeling/classification_model.py  \n","  inflating: models-master/official/vision/beta/modeling/classification_model_test.py  \n","   creating: models-master/official/vision/beta/modeling/decoders/\n","  inflating: models-master/official/vision/beta/modeling/decoders/__init__.py  \n","  inflating: models-master/official/vision/beta/modeling/decoders/aspp.py  \n","  inflating: models-master/official/vision/beta/modeling/decoders/aspp_test.py  \n","  inflating: models-master/official/vision/beta/modeling/decoders/factory.py  \n","  inflating: models-master/official/vision/beta/modeling/decoders/fpn.py  \n","  inflating: models-master/official/vision/beta/modeling/decoders/fpn_test.py  \n","  inflating: models-master/official/vision/beta/modeling/decoders/nasfpn.py  \n","  inflating: models-master/official/vision/beta/modeling/decoders/nasfpn_test.py  \n","  inflating: models-master/official/vision/beta/modeling/factory.py  \n","  inflating: models-master/official/vision/beta/modeling/factory_3d.py  \n","  inflating: models-master/official/vision/beta/modeling/factory_test.py  \n","   creating: models-master/official/vision/beta/modeling/heads/\n","  inflating: models-master/official/vision/beta/modeling/heads/dense_prediction_heads.py  \n","  inflating: models-master/official/vision/beta/modeling/heads/dense_prediction_heads_test.py  \n","  inflating: models-master/official/vision/beta/modeling/heads/instance_heads.py  \n","  inflating: models-master/official/vision/beta/modeling/heads/instance_heads_test.py  \n","  inflating: models-master/official/vision/beta/modeling/heads/segmentation_heads.py  \n","  inflating: models-master/official/vision/beta/modeling/heads/segmentation_heads_test.py  \n","   creating: models-master/official/vision/beta/modeling/layers/\n","  inflating: models-master/official/vision/beta/modeling/layers/box_sampler.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/detection_generator.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/detection_generator_test.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/mask_sampler.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/nn_blocks.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/nn_blocks_3d.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/nn_blocks_3d_test.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/nn_blocks_test.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/nn_layers.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/roi_aligner.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/roi_aligner_test.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/roi_generator.py  \n","  inflating: models-master/official/vision/beta/modeling/layers/roi_sampler.py  \n","  inflating: models-master/official/vision/beta/modeling/maskrcnn_model.py  \n","  inflating: models-master/official/vision/beta/modeling/maskrcnn_model_test.py  \n","  inflating: models-master/official/vision/beta/modeling/retinanet_model.py  \n","  inflating: models-master/official/vision/beta/modeling/retinanet_model_test.py  \n","  inflating: models-master/official/vision/beta/modeling/segmentation_model.py  \n","  inflating: models-master/official/vision/beta/modeling/segmentation_model_test.py  \n","  inflating: models-master/official/vision/beta/modeling/video_classification_model.py  \n","  inflating: models-master/official/vision/beta/modeling/video_classification_model_test.py  \n","   creating: models-master/official/vision/beta/ops/\n","  inflating: models-master/official/vision/beta/ops/anchor.py  \n","  inflating: models-master/official/vision/beta/ops/anchor_test.py  \n","  inflating: models-master/official/vision/beta/ops/augment.py  \n","  inflating: models-master/official/vision/beta/ops/augment_test.py  \n","  inflating: models-master/official/vision/beta/ops/box_ops.py  \n","  inflating: models-master/official/vision/beta/ops/mask_ops.py  \n","  inflating: models-master/official/vision/beta/ops/mask_ops_test.py  \n","  inflating: models-master/official/vision/beta/ops/nms.py  \n","  inflating: models-master/official/vision/beta/ops/preprocess_ops.py  \n","  inflating: models-master/official/vision/beta/ops/preprocess_ops_3d.py  \n","  inflating: models-master/official/vision/beta/ops/preprocess_ops_3d_test.py  \n","  inflating: models-master/official/vision/beta/ops/preprocess_ops_test.py  \n","  inflating: models-master/official/vision/beta/ops/sampling_ops.py  \n","  inflating: models-master/official/vision/beta/ops/spatial_transform_ops.py  \n","   creating: models-master/official/vision/beta/projects/\n","  inflating: models-master/official/vision/beta/projects/README.md  \n","   creating: models-master/official/vision/beta/projects/keypoint/\n"," extracting: models-master/official/vision/beta/projects/keypoint/README.md  \n","   creating: models-master/official/vision/beta/projects/yolo/\n","  inflating: models-master/official/vision/beta/projects/yolo/README.md  \n","   creating: models-master/official/vision/beta/projects/yolo/common/\n","  inflating: models-master/official/vision/beta/projects/yolo/common/registry_imports.py  \n","   creating: models-master/official/vision/beta/projects/yolo/configs/\n","  inflating: models-master/official/vision/beta/projects/yolo/configs/backbones.py  \n","  inflating: models-master/official/vision/beta/projects/yolo/configs/darknet_classification.py  \n","   creating: models-master/official/vision/beta/projects/yolo/configs/experiments/\n","  inflating: models-master/official/vision/beta/projects/yolo/configs/experiments/csp_darknet53.yaml  \n","  inflating: models-master/official/vision/beta/projects/yolo/configs/experiments/csp_darknet53_tfds.yaml  \n","  inflating: models-master/official/vision/beta/projects/yolo/configs/experiments/darknet53.yaml  \n","  inflating: models-master/official/vision/beta/projects/yolo/configs/experiments/darknet53_tfds.yaml  \n","   creating: models-master/official/vision/beta/projects/yolo/dataloaders/\n","  inflating: models-master/official/vision/beta/projects/yolo/dataloaders/classification_tfds_decoder.py  \n","   creating: models-master/official/vision/beta/projects/yolo/modeling/\n","   creating: models-master/official/vision/beta/projects/yolo/modeling/backbones/\n","  inflating: models-master/official/vision/beta/projects/yolo/modeling/backbones/darknet.py  \n","  inflating: models-master/official/vision/beta/projects/yolo/modeling/backbones/darknet_test.py  \n","   creating: models-master/official/vision/beta/projects/yolo/modeling/layers/\n","  inflating: models-master/official/vision/beta/projects/yolo/modeling/layers/nn_blocks.py  \n","  inflating: models-master/official/vision/beta/projects/yolo/modeling/layers/nn_blocks_test.py  \n","   creating: models-master/official/vision/beta/projects/yolo/tasks/\n","  inflating: models-master/official/vision/beta/projects/yolo/tasks/image_classification.py  \n","  inflating: models-master/official/vision/beta/projects/yolo/train.py  \n","   creating: models-master/official/vision/beta/serving/\n","  inflating: models-master/official/vision/beta/serving/detection.py  \n","  inflating: models-master/official/vision/beta/serving/detection_test.py  \n","  inflating: models-master/official/vision/beta/serving/export_base.py  \n","  inflating: models-master/official/vision/beta/serving/export_saved_model.py  \n","  inflating: models-master/official/vision/beta/serving/image_classification.py  \n","  inflating: models-master/official/vision/beta/serving/image_classification_test.py  \n","   creating: models-master/official/vision/beta/tasks/\n","  inflating: models-master/official/vision/beta/tasks/__init__.py  \n","  inflating: models-master/official/vision/beta/tasks/image_classification.py  \n","  inflating: models-master/official/vision/beta/tasks/maskrcnn.py  \n","  inflating: models-master/official/vision/beta/tasks/retinanet.py  \n","  inflating: models-master/official/vision/beta/tasks/semantic_segmentation.py  \n","  inflating: models-master/official/vision/beta/tasks/video_classification.py  \n","  inflating: models-master/official/vision/beta/train.py  \n","  inflating: models-master/official/vision/beta/train_spatial_partitioning.py  \n","   creating: models-master/official/vision/detection/\n","  inflating: models-master/official/vision/detection/README.md  \n"," extracting: models-master/official/vision/detection/__init__.py  \n","   creating: models-master/official/vision/detection/configs/\n","  inflating: models-master/official/vision/detection/configs/__init__.py  \n","  inflating: models-master/official/vision/detection/configs/base_config.py  \n","  inflating: models-master/official/vision/detection/configs/factory.py  \n","  inflating: models-master/official/vision/detection/configs/maskrcnn_config.py  \n","  inflating: models-master/official/vision/detection/configs/olnmask_config.py  \n","  inflating: models-master/official/vision/detection/configs/retinanet_config.py  \n","  inflating: models-master/official/vision/detection/configs/shapemask_config.py  \n","   creating: models-master/official/vision/detection/dataloader/\n","  inflating: models-master/official/vision/detection/dataloader/__init__.py  \n","  inflating: models-master/official/vision/detection/dataloader/anchor.py  \n","  inflating: models-master/official/vision/detection/dataloader/factory.py  \n","  inflating: models-master/official/vision/detection/dataloader/input_reader.py  \n","  inflating: models-master/official/vision/detection/dataloader/maskrcnn_parser.py  \n","  inflating: models-master/official/vision/detection/dataloader/mode_keys.py  \n","  inflating: models-master/official/vision/detection/dataloader/olnmask_parser.py  \n","  inflating: models-master/official/vision/detection/dataloader/retinanet_parser.py  \n","  inflating: models-master/official/vision/detection/dataloader/shapemask_parser.py  \n","  inflating: models-master/official/vision/detection/dataloader/tf_example_decoder.py  \n","   creating: models-master/official/vision/detection/evaluation/\n","  inflating: models-master/official/vision/detection/evaluation/__init__.py  \n","  inflating: models-master/official/vision/detection/evaluation/coco_evaluator.py  \n","  inflating: models-master/official/vision/detection/evaluation/coco_utils.py  \n","  inflating: models-master/official/vision/detection/evaluation/factory.py  \n","   creating: models-master/official/vision/detection/executor/\n","  inflating: models-master/official/vision/detection/executor/__init__.py  \n","  inflating: models-master/official/vision/detection/executor/detection_executor.py  \n","  inflating: models-master/official/vision/detection/executor/distributed_executor.py  \n","  inflating: models-master/official/vision/detection/main.py  \n","   creating: models-master/official/vision/detection/modeling/\n","  inflating: models-master/official/vision/detection/modeling/__init__.py  \n","   creating: models-master/official/vision/detection/modeling/architecture/\n","  inflating: models-master/official/vision/detection/modeling/architecture/__init__.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/factory.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/fpn.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/heads.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/identity.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/keras_utils.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/nn_blocks.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/nn_ops.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/resnet.py  \n","  inflating: models-master/official/vision/detection/modeling/architecture/spinenet.py  \n","  inflating: models-master/official/vision/detection/modeling/base_model.py  \n","  inflating: models-master/official/vision/detection/modeling/checkpoint_utils.py  \n","  inflating: models-master/official/vision/detection/modeling/factory.py  \n","  inflating: models-master/official/vision/detection/modeling/learning_rates.py  \n","  inflating: models-master/official/vision/detection/modeling/losses.py  \n","  inflating: models-master/official/vision/detection/modeling/maskrcnn_model.py  \n","  inflating: models-master/official/vision/detection/modeling/olnmask_model.py  \n","  inflating: models-master/official/vision/detection/modeling/optimizers.py  \n","  inflating: models-master/official/vision/detection/modeling/retinanet_model.py  \n","  inflating: models-master/official/vision/detection/modeling/shapemask_model.py  \n","   creating: models-master/official/vision/detection/ops/\n","  inflating: models-master/official/vision/detection/ops/__init__.py  \n","  inflating: models-master/official/vision/detection/ops/nms.py  \n","  inflating: models-master/official/vision/detection/ops/postprocess_ops.py  \n","  inflating: models-master/official/vision/detection/ops/roi_ops.py  \n","  inflating: models-master/official/vision/detection/ops/spatial_transform_ops.py  \n","  inflating: models-master/official/vision/detection/ops/target_ops.py  \n","   creating: models-master/official/vision/detection/utils/\n","  inflating: models-master/official/vision/detection/utils/__init__.py  \n","  inflating: models-master/official/vision/detection/utils/box_utils.py  \n","  inflating: models-master/official/vision/detection/utils/class_utils.py  \n","  inflating: models-master/official/vision/detection/utils/dataloader_utils.py  \n","  inflating: models-master/official/vision/detection/utils/input_utils.py  \n","  inflating: models-master/official/vision/detection/utils/mask_utils.py  \n","   creating: models-master/official/vision/detection/utils/object_detection/\n","  inflating: models-master/official/vision/detection/utils/object_detection/__init__.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/argmax_matcher.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/balanced_positive_negative_sampler.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/box_coder.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/box_list.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/box_list_ops.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/faster_rcnn_box_coder.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/matcher.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/minibatch_sampler.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/ops.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/preprocessor.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/region_similarity_calculator.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/shape_utils.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/target_assigner.py  \n","  inflating: models-master/official/vision/detection/utils/object_detection/visualization_utils.py  \n","   creating: models-master/official/vision/image_classification/\n","  inflating: models-master/official/vision/image_classification/README.md  \n"," extracting: models-master/official/vision/image_classification/__init__.py  \n","  inflating: models-master/official/vision/image_classification/augment.py  \n","  inflating: models-master/official/vision/image_classification/augment_test.py  \n","  inflating: models-master/official/vision/image_classification/callbacks.py  \n","  inflating: models-master/official/vision/image_classification/classifier_trainer.py  \n","  inflating: models-master/official/vision/image_classification/classifier_trainer_test.py  \n","  inflating: models-master/official/vision/image_classification/classifier_trainer_util_test.py  \n","   creating: models-master/official/vision/image_classification/configs/\n","  inflating: models-master/official/vision/image_classification/configs/__init__.py  \n","  inflating: models-master/official/vision/image_classification/configs/base_configs.py  \n","  inflating: models-master/official/vision/image_classification/configs/configs.py  \n","   creating: models-master/official/vision/image_classification/configs/examples/\n","   creating: models-master/official/vision/image_classification/configs/examples/efficientnet/\n","   creating: models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/\n","  inflating: models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b0-gpu.yaml  \n","  inflating: models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b0-tpu.yaml  \n","  inflating: models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b1-gpu.yaml  \n","  inflating: models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b1-tpu.yaml  \n","   creating: models-master/official/vision/image_classification/configs/examples/resnet/\n","   creating: models-master/official/vision/image_classification/configs/examples/resnet/imagenet/\n","  inflating: models-master/official/vision/image_classification/configs/examples/resnet/imagenet/gpu.yaml  \n","  inflating: models-master/official/vision/image_classification/configs/examples/resnet/imagenet/tpu.yaml  \n","  inflating: models-master/official/vision/image_classification/dataset_factory.py  \n","   creating: models-master/official/vision/image_classification/efficientnet/\n"," extracting: models-master/official/vision/image_classification/efficientnet/__init__.py  \n","  inflating: models-master/official/vision/image_classification/efficientnet/common_modules.py  \n","  inflating: models-master/official/vision/image_classification/efficientnet/efficientnet_config.py  \n","  inflating: models-master/official/vision/image_classification/efficientnet/efficientnet_model.py  \n","  inflating: models-master/official/vision/image_classification/efficientnet/tfhub_export.py  \n","  inflating: models-master/official/vision/image_classification/learning_rate.py  \n","  inflating: models-master/official/vision/image_classification/learning_rate_test.py  \n","  inflating: models-master/official/vision/image_classification/mnist_main.py  \n","  inflating: models-master/official/vision/image_classification/mnist_test.py  \n","  inflating: models-master/official/vision/image_classification/optimizer_factory.py  \n","  inflating: models-master/official/vision/image_classification/optimizer_factory_test.py  \n","  inflating: models-master/official/vision/image_classification/preprocessing.py  \n","   creating: models-master/official/vision/image_classification/resnet/\n","  inflating: models-master/official/vision/image_classification/resnet/README.md  \n"," extracting: models-master/official/vision/image_classification/resnet/__init__.py  \n","  inflating: models-master/official/vision/image_classification/resnet/common.py  \n","  inflating: models-master/official/vision/image_classification/resnet/imagenet_preprocessing.py  \n","  inflating: models-master/official/vision/image_classification/resnet/resnet_config.py  \n","  inflating: models-master/official/vision/image_classification/resnet/resnet_ctl_imagenet_main.py  \n","  inflating: models-master/official/vision/image_classification/resnet/resnet_model.py  \n","  inflating: models-master/official/vision/image_classification/resnet/resnet_runnable.py  \n","  inflating: models-master/official/vision/image_classification/resnet/tfhub_export.py  \n","  inflating: models-master/official/vision/image_classification/test_utils.py  \n","   creating: models-master/official/vision/keras_cv/\n","  inflating: models-master/official/vision/keras_cv/LICENSE  \n","  inflating: models-master/official/vision/keras_cv/README.md  \n","  inflating: models-master/official/vision/keras_cv/__init__.py  \n","  inflating: models-master/official/vision/keras_cv/contributing.md  \n","   creating: models-master/official/vision/keras_cv/layers/\n","  inflating: models-master/official/vision/keras_cv/layers/__init__.py  \n","  inflating: models-master/official/vision/keras_cv/layers/deeplab.py  \n","  inflating: models-master/official/vision/keras_cv/layers/deeplab_test.py  \n","   creating: models-master/official/vision/keras_cv/losses/\n","  inflating: models-master/official/vision/keras_cv/losses/__init__.py  \n","  inflating: models-master/official/vision/keras_cv/losses/focal_loss.py  \n","  inflating: models-master/official/vision/keras_cv/losses/loss_utils.py  \n","   creating: models-master/official/vision/keras_cv/metrics/\n","  inflating: models-master/official/vision/keras_cv/metrics/__init__.py  \n","  inflating: models-master/official/vision/keras_cv/metrics/iou.py  \n","  inflating: models-master/official/vision/keras_cv/metrics/iou_test.py  \n","   creating: models-master/official/vision/keras_cv/ops/\n","  inflating: models-master/official/vision/keras_cv/ops/__init__.py  \n","  inflating: models-master/official/vision/keras_cv/ops/anchor_generator.py  \n","  inflating: models-master/official/vision/keras_cv/ops/anchor_generator_test.py  \n","  inflating: models-master/official/vision/keras_cv/ops/box_matcher.py  \n","  inflating: models-master/official/vision/keras_cv/ops/box_matcher_test.py  \n","  inflating: models-master/official/vision/keras_cv/ops/iou_similarity.py  \n","  inflating: models-master/official/vision/keras_cv/ops/iou_similarity_test.py  \n","  inflating: models-master/official/vision/keras_cv/ops/target_gather.py  \n","  inflating: models-master/official/vision/keras_cv/ops/target_gather_test.py  \n"," extracting: models-master/official/vision/keras_cv/requirements.txt  \n","  inflating: models-master/official/vision/keras_cv/setup.py  \n","   creating: models-master/orbit/\n","  inflating: models-master/orbit/LICENSE  \n","  inflating: models-master/orbit/README.md  \n","  inflating: models-master/orbit/__init__.py  \n","  inflating: models-master/orbit/controller.py  \n","  inflating: models-master/orbit/controller_test.py  \n","  inflating: models-master/orbit/runner.py  \n","  inflating: models-master/orbit/standard_runner.py  \n","  inflating: models-master/orbit/standard_runner_test.py  \n","   creating: models-master/orbit/utils/\n","  inflating: models-master/orbit/utils/__init__.py  \n","  inflating: models-master/orbit/utils/common.py  \n","  inflating: models-master/orbit/utils/common_test.py  \n","  inflating: models-master/orbit/utils/epoch_helper.py  \n","  inflating: models-master/orbit/utils/loop_fns.py  \n","  inflating: models-master/orbit/utils/summary_manager.py  \n","  inflating: models-master/orbit/utils/tpu_summaries.py  \n","  inflating: models-master/orbit/utils/tpu_summaries_test.py  \n","   creating: models-master/research/\n","  inflating: models-master/research/README.md  \n","   creating: models-master/research/a3c_blogpost/\n","  inflating: models-master/research/a3c_blogpost/README.md  \n","  inflating: models-master/research/a3c_blogpost/a3c_cartpole.py  \n","   creating: models-master/research/adversarial_text/\n","  inflating: models-master/research/adversarial_text/README.md  \n"," extracting: models-master/research/adversarial_text/__init__.py  \n","  inflating: models-master/research/adversarial_text/adversarial_losses.py  \n","   creating: models-master/research/adversarial_text/data/\n"," extracting: models-master/research/adversarial_text/data/__init__.py  \n","  inflating: models-master/research/adversarial_text/data/data_utils.py  \n","  inflating: models-master/research/adversarial_text/data/data_utils_test.py  \n","  inflating: models-master/research/adversarial_text/data/document_generators.py  \n","  inflating: models-master/research/adversarial_text/evaluate.py  \n","  inflating: models-master/research/adversarial_text/gen_data.py  \n","  inflating: models-master/research/adversarial_text/gen_vocab.py  \n","  inflating: models-master/research/adversarial_text/graphs.py  \n","  inflating: models-master/research/adversarial_text/graphs_test.py  \n","  inflating: models-master/research/adversarial_text/inputs.py  \n","  inflating: models-master/research/adversarial_text/layers.py  \n","  inflating: models-master/research/adversarial_text/pretrain.py  \n","  inflating: models-master/research/adversarial_text/train_classifier.py  \n","  inflating: models-master/research/adversarial_text/train_utils.py  \n","   creating: models-master/research/attention_ocr/\n","  inflating: models-master/research/attention_ocr/README.md  \n","   creating: models-master/research/attention_ocr/python/\n","  inflating: models-master/research/attention_ocr/python/all_jobs.screenrc  \n","  inflating: models-master/research/attention_ocr/python/common_flags.py  \n","  inflating: models-master/research/attention_ocr/python/data_provider.py  \n","  inflating: models-master/research/attention_ocr/python/data_provider_test.py  \n","   creating: models-master/research/attention_ocr/python/datasets/\n","  inflating: models-master/research/attention_ocr/python/datasets/__init__.py  \n","  inflating: models-master/research/attention_ocr/python/datasets/fsns.py  \n","  inflating: models-master/research/attention_ocr/python/datasets/fsns_test.py  \n","   creating: models-master/research/attention_ocr/python/datasets/testdata/\n","   creating: models-master/research/attention_ocr/python/datasets/testdata/fsns/\n","  inflating: models-master/research/attention_ocr/python/datasets/testdata/fsns/charset_size=134.txt  \n","  inflating: models-master/research/attention_ocr/python/datasets/testdata/fsns/download_data.py  \n","  inflating: models-master/research/attention_ocr/python/datasets/testdata/fsns/fsns-00000-of-00001  \n","  inflating: models-master/research/attention_ocr/python/datasets/testdata/fsns/links.txt  \n","  inflating: models-master/research/attention_ocr/python/datasets/unittest_utils.py  \n","  inflating: models-master/research/attention_ocr/python/datasets/unittest_utils_test.py  \n","  inflating: models-master/research/attention_ocr/python/demo_inference.py  \n","  inflating: models-master/research/attention_ocr/python/demo_inference_test.py  \n","  inflating: models-master/research/attention_ocr/python/eval.py  \n","  inflating: models-master/research/attention_ocr/python/inception_preprocessing.py  \n","  inflating: models-master/research/attention_ocr/python/metrics.py  \n","  inflating: models-master/research/attention_ocr/python/metrics_test.py  \n","  inflating: models-master/research/attention_ocr/python/model.py  \n","  inflating: models-master/research/attention_ocr/python/model_export.py  \n","  inflating: models-master/research/attention_ocr/python/model_export_lib.py  \n","  inflating: models-master/research/attention_ocr/python/model_export_test.py  \n","  inflating: models-master/research/attention_ocr/python/model_test.py  \n","  inflating: models-master/research/attention_ocr/python/sequence_layers.py  \n","  inflating: models-master/research/attention_ocr/python/sequence_layers_test.py  \n","   creating: models-master/research/attention_ocr/python/testdata/\n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_00.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_01.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_02.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_03.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_04.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_05.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_06.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_07.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_08.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_09.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_10.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_11.png  \n","  inflating: models-master/research/attention_ocr/python/testdata/fsns_train_12.png  \n","  inflating: models-master/research/attention_ocr/python/testdata/fsns_train_13.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_14.png  \n","  inflating: models-master/research/attention_ocr/python/testdata/fsns_train_15.png  \n","  inflating: models-master/research/attention_ocr/python/testdata/fsns_train_16.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_17.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_18.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_19.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_20.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_21.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_22.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_23.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_24.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_25.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_26.png  \n","  inflating: models-master/research/attention_ocr/python/testdata/fsns_train_27.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_28.png  \n","  inflating: models-master/research/attention_ocr/python/testdata/fsns_train_29.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_30.png  \n"," extracting: models-master/research/attention_ocr/python/testdata/fsns_train_31.png  \n","  inflating: models-master/research/attention_ocr/python/train.py  \n","  inflating: models-master/research/attention_ocr/python/utils.py  \n","   creating: models-master/research/audioset/\n","  inflating: models-master/research/audioset/README.md  \n","   creating: models-master/research/audioset/vggish/\n","  inflating: models-master/research/audioset/vggish/README.md  \n","  inflating: models-master/research/audioset/vggish/mel_features.py  \n","  inflating: models-master/research/audioset/vggish/vggish_export_tfhub.py  \n","  inflating: models-master/research/audioset/vggish/vggish_inference_demo.py  \n","  inflating: models-master/research/audioset/vggish/vggish_input.py  \n","  inflating: models-master/research/audioset/vggish/vggish_params.py  \n","  inflating: models-master/research/audioset/vggish/vggish_postprocess.py  \n","  inflating: models-master/research/audioset/vggish/vggish_slim.py  \n","  inflating: models-master/research/audioset/vggish/vggish_smoke_test.py  \n","  inflating: models-master/research/audioset/vggish/vggish_train_demo.py  \n","   creating: models-master/research/audioset/yamnet/\n","  inflating: models-master/research/audioset/yamnet/README.md  \n","  inflating: models-master/research/audioset/yamnet/export.py  \n","  inflating: models-master/research/audioset/yamnet/features.py  \n","  inflating: models-master/research/audioset/yamnet/inference.py  \n","  inflating: models-master/research/audioset/yamnet/params.py  \n","  inflating: models-master/research/audioset/yamnet/yamnet.py  \n","  inflating: models-master/research/audioset/yamnet/yamnet_class_map.csv  \n","  inflating: models-master/research/audioset/yamnet/yamnet_test.py  \n","  inflating: models-master/research/audioset/yamnet/yamnet_visualization.ipynb  \n","   creating: models-master/research/autoaugment/\n","  inflating: models-master/research/autoaugment/README.md  \n","  inflating: models-master/research/autoaugment/augmentation_transforms.py  \n","  inflating: models-master/research/autoaugment/custom_ops.py  \n","  inflating: models-master/research/autoaugment/data_utils.py  \n","  inflating: models-master/research/autoaugment/helper_utils.py  \n","  inflating: models-master/research/autoaugment/policies.py  \n","  inflating: models-master/research/autoaugment/shake_drop.py  \n","  inflating: models-master/research/autoaugment/shake_shake.py  \n","  inflating: models-master/research/autoaugment/train_cifar.py  \n","  inflating: models-master/research/autoaugment/wrn.py  \n","   creating: models-master/research/cognitive_planning/\n","  inflating: models-master/research/cognitive_planning/BUILD  \n","  inflating: models-master/research/cognitive_planning/README.md  \n"," extracting: models-master/research/cognitive_planning/__init__.py  \n","  inflating: models-master/research/cognitive_planning/command  \n","  inflating: models-master/research/cognitive_planning/embedders.py  \n","   creating: models-master/research/cognitive_planning/envs/\n"," extracting: models-master/research/cognitive_planning/envs/__init__.py  \n","  inflating: models-master/research/cognitive_planning/envs/active_vision_dataset_env.py  \n","   creating: models-master/research/cognitive_planning/envs/configs/\n","  inflating: models-master/research/cognitive_planning/envs/configs/active_vision_config.gin  \n","  inflating: models-master/research/cognitive_planning/envs/task_env.py  \n","  inflating: models-master/research/cognitive_planning/envs/util.py  \n","  inflating: models-master/research/cognitive_planning/label_map.txt  \n","  inflating: models-master/research/cognitive_planning/label_map_util.py  \n","  inflating: models-master/research/cognitive_planning/policies.py  \n","   creating: models-master/research/cognitive_planning/preprocessing/\n"," extracting: models-master/research/cognitive_planning/preprocessing/__init__.py  \n","  inflating: models-master/research/cognitive_planning/preprocessing/cifarnet_preprocessing.py  \n","  inflating: models-master/research/cognitive_planning/preprocessing/inception_preprocessing.py  \n","  inflating: models-master/research/cognitive_planning/preprocessing/lenet_preprocessing.py  \n","  inflating: models-master/research/cognitive_planning/preprocessing/preprocessing_factory.py  \n","  inflating: models-master/research/cognitive_planning/preprocessing/vgg_preprocessing.py  \n","  inflating: models-master/research/cognitive_planning/standard_fields.py  \n","  inflating: models-master/research/cognitive_planning/string_int_label_map_pb2.py  \n","  inflating: models-master/research/cognitive_planning/tasks.py  \n","  inflating: models-master/research/cognitive_planning/train_supervised_active_vision.py  \n","  inflating: models-master/research/cognitive_planning/train_supervised_active_vision.sh  \n","  inflating: models-master/research/cognitive_planning/visualization_utils.py  \n","  inflating: models-master/research/cognitive_planning/viz_active_vision_dataset_main.py  \n","   creating: models-master/research/cvt_text/\n","  inflating: models-master/research/cvt_text/README.md  \n"," extracting: models-master/research/cvt_text/__init__.py  \n","   creating: models-master/research/cvt_text/base/\n"," extracting: models-master/research/cvt_text/base/__init__.py  \n","  inflating: models-master/research/cvt_text/base/configure.py  \n","  inflating: models-master/research/cvt_text/base/embeddings.py  \n","  inflating: models-master/research/cvt_text/base/utils.py  \n","   creating: models-master/research/cvt_text/corpus_processing/\n"," extracting: models-master/research/cvt_text/corpus_processing/__init__.py  \n","  inflating: models-master/research/cvt_text/corpus_processing/example.py  \n","  inflating: models-master/research/cvt_text/corpus_processing/minibatching.py  \n","  inflating: models-master/research/cvt_text/corpus_processing/scorer.py  \n","  inflating: models-master/research/cvt_text/corpus_processing/unlabeled_data.py  \n","  inflating: models-master/research/cvt_text/cvt.py  \n","  inflating: models-master/research/cvt_text/fetch_data.sh  \n","   creating: models-master/research/cvt_text/model/\n"," extracting: models-master/research/cvt_text/model/__init__.py  \n","  inflating: models-master/research/cvt_text/model/encoder.py  \n","  inflating: models-master/research/cvt_text/model/model_helpers.py  \n","  inflating: models-master/research/cvt_text/model/multitask_model.py  \n","  inflating: models-master/research/cvt_text/model/shared_inputs.py  \n","  inflating: models-master/research/cvt_text/model/task_module.py  \n","  inflating: models-master/research/cvt_text/preprocessing.py  \n","   creating: models-master/research/cvt_text/task_specific/\n"," extracting: models-master/research/cvt_text/task_specific/__init__.py  \n","  inflating: models-master/research/cvt_text/task_specific/task_definitions.py  \n","   creating: models-master/research/cvt_text/task_specific/word_level/\n"," extracting: models-master/research/cvt_text/task_specific/word_level/__init__.py  \n","  inflating: models-master/research/cvt_text/task_specific/word_level/depparse_module.py  \n","  inflating: models-master/research/cvt_text/task_specific/word_level/depparse_scorer.py  \n","  inflating: models-master/research/cvt_text/task_specific/word_level/tagging_module.py  \n","  inflating: models-master/research/cvt_text/task_specific/word_level/tagging_scorers.py  \n","  inflating: models-master/research/cvt_text/task_specific/word_level/tagging_utils.py  \n","  inflating: models-master/research/cvt_text/task_specific/word_level/word_level_data.py  \n","  inflating: models-master/research/cvt_text/task_specific/word_level/word_level_scorer.py  \n","   creating: models-master/research/cvt_text/training/\n"," extracting: models-master/research/cvt_text/training/__init__.py  \n","  inflating: models-master/research/cvt_text/training/trainer.py  \n","  inflating: models-master/research/cvt_text/training/training_progress.py  \n","   creating: models-master/research/deep_speech/\n","  inflating: models-master/research/deep_speech/README.md  \n"," extracting: models-master/research/deep_speech/__init__.py  \n","   creating: models-master/research/deep_speech/data/\n"," extracting: models-master/research/deep_speech/data/__init__.py  \n","  inflating: models-master/research/deep_speech/data/dataset.py  \n","  inflating: models-master/research/deep_speech/data/download.py  \n","  inflating: models-master/research/deep_speech/data/featurizer.py  \n","  inflating: models-master/research/deep_speech/data/vocabulary.txt  \n","  inflating: models-master/research/deep_speech/decoder.py  \n","  inflating: models-master/research/deep_speech/deep_speech.py  \n","  inflating: models-master/research/deep_speech/deep_speech_model.py  \n","  inflating: models-master/research/deep_speech/requirements.txt  \n","  inflating: models-master/research/deep_speech/run_deep_speech.sh  \n","   creating: models-master/research/deeplab/\n","  inflating: models-master/research/deeplab/README.md  \n"," extracting: models-master/research/deeplab/__init__.py  \n","  inflating: models-master/research/deeplab/common.py  \n","  inflating: models-master/research/deeplab/common_test.py  \n","  inflating: models-master/research/deeplab/convert_to_tflite.py  \n","   creating: models-master/research/deeplab/core/\n"," extracting: models-master/research/deeplab/core/__init__.py  \n","  inflating: models-master/research/deeplab/core/conv2d_ws.py  \n","  inflating: models-master/research/deeplab/core/conv2d_ws_test.py  \n","  inflating: models-master/research/deeplab/core/dense_prediction_cell.py  \n","  inflating: models-master/research/deeplab/core/dense_prediction_cell_branch5_top1_cityscapes.json  \n","  inflating: models-master/research/deeplab/core/dense_prediction_cell_test.py  \n","  inflating: models-master/research/deeplab/core/feature_extractor.py  \n","  inflating: models-master/research/deeplab/core/nas_cell.py  \n","  inflating: models-master/research/deeplab/core/nas_genotypes.py  \n","  inflating: models-master/research/deeplab/core/nas_network.py  \n","  inflating: models-master/research/deeplab/core/nas_network_test.py  \n","  inflating: models-master/research/deeplab/core/preprocess_utils.py  \n","  inflating: models-master/research/deeplab/core/preprocess_utils_test.py  \n","  inflating: models-master/research/deeplab/core/resnet_v1_beta.py  \n","  inflating: models-master/research/deeplab/core/resnet_v1_beta_test.py  \n","  inflating: models-master/research/deeplab/core/utils.py  \n","  inflating: models-master/research/deeplab/core/utils_test.py  \n","  inflating: models-master/research/deeplab/core/xception.py  \n","  inflating: models-master/research/deeplab/core/xception_test.py  \n","   creating: models-master/research/deeplab/datasets/\n"," extracting: models-master/research/deeplab/datasets/__init__.py  \n","  inflating: models-master/research/deeplab/datasets/build_ade20k_data.py  \n","  inflating: models-master/research/deeplab/datasets/build_cityscapes_data.py  \n","  inflating: models-master/research/deeplab/datasets/build_data.py  \n","  inflating: models-master/research/deeplab/datasets/build_voc2012_data.py  \n","  inflating: models-master/research/deeplab/datasets/convert_cityscapes.sh  \n","  inflating: models-master/research/deeplab/datasets/data_generator.py  \n","  inflating: models-master/research/deeplab/datasets/data_generator_test.py  \n","  inflating: models-master/research/deeplab/datasets/download_and_convert_ade20k.sh  \n","  inflating: models-master/research/deeplab/datasets/download_and_convert_voc2012.sh  \n","  inflating: models-master/research/deeplab/datasets/remove_gt_colormap.py  \n","  inflating: models-master/research/deeplab/deeplab_demo.ipynb  \n","   creating: models-master/research/deeplab/deprecated/\n"," extracting: models-master/research/deeplab/deprecated/__init__.py  \n","  inflating: models-master/research/deeplab/deprecated/segmentation_dataset.py  \n","  inflating: models-master/research/deeplab/eval.py  \n","   creating: models-master/research/deeplab/evaluation/\n","  inflating: models-master/research/deeplab/evaluation/README.md  \n"," extracting: models-master/research/deeplab/evaluation/__init__.py  \n","  inflating: models-master/research/deeplab/evaluation/base_metric.py  \n","  inflating: models-master/research/deeplab/evaluation/eval_coco_format.py  \n","  inflating: models-master/research/deeplab/evaluation/eval_coco_format_test.py  \n","   creating: models-master/research/deeplab/evaluation/g3doc/\n","   creating: models-master/research/deeplab/evaluation/g3doc/img/\n","  inflating: models-master/research/deeplab/evaluation/g3doc/img/equation_pc.png  \n","  inflating: models-master/research/deeplab/evaluation/g3doc/img/equation_pq.png  \n","  inflating: models-master/research/deeplab/evaluation/panoptic_quality.py  \n","  inflating: models-master/research/deeplab/evaluation/panoptic_quality_test.py  \n","  inflating: models-master/research/deeplab/evaluation/parsing_covering.py  \n","  inflating: models-master/research/deeplab/evaluation/parsing_covering_test.py  \n","  inflating: models-master/research/deeplab/evaluation/streaming_metrics.py  \n","  inflating: models-master/research/deeplab/evaluation/streaming_metrics_test.py  \n","  inflating: models-master/research/deeplab/evaluation/test_utils.py  \n","  inflating: models-master/research/deeplab/evaluation/test_utils_test.py  \n","   creating: models-master/research/deeplab/evaluation/testdata/\n","  inflating: models-master/research/deeplab/evaluation/testdata/README.md  \n"," extracting: models-master/research/deeplab/evaluation/testdata/bird_gt.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/bird_pred_class.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/bird_pred_instance.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/cat_gt.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/cat_pred_class.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/cat_pred_instance.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_gt.json  \n","   creating: models-master/research/deeplab/evaluation/testdata/coco_gt/\n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_gt/bird.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_gt/cat.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_gt/congress.png  \n"," extracting: models-master/research/deeplab/evaluation/testdata/coco_gt/team.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_pred.json  \n","   creating: models-master/research/deeplab/evaluation/testdata/coco_pred/\n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_pred/bird.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_pred/cat.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_pred/congress.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/coco_pred/team.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/team_gt_instance.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/team_pred_class.png  \n","  inflating: models-master/research/deeplab/evaluation/testdata/team_pred_instance.png  \n","  inflating: models-master/research/deeplab/export_model.py  \n","   creating: models-master/research/deeplab/g3doc/\n","  inflating: models-master/research/deeplab/g3doc/ade20k.md  \n","  inflating: models-master/research/deeplab/g3doc/cityscapes.md  \n","  inflating: models-master/research/deeplab/g3doc/export_model.md  \n","  inflating: models-master/research/deeplab/g3doc/faq.md  \n","   creating: models-master/research/deeplab/g3doc/img/\n","  inflating: models-master/research/deeplab/g3doc/img/image1.jpg  \n","  inflating: models-master/research/deeplab/g3doc/img/image2.jpg  \n","  inflating: models-master/research/deeplab/g3doc/img/image3.jpg  \n","  inflating: models-master/research/deeplab/g3doc/img/image_info.txt  \n","  inflating: models-master/research/deeplab/g3doc/img/vis1.png  \n","  inflating: models-master/research/deeplab/g3doc/img/vis2.png  \n","  inflating: models-master/research/deeplab/g3doc/img/vis3.png  \n","  inflating: models-master/research/deeplab/g3doc/installation.md  \n","  inflating: models-master/research/deeplab/g3doc/model_zoo.md  \n","  inflating: models-master/research/deeplab/g3doc/pascal.md  \n","  inflating: models-master/research/deeplab/g3doc/quantize.md  \n","  inflating: models-master/research/deeplab/input_preprocess.py  \n","  inflating: models-master/research/deeplab/local_test.sh  \n","  inflating: models-master/research/deeplab/local_test_mobilenetv2.sh  \n","  inflating: models-master/research/deeplab/model.py  \n","  inflating: models-master/research/deeplab/model_test.py  \n","   creating: models-master/research/deeplab/testing/\n","  inflating: models-master/research/deeplab/testing/info.md  \n","   creating: models-master/research/deeplab/testing/pascal_voc_seg/\n","  inflating: models-master/research/deeplab/testing/pascal_voc_seg/val-00000-of-00001.tfrecord  \n","  inflating: models-master/research/deeplab/train.py  \n","   creating: models-master/research/deeplab/utils/\n"," extracting: models-master/research/deeplab/utils/__init__.py  \n","  inflating: models-master/research/deeplab/utils/get_dataset_colormap.py  \n","  inflating: models-master/research/deeplab/utils/get_dataset_colormap_test.py  \n","  inflating: models-master/research/deeplab/utils/save_annotation.py  \n","  inflating: models-master/research/deeplab/utils/train_utils.py  \n","  inflating: models-master/research/deeplab/vis.py  \n","   creating: models-master/research/delf/\n","  inflating: models-master/research/delf/.gitignore  \n","  inflating: models-master/research/delf/DETECTION.md  \n","  inflating: models-master/research/delf/EXTRACTION_MATCHING.md  \n","  inflating: models-master/research/delf/INSTALL_INSTRUCTIONS.md  \n","  inflating: models-master/research/delf/README.md  \n","   creating: models-master/research/delf/delf/\n","  inflating: models-master/research/delf/delf/__init__.py  \n","   creating: models-master/research/delf/delf/protos/\n"," extracting: models-master/research/delf/delf/protos/__init__.py  \n","  inflating: models-master/research/delf/delf/protos/aggregation_config.proto  \n","  inflating: models-master/research/delf/delf/protos/box.proto  \n","  inflating: models-master/research/delf/delf/protos/datum.proto  \n","  inflating: models-master/research/delf/delf/protos/delf_config.proto  \n","  inflating: models-master/research/delf/delf/protos/feature.proto  \n","   creating: models-master/research/delf/delf/python/\n"," extracting: models-master/research/delf/delf/python/__init__.py  \n","  inflating: models-master/research/delf/delf/python/box_io.py  \n","  inflating: models-master/research/delf/delf/python/box_io_test.py  \n","  inflating: models-master/research/delf/delf/python/datum_io.py  \n","  inflating: models-master/research/delf/delf/python/datum_io_test.py  \n","   creating: models-master/research/delf/delf/python/delg/\n","  inflating: models-master/research/delf/delf/python/delg/DELG_INSTRUCTIONS.md  \n","  inflating: models-master/research/delf/delf/python/delg/extract_features.py  \n","  inflating: models-master/research/delf/delf/python/delg/measure_latency.py  \n","  inflating: models-master/research/delf/delf/python/delg/perform_retrieval.py  \n","  inflating: models-master/research/delf/delf/python/delg/r101delg_gld_config.pbtxt  \n","  inflating: models-master/research/delf/delf/python/delg/r101delg_gldv2clean_config.pbtxt  \n","  inflating: models-master/research/delf/delf/python/delg/r50delg_gld_config.pbtxt  \n","  inflating: models-master/research/delf/delf/python/delg/r50delg_gldv2clean_config.pbtxt  \n","   creating: models-master/research/delf/delf/python/detect_to_retrieve/\n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/DETECT_TO_RETRIEVE_INSTRUCTIONS.md  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/__init__.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/aggregation_extraction.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/boxes_and_features_extraction.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/cluster_delf_features.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/dataset.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/dataset_test.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/delf_gld_config.pbtxt  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/extract_aggregation.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/extract_index_boxes_and_features.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/extract_query_features.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/image_reranking.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/index_aggregation_config.pbtxt  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/perform_retrieval.py  \n","  inflating: models-master/research/delf/delf/python/detect_to_retrieve/query_aggregation_config.pbtxt  \n","   creating: models-master/research/delf/delf/python/examples/\n"," extracting: models-master/research/delf/delf/python/examples/__init__.py  \n","  inflating: models-master/research/delf/delf/python/examples/delf_config_example.pbtxt  \n","  inflating: models-master/research/delf/delf/python/examples/detection_example_1.jpg  \n","  inflating: models-master/research/delf/delf/python/examples/detection_example_2.jpg  \n","  inflating: models-master/research/delf/delf/python/examples/detector.py  \n","  inflating: models-master/research/delf/delf/python/examples/extract_boxes.py  \n","  inflating: models-master/research/delf/delf/python/examples/extract_features.py  \n","  inflating: models-master/research/delf/delf/python/examples/extractor.py  \n","  inflating: models-master/research/delf/delf/python/examples/match_images.py  \n","  inflating: models-master/research/delf/delf/python/examples/matched_images_example.jpg  \n","  inflating: models-master/research/delf/delf/python/feature_aggregation_extractor.py  \n","  inflating: models-master/research/delf/delf/python/feature_aggregation_extractor_test.py  \n","  inflating: models-master/research/delf/delf/python/feature_aggregation_similarity.py  \n","  inflating: models-master/research/delf/delf/python/feature_aggregation_similarity_test.py  \n","  inflating: models-master/research/delf/delf/python/feature_extractor.py  \n","  inflating: models-master/research/delf/delf/python/feature_extractor_test.py  \n","  inflating: models-master/research/delf/delf/python/feature_io.py  \n","  inflating: models-master/research/delf/delf/python/feature_io_test.py  \n","   creating: models-master/research/delf/delf/python/google_landmarks_dataset/\n","  inflating: models-master/research/delf/delf/python/google_landmarks_dataset/README.md  \n","  inflating: models-master/research/delf/delf/python/google_landmarks_dataset/compute_recognition_metrics.py  \n","  inflating: models-master/research/delf/delf/python/google_landmarks_dataset/compute_retrieval_metrics.py  \n","  inflating: models-master/research/delf/delf/python/google_landmarks_dataset/dataset_file_io.py  \n","  inflating: models-master/research/delf/delf/python/google_landmarks_dataset/dataset_file_io_test.py  \n","  inflating: models-master/research/delf/delf/python/google_landmarks_dataset/metrics.py  \n","  inflating: models-master/research/delf/delf/python/google_landmarks_dataset/metrics_test.py  \n","  inflating: models-master/research/delf/delf/python/google_landmarks_dataset/rn101_af_gldv2clean_config.pbtxt  \n","   creating: models-master/research/delf/delf/python/training/\n","  inflating: models-master/research/delf/delf/python/training/README.md  \n","  inflating: models-master/research/delf/delf/python/training/__init__.py  \n","  inflating: models-master/research/delf/delf/python/training/build_image_dataset.py  \n","   creating: models-master/research/delf/delf/python/training/datasets/\n","  inflating: models-master/research/delf/delf/python/training/datasets/__init__.py  \n","  inflating: models-master/research/delf/delf/python/training/datasets/googlelandmarks.py  \n","  inflating: models-master/research/delf/delf/python/training/download_dataset.sh  \n","  inflating: models-master/research/delf/delf/python/training/install_delf.sh  \n","  inflating: models-master/research/delf/delf/python/training/matched_images_demo.png  \n","   creating: models-master/research/delf/delf/python/training/model/\n","  inflating: models-master/research/delf/delf/python/training/model/__init__.py  \n","  inflating: models-master/research/delf/delf/python/training/model/delf_model.py  \n","  inflating: models-master/research/delf/delf/python/training/model/delf_model_test.py  \n","  inflating: models-master/research/delf/delf/python/training/model/delg_model.py  \n","  inflating: models-master/research/delf/delf/python/training/model/export_global_model.py  \n","  inflating: models-master/research/delf/delf/python/training/model/export_local_and_global_model.py  \n","  inflating: models-master/research/delf/delf/python/training/model/export_local_model.py  \n","  inflating: models-master/research/delf/delf/python/training/model/export_model_utils.py  \n","  inflating: models-master/research/delf/delf/python/training/model/resnet50.py  \n","  inflating: models-master/research/delf/delf/python/training/model/resnet50_test.py  \n","  inflating: models-master/research/delf/delf/python/training/train.py  \n","  inflating: models-master/research/delf/delf/python/utils.py  \n","  inflating: models-master/research/delf/delf/python/utils_test.py  \n","  inflating: models-master/research/delf/setup.py  \n","   creating: models-master/research/efficient-hrl/\n","  inflating: models-master/research/efficient-hrl/README.md  \n","  inflating: models-master/research/efficient-hrl/agent.py  \n","   creating: models-master/research/efficient-hrl/agents/\n"," extracting: models-master/research/efficient-hrl/agents/__init__.py  \n","  inflating: models-master/research/efficient-hrl/agents/circular_buffer.py  \n","  inflating: models-master/research/efficient-hrl/agents/ddpg_agent.py  \n","  inflating: models-master/research/efficient-hrl/agents/ddpg_networks.py  \n","  inflating: models-master/research/efficient-hrl/cond_fn.py  \n","   creating: models-master/research/efficient-hrl/configs/\n","  inflating: models-master/research/efficient-hrl/configs/base_uvf.gin  \n","  inflating: models-master/research/efficient-hrl/configs/eval_uvf.gin  \n","  inflating: models-master/research/efficient-hrl/configs/train_uvf.gin  \n","   creating: models-master/research/efficient-hrl/context/\n"," extracting: models-master/research/efficient-hrl/context/__init__.py  \n","   creating: models-master/research/efficient-hrl/context/configs/\n","  inflating: models-master/research/efficient-hrl/context/configs/ant_block.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_block_maze.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_fall_multi.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_fall_multi_img.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_fall_single.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_maze.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_maze_img.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_push_multi.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_push_multi_img.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/ant_push_single.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/default.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/hiro_orig.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/hiro_repr.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/hiro_xy.gin  \n","  inflating: models-master/research/efficient-hrl/context/configs/point_maze.gin  \n","  inflating: models-master/research/efficient-hrl/context/context.py  \n","  inflating: models-master/research/efficient-hrl/context/context_transition_functions.py  \n","  inflating: models-master/research/efficient-hrl/context/gin_imports.py  \n","  inflating: models-master/research/efficient-hrl/context/gin_utils.py  \n","  inflating: models-master/research/efficient-hrl/context/rewards_functions.py  \n","  inflating: models-master/research/efficient-hrl/context/samplers.py  \n","   creating: models-master/research/efficient-hrl/environments/\n"," extracting: models-master/research/efficient-hrl/environments/__init__.py  \n","  inflating: models-master/research/efficient-hrl/environments/ant.py  \n","  inflating: models-master/research/efficient-hrl/environments/ant_maze_env.py  \n","   creating: models-master/research/efficient-hrl/environments/assets/\n","  inflating: models-master/research/efficient-hrl/environments/assets/ant.xml  \n","  inflating: models-master/research/efficient-hrl/environments/create_maze_env.py  \n","  inflating: models-master/research/efficient-hrl/environments/maze_env.py  \n","  inflating: models-master/research/efficient-hrl/environments/maze_env_utils.py  \n","  inflating: models-master/research/efficient-hrl/environments/point.py  \n","  inflating: models-master/research/efficient-hrl/environments/point_maze_env.py  \n","  inflating: models-master/research/efficient-hrl/eval.py  \n","  inflating: models-master/research/efficient-hrl/run_env.py  \n","  inflating: models-master/research/efficient-hrl/run_eval.py  \n","  inflating: models-master/research/efficient-hrl/run_train.py  \n","   creating: models-master/research/efficient-hrl/scripts/\n","  inflating: models-master/research/efficient-hrl/scripts/local_eval.py  \n","  inflating: models-master/research/efficient-hrl/scripts/local_train.py  \n","  inflating: models-master/research/efficient-hrl/train.py  \n","  inflating: models-master/research/efficient-hrl/train_utils.py  \n","   creating: models-master/research/efficient-hrl/utils/\n"," extracting: models-master/research/efficient-hrl/utils/__init__.py  \n","  inflating: models-master/research/efficient-hrl/utils/eval_utils.py  \n","  inflating: models-master/research/efficient-hrl/utils/utils.py  \n","   creating: models-master/research/lfads/\n","  inflating: models-master/research/lfads/README.md  \n","  inflating: models-master/research/lfads/distributions.py  \n","  inflating: models-master/research/lfads/lfads.py  \n","  inflating: models-master/research/lfads/plot_lfads.py  \n","  inflating: models-master/research/lfads/run_lfads.py  \n","   creating: models-master/research/lfads/synth_data/\n","  inflating: models-master/research/lfads/synth_data/generate_chaotic_rnn_data.py  \n","  inflating: models-master/research/lfads/synth_data/generate_itb_data.py  \n","  inflating: models-master/research/lfads/synth_data/generate_labeled_rnn_data.py  \n","  inflating: models-master/research/lfads/synth_data/run_generate_synth_data.sh  \n","  inflating: models-master/research/lfads/synth_data/synthetic_data_utils.py  \n","   creating: models-master/research/lfads/synth_data/trained_itb/\n","  inflating: models-master/research/lfads/synth_data/trained_itb/model-65000.data-00000-of-00001  \n","  inflating: models-master/research/lfads/synth_data/trained_itb/model-65000.index  \n","  inflating: models-master/research/lfads/synth_data/trained_itb/model-65000.meta  \n","  inflating: models-master/research/lfads/utils.py  \n","   creating: models-master/research/lstm_object_detection/\n","  inflating: models-master/research/lstm_object_detection/README.md  \n"," extracting: models-master/research/lstm_object_detection/__init__.py  \n","   creating: models-master/research/lstm_object_detection/builders/\n"," extracting: models-master/research/lstm_object_detection/builders/__init__.py  \n","  inflating: models-master/research/lstm_object_detection/builders/graph_rewriter_builder.py  \n","  inflating: models-master/research/lstm_object_detection/builders/graph_rewriter_builder_test.py  \n","   creating: models-master/research/lstm_object_detection/configs/\n","  inflating: models-master/research/lstm_object_detection/configs/lstm_ssd_interleaved_mobilenet_v2_imagenet.config  \n","  inflating: models-master/research/lstm_object_detection/configs/lstm_ssd_mobilenet_v1_imagenet.config  \n","  inflating: models-master/research/lstm_object_detection/eval.py  \n","  inflating: models-master/research/lstm_object_detection/evaluator.py  \n","  inflating: models-master/research/lstm_object_detection/export_tflite_lstd_graph.py  \n","  inflating: models-master/research/lstm_object_detection/export_tflite_lstd_graph_lib.py  \n","  inflating: models-master/research/lstm_object_detection/export_tflite_lstd_model.py  \n","   creating: models-master/research/lstm_object_detection/g3doc/\n","  inflating: models-master/research/lstm_object_detection/g3doc/Interleaved_Intro.png  \n","  inflating: models-master/research/lstm_object_detection/g3doc/exporting_models.md  \n","  inflating: models-master/research/lstm_object_detection/g3doc/lstm_ssd_intro.png  \n","   creating: models-master/research/lstm_object_detection/inputs/\n"," extracting: models-master/research/lstm_object_detection/inputs/__init__.py  \n","  inflating: models-master/research/lstm_object_detection/inputs/seq_dataset_builder.py  \n","  inflating: models-master/research/lstm_object_detection/inputs/seq_dataset_builder_test.py  \n","  inflating: models-master/research/lstm_object_detection/inputs/tf_sequence_example_decoder.py  \n","  inflating: models-master/research/lstm_object_detection/inputs/tf_sequence_example_decoder_test.py  \n","   creating: models-master/research/lstm_object_detection/lstm/\n"," extracting: models-master/research/lstm_object_detection/lstm/__init__.py  \n","  inflating: models-master/research/lstm_object_detection/lstm/lstm_cells.py  \n","  inflating: models-master/research/lstm_object_detection/lstm/lstm_cells_test.py  \n","  inflating: models-master/research/lstm_object_detection/lstm/rnn_decoder.py  \n","  inflating: models-master/research/lstm_object_detection/lstm/rnn_decoder_test.py  \n","  inflating: models-master/research/lstm_object_detection/lstm/utils.py  \n","  inflating: models-master/research/lstm_object_detection/lstm/utils_test.py  \n","   creating: models-master/research/lstm_object_detection/meta_architectures/\n"," extracting: models-master/research/lstm_object_detection/meta_architectures/__init__.py  \n","  inflating: models-master/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch.py  \n","  inflating: models-master/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch_test.py  \n","   creating: models-master/research/lstm_object_detection/metrics/\n"," extracting: models-master/research/lstm_object_detection/metrics/__init__.py  \n","  inflating: models-master/research/lstm_object_detection/metrics/coco_evaluation_all_frames.py  \n","  inflating: models-master/research/lstm_object_detection/metrics/coco_evaluation_all_frames_test.py  \n","  inflating: models-master/research/lstm_object_detection/model_builder.py  \n","  inflating: models-master/research/lstm_object_detection/model_builder_test.py  \n","   creating: models-master/research/lstm_object_detection/models/\n"," extracting: models-master/research/lstm_object_detection/models/__init__.py  \n","  inflating: models-master/research/lstm_object_detection/models/lstm_ssd_interleaved_mobilenet_v2_feature_extractor.py  \n","  inflating: models-master/research/lstm_object_detection/models/lstm_ssd_interleaved_mobilenet_v2_feature_extractor_test.py  \n","  inflating: models-master/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor.py  \n","  inflating: models-master/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor_test.py  \n","  inflating: models-master/research/lstm_object_detection/models/mobilenet_defs.py  \n","  inflating: models-master/research/lstm_object_detection/models/mobilenet_defs_test.py  \n","   creating: models-master/research/lstm_object_detection/protos/\n"," extracting: models-master/research/lstm_object_detection/protos/__init__.py  \n","  inflating: models-master/research/lstm_object_detection/protos/input_reader_google.proto  \n","  inflating: models-master/research/lstm_object_detection/protos/pipeline.proto  \n","  inflating: models-master/research/lstm_object_detection/protos/quant_overrides.proto  \n","  inflating: models-master/research/lstm_object_detection/test_tflite_model.py  \n","   creating: models-master/research/lstm_object_detection/tflite/\n","  inflating: models-master/research/lstm_object_detection/tflite/BUILD  \n","  inflating: models-master/research/lstm_object_detection/tflite/WORKSPACE  \n","  inflating: models-master/research/lstm_object_detection/tflite/mobile_lstd_tflite_client.cc  \n","  inflating: models-master/research/lstm_object_detection/tflite/mobile_lstd_tflite_client.h  \n","  inflating: models-master/research/lstm_object_detection/tflite/mobile_ssd_client.cc  \n","  inflating: models-master/research/lstm_object_detection/tflite/mobile_ssd_client.h  \n","  inflating: models-master/research/lstm_object_detection/tflite/mobile_ssd_tflite_client.cc  \n","  inflating: models-master/research/lstm_object_detection/tflite/mobile_ssd_tflite_client.h  \n","   creating: models-master/research/lstm_object_detection/tflite/protos/\n","  inflating: models-master/research/lstm_object_detection/tflite/protos/BUILD  \n","  inflating: models-master/research/lstm_object_detection/tflite/protos/anchor_generation_options.proto  \n","  inflating: models-master/research/lstm_object_detection/tflite/protos/box_encodings.proto  \n","  inflating: models-master/research/lstm_object_detection/tflite/protos/detections.proto  \n","  inflating: models-master/research/lstm_object_detection/tflite/protos/labelmap.proto  \n","  inflating: models-master/research/lstm_object_detection/tflite/protos/mobile_ssd_client_options.proto  \n","  inflating: models-master/research/lstm_object_detection/tflite/protos/proto_config.asciipb  \n","   creating: models-master/research/lstm_object_detection/tflite/utils/\n","  inflating: models-master/research/lstm_object_detection/tflite/utils/BUILD  \n","  inflating: models-master/research/lstm_object_detection/tflite/utils/conversion_utils.cc  \n","  inflating: models-master/research/lstm_object_detection/tflite/utils/conversion_utils.h  \n","  inflating: models-master/research/lstm_object_detection/tflite/utils/conversion_utils_test.cc  \n","  inflating: models-master/research/lstm_object_detection/tflite/utils/file_utils.cc  \n","  inflating: models-master/research/lstm_object_detection/tflite/utils/file_utils.h  \n","  inflating: models-master/research/lstm_object_detection/tflite/utils/ssd_utils.cc  \n","  inflating: models-master/research/lstm_object_detection/tflite/utils/ssd_utils.h  \n","  inflating: models-master/research/lstm_object_detection/train.py  \n","  inflating: models-master/research/lstm_object_detection/trainer.py  \n","   creating: models-master/research/lstm_object_detection/utils/\n"," extracting: models-master/research/lstm_object_detection/utils/__init__.py  \n","  inflating: models-master/research/lstm_object_detection/utils/config_util.py  \n","  inflating: models-master/research/lstm_object_detection/utils/config_util_test.py  \n","   creating: models-master/research/marco/\n","  inflating: models-master/research/marco/Automated_Marco.py  \n","  inflating: models-master/research/marco/README.md  \n","  inflating: models-master/research/marco/jpeg2json.py  \n","  inflating: models-master/research/marco/request.json  \n","   creating: models-master/research/nst_blogpost/\n","  inflating: models-master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb  \n","  inflating: models-master/research/nst_blogpost/Green_Sea_Turtle_grazing_seagrass.jpg  \n","  inflating: models-master/research/nst_blogpost/The_Great_Wave_off_Kanagawa.jpg  \n"," extracting: models-master/research/nst_blogpost/wave_turtle.png  \n","   creating: models-master/research/object_detection/\n","  inflating: models-master/research/object_detection/CONTRIBUTING.md  \n","  inflating: models-master/research/object_detection/README.md  \n"," extracting: models-master/research/object_detection/__init__.py  \n","   creating: models-master/research/object_detection/anchor_generators/\n"," extracting: models-master/research/object_detection/anchor_generators/__init__.py  \n","  inflating: models-master/research/object_detection/anchor_generators/flexible_grid_anchor_generator.py  \n","  inflating: models-master/research/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py  \n","  inflating: models-master/research/object_detection/anchor_generators/grid_anchor_generator.py  \n","  inflating: models-master/research/object_detection/anchor_generators/grid_anchor_generator_test.py  \n","  inflating: models-master/research/object_detection/anchor_generators/multiple_grid_anchor_generator.py  \n","  inflating: models-master/research/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py  \n","  inflating: models-master/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py  \n","  inflating: models-master/research/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py  \n","   creating: models-master/research/object_detection/box_coders/\n"," extracting: models-master/research/object_detection/box_coders/__init__.py  \n","  inflating: models-master/research/object_detection/box_coders/faster_rcnn_box_coder.py  \n","  inflating: models-master/research/object_detection/box_coders/faster_rcnn_box_coder_test.py  \n","  inflating: models-master/research/object_detection/box_coders/keypoint_box_coder.py  \n","  inflating: models-master/research/object_detection/box_coders/keypoint_box_coder_test.py  \n","  inflating: models-master/research/object_detection/box_coders/mean_stddev_box_coder.py  \n","  inflating: models-master/research/object_detection/box_coders/mean_stddev_box_coder_test.py  \n","  inflating: models-master/research/object_detection/box_coders/square_box_coder.py  \n","  inflating: models-master/research/object_detection/box_coders/square_box_coder_test.py  \n","   creating: models-master/research/object_detection/builders/\n"," extracting: models-master/research/object_detection/builders/__init__.py  \n","  inflating: models-master/research/object_detection/builders/anchor_generator_builder.py  \n","  inflating: models-master/research/object_detection/builders/anchor_generator_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/box_coder_builder.py  \n","  inflating: models-master/research/object_detection/builders/box_coder_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/box_predictor_builder.py  \n","  inflating: models-master/research/object_detection/builders/box_predictor_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/calibration_builder.py  \n","  inflating: models-master/research/object_detection/builders/calibration_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/dataset_builder.py  \n","  inflating: models-master/research/object_detection/builders/dataset_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/decoder_builder.py  \n","  inflating: models-master/research/object_detection/builders/decoder_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/graph_rewriter_builder.py  \n","  inflating: models-master/research/object_detection/builders/graph_rewriter_builder_tf1_test.py  \n","  inflating: models-master/research/object_detection/builders/hyperparams_builder.py  \n","  inflating: models-master/research/object_detection/builders/hyperparams_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/image_resizer_builder.py  \n","  inflating: models-master/research/object_detection/builders/image_resizer_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/input_reader_builder.py  \n","  inflating: models-master/research/object_detection/builders/input_reader_builder_tf1_test.py  \n","  inflating: models-master/research/object_detection/builders/losses_builder.py  \n","  inflating: models-master/research/object_detection/builders/losses_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/matcher_builder.py  \n","  inflating: models-master/research/object_detection/builders/matcher_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/model_builder.py  \n","  inflating: models-master/research/object_detection/builders/model_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/model_builder_tf1_test.py  \n","  inflating: models-master/research/object_detection/builders/model_builder_tf2_test.py  \n","  inflating: models-master/research/object_detection/builders/optimizer_builder.py  \n","  inflating: models-master/research/object_detection/builders/optimizer_builder_tf1_test.py  \n","  inflating: models-master/research/object_detection/builders/optimizer_builder_tf2_test.py  \n","  inflating: models-master/research/object_detection/builders/post_processing_builder.py  \n","  inflating: models-master/research/object_detection/builders/post_processing_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/preprocessor_builder.py  \n","  inflating: models-master/research/object_detection/builders/preprocessor_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/region_similarity_calculator_builder.py  \n","  inflating: models-master/research/object_detection/builders/region_similarity_calculator_builder_test.py  \n","  inflating: models-master/research/object_detection/builders/target_assigner_builder.py  \n","  inflating: models-master/research/object_detection/builders/target_assigner_builder_test.py  \n","   creating: models-master/research/object_detection/colab_tutorials/\n","  inflating: models-master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb  \n","  inflating: models-master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb  \n","  inflating: models-master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tflite.ipynb  \n","  inflating: models-master/research/object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb  \n","  inflating: models-master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb  \n","  inflating: models-master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb  \n","   creating: models-master/research/object_detection/configs/\n","   creating: models-master/research/object_detection/configs/tf2/\n","  inflating: models-master/research/object_detection/configs/tf2/centernet_hourglass104_1024x1024_coco17_tpu-32.config  \n","  inflating: models-master/research/object_detection/configs/tf2/centernet_hourglass104_1024x1024_kpts_coco17_tpu-32.config  \n","  inflating: models-master/research/object_detection/configs/tf2/centernet_hourglass104_512x512_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/centernet_hourglass104_512x512_kpts_coco17_tpu-32.config  \n","  inflating: models-master/research/object_detection/configs/tf2/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/centernet_resnet50_v2_512x512_kpts_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_fpn_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_efficientdet_d1_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_efficientdet_d2_768x768_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_efficientdet_d3_896x896_coco17_tpu-32.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_efficientdet_d5_1280x1280_coco17_tpu-32.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_efficientdet_d6_1408x1408_coco17_tpu-32.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_efficientdet_d7_1536x1536_coco17_tpu-32.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.config  \n","  inflating: models-master/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config  \n","   creating: models-master/research/object_detection/core/\n"," extracting: models-master/research/object_detection/core/__init__.py  \n","  inflating: models-master/research/object_detection/core/anchor_generator.py  \n","  inflating: models-master/research/object_detection/core/balanced_positive_negative_sampler.py  \n","  inflating: models-master/research/object_detection/core/balanced_positive_negative_sampler_test.py  \n","  inflating: models-master/research/object_detection/core/batch_multiclass_nms_test.py  \n","  inflating: models-master/research/object_detection/core/batcher.py  \n","  inflating: models-master/research/object_detection/core/batcher_tf1_test.py  \n","  inflating: models-master/research/object_detection/core/box_coder.py  \n","  inflating: models-master/research/object_detection/core/box_coder_test.py  \n","  inflating: models-master/research/object_detection/core/box_list.py  \n","  inflating: models-master/research/object_detection/core/box_list_ops.py  \n","  inflating: models-master/research/object_detection/core/box_list_ops_test.py  \n","  inflating: models-master/research/object_detection/core/box_list_test.py  \n","  inflating: models-master/research/object_detection/core/box_predictor.py  \n","  inflating: models-master/research/object_detection/core/class_agnostic_nms_test.py  \n","  inflating: models-master/research/object_detection/core/data_decoder.py  \n","  inflating: models-master/research/object_detection/core/data_parser.py  \n","  inflating: models-master/research/object_detection/core/densepose_ops.py  \n","  inflating: models-master/research/object_detection/core/densepose_ops_test.py  \n","  inflating: models-master/research/object_detection/core/freezable_batch_norm.py  \n","  inflating: models-master/research/object_detection/core/freezable_batch_norm_tf2_test.py  \n","  inflating: models-master/research/object_detection/core/keypoint_ops.py  \n","  inflating: models-master/research/object_detection/core/keypoint_ops_test.py  \n","  inflating: models-master/research/object_detection/core/losses.py  \n","  inflating: models-master/research/object_detection/core/losses_test.py  \n","  inflating: models-master/research/object_detection/core/matcher.py  \n","  inflating: models-master/research/object_detection/core/matcher_test.py  \n","  inflating: models-master/research/object_detection/core/minibatch_sampler.py  \n","  inflating: models-master/research/object_detection/core/minibatch_sampler_test.py  \n","  inflating: models-master/research/object_detection/core/model.py  \n","  inflating: models-master/research/object_detection/core/model_test.py  \n","  inflating: models-master/research/object_detection/core/multiclass_nms_test.py  \n","  inflating: models-master/research/object_detection/core/post_processing.py  \n","  inflating: models-master/research/object_detection/core/prefetcher.py  \n","  inflating: models-master/research/object_detection/core/prefetcher_tf1_test.py  \n","  inflating: models-master/research/object_detection/core/preprocessor.py  \n","  inflating: models-master/research/object_detection/core/preprocessor_cache.py  \n","  inflating: models-master/research/object_detection/core/preprocessor_test.py  \n","  inflating: models-master/research/object_detection/core/region_similarity_calculator.py  \n","  inflating: models-master/research/object_detection/core/region_similarity_calculator_test.py  \n","  inflating: models-master/research/object_detection/core/standard_fields.py  \n","  inflating: models-master/research/object_detection/core/target_assigner.py  \n","  inflating: models-master/research/object_detection/core/target_assigner_test.py  \n","   creating: models-master/research/object_detection/data/\n","  inflating: models-master/research/object_detection/data/ava_label_map_v2.1.pbtxt  \n","  inflating: models-master/research/object_detection/data/face_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/face_person_with_keypoints_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/fgvc_2854_classes_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/kitti_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/mscoco_complete_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/mscoco_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/mscoco_minival_ids.txt  \n","  inflating: models-master/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/oid_v4_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/pascal_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/pet_label_map.pbtxt  \n","  inflating: models-master/research/object_detection/data/snapshot_serengeti_label_map.pbtxt  \n","   creating: models-master/research/object_detection/data_decoders/\n"," extracting: models-master/research/object_detection/data_decoders/__init__.py  \n","  inflating: models-master/research/object_detection/data_decoders/tf_example_decoder.py  \n","  inflating: models-master/research/object_detection/data_decoders/tf_example_decoder_test.py  \n","  inflating: models-master/research/object_detection/data_decoders/tf_sequence_example_decoder.py  \n","  inflating: models-master/research/object_detection/data_decoders/tf_sequence_example_decoder_test.py  \n","   creating: models-master/research/object_detection/dataset_tools/\n"," extracting: models-master/research/object_detection/dataset_tools/__init__.py  \n","   creating: models-master/research/object_detection/dataset_tools/context_rcnn/\n"," extracting: models-master/research/object_detection/dataset_tools/context_rcnn/__init__.py  \n","  inflating: models-master/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py  \n","  inflating: models-master/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py  \n","  inflating: models-master/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/context_rcnn/generate_detection_data.py  \n","  inflating: models-master/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py  \n","  inflating: models-master/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_ava_actions_tf_record.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_coco_tf_record.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_coco_tf_record_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_kitti_tf_record.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_kitti_tf_record_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_oid_tf_record.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_pascal_tf_record.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_pascal_tf_record_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_pet_tf_record.py  \n","  inflating: models-master/research/object_detection/dataset_tools/create_pycocotools_package.sh  \n","   creating: models-master/research/object_detection/dataset_tools/densepose/\n","  inflating: models-master/research/object_detection/dataset_tools/densepose/UV_symmetry_transforms.mat  \n","  inflating: models-master/research/object_detection/dataset_tools/download_and_preprocess_ava.sh  \n","  inflating: models-master/research/object_detection/dataset_tools/download_and_preprocess_mscoco.sh  \n","  inflating: models-master/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py  \n","  inflating: models-master/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/oid_tfrecord_creation.py  \n","  inflating: models-master/research/object_detection/dataset_tools/oid_tfrecord_creation_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/seq_example_util.py  \n","  inflating: models-master/research/object_detection/dataset_tools/seq_example_util_test.py  \n","  inflating: models-master/research/object_detection/dataset_tools/tf_record_creation_util.py  \n","  inflating: models-master/research/object_detection/dataset_tools/tf_record_creation_util_test.py  \n","   creating: models-master/research/object_detection/dockerfiles/\n","   creating: models-master/research/object_detection/dockerfiles/android/\n","  inflating: models-master/research/object_detection/dockerfiles/android/Dockerfile  \n","  inflating: models-master/research/object_detection/dockerfiles/android/README.md  \n","   creating: models-master/research/object_detection/dockerfiles/tf1/\n","  inflating: models-master/research/object_detection/dockerfiles/tf1/Dockerfile  \n","  inflating: models-master/research/object_detection/dockerfiles/tf1/README.md  \n","   creating: models-master/research/object_detection/dockerfiles/tf2/\n","  inflating: models-master/research/object_detection/dockerfiles/tf2/Dockerfile  \n","  inflating: models-master/research/object_detection/dockerfiles/tf2/README.md  \n","  inflating: models-master/research/object_detection/eval_util.py  \n","  inflating: models-master/research/object_detection/eval_util_test.py  \n","  inflating: models-master/research/object_detection/export_inference_graph.py  \n","  inflating: models-master/research/object_detection/export_tflite_graph_lib_tf2.py  \n","  inflating: models-master/research/object_detection/export_tflite_graph_lib_tf2_test.py  \n","  inflating: models-master/research/object_detection/export_tflite_graph_tf2.py  \n","  inflating: models-master/research/object_detection/export_tflite_ssd_graph.py  \n","  inflating: models-master/research/object_detection/export_tflite_ssd_graph_lib.py  \n","  inflating: models-master/research/object_detection/export_tflite_ssd_graph_lib_tf1_test.py  \n","  inflating: models-master/research/object_detection/exporter.py  \n","  inflating: models-master/research/object_detection/exporter_lib_tf2_test.py  \n","  inflating: models-master/research/object_detection/exporter_lib_v2.py  \n","  inflating: models-master/research/object_detection/exporter_main_v2.py  \n","  inflating: models-master/research/object_detection/exporter_tf1_test.py  \n","   creating: models-master/research/object_detection/g3doc/\n","  inflating: models-master/research/object_detection/g3doc/challenge_evaluation.md  \n","  inflating: models-master/research/object_detection/g3doc/configuring_jobs.md  \n","  inflating: models-master/research/object_detection/g3doc/context_rcnn.md  \n","  inflating: models-master/research/object_detection/g3doc/defining_your_own_model.md  \n","  inflating: models-master/research/object_detection/g3doc/evaluation_protocols.md  \n","  inflating: models-master/research/object_detection/g3doc/exporting_models.md  \n","  inflating: models-master/research/object_detection/g3doc/faq.md  \n","   creating: models-master/research/object_detection/g3doc/img/\n","  inflating: models-master/research/object_detection/g3doc/img/dogs_detections_output.jpg  \n","  inflating: models-master/research/object_detection/g3doc/img/example_cat.jpg  \n"," extracting: models-master/research/object_detection/g3doc/img/groupof_case_eval.png  \n","  inflating: models-master/research/object_detection/g3doc/img/kites_detections_output.jpg  \n"," extracting: models-master/research/object_detection/g3doc/img/kites_with_segment_overlay.png  \n"," extracting: models-master/research/object_detection/g3doc/img/nongroupof_case_eval.png  \n","  inflating: models-master/research/object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg  \n","  inflating: models-master/research/object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg  \n"," extracting: models-master/research/object_detection/g3doc/img/oxford_pet.png  \n","  inflating: models-master/research/object_detection/g3doc/img/tensorboard.png  \n","  inflating: models-master/research/object_detection/g3doc/img/tensorboard2.png  \n","  inflating: models-master/research/object_detection/g3doc/img/tf-od-api-logo.png  \n","  inflating: models-master/research/object_detection/g3doc/instance_segmentation.md  \n","  inflating: models-master/research/object_detection/g3doc/oid_inference_and_evaluation.md  \n","  inflating: models-master/research/object_detection/g3doc/preparing_inputs.md  \n","  inflating: models-master/research/object_detection/g3doc/release_notes.md  \n","  inflating: models-master/research/object_detection/g3doc/running_notebook.md  \n","  inflating: models-master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md  \n","  inflating: models-master/research/object_detection/g3doc/running_on_mobile_tf2.md  \n","  inflating: models-master/research/object_detection/g3doc/running_pets.md  \n","  inflating: models-master/research/object_detection/g3doc/tf1.md  \n","  inflating: models-master/research/object_detection/g3doc/tf1_detection_zoo.md  \n","  inflating: models-master/research/object_detection/g3doc/tf1_training_and_evaluation.md  \n","  inflating: models-master/research/object_detection/g3doc/tf2.md  \n","  inflating: models-master/research/object_detection/g3doc/tf2_classification_zoo.md  \n","  inflating: models-master/research/object_detection/g3doc/tf2_detection_zoo.md  \n","  inflating: models-master/research/object_detection/g3doc/tf2_training_and_evaluation.md  \n","  inflating: models-master/research/object_detection/g3doc/tpu_compatibility.md  \n","  inflating: models-master/research/object_detection/g3doc/tpu_exporters.md  \n","  inflating: models-master/research/object_detection/g3doc/using_your_own_dataset.md  \n","   creating: models-master/research/object_detection/inference/\n"," extracting: models-master/research/object_detection/inference/__init__.py  \n","  inflating: models-master/research/object_detection/inference/detection_inference.py  \n","  inflating: models-master/research/object_detection/inference/detection_inference_tf1_test.py  \n","  inflating: models-master/research/object_detection/inference/infer_detections.py  \n","  inflating: models-master/research/object_detection/inputs.py  \n","  inflating: models-master/research/object_detection/inputs_test.py  \n","   creating: models-master/research/object_detection/legacy/\n"," extracting: models-master/research/object_detection/legacy/__init__.py  \n","  inflating: models-master/research/object_detection/legacy/eval.py  \n","  inflating: models-master/research/object_detection/legacy/evaluator.py  \n","  inflating: models-master/research/object_detection/legacy/train.py  \n","  inflating: models-master/research/object_detection/legacy/trainer.py  \n","  inflating: models-master/research/object_detection/legacy/trainer_tf1_test.py  \n","   creating: models-master/research/object_detection/matchers/\n"," extracting: models-master/research/object_detection/matchers/__init__.py  \n","  inflating: models-master/research/object_detection/matchers/argmax_matcher.py  \n","  inflating: models-master/research/object_detection/matchers/argmax_matcher_test.py  \n","  inflating: models-master/research/object_detection/matchers/bipartite_matcher.py  \n","  inflating: models-master/research/object_detection/matchers/bipartite_matcher_tf1_test.py  \n","  inflating: models-master/research/object_detection/matchers/hungarian_matcher.py  \n","  inflating: models-master/research/object_detection/matchers/hungarian_matcher_tf2_test.py  \n","   creating: models-master/research/object_detection/meta_architectures/\n"," extracting: models-master/research/object_detection/meta_architectures/__init__.py  \n","  inflating: models-master/research/object_detection/meta_architectures/center_net_meta_arch.py  \n","  inflating: models-master/research/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py  \n","  inflating: models-master/research/object_detection/meta_architectures/context_rcnn_lib.py  \n","  inflating: models-master/research/object_detection/meta_architectures/context_rcnn_lib_tf1_test.py  \n","  inflating: models-master/research/object_detection/meta_architectures/context_rcnn_lib_tf2.py  \n","  inflating: models-master/research/object_detection/meta_architectures/context_rcnn_lib_tf2_test.py  \n","  inflating: models-master/research/object_detection/meta_architectures/context_rcnn_meta_arch.py  \n","  inflating: models-master/research/object_detection/meta_architectures/context_rcnn_meta_arch_test.py  \n","  inflating: models-master/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py  \n","  inflating: models-master/research/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py  \n","  inflating: models-master/research/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py  \n","  inflating: models-master/research/object_detection/meta_architectures/rfcn_meta_arch.py  \n","  inflating: models-master/research/object_detection/meta_architectures/rfcn_meta_arch_test.py  \n","  inflating: models-master/research/object_detection/meta_architectures/ssd_meta_arch.py  \n","  inflating: models-master/research/object_detection/meta_architectures/ssd_meta_arch_test.py  \n","  inflating: models-master/research/object_detection/meta_architectures/ssd_meta_arch_test_lib.py  \n","   creating: models-master/research/object_detection/metrics/\n"," extracting: models-master/research/object_detection/metrics/__init__.py  \n","  inflating: models-master/research/object_detection/metrics/calibration_evaluation.py  \n","  inflating: models-master/research/object_detection/metrics/calibration_evaluation_tf1_test.py  \n","  inflating: models-master/research/object_detection/metrics/calibration_metrics.py  \n","  inflating: models-master/research/object_detection/metrics/calibration_metrics_tf1_test.py  \n","  inflating: models-master/research/object_detection/metrics/coco_evaluation.py  \n","  inflating: models-master/research/object_detection/metrics/coco_evaluation_test.py  \n","  inflating: models-master/research/object_detection/metrics/coco_tools.py  \n","  inflating: models-master/research/object_detection/metrics/coco_tools_test.py  \n","  inflating: models-master/research/object_detection/metrics/io_utils.py  \n","  inflating: models-master/research/object_detection/metrics/lvis_evaluation.py  \n","  inflating: models-master/research/object_detection/metrics/lvis_evaluation_test.py  \n","  inflating: models-master/research/object_detection/metrics/lvis_tools.py  \n","  inflating: models-master/research/object_detection/metrics/lvis_tools_test.py  \n","  inflating: models-master/research/object_detection/metrics/offline_eval_map_corloc.py  \n","  inflating: models-master/research/object_detection/metrics/offline_eval_map_corloc_test.py  \n","  inflating: models-master/research/object_detection/metrics/oid_challenge_evaluation.py  \n","  inflating: models-master/research/object_detection/metrics/oid_challenge_evaluation_utils.py  \n","  inflating: models-master/research/object_detection/metrics/oid_challenge_evaluation_utils_test.py  \n","  inflating: models-master/research/object_detection/metrics/oid_vrd_challenge_evaluation.py  \n","  inflating: models-master/research/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py  \n","  inflating: models-master/research/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py  \n","  inflating: models-master/research/object_detection/metrics/tf_example_parser.py  \n","  inflating: models-master/research/object_detection/metrics/tf_example_parser_test.py  \n","  inflating: models-master/research/object_detection/model_hparams.py  \n","  inflating: models-master/research/object_detection/model_lib.py  \n","  inflating: models-master/research/object_detection/model_lib_tf1_test.py  \n","  inflating: models-master/research/object_detection/model_lib_tf2_test.py  \n","  inflating: models-master/research/object_detection/model_lib_v2.py  \n","  inflating: models-master/research/object_detection/model_main.py  \n","  inflating: models-master/research/object_detection/model_main_tf2.py  \n","  inflating: models-master/research/object_detection/model_tpu_main.py  \n","   creating: models-master/research/object_detection/models/\n"," extracting: models-master/research/object_detection/models/__init__.py  \n","  inflating: models-master/research/object_detection/models/bidirectional_feature_pyramid_generators.py  \n","  inflating: models-master/research/object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/center_net_hourglass_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/center_net_mobilenet_v2_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/center_net_resnet_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/center_net_resnet_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_nas_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_pnas_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/feature_map_generators.py  \n","  inflating: models-master/research/object_detection/models/feature_map_generators_test.py  \n","   creating: models-master/research/object_detection/models/keras_models/\n"," extracting: models-master/research/object_detection/models/keras_models/__init__.py  \n","   creating: models-master/research/object_detection/models/keras_models/base_models/\n","  inflating: models-master/research/object_detection/models/keras_models/base_models/original_mobilenet_v2.py  \n","  inflating: models-master/research/object_detection/models/keras_models/convert_keras_models.py  \n","  inflating: models-master/research/object_detection/models/keras_models/hourglass_network.py  \n","  inflating: models-master/research/object_detection/models/keras_models/hourglass_network_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/keras_models/inception_resnet_v2.py  \n","  inflating: models-master/research/object_detection/models/keras_models/inception_resnet_v2_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/keras_models/mobilenet_v1.py  \n","  inflating: models-master/research/object_detection/models/keras_models/mobilenet_v1_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/keras_models/mobilenet_v2.py  \n","  inflating: models-master/research/object_detection/models/keras_models/mobilenet_v2_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/keras_models/model_utils.py  \n","  inflating: models-master/research/object_detection/models/keras_models/resnet_v1.py  \n","  inflating: models-master/research/object_detection/models/keras_models/resnet_v1_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/keras_models/test_utils.py  \n","  inflating: models-master/research/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_feature_extractor_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_inception_v2_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_inception_v3_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobiledet_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v3_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py  \n","  inflating: models-master/research/object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_pnasnet_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py  \n","  inflating: models-master/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py  \n","  inflating: models-master/research/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py  \n","  inflating: models-master/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py  \n","  inflating: models-master/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py  \n","   creating: models-master/research/object_detection/packages/\n","   creating: models-master/research/object_detection/packages/tf1/\n","  inflating: models-master/research/object_detection/packages/tf1/setup.py  \n","   creating: models-master/research/object_detection/packages/tf2/\n","  inflating: models-master/research/object_detection/packages/tf2/setup.py  \n","   creating: models-master/research/object_detection/predictors/\n"," extracting: models-master/research/object_detection/predictors/__init__.py  \n","  inflating: models-master/research/object_detection/predictors/convolutional_box_predictor.py  \n","  inflating: models-master/research/object_detection/predictors/convolutional_box_predictor_tf1_test.py  \n","  inflating: models-master/research/object_detection/predictors/convolutional_keras_box_predictor.py  \n","  inflating: models-master/research/object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py  \n","   creating: models-master/research/object_detection/predictors/heads/\n"," extracting: models-master/research/object_detection/predictors/heads/__init__.py  \n","  inflating: models-master/research/object_detection/predictors/heads/box_head.py  \n","  inflating: models-master/research/object_detection/predictors/heads/box_head_tf1_test.py  \n","  inflating: models-master/research/object_detection/predictors/heads/class_head.py  \n","  inflating: models-master/research/object_detection/predictors/heads/class_head_tf1_test.py  \n","  inflating: models-master/research/object_detection/predictors/heads/head.py  \n","  inflating: models-master/research/object_detection/predictors/heads/keras_box_head.py  \n","  inflating: models-master/research/object_detection/predictors/heads/keras_box_head_tf2_test.py  \n","  inflating: models-master/research/object_detection/predictors/heads/keras_class_head.py  \n","  inflating: models-master/research/object_detection/predictors/heads/keras_class_head_tf2_test.py  \n","  inflating: models-master/research/object_detection/predictors/heads/keras_mask_head.py  \n","  inflating: models-master/research/object_detection/predictors/heads/keras_mask_head_tf2_test.py  \n","  inflating: models-master/research/object_detection/predictors/heads/keypoint_head.py  \n","  inflating: models-master/research/object_detection/predictors/heads/keypoint_head_tf1_test.py  \n","  inflating: models-master/research/object_detection/predictors/heads/mask_head.py  \n","  inflating: models-master/research/object_detection/predictors/heads/mask_head_tf1_test.py  \n","  inflating: models-master/research/object_detection/predictors/mask_rcnn_box_predictor.py  \n","  inflating: models-master/research/object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py  \n","  inflating: models-master/research/object_detection/predictors/mask_rcnn_keras_box_predictor.py  \n","  inflating: models-master/research/object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py  \n","  inflating: models-master/research/object_detection/predictors/rfcn_box_predictor.py  \n","  inflating: models-master/research/object_detection/predictors/rfcn_box_predictor_tf1_test.py  \n","  inflating: models-master/research/object_detection/predictors/rfcn_keras_box_predictor.py  \n","  inflating: models-master/research/object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py  \n","   creating: models-master/research/object_detection/protos/\n"," extracting: models-master/research/object_detection/protos/__init__.py  \n","  inflating: models-master/research/object_detection/protos/anchor_generator.proto  \n","  inflating: models-master/research/object_detection/protos/argmax_matcher.proto  \n","  inflating: models-master/research/object_detection/protos/bipartite_matcher.proto  \n","  inflating: models-master/research/object_detection/protos/box_coder.proto  \n","  inflating: models-master/research/object_detection/protos/box_predictor.proto  \n","  inflating: models-master/research/object_detection/protos/calibration.proto  \n","  inflating: models-master/research/object_detection/protos/center_net.proto  \n","  inflating: models-master/research/object_detection/protos/eval.proto  \n","  inflating: models-master/research/object_detection/protos/faster_rcnn.proto  \n","  inflating: models-master/research/object_detection/protos/faster_rcnn_box_coder.proto  \n","  inflating: models-master/research/object_detection/protos/flexible_grid_anchor_generator.proto  \n","  inflating: models-master/research/object_detection/protos/fpn.proto  \n","  inflating: models-master/research/object_detection/protos/graph_rewriter.proto  \n","  inflating: models-master/research/object_detection/protos/grid_anchor_generator.proto  \n","  inflating: models-master/research/object_detection/protos/hyperparams.proto  \n","  inflating: models-master/research/object_detection/protos/image_resizer.proto  \n","  inflating: models-master/research/object_detection/protos/input_reader.proto  \n","  inflating: models-master/research/object_detection/protos/keypoint_box_coder.proto  \n","  inflating: models-master/research/object_detection/protos/losses.proto  \n","  inflating: models-master/research/object_detection/protos/matcher.proto  \n","  inflating: models-master/research/object_detection/protos/mean_stddev_box_coder.proto  \n","  inflating: models-master/research/object_detection/protos/model.proto  \n","  inflating: models-master/research/object_detection/protos/multiscale_anchor_generator.proto  \n","  inflating: models-master/research/object_detection/protos/optimizer.proto  \n","  inflating: models-master/research/object_detection/protos/pipeline.proto  \n","  inflating: models-master/research/object_detection/protos/post_processing.proto  \n","  inflating: models-master/research/object_detection/protos/preprocessor.proto  \n","  inflating: models-master/research/object_detection/protos/region_similarity_calculator.proto  \n","  inflating: models-master/research/object_detection/protos/square_box_coder.proto  \n","  inflating: models-master/research/object_detection/protos/ssd.proto  \n","  inflating: models-master/research/object_detection/protos/ssd_anchor_generator.proto  \n","  inflating: models-master/research/object_detection/protos/string_int_label_map.proto  \n","  inflating: models-master/research/object_detection/protos/target_assigner.proto  \n","  inflating: models-master/research/object_detection/protos/train.proto  \n","   creating: models-master/research/object_detection/samples/\n","   creating: models-master/research/object_detection/samples/cloud/\n","  inflating: models-master/research/object_detection/samples/cloud/cloud.yml  \n","   creating: models-master/research/object_detection/samples/configs/\n","  inflating: models-master/research/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti.config  \n","  inflating: models-master/research/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_nas_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_kitti.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_voc07.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet152_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet152_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet50_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config  \n","  inflating: models-master/research/object_detection/samples/configs/faster_rcnn_resnet50_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/mask_rcnn_resnet101_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/rfcn_resnet101_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/rfcn_resnet101_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_inception_v2_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_inception_v2_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_inception_v3_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_pets.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobiledet_cpu_320x320_coco_sync_4x4.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobiledet_dsp_320x320_coco_sync_4x4.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobiledet_edgetpu_320x320_coco_sync_4x4.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobiledet_gpu_320x320_coco_sync_4x4.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco_quant.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config  \n","  inflating: models-master/research/object_detection/samples/configs/ssdlite_mobilenet_v3_small_320x320_coco.config  \n","   creating: models-master/research/object_detection/test_data/\n","  inflating: models-master/research/object_detection/test_data/context_rcnn_camera_trap.config  \n","  inflating: models-master/research/object_detection/test_data/pets_examples.record  \n","  inflating: models-master/research/object_detection/test_data/snapshot_serengeti_sequence_examples.record  \n","  inflating: models-master/research/object_detection/test_data/ssd_mobilenet_v1_fpp.config  \n","   creating: models-master/research/object_detection/test_images/\n","   creating: models-master/research/object_detection/test_images/ducky/\n","   creating: models-master/research/object_detection/test_images/ducky/test/\n","  inflating: models-master/research/object_detection/test_images/ducky/test/out1.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out10.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out11.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out12.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out13.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out14.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out15.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out16.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out17.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out18.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out19.jpg  \n"," extracting: models-master/research/object_detection/test_images/ducky/test/out2.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out20.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out21.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out22.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out23.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out24.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out25.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out26.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out27.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out28.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out29.jpg  \n"," extracting: models-master/research/object_detection/test_images/ducky/test/out3.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out30.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out31.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out32.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out33.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out34.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out35.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out36.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out37.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out38.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out39.jpg  \n"," extracting: models-master/research/object_detection/test_images/ducky/test/out4.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out40.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out41.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out42.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out43.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out44.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out45.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out46.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out47.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out48.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out49.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out5.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out6.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out7.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out8.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/test/out9.jpg  \n","   creating: models-master/research/object_detection/test_images/ducky/train/\n","  inflating: models-master/research/object_detection/test_images/ducky/train/robertducky1.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/train/robertducky2.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/train/robertducky3.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/train/robertducky4.jpg  \n","  inflating: models-master/research/object_detection/test_images/ducky/train/robertducky5.jpg  \n"," extracting: models-master/research/object_detection/test_images/image1.jpg  \n","  inflating: models-master/research/object_detection/test_images/image2.jpg  \n","  inflating: models-master/research/object_detection/test_images/image_info.txt  \n","   creating: models-master/research/object_detection/test_images/snapshot_serengeti/\n","  inflating: models-master/research/object_detection/test_images/snapshot_serengeti/README.md  \n","  inflating: models-master/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0038.jpeg  \n","  inflating: models-master/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0039.jpeg  \n","  inflating: models-master/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0040.jpeg  \n","  inflating: models-master/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0041.jpeg  \n","  inflating: models-master/research/object_detection/test_images/snapshot_serengeti/context_rcnn_demo_metadata.json  \n","   creating: models-master/research/object_detection/tpu_exporters/\n"," extracting: models-master/research/object_detection/tpu_exporters/__init__.py  \n","  inflating: models-master/research/object_detection/tpu_exporters/export_saved_model_tpu.py  \n","  inflating: models-master/research/object_detection/tpu_exporters/export_saved_model_tpu_lib.py  \n","  inflating: models-master/research/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py  \n","  inflating: models-master/research/object_detection/tpu_exporters/faster_rcnn.py  \n","  inflating: models-master/research/object_detection/tpu_exporters/ssd.py  \n","   creating: models-master/research/object_detection/tpu_exporters/testdata/\n"," extracting: models-master/research/object_detection/tpu_exporters/testdata/__init__.py  \n","   creating: models-master/research/object_detection/tpu_exporters/testdata/faster_rcnn/\n","  inflating: models-master/research/object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config  \n","   creating: models-master/research/object_detection/tpu_exporters/testdata/ssd/\n","  inflating: models-master/research/object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config  \n","  inflating: models-master/research/object_detection/tpu_exporters/utils.py  \n","  inflating: models-master/research/object_detection/tpu_exporters/utils_test.py  \n","   creating: models-master/research/object_detection/utils/\n"," extracting: models-master/research/object_detection/utils/__init__.py  \n","  inflating: models-master/research/object_detection/utils/autoaugment_utils.py  \n","  inflating: models-master/research/object_detection/utils/bifpn_utils.py  \n","  inflating: models-master/research/object_detection/utils/category_util.py  \n","  inflating: models-master/research/object_detection/utils/category_util_test.py  \n","  inflating: models-master/research/object_detection/utils/colab_utils.py  \n","  inflating: models-master/research/object_detection/utils/config_util.py  \n","  inflating: models-master/research/object_detection/utils/config_util_test.py  \n","  inflating: models-master/research/object_detection/utils/context_manager.py  \n","  inflating: models-master/research/object_detection/utils/context_manager_test.py  \n","  inflating: models-master/research/object_detection/utils/dataset_util.py  \n","  inflating: models-master/research/object_detection/utils/dataset_util_test.py  \n","  inflating: models-master/research/object_detection/utils/json_utils.py  \n","  inflating: models-master/research/object_detection/utils/json_utils_test.py  \n","  inflating: models-master/research/object_detection/utils/label_map_util.py  \n","  inflating: models-master/research/object_detection/utils/label_map_util_test.py  \n","  inflating: models-master/research/object_detection/utils/learning_schedules.py  \n","  inflating: models-master/research/object_detection/utils/learning_schedules_test.py  \n","  inflating: models-master/research/object_detection/utils/metrics.py  \n","  inflating: models-master/research/object_detection/utils/metrics_test.py  \n","  inflating: models-master/research/object_detection/utils/model_util.py  \n","  inflating: models-master/research/object_detection/utils/model_util_tf2_test.py  \n","  inflating: models-master/research/object_detection/utils/np_box_list.py  \n","  inflating: models-master/research/object_detection/utils/np_box_list_ops.py  \n","  inflating: models-master/research/object_detection/utils/np_box_list_ops_test.py  \n","  inflating: models-master/research/object_detection/utils/np_box_list_test.py  \n","  inflating: models-master/research/object_detection/utils/np_box_mask_list.py  \n","  inflating: models-master/research/object_detection/utils/np_box_mask_list_ops.py  \n","  inflating: models-master/research/object_detection/utils/np_box_mask_list_ops_test.py  \n","  inflating: models-master/research/object_detection/utils/np_box_mask_list_test.py  \n","  inflating: models-master/research/object_detection/utils/np_box_ops.py  \n","  inflating: models-master/research/object_detection/utils/np_box_ops_test.py  \n","  inflating: models-master/research/object_detection/utils/np_mask_ops.py  \n","  inflating: models-master/research/object_detection/utils/np_mask_ops_test.py  \n","  inflating: models-master/research/object_detection/utils/object_detection_evaluation.py  \n","  inflating: models-master/research/object_detection/utils/object_detection_evaluation_test.py  \n","  inflating: models-master/research/object_detection/utils/ops.py  \n","  inflating: models-master/research/object_detection/utils/ops_test.py  \n","  inflating: models-master/research/object_detection/utils/patch_ops.py  \n","  inflating: models-master/research/object_detection/utils/patch_ops_test.py  \n","  inflating: models-master/research/object_detection/utils/per_image_evaluation.py  \n","  inflating: models-master/research/object_detection/utils/per_image_evaluation_test.py  \n","  inflating: models-master/research/object_detection/utils/per_image_vrd_evaluation.py  \n","  inflating: models-master/research/object_detection/utils/per_image_vrd_evaluation_test.py  \n","  inflating: models-master/research/object_detection/utils/shape_utils.py  \n","  inflating: models-master/research/object_detection/utils/shape_utils_test.py  \n","  inflating: models-master/research/object_detection/utils/spatial_transform_ops.py  \n","  inflating: models-master/research/object_detection/utils/spatial_transform_ops_test.py  \n","  inflating: models-master/research/object_detection/utils/static_shape.py  \n","  inflating: models-master/research/object_detection/utils/static_shape_test.py  \n","  inflating: models-master/research/object_detection/utils/target_assigner_utils.py  \n","  inflating: models-master/research/object_detection/utils/target_assigner_utils_test.py  \n","  inflating: models-master/research/object_detection/utils/test_case.py  \n","  inflating: models-master/research/object_detection/utils/test_case_test.py  \n","  inflating: models-master/research/object_detection/utils/test_utils.py  \n","  inflating: models-master/research/object_detection/utils/test_utils_test.py  \n","  inflating: models-master/research/object_detection/utils/tf_version.py  \n","  inflating: models-master/research/object_detection/utils/variables_helper.py  \n","  inflating: models-master/research/object_detection/utils/variables_helper_tf1_test.py  \n","  inflating: models-master/research/object_detection/utils/visualization_utils.py  \n","  inflating: models-master/research/object_detection/utils/visualization_utils_test.py  \n","  inflating: models-master/research/object_detection/utils/vrd_evaluation.py  \n","  inflating: models-master/research/object_detection/utils/vrd_evaluation_test.py  \n","   creating: models-master/research/pcl_rl/\n","  inflating: models-master/research/pcl_rl/README.md  \n","  inflating: models-master/research/pcl_rl/baseline.py  \n","  inflating: models-master/research/pcl_rl/controller.py  \n","  inflating: models-master/research/pcl_rl/env_spec.py  \n","  inflating: models-master/research/pcl_rl/expert_paths.py  \n","  inflating: models-master/research/pcl_rl/full_episode_objective.py  \n","  inflating: models-master/research/pcl_rl/gym_wrapper.py  \n","  inflating: models-master/research/pcl_rl/model.py  \n","  inflating: models-master/research/pcl_rl/objective.py  \n","  inflating: models-master/research/pcl_rl/optimizers.py  \n","  inflating: models-master/research/pcl_rl/policy.py  \n","  inflating: models-master/research/pcl_rl/replay_buffer.py  \n","  inflating: models-master/research/pcl_rl/trainer.py  \n","  inflating: models-master/research/pcl_rl/trust_region.py  \n","   creating: models-master/research/rebar/\n","  inflating: models-master/research/rebar/README.md  \n","  inflating: models-master/research/rebar/config.py  \n","  inflating: models-master/research/rebar/datasets.py  \n","  inflating: models-master/research/rebar/download_data.py  \n","  inflating: models-master/research/rebar/logger.py  \n","  inflating: models-master/research/rebar/rebar.py  \n","  inflating: models-master/research/rebar/rebar_train.py  \n","  inflating: models-master/research/rebar/utils.py  \n","   creating: models-master/research/seq_flow_lite/\n","  inflating: models-master/research/seq_flow_lite/.bazelrc  \n","  inflating: models-master/research/seq_flow_lite/BUILD  \n","  inflating: models-master/research/seq_flow_lite/CONTRIBUTING.md  \n","  inflating: models-master/research/seq_flow_lite/README.md  \n","  inflating: models-master/research/seq_flow_lite/WORKSPACE  \n","   creating: models-master/research/seq_flow_lite/colab/\n","  inflating: models-master/research/seq_flow_lite/colab/BUILD  \n","  inflating: models-master/research/seq_flow_lite/colab/move_ops.sh  \n","  inflating: models-master/research/seq_flow_lite/colab/setup.py  \n","  inflating: models-master/research/seq_flow_lite/colab/setup_workspace.sh  \n","   creating: models-master/research/seq_flow_lite/configs/\n","  inflating: models-master/research/seq_flow_lite/configs/civil_comments_prado.txt  \n","  inflating: models-master/research/seq_flow_lite/configs/go_emotion_prado.txt  \n","   creating: models-master/research/seq_flow_lite/demo/\n","   creating: models-master/research/seq_flow_lite/demo/colab/\n","  inflating: models-master/research/seq_flow_lite/demo/colab/BUILD  \n","  inflating: models-master/research/seq_flow_lite/demo/colab/move_ops.sh  \n","  inflating: models-master/research/seq_flow_lite/demo/colab/setup.py  \n","  inflating: models-master/research/seq_flow_lite/demo/colab/setup_workspace.sh  \n","   creating: models-master/research/seq_flow_lite/demo/prado/\n","  inflating: models-master/research/seq_flow_lite/demo/prado/BUILD  \n","   creating: models-master/research/seq_flow_lite/demo/prado/data/\n","  inflating: models-master/research/seq_flow_lite/demo/prado/data/tflite.fb  \n","  inflating: models-master/research/seq_flow_lite/demo/prado/prado_tflite_example.cc  \n","  inflating: models-master/research/seq_flow_lite/export_to_tflite.py  \n","  inflating: models-master/research/seq_flow_lite/input_fn_reader.py  \n","   creating: models-master/research/seq_flow_lite/layers/\n","  inflating: models-master/research/seq_flow_lite/layers/BUILD  \n","  inflating: models-master/research/seq_flow_lite/layers/base_layers.py  \n","  inflating: models-master/research/seq_flow_lite/layers/conv_layers.py  \n","  inflating: models-master/research/seq_flow_lite/layers/dense_layers.py  \n","  inflating: models-master/research/seq_flow_lite/layers/normalization_layers.py  \n","  inflating: models-master/research/seq_flow_lite/layers/projection_layers.py  \n","  inflating: models-master/research/seq_flow_lite/layers/quantization_layers.py  \n","  inflating: models-master/research/seq_flow_lite/metric_functions.py  \n","   creating: models-master/research/seq_flow_lite/models/\n","  inflating: models-master/research/seq_flow_lite/models/BUILD  \n","  inflating: models-master/research/seq_flow_lite/models/prado.py  \n","   creating: models-master/research/seq_flow_lite/models/sgnn/\n","  inflating: models-master/research/seq_flow_lite/models/sgnn/BUILD  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/run_tflite.py  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/sgnn.py  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/sgnn_projection.cc  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/sgnn_projection.h  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/sgnn_projection_op_resolver.cc  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/sgnn_projection_op_resolver.h  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/sgnn_projection_test.cc  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/sgnn_test.py  \n","  inflating: models-master/research/seq_flow_lite/models/sgnn/train.py  \n","   creating: models-master/research/seq_flow_lite/tf_ops/\n","  inflating: models-master/research/seq_flow_lite/tf_ops/BUILD  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/build_def.bzl  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/projection_normalizer_util.cc  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/projection_normalizer_util.h  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/projection_tokenizer_util.cc  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/projection_tokenizer_util.h  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/projection_util.cc  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/projection_util.h  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/repo.bzl  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/sequence_string_projection.cc  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/sequence_string_projection_op_v2.cc  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/sequence_string_projection_op_v2_test.cc  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/sequence_string_projection_test.cc  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/text_distorter.cc  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/text_distorter.h  \n","  inflating: models-master/research/seq_flow_lite/tf_ops/tf_custom_ops.cc  \n","   creating: models-master/research/seq_flow_lite/tflite_ops/\n","  inflating: models-master/research/seq_flow_lite/tflite_ops/BUILD  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/expected_value.cc  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/expected_value.h  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/layer_norm.cc  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/layer_norm.h  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/layer_norm_test.cc  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/quantization_util.h  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/sequence_string_projection.cc  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/sequence_string_projection.h  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/sequence_string_projection_test.cc  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/tf_tflite_diff_test_util.cc  \n","  inflating: models-master/research/seq_flow_lite/tflite_ops/tf_tflite_diff_test_util.h  \n","   creating: models-master/research/seq_flow_lite/third_party/\n"," extracting: models-master/research/seq_flow_lite/third_party/BUILD  \n","   creating: models-master/research/seq_flow_lite/third_party/android/\n"," extracting: models-master/research/seq_flow_lite/third_party/android/BUILD  \n","  inflating: models-master/research/seq_flow_lite/third_party/android/android.bzl.tpl  \n"," extracting: models-master/research/seq_flow_lite/third_party/android/android_configure.BUILD.tpl  \n","  inflating: models-master/research/seq_flow_lite/third_party/android/android_configure.bzl  \n","  inflating: models-master/research/seq_flow_lite/third_party/farmhash.BUILD  \n","   creating: models-master/research/seq_flow_lite/third_party/flatbuffers/\n","  inflating: models-master/research/seq_flow_lite/third_party/flatbuffers/BUILD  \n","  inflating: models-master/research/seq_flow_lite/third_party/flatbuffers/BUILD.bazel  \n","  inflating: models-master/research/seq_flow_lite/third_party/flatbuffers/build_defs.bzl  \n","  inflating: models-master/research/seq_flow_lite/third_party/flatbuffers/workspace.bzl  \n","  inflating: models-master/research/seq_flow_lite/third_party/icu.BUILD  \n","  inflating: models-master/research/seq_flow_lite/third_party/protobuf.BUILD  \n","   creating: models-master/research/seq_flow_lite/third_party/py/\n"," extracting: models-master/research/seq_flow_lite/third_party/py/BUILD  \n","  inflating: models-master/research/seq_flow_lite/third_party/py/BUILD.tpl  \n","  inflating: models-master/research/seq_flow_lite/third_party/py/python_configure.bzl  \n","  inflating: models-master/research/seq_flow_lite/third_party/pybind11.BUILD  \n","   creating: models-master/research/seq_flow_lite/third_party/python_runtime/\n","  inflating: models-master/research/seq_flow_lite/third_party/python_runtime/BUILD  \n","  inflating: models-master/research/seq_flow_lite/third_party/repo.bzl  \n","  inflating: models-master/research/seq_flow_lite/third_party/utf.BUILD  \n","  inflating: models-master/research/seq_flow_lite/trainer.py  \n","   creating: models-master/research/seq_flow_lite/utils/\n","  inflating: models-master/research/seq_flow_lite/utils/BUILD  \n","  inflating: models-master/research/seq_flow_lite/utils/misc_utils.py  \n","  inflating: models-master/research/seq_flow_lite/utils/tflite_utils.py  \n","  inflating: models-master/research/setup.py  \n","   creating: models-master/research/slim/\n","  inflating: models-master/research/slim/BUILD  \n","  inflating: models-master/research/slim/README.md  \n"," extracting: models-master/research/slim/WORKSPACE  \n"," extracting: models-master/research/slim/__init__.py  \n","   creating: models-master/research/slim/datasets/\n"," extracting: models-master/research/slim/datasets/__init__.py  \n","  inflating: models-master/research/slim/datasets/build_imagenet_data.py  \n","  inflating: models-master/research/slim/datasets/cifar10.py  \n","  inflating: models-master/research/slim/datasets/dataset_factory.py  \n","  inflating: models-master/research/slim/datasets/dataset_utils.py  \n","  inflating: models-master/research/slim/datasets/download_and_convert_cifar10.py  \n","  inflating: models-master/research/slim/datasets/download_and_convert_flowers.py  \n","  inflating: models-master/research/slim/datasets/download_and_convert_imagenet.sh  \n","  inflating: models-master/research/slim/datasets/download_and_convert_mnist.py  \n","  inflating: models-master/research/slim/datasets/download_and_convert_visualwakewords.py  \n","  inflating: models-master/research/slim/datasets/download_and_convert_visualwakewords_lib.py  \n","  inflating: models-master/research/slim/datasets/download_imagenet.sh  \n","  inflating: models-master/research/slim/datasets/flowers.py  \n","  inflating: models-master/research/slim/datasets/imagenet.py  \n","  inflating: models-master/research/slim/datasets/imagenet_2012_validation_synset_labels.txt  \n","  inflating: models-master/research/slim/datasets/imagenet_lsvrc_2015_synsets.txt  \n","  inflating: models-master/research/slim/datasets/imagenet_metadata.txt  \n","  inflating: models-master/research/slim/datasets/mnist.py  \n","  inflating: models-master/research/slim/datasets/preprocess_imagenet_validation_data.py  \n","  inflating: models-master/research/slim/datasets/process_bounding_boxes.py  \n","  inflating: models-master/research/slim/datasets/visualwakewords.py  \n","   creating: models-master/research/slim/deployment/\n"," extracting: models-master/research/slim/deployment/__init__.py  \n","  inflating: models-master/research/slim/deployment/model_deploy.py  \n","  inflating: models-master/research/slim/deployment/model_deploy_test.py  \n","  inflating: models-master/research/slim/download_and_convert_data.py  \n","  inflating: models-master/research/slim/eval_image_classifier.py  \n","  inflating: models-master/research/slim/export_inference_graph.py  \n","  inflating: models-master/research/slim/export_inference_graph_test.py  \n","   creating: models-master/research/slim/nets/\n"," extracting: models-master/research/slim/nets/__init__.py  \n","  inflating: models-master/research/slim/nets/alexnet.py  \n","  inflating: models-master/research/slim/nets/alexnet_test.py  \n","  inflating: models-master/research/slim/nets/cifarnet.py  \n","  inflating: models-master/research/slim/nets/cyclegan.py  \n","  inflating: models-master/research/slim/nets/cyclegan_test.py  \n","  inflating: models-master/research/slim/nets/dcgan.py  \n","  inflating: models-master/research/slim/nets/dcgan_test.py  \n","  inflating: models-master/research/slim/nets/i3d.py  \n","  inflating: models-master/research/slim/nets/i3d_test.py  \n","  inflating: models-master/research/slim/nets/i3d_utils.py  \n","  inflating: models-master/research/slim/nets/inception.py  \n","  inflating: models-master/research/slim/nets/inception_resnet_v2.py  \n","  inflating: models-master/research/slim/nets/inception_resnet_v2_test.py  \n","  inflating: models-master/research/slim/nets/inception_utils.py  \n","  inflating: models-master/research/slim/nets/inception_v1.py  \n","  inflating: models-master/research/slim/nets/inception_v1_test.py  \n","  inflating: models-master/research/slim/nets/inception_v2.py  \n","  inflating: models-master/research/slim/nets/inception_v2_test.py  \n","  inflating: models-master/research/slim/nets/inception_v3.py  \n","  inflating: models-master/research/slim/nets/inception_v3_test.py  \n","  inflating: models-master/research/slim/nets/inception_v4.py  \n","  inflating: models-master/research/slim/nets/inception_v4_test.py  \n","  inflating: models-master/research/slim/nets/lenet.py  \n","   creating: models-master/research/slim/nets/mobilenet/\n","  inflating: models-master/research/slim/nets/mobilenet/README.md  \n"," extracting: models-master/research/slim/nets/mobilenet/__init__.py  \n","  inflating: models-master/research/slim/nets/mobilenet/conv_blocks.py  \n","   creating: models-master/research/slim/nets/mobilenet/g3doc/\n","  inflating: models-master/research/slim/nets/mobilenet/g3doc/edgetpu_latency.png  \n","  inflating: models-master/research/slim/nets/mobilenet/g3doc/latency_pixel1.png  \n","  inflating: models-master/research/slim/nets/mobilenet/g3doc/madds_top1_accuracy.png  \n","  inflating: models-master/research/slim/nets/mobilenet/mnet_v1_vs_v2_pixel1_latency.png  \n","  inflating: models-master/research/slim/nets/mobilenet/mobilenet.py  \n","  inflating: models-master/research/slim/nets/mobilenet/mobilenet_example.ipynb  \n","  inflating: models-master/research/slim/nets/mobilenet/mobilenet_v2.py  \n","  inflating: models-master/research/slim/nets/mobilenet/mobilenet_v2_test.py  \n","  inflating: models-master/research/slim/nets/mobilenet/mobilenet_v3.py  \n","  inflating: models-master/research/slim/nets/mobilenet/mobilenet_v3_test.py  \n","  inflating: models-master/research/slim/nets/mobilenet_v1.md  \n","  inflating: models-master/research/slim/nets/mobilenet_v1.png  \n","  inflating: models-master/research/slim/nets/mobilenet_v1.py  \n","  inflating: models-master/research/slim/nets/mobilenet_v1_eval.py  \n","  inflating: models-master/research/slim/nets/mobilenet_v1_test.py  \n","  inflating: models-master/research/slim/nets/mobilenet_v1_train.py  \n","   creating: models-master/research/slim/nets/nasnet/\n","  inflating: models-master/research/slim/nets/nasnet/README.md  \n"," extracting: models-master/research/slim/nets/nasnet/__init__.py  \n","  inflating: models-master/research/slim/nets/nasnet/nasnet.py  \n","  inflating: models-master/research/slim/nets/nasnet/nasnet_test.py  \n","  inflating: models-master/research/slim/nets/nasnet/nasnet_utils.py  \n","  inflating: models-master/research/slim/nets/nasnet/nasnet_utils_test.py  \n","  inflating: models-master/research/slim/nets/nasnet/pnasnet.py  \n","  inflating: models-master/research/slim/nets/nasnet/pnasnet_test.py  \n","  inflating: models-master/research/slim/nets/nets_factory.py  \n","  inflating: models-master/research/slim/nets/nets_factory_test.py  \n","  inflating: models-master/research/slim/nets/overfeat.py  \n","  inflating: models-master/research/slim/nets/overfeat_test.py  \n","  inflating: models-master/research/slim/nets/pix2pix.py  \n","  inflating: models-master/research/slim/nets/pix2pix_test.py  \n","  inflating: models-master/research/slim/nets/post_training_quantization.py  \n","  inflating: models-master/research/slim/nets/resnet_utils.py  \n","  inflating: models-master/research/slim/nets/resnet_v1.py  \n","  inflating: models-master/research/slim/nets/resnet_v1_test.py  \n","  inflating: models-master/research/slim/nets/resnet_v2.py  \n","  inflating: models-master/research/slim/nets/resnet_v2_test.py  \n","  inflating: models-master/research/slim/nets/s3dg.py  \n","  inflating: models-master/research/slim/nets/s3dg_test.py  \n","  inflating: models-master/research/slim/nets/vgg.py  \n","  inflating: models-master/research/slim/nets/vgg_test.py  \n","   creating: models-master/research/slim/preprocessing/\n"," extracting: models-master/research/slim/preprocessing/__init__.py  \n","  inflating: models-master/research/slim/preprocessing/cifarnet_preprocessing.py  \n","  inflating: models-master/research/slim/preprocessing/inception_preprocessing.py  \n","  inflating: models-master/research/slim/preprocessing/lenet_preprocessing.py  \n","  inflating: models-master/research/slim/preprocessing/preprocessing_factory.py  \n","  inflating: models-master/research/slim/preprocessing/vgg_preprocessing.py  \n","   creating: models-master/research/slim/scripts/\n","  inflating: models-master/research/slim/scripts/export_mobilenet.sh  \n","  inflating: models-master/research/slim/scripts/finetune_inception_resnet_v2_on_flowers.sh  \n","  inflating: models-master/research/slim/scripts/finetune_inception_v1_on_flowers.sh  \n","  inflating: models-master/research/slim/scripts/finetune_inception_v3_on_flowers.sh  \n","  inflating: models-master/research/slim/scripts/finetune_resnet_v1_50_on_flowers.sh  \n","  inflating: models-master/research/slim/scripts/train_cifarnet_on_cifar10.sh  \n","  inflating: models-master/research/slim/scripts/train_lenet_on_mnist.sh  \n","  inflating: models-master/research/slim/setup.py  \n","  inflating: models-master/research/slim/slim_walkthrough.ipynb  \n","  inflating: models-master/research/slim/train_image_classifier.py  \n","   creating: models-master/research/vid2depth/\n","  inflating: models-master/research/vid2depth/.bazelrc  \n","  inflating: models-master/research/vid2depth/BUILD  \n","  inflating: models-master/research/vid2depth/README.md  \n","  inflating: models-master/research/vid2depth/WORKSPACE  \n","   creating: models-master/research/vid2depth/dataset/\n","  inflating: models-master/research/vid2depth/dataset/__init__.py  \n","  inflating: models-master/research/vid2depth/dataset/dataset_loader.py  \n","  inflating: models-master/research/vid2depth/dataset/gen_data.py  \n","   creating: models-master/research/vid2depth/dataset/kitti/\n","  inflating: models-master/research/vid2depth/dataset/kitti/static_frames.txt  \n","  inflating: models-master/research/vid2depth/dataset/kitti/test_files_eigen.txt  \n","  inflating: models-master/research/vid2depth/dataset/kitti/test_files_stereo.txt  \n","  inflating: models-master/research/vid2depth/dataset/kitti/test_scenes_eigen.txt  \n","  inflating: models-master/research/vid2depth/dataset/kitti/test_scenes_stereo.txt  \n","  inflating: models-master/research/vid2depth/inference.py  \n","  inflating: models-master/research/vid2depth/model.py  \n","  inflating: models-master/research/vid2depth/nets.py  \n","   creating: models-master/research/vid2depth/ops/\n","  inflating: models-master/research/vid2depth/ops/BUILD  \n","  inflating: models-master/research/vid2depth/ops/__init__.py  \n","  inflating: models-master/research/vid2depth/ops/icp_grad.py  \n","  inflating: models-master/research/vid2depth/ops/icp_grad_test.py  \n","  inflating: models-master/research/vid2depth/ops/icp_op.py  \n","  inflating: models-master/research/vid2depth/ops/icp_op_kernel.cc  \n","  inflating: models-master/research/vid2depth/ops/icp_test.py  \n","  inflating: models-master/research/vid2depth/ops/icp_train_demo.py  \n","  inflating: models-master/research/vid2depth/ops/icp_util.py  \n","  inflating: models-master/research/vid2depth/ops/pcl_demo.cc  \n","   creating: models-master/research/vid2depth/ops/testdata/\n","  inflating: models-master/research/vid2depth/ops/testdata/pointcloud.npy  \n","  inflating: models-master/research/vid2depth/project.py  \n","  inflating: models-master/research/vid2depth/reader.py  \n","  inflating: models-master/research/vid2depth/repo.bzl  \n","   creating: models-master/research/vid2depth/third_party/\n"," extracting: models-master/research/vid2depth/third_party/BUILD  \n","  inflating: models-master/research/vid2depth/third_party/eigen.BUILD  \n","  inflating: models-master/research/vid2depth/third_party/flann.BUILD  \n","  inflating: models-master/research/vid2depth/third_party/hdf5.BUILD  \n","  inflating: models-master/research/vid2depth/third_party/pcl.BUILD  \n","  inflating: models-master/research/vid2depth/train.py  \n","  inflating: models-master/research/vid2depth/util.py  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6F6BlIw0Dct8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608054979083,"user_tz":-330,"elapsed":5326,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"26766687-7899-4e7d-c9e0-cb01632d47b6"},"source":["%cd /content/models-master/research/object_detection\n","\n","!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n","!tar -zxvf ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/models-master/research/object_detection\n","--2020-12-15 17:56:15--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.20.128, 2607:f8b0:400e:c09::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.20.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 144806142 (138M) [application/x-tar]\n","Saving to: ‘ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz’\n","\n","ssd_mobilenet_v2_qu 100%[===================>] 138.10M   114MB/s    in 1.2s    \n","\n","2020-12-15 17:56:17 (114 MB/s) - ‘ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz’ saved [144806142/144806142]\n","\n","ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/\n","ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt.data-00000-of-00001\n","ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt.index\n","ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt.meta\n","ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/pipeline.config\n","ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/tflite_graph.pb\n","ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/tflite_graph.pbtxt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oxoPGoSiDmIb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608054992497,"user_tz":-330,"elapsed":12153,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"70933908-3229-490a-d6d9-9268dbfccf98"},"source":["!apt-get install protobuf-compiler python-pil python-lxml python-tk\n","!pip install Cython\n","%cd /content/models-master/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models-master/research/:/content/models-master/research/slim'\n","\n","!python setup.py build\n","!python setup.py install"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","python-tk is already the newest version (2.7.17-1~18.04).\n","The following additional packages will be installed:\n","  python-bs4 python-chardet python-html5lib python-olefile\n","  python-pkg-resources python-six python-webencodings\n","Suggested packages:\n","  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n","  python-setuptools\n","The following NEW packages will be installed:\n","  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n","  python-pil python-pkg-resources python-six python-webencodings\n","0 upgraded, 9 newly installed, 0 to remove and 14 not upgraded.\n","Need to get 1,791 kB of archives.\n","After this operation, 7,807 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n","Ign:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-pil amd64 5.1.0-1ubuntu0.3 [301 kB]\n","Err:7 http://security.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1\n","  404  Not Found [IP: 91.189.88.152 80]\n","Fetched 716 kB in 2s (460 kB/s)\n","E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/l/lxml/python-lxml_4.2.1-1ubuntu0.1_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n","E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n","/content/models-master/research\n","running build\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph_lib.py -> build/lib/object_detection\n","copying object_detection/export_tflite_graph_lib_tf2.py -> build/lib/object_detection\n","copying object_detection/eval_util.py -> build/lib/object_detection\n","copying object_detection/export_tflite_graph_tf2.py -> build/lib/object_detection\n","copying object_detection/model_lib.py -> build/lib/object_detection\n","copying object_detection/export_tflite_graph_lib_tf2_test.py -> build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph.py -> build/lib/object_detection\n","copying object_detection/model_lib_tf1_test.py -> build/lib/object_detection\n","copying object_detection/model_hparams.py -> build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph_lib_tf1_test.py -> build/lib/object_detection\n","copying object_detection/model_lib_v2.py -> build/lib/object_detection\n","copying object_detection/eval_util_test.py -> build/lib/object_detection\n","copying object_detection/model_main_tf2.py -> build/lib/object_detection\n","copying object_detection/exporter_lib_v2.py -> build/lib/object_detection\n","copying object_detection/inputs_test.py -> build/lib/object_detection\n","copying object_detection/model_tpu_main.py -> build/lib/object_detection\n","copying object_detection/model_main.py -> build/lib/object_detection\n","copying object_detection/model_lib_tf2_test.py -> build/lib/object_detection\n","copying object_detection/__init__.py -> build/lib/object_detection\n","copying object_detection/exporter_lib_tf2_test.py -> build/lib/object_detection\n","copying object_detection/export_inference_graph.py -> build/lib/object_detection\n","copying object_detection/inputs.py -> build/lib/object_detection\n","copying object_detection/exporter.py -> build/lib/object_detection\n","copying object_detection/exporter_main_v2.py -> build/lib/object_detection\n","copying object_detection/exporter_tf1_test.py -> build/lib/object_detection\n","creating build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_example_decoder_test.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_sequence_example_decoder_test.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_sequence_example_decoder.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/__init__.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_example_decoder.py -> build/lib/object_detection/data_decoders\n","creating build/lib/object_detection/core\n","copying object_detection/core/batch_multiclass_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/post_processing.py -> build/lib/object_detection/core\n","copying object_detection/core/class_agnostic_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/freezable_batch_norm.py -> build/lib/object_detection/core\n","copying object_detection/core/batcher.py -> build/lib/object_detection/core\n","copying object_detection/core/keypoint_ops.py -> build/lib/object_detection/core\n","copying object_detection/core/matcher.py -> build/lib/object_detection/core\n","copying object_detection/core/keypoint_ops_test.py -> build/lib/object_detection/core\n","copying object_detection/core/data_parser.py -> build/lib/object_detection/core\n","copying object_detection/core/prefetcher.py -> build/lib/object_detection/core\n","copying object_detection/core/box_predictor.py -> build/lib/object_detection/core\n","copying object_detection/core/prefetcher_tf1_test.py -> build/lib/object_detection/core\n","copying object_detection/core/region_similarity_calculator.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_coder.py -> build/lib/object_detection/core\n","copying object_detection/core/box_coder_test.py -> build/lib/object_detection/core\n","copying object_detection/core/anchor_generator.py -> build/lib/object_detection/core\n","copying object_detection/core/data_decoder.py -> build/lib/object_detection/core\n","copying object_detection/core/minibatch_sampler.py -> build/lib/object_detection/core\n","copying object_detection/core/losses.py -> build/lib/object_detection/core\n","copying object_detection/core/balanced_positive_negative_sampler_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list.py -> build/lib/object_detection/core\n","copying object_detection/core/batcher_tf1_test.py -> build/lib/object_detection/core\n","copying object_detection/core/region_similarity_calculator_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_ops_test.py -> build/lib/object_detection/core\n","copying object_detection/core/losses_test.py -> build/lib/object_detection/core\n","copying object_detection/core/densepose_ops_test.py -> build/lib/object_detection/core\n","copying object_detection/core/matcher_test.py -> build/lib/object_detection/core\n","copying object_detection/core/minibatch_sampler_test.py -> build/lib/object_detection/core\n","copying object_detection/core/balanced_positive_negative_sampler.py -> build/lib/object_detection/core\n","copying object_detection/core/target_assigner_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_ops.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor_cache.py -> build/lib/object_detection/core\n","copying object_detection/core/model.py -> build/lib/object_detection/core\n","copying object_detection/core/densepose_ops.py -> build/lib/object_detection/core\n","copying object_detection/core/freezable_batch_norm_tf2_test.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor.py -> build/lib/object_detection/core\n","copying object_detection/core/__init__.py -> build/lib/object_detection/core\n","copying object_detection/core/multiclass_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/standard_fields.py -> build/lib/object_detection/core\n","copying object_detection/core/model_test.py -> build/lib/object_detection/core\n","copying object_detection/core/target_assigner.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor_test.py -> build/lib/object_detection/core\n","creating build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/__init__.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","creating build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/utils_test.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/faster_rcnn.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/__init__.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/ssd.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/utils.py -> build/lib/object_detection/tpu_exporters\n","creating build/lib/object_detection/box_coders\n","copying object_detection/box_coders/faster_rcnn_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/keypoint_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/mean_stddev_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/square_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/keypoint_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/__init__.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/square_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/mean_stddev_box_coder_test.py -> build/lib/object_detection/box_coders\n","creating build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_tools_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/lvis_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_evaluation_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_tools.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_metrics_tf1_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/tf_example_parser.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/io_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/lvis_evaluation_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/lvis_tools_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/offline_eval_map_corloc.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_metrics.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/__init__.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_evaluation_tf1_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/lvis_tools.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/offline_eval_map_corloc_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/tf_example_parser_test.py -> build/lib/object_detection/metrics\n","creating build/lib/object_detection/matchers\n","copying object_detection/matchers/argmax_matcher_test.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/hungarian_matcher_tf2_test.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/argmax_matcher.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/bipartite_matcher_tf1_test.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/hungarian_matcher.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/bipartite_matcher.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/__init__.py -> build/lib/object_detection/matchers\n","creating build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_mobilenet_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_hourglass_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_pnasnet_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v3_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_resnet_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobiledet_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/feature_map_generators_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/__init__.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/bidirectional_feature_pyramid_generators.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/feature_map_generators.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_resnet_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py -> build/lib/object_detection/models\n","creating build/lib/object_detection/inference\n","copying object_detection/inference/infer_detections.py -> build/lib/object_detection/inference\n","copying object_detection/inference/detection_inference.py -> build/lib/object_detection/inference\n","copying object_detection/inference/detection_inference_tf1_test.py -> build/lib/object_detection/inference\n","copying object_detection/inference/__init__.py -> build/lib/object_detection/inference\n","creating build/lib/object_detection/builders\n","copying object_detection/builders/input_reader_builder_tf1_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder_tf1_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/optimizer_builder_tf2_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/hyperparams_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_predictor_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/graph_rewriter_builder_tf1_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/post_processing_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/hyperparams_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/region_similarity_calculator_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/calibration_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/losses_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/target_assigner_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/optimizer_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_predictor_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder_tf2_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/matcher_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/decoder_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/input_reader_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/optimizer_builder_tf1_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/dataset_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/dataset_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/anchor_generator_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/graph_rewriter_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/preprocessor_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/calibration_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/image_resizer_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/region_similarity_calculator_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/__init__.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_coder_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/post_processing_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/matcher_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/anchor_generator_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_coder_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/losses_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/preprocessor_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/image_resizer_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/target_assigner_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/decoder_builder.py -> build/lib/object_detection/builders\n","creating build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/static_shape.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_vrd_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/dataset_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/patch_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/label_map_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/label_map_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/vrd_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_mask_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/json_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list.py -> build/lib/object_detection/utils\n","copying object_detection/utils/category_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/spatial_transform_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/variables_helper.py -> build/lib/object_detection/utils\n","copying object_detection/utils/model_util_tf2_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/target_assigner_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/colab_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_case.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/model_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/category_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/variables_helper_tf1_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/metrics_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/context_manager.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list.py -> build/lib/object_detection/utils\n","copying object_detection/utils/config_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/visualization_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/vrd_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/learning_schedules.py -> build/lib/object_detection/utils\n","copying object_detection/utils/json_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/shape_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/static_shape_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/learning_schedules_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/target_assigner_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/spatial_transform_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/patch_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/context_manager_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/visualization_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_case_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/shape_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/bifpn_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/config_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/metrics.py -> build/lib/object_detection/utils\n","copying object_detection/utils/object_detection_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/tf_version.py -> build/lib/object_detection/utils\n","copying object_detection/utils/dataset_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/object_detection_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/__init__.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_vrd_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_mask_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/autoaugment_utils.py -> build/lib/object_detection/utils\n","creating build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/rfcn_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/center_net_meta_arch_tf2_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_lib_tf1_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/center_net_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_lib_tf2_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_lib_tf2.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/__init__.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/context_rcnn_lib.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/lib/object_detection/meta_architectures\n","creating build/lib/object_detection/protos\n","copying object_detection/protos/string_int_label_map_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/center_net_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/box_predictor_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/optimizer_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/preprocessor_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/multiscale_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/input_reader_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/square_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/post_processing_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/mean_stddev_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/model_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/fpn_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/target_assigner_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/calibration_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/hyperparams_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/eval_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/train_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/__init__.py -> build/lib/object_detection/protos\n","copying object_detection/protos/bipartite_matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/losses_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/graph_rewriter_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/pipeline_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/argmax_matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/keypoint_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/image_resizer_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/region_similarity_calculator_pb2.py -> build/lib/object_detection/protos\n","creating build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_coco_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_tfrecord_creation.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_oid_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_coco_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pascal_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/tf_record_creation_util_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/seq_example_util_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pet_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/__init__.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/seq_example_util.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_kitti_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/tf_record_creation_util.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_ava_actions_tf_record.py -> build/lib/object_detection/dataset_tools\n","creating build/lib/object_detection/legacy\n","copying object_detection/legacy/train.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/evaluator.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/trainer_tf1_test.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/__init__.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/eval.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/trainer.py -> build/lib/object_detection/legacy\n","creating build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_box_predictor_tf1_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_keras_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_box_predictor_tf1_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/__init__.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_keras_box_predictor.py -> build/lib/object_detection/predictors\n","creating build/lib/object_detection/tpu_exporters/testdata\n","copying object_detection/tpu_exporters/testdata/__init__.py -> build/lib/object_detection/tpu_exporters/testdata\n","creating build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v1.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/model_utils.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/resnet_v1_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/convert_keras_models.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v1_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/inception_resnet_v2.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v2.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v2_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/hourglass_network_tf2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/resnet_v1.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/__init__.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/hourglass_network.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/test_utils.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/inception_resnet_v2_tf2_test.py -> build/lib/object_detection/models/keras_models\n","creating build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/generate_detection_data.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/add_context_to_examples.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/generate_embedding_data.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/__init__.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","copying object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py -> build/lib/object_detection/dataset_tools/context_rcnn\n","creating build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_class_head_tf2_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_mask_head_tf2_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keypoint_head_tf1_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_mask_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/mask_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keypoint_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_class_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/class_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/class_head_tf1_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_box_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/__init__.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/box_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/mask_head_tf1_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/box_head_tf1_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_box_head_tf2_test.py -> build/lib/object_detection/predictors/heads\n","running egg_info\n","creating object_detection.egg-info\n","writing object_detection.egg-info/PKG-INFO\n","writing dependency_links to object_detection.egg-info/dependency_links.txt\n","writing requirements to object_detection.egg-info/requires.txt\n","writing top-level names to object_detection.egg-info/top_level.txt\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","reading manifest file 'object_detection.egg-info/SOURCES.txt'\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","running install\n","running bdist_egg\n","running egg_info\n","writing object_detection.egg-info/PKG-INFO\n","writing dependency_links to object_detection.egg-info/dependency_links.txt\n","writing requirements to object_detection.egg-info/requires.txt\n","writing top-level names to object_detection.egg-info/top_level.txt\n","reading manifest file 'object_detection.egg-info/SOURCES.txt'\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_ssd_graph_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_graph_lib_tf2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/eval_util.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_graph_tf2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_example_decoder_test.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_sequence_example_decoder_test.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_sequence_example_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_example_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/export_tflite_graph_lib_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batch_multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/post_processing.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/class_agnostic_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/freezable_batch_norm.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/keypoint_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/matcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/keypoint_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/data_parser.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/prefetcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/prefetcher_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/region_similarity_calculator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/data_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/minibatch_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/losses.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/balanced_positive_negative_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batcher_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/region_similarity_calculator_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/losses_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/densepose_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/minibatch_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/balanced_positive_negative_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/target_assigner_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor_cache.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/model.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/densepose_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/freezable_batch_norm_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/standard_fields.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/model_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/target_assigner.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/export_tflite_ssd_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/faster_rcnn.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/ssd.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/utils.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n","copying build/lib/object_detection/tpu_exporters/testdata/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n","copying build/lib/object_detection/model_lib_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/faster_rcnn_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/keypoint_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/mean_stddev_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/square_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/keypoint_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/square_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/mean_stddev_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/model_hparams.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_ssd_graph_lib_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_tools_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/lvis_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_tools.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_metrics_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/tf_example_parser.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/io_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/lvis_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/lvis_tools_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/offline_eval_map_corloc.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_metrics.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_evaluation_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/lvis_tools.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/offline_eval_map_corloc_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/tf_example_parser_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","creating build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/argmax_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/hungarian_matcher_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/argmax_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/bipartite_matcher_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/hungarian_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/bipartite_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","creating build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_mobilenet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_hourglass_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_resnet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobiledet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/feature_map_generators_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/model_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/resnet_v1_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/convert_keras_models.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v1_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/inception_resnet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v2_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/hourglass_network_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/resnet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/hourglass_network.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/inception_resnet_v2_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/bidirectional_feature_pyramid_generators.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/feature_map_generators.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_resnet_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/eval_util_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/infer_detections.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/detection_inference.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/detection_inference_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","creating build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/input_reader_builder_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/hyperparams_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_predictor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/graph_rewriter_builder_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/post_processing_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/hyperparams_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/region_similarity_calculator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/calibration_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/losses_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/target_assigner_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_predictor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/matcher_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/decoder_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/input_reader_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/dataset_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/dataset_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/anchor_generator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/graph_rewriter_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/preprocessor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/calibration_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/image_resizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/region_similarity_calculator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_coder_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/post_processing_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/matcher_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/anchor_generator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_coder_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/losses_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/preprocessor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/image_resizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/target_assigner_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/decoder_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/model_main_tf2.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/static_shape.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/dataset_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/patch_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/label_map_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/label_map_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_mask_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/json_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/category_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/spatial_transform_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/variables_helper.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/model_util_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/target_assigner_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/colab_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_case.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/model_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/category_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/variables_helper_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/context_manager.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/config_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/visualization_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/learning_schedules.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/json_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/shape_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/static_shape_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/learning_schedules_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/target_assigner_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/spatial_transform_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/patch_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/context_manager_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/visualization_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_case_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/shape_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/bifpn_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/config_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/metrics.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/object_detection_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/tf_version.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/dataset_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/object_detection_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_mask_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/autoaugment_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","creating build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/rfcn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_lib_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/center_net_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_lib_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_lib_tf2.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/context_rcnn_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/exporter_lib_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/inputs_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_tpu_main.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_main.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/__init__.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter_lib_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/string_int_label_map_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/center_net_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_predictor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/optimizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/preprocessor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/multiscale_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/input_reader_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/square_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/post_processing_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/mean_stddev_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/model_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/fpn_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/target_assigner_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/calibration_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/hyperparams_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/eval_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/train_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/bipartite_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/losses_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/graph_rewriter_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/pipeline_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/argmax_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/keypoint_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/image_resizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/region_similarity_calculator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/export_inference_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/inputs.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_coco_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_oid_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_coco_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pascal_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/generate_detection_data.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn\n","copying build/lib/object_detection/dataset_tools/tf_record_creation_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/seq_example_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pet_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/seq_example_util.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_kitti_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/tf_record_creation_util.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_ava_actions_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","creating build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/train.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/evaluator.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/trainer_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/eval.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/trainer.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/exporter.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_box_predictor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","creating build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_class_head_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_mask_head_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keypoint_head_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keypoint_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/class_head_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/mask_head_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/box_head_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_box_head_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_box_predictor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/exporter_main_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/exporter_tf1_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib.py to export_tflite_ssd_graph_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_graph_lib_tf2.py to export_tflite_graph_lib_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util.py to eval_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_graph_tf2.py to export_tflite_graph_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib.py to model_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder_test.py to tf_example_decoder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_sequence_example_decoder_test.py to tf_sequence_example_decoder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_sequence_example_decoder.py to tf_sequence_example_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder.py to tf_example_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_graph_lib_tf2_test.py to export_tflite_graph_lib_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batch_multiclass_nms_test.py to batch_multiclass_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/post_processing.py to post_processing.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/class_agnostic_nms_test.py to class_agnostic_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm.py to freezable_batch_norm.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher.py to batcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops.py to keypoint_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher.py to matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops_test.py to keypoint_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_parser.py to data_parser.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher.py to prefetcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_predictor.py to box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher_tf1_test.py to prefetcher_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator.py to region_similarity_calculator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_test.py to box_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder.py to box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder_test.py to box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/anchor_generator.py to anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_decoder.py to data_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler.py to minibatch_sampler.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses.py to losses.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler_test.py to balanced_positive_negative_sampler_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list.py to box_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher_tf1_test.py to batcher_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator_test.py to region_similarity_calculator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops_test.py to box_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses_test.py to losses_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/densepose_ops_test.py to densepose_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher_test.py to matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler_test.py to minibatch_sampler_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler.py to balanced_positive_negative_sampler.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner_test.py to target_assigner_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops.py to box_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_cache.py to preprocessor_cache.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/model.py to model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/densepose_ops.py to densepose_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm_tf2_test.py to freezable_batch_norm_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor.py to preprocessor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/multiclass_nms_test.py to multiclass_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/standard_fields.py to standard_fields.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/model_test.py to model_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner.py to target_assigner.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_test.py to preprocessor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph.py to export_tflite_ssd_graph.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator_test.py to grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator.py to multiple_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py to multiscale_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py to flexible_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator.py to grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator.py to flexible_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py to multiple_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator.py to multiscale_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils_test.py to utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib.py to export_saved_model_tpu_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/faster_rcnn.py to faster_rcnn.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py to export_saved_model_tpu_lib_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu.py to export_saved_model_tpu.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/ssd.py to ssd.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils.py to utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_tf1_test.py to model_lib_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder.py to faster_rcnn_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder_test.py to faster_rcnn_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder.py to keypoint_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder.py to mean_stddev_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder.py to square_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder_test.py to keypoint_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder_test.py to square_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder_test.py to mean_stddev_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_hparams.py to model_hparams.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib_tf1_test.py to export_tflite_ssd_graph_lib_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2.py to model_lib_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation.py to oid_vrd_challenge_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools_test.py to coco_tools_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/lvis_evaluation.py to lvis_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation.py to oid_challenge_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils.py to oid_challenge_evaluation_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py to oid_vrd_challenge_evaluation_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation_test.py to coco_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools.py to coco_tools.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics_tf1_test.py to calibration_metrics_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser.py to tf_example_parser.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation.py to coco_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/io_utils.py to io_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/lvis_evaluation_test.py to lvis_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/lvis_tools_test.py to lvis_tools_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py to oid_vrd_challenge_evaluation_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc.py to offline_eval_map_corloc.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation.py to calibration_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics.py to calibration_metrics.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation_tf1_test.py to calibration_evaluation_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/lvis_tools.py to lvis_tools.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc_test.py to offline_eval_map_corloc_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils_test.py to oid_challenge_evaluation_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser_test.py to tf_example_parser_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher_test.py to argmax_matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/hungarian_matcher_tf2_test.py to hungarian_matcher_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher.py to argmax_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher_tf1_test.py to bipartite_matcher_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/hungarian_matcher.py to hungarian_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher.py to bipartite_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py to faster_rcnn_resnet_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_mobilenet_v2_feature_extractor.py to center_net_mobilenet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py to faster_rcnn_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_hourglass_feature_extractor.py to center_net_hourglass_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py to embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py to ssd_mobilenet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py to ssd_mobilenet_v1_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py to ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py to ssd_mobilenet_v1_ppn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py to center_net_mobilenet_v2_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py to bidirectional_feature_pyramid_generators_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor.py to ssd_pnasnet_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py to ssd_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py to center_net_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py to faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py to ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_feature_extractor_test.py to ssd_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py to ssd_inception_v2_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py to faster_rcnn_pnas_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py to ssd_resnet_v1_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py to ssd_efficientnet_bifpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py to faster_rcnn_inception_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py to center_net_resnet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py to faster_rcnn_resnet_keras_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py to ssd_pnasnet_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py to ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor.py to ssd_mobilenet_v3_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py to ssd_mobilenet_v2_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py to ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py to faster_rcnn_resnet_v1_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py to ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py to faster_rcnn_nas_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor.py to ssd_inception_v3_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py to ssd_mobilenet_v2_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py to ssd_inception_v3_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_resnet_feature_extractor.py to center_net_resnet_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobiledet_feature_extractor.py to ssd_mobiledet_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py to faster_rcnn_inception_v2_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor.py to faster_rcnn_nas_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py to ssd_resnet_v1_ppn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py to faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor.py to faster_rcnn_pnas_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py to ssd_mobilenet_v3_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py to ssd_resnet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor.py to ssd_mobilenet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor.py to ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py to ssd_resnet_v1_fpn_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py to ssd_mobilenet_v1_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py to center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py to faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py to center_net_resnet_v1_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor.py to ssd_inception_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py to ssd_mobilenet_v2_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators_test.py to feature_map_generators_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py to ssd_resnet_v1_ppn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1.py to mobilenet_v1.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/model_utils.py to model_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1_tf2_test.py to resnet_v1_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/convert_keras_models.py to convert_keras_models.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1_tf2_test.py to mobilenet_v1_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2.py to inception_resnet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2.py to mobilenet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2_tf2_test.py to mobilenet_v2_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/hourglass_network_tf2_test.py to hourglass_network_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1.py to resnet_v1.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/hourglass_network.py to hourglass_network.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/test_utils.py to test_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2_tf2_test.py to inception_resnet_v2_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py to faster_rcnn_resnet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py to ssd_mobilenet_v2_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py to ssd_mobilenet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/bidirectional_feature_pyramid_generators.py to bidirectional_feature_pyramid_generators.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py to ssd_resnet_v1_ppn_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py to ssd_mobilenet_v3_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators.py to feature_map_generators.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py to ssd_mobilenet_edgetpu_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py to ssd_mobilenet_v1_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_resnet_feature_extractor_tf2_test.py to center_net_resnet_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py to ssd_resnet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py to embedded_ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py to ssd_mobilenet_v2_mnasfpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py to ssd_mobilenet_edgetpu_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py to ssd_resnet_v1_fpn_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py to faster_rcnn_resnet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py to ssd_mobilenet_edgetpu_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py to faster_rcnn_inception_resnet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py to center_net_hourglass_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py to ssd_mobiledet_feature_extractor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py to ssd_efficientnet_bifpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py to ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util_test.py to eval_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/infer_detections.py to infer_detections.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference.py to detection_inference.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference_tf1_test.py to detection_inference_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder_tf1_test.py to input_reader_builder_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_tf1_test.py to model_builder_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder_tf2_test.py to optimizer_builder_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_test.py to model_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder.py to hyperparams_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder.py to box_predictor_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder_tf1_test.py to graph_rewriter_builder_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder_test.py to post_processing_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder_test.py to hyperparams_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder_test.py to region_similarity_calculator_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder_test.py to calibration_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder.py to model_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder.py to losses_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder_test.py to target_assigner_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder.py to optimizer_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder_test.py to box_predictor_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_tf2_test.py to model_builder_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder_test.py to matcher_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/decoder_builder_test.py to decoder_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder.py to input_reader_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder_tf1_test.py to optimizer_builder_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder.py to dataset_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder_test.py to dataset_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder.py to anchor_generator_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder.py to graph_rewriter_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder.py to preprocessor_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder.py to calibration_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder.py to image_resizer_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder.py to region_similarity_calculator_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder_test.py to box_coder_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder.py to post_processing_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder.py to matcher_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder_test.py to anchor_generator_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder.py to box_coder_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder_test.py to losses_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder_test.py to preprocessor_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder_test.py to image_resizer_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder.py to target_assigner_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/decoder_builder.py to decoder_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_main_tf2.py to model_main_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_test.py to np_box_mask_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape.py to static_shape.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation.py to per_image_vrd_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation_test.py to per_image_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util.py to dataset_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops_test.py to patch_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util.py to label_map_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util_test.py to label_map_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation.py to vrd_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops.py to np_mask_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils.py to json_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops.py to np_box_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list.py to np_box_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util.py to category_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops.py to spatial_transform_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper.py to variables_helper.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util_tf2_test.py to model_util_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/target_assigner_utils.py to target_assigner_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/colab_utils.py to colab_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops_test.py to np_box_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_case.py to test_case.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops.py to np_box_mask_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util.py to model_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util_test.py to category_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper_tf1_test.py to variables_helper_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics_test.py to metrics_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager.py to context_manager.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list.py to np_box_mask_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util.py to config_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils.py to visualization_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops_test.py to ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops.py to ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops_test.py to np_box_mask_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation_test.py to vrd_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules.py to learning_schedules.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils_test.py to json_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils.py to shape_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape_test.py to static_shape_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules_test.py to learning_schedules_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/target_assigner_utils_test.py to target_assigner_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops_test.py to spatial_transform_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops.py to patch_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager_test.py to context_manager_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils_test.py to visualization_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops_test.py to np_box_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_case_test.py to test_case_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils_test.py to shape_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/bifpn_utils.py to bifpn_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils_test.py to test_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util_test.py to config_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics.py to metrics.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation_test.py to object_detection_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation.py to per_image_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops.py to np_box_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/tf_version.py to tf_version.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util_test.py to dataset_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation.py to object_detection_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils.py to test_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation_test.py to per_image_vrd_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops_test.py to np_mask_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_test.py to np_box_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/autoaugment_utils.py to autoaugment_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch.py to rfcn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test.py to ssd_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py to faster_rcnn_meta_arch_test_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py to faster_rcnn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py to center_net_meta_arch_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_lib_tf1_test.py to context_rcnn_lib_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_meta_arch.py to context_rcnn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/center_net_meta_arch.py to center_net_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_meta_arch_test.py to context_rcnn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_lib_tf2_test.py to context_rcnn_lib_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch_test.py to rfcn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch.py to ssd_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_lib_tf2.py to context_rcnn_lib_tf2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py to faster_rcnn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/context_rcnn_lib.py to context_rcnn_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test_lib.py to ssd_meta_arch_test_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_lib_v2.py to exporter_lib_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs_test.py to inputs_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_tpu_main.py to model_tpu_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_main.py to model_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_tf2_test.py to model_lib_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_lib_tf2_test.py to exporter_lib_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/string_int_label_map_pb2.py to string_int_label_map_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/anchor_generator_pb2.py to anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/center_net_pb2.py to center_net_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_predictor_pb2.py to box_predictor_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/optimizer_pb2.py to optimizer_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/preprocessor_pb2.py to preprocessor_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/multiscale_anchor_generator_pb2.py to multiscale_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/input_reader_pb2.py to input_reader_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/flexible_grid_anchor_generator_pb2.py to flexible_grid_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/square_box_coder_pb2.py to square_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/post_processing_pb2.py to post_processing_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_anchor_generator_pb2.py to ssd_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/mean_stddev_box_coder_pb2.py to mean_stddev_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/model_pb2.py to model_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/fpn_pb2.py to fpn_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/target_assigner_pb2.py to target_assigner_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_pb2.py to faster_rcnn_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_box_coder_pb2.py to faster_rcnn_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_coder_pb2.py to box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/matcher_pb2.py to matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/calibration_pb2.py to calibration_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/hyperparams_pb2.py to hyperparams_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/eval_pb2.py to eval_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/train_pb2.py to train_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_pb2.py to ssd_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/grid_anchor_generator_pb2.py to grid_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/bipartite_matcher_pb2.py to bipartite_matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/losses_pb2.py to losses_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/graph_rewriter_pb2.py to graph_rewriter_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/pipeline_pb2.py to pipeline_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/argmax_matcher_pb2.py to argmax_matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/keypoint_box_coder_pb2.py to keypoint_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/image_resizer_pb2.py to image_resizer_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/region_similarity_calculator_pb2.py to region_similarity_calculator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_inference_graph.py to export_inference_graph.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs.py to inputs.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record.py to create_coco_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation.py to oid_tfrecord_creation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record_test.py to create_kitti_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py to oid_hierarchical_labels_expansion_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_oid_tf_record.py to create_oid_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record_test.py to create_coco_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record.py to create_pascal_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/generate_detection_data.py to generate_detection_data.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py to add_context_to_examples.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py to add_context_to_examples_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py to generate_embedding_data.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py to create_cococameratraps_tfexample_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py to generate_embedding_data_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py to create_cococameratraps_tfexample_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py to generate_detection_data_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util_test.py to tf_record_creation_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py to oid_hierarchical_labels_expansion.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/seq_example_util_test.py to seq_example_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record_test.py to create_pascal_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pet_tf_record.py to create_pet_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/seq_example_util.py to seq_example_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record.py to create_kitti_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util.py to tf_record_creation_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation_test.py to oid_tfrecord_creation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_ava_actions_tf_record.py to create_ava_actions_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/train.py to train.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/evaluator.py to evaluator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer_tf1_test.py to trainer_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/eval.py to eval.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer.py to trainer.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter.py to exporter.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor_tf1_test.py to convolutional_box_predictor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor.py to mask_rcnn_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head_tf2_test.py to keras_class_head_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head_tf2_test.py to keras_mask_head_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head_tf1_test.py to keypoint_head_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head.py to keras_mask_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head.py to mask_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head.py to keypoint_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head.py to keras_class_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head.py to class_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head_tf1_test.py to class_head_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head.py to keras_box_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head.py to box_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head_tf1_test.py to mask_head_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head_tf1_test.py to box_head_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/head.py to head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head_tf2_test.py to keras_box_head_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor.py to mask_rcnn_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor.py to rfcn_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py to mask_rcnn_keras_box_predictor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor_tf1_test.py to rfcn_box_predictor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor.py to rfcn_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor.py to convolutional_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py to convolutional_keras_box_predictor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py to mask_rcnn_box_predictor_tf1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py to rfcn_keras_box_predictor_tf2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor.py to convolutional_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_main_v2.py to exporter_main_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_tf1_test.py to exporter_tf1_test.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","object_detection.core.__pycache__.densepose_ops.cpython-36: module references __file__\n","object_detection.core.__pycache__.preprocessor.cpython-36: module MAY be using inspect.stack\n","object_detection.utils.__pycache__.autoaugment_utils.cpython-36: module MAY be using inspect.stack\n","creating dist\n","creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing object_detection-0.1-py3.6.egg\n","creating /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n","Extracting object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding object-detection 0.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n","Processing dependencies for object-detection==0.1\n","Searching for Cython==0.29.21\n","Best match: Cython 0.29.21\n","Adding Cython 0.29.21 to easy-install.pth file\n","Installing cygdb script to /usr/local/bin\n","Installing cython script to /usr/local/bin\n","Installing cythonize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for matplotlib==3.2.2\n","Best match: matplotlib 3.2.2\n","Adding matplotlib 3.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Pillow==7.0.0\n","Best match: Pillow 7.0.0\n","Adding Pillow 7.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for kiwisolver==1.3.1\n","Best match: kiwisolver 1.3.1\n","Adding kiwisolver 1.3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pyparsing==2.4.7\n","Best match: pyparsing 2.4.7\n","Adding pyparsing 2.4.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for python-dateutil==2.8.1\n","Best match: python-dateutil 2.8.1\n","Adding python-dateutil 2.8.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for cycler==0.10.0\n","Best match: cycler 0.10.0\n","Adding cycler 0.10.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.18.5\n","Best match: numpy 1.18.5\n","Adding numpy 1.18.5 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.6 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for object-detection==0.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HmH0H-sWNHZ5"},"source":["This part we play with our zip file\n"]},{"cell_type":"code","metadata":{"id":"-BcDq_XGFSNs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608054995945,"user_tz":-330,"elapsed":1890,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"ab151060-3304-4962-e1ea-8eb1d79d0154"},"source":["%cp -a /content/drive/'My Drive'/Preparation.zip /content/models-master/research/object_detection\n","%cd /content/models-master/research/object_detection\n","!unzip Preparation.zip"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/models-master/research/object_detection\n","Archive:  Preparation.zip\n","   creating: Preparation/\n","  inflating: Preparation/generate_tfrecord.py  \n","   creating: Preparation/images/\n","   creating: Preparation/images/test/\n","  inflating: Preparation/images/test/0001.JPEG  \n","  inflating: Preparation/images/test/0001.xml  \n","  inflating: Preparation/images/test/0002.JPEG  \n","  inflating: Preparation/images/test/0002.xml  \n","  inflating: Preparation/images/test/0003.JPEG  \n","  inflating: Preparation/images/test/0003.xml  \n","  inflating: Preparation/images/test/0004.JPEG  \n","  inflating: Preparation/images/test/0004.xml  \n","  inflating: Preparation/images/test/0005.JPEG  \n","  inflating: Preparation/images/test/0005.xml  \n","  inflating: Preparation/images/test/0006.JPEG  \n","  inflating: Preparation/images/test/0006.xml  \n","  inflating: Preparation/images/test/0007.JPEG  \n","  inflating: Preparation/images/test/0007.xml  \n","  inflating: Preparation/images/test/0008.JPEG  \n","  inflating: Preparation/images/test/0008.xml  \n","  inflating: Preparation/images/test/0009.JPEG  \n","  inflating: Preparation/images/test/0009.xml  \n","  inflating: Preparation/images/test/0010.JPEG  \n","  inflating: Preparation/images/test/0010.xml  \n","  inflating: Preparation/images/test/0011.JPEG  \n","  inflating: Preparation/images/test/0011.xml  \n","  inflating: Preparation/images/test/0012.JPEG  \n","  inflating: Preparation/images/test/0012.xml  \n","  inflating: Preparation/images/test/0013.JPEG  \n","  inflating: Preparation/images/test/0013.xml  \n","  inflating: Preparation/images/test/0014.JPEG  \n","  inflating: Preparation/images/test/0014.xml  \n","  inflating: Preparation/images/test/0015.JPEG  \n","  inflating: Preparation/images/test/0015.xml  \n","  inflating: Preparation/images/test/0016.JPEG  \n","  inflating: Preparation/images/test/0016.xml  \n","  inflating: Preparation/images/test/0017.JPEG  \n","  inflating: Preparation/images/test/0017.xml  \n","  inflating: Preparation/images/test/0018.JPEG  \n","  inflating: Preparation/images/test/0018.xml  \n","  inflating: Preparation/images/test/0019.JPEG  \n","  inflating: Preparation/images/test/0019.xml  \n","  inflating: Preparation/images/test/0020.JPEG  \n","  inflating: Preparation/images/test/0020.xml  \n","  inflating: Preparation/images/test/0021.JPEG  \n","  inflating: Preparation/images/test/0021.xml  \n","  inflating: Preparation/images/test/0022.JPEG  \n","  inflating: Preparation/images/test/0022.xml  \n","  inflating: Preparation/images/test/0023.JPEG  \n","  inflating: Preparation/images/test/0023.xml  \n","  inflating: Preparation/images/test/0024.JPEG  \n","  inflating: Preparation/images/test/0024.xml  \n","  inflating: Preparation/images/test/0025.jpeg  \n","  inflating: Preparation/images/test/0025.xml  \n","  inflating: Preparation/images/test/0026.JPEG  \n","  inflating: Preparation/images/test/0026.xml  \n","  inflating: Preparation/images/test/0027.jpeg  \n","  inflating: Preparation/images/test/0027.xml  \n","  inflating: Preparation/images/test/0028.JPEG  \n","  inflating: Preparation/images/test/0028.xml  \n","  inflating: Preparation/images/test/0029.JPEG  \n","  inflating: Preparation/images/test/0029.xml  \n","  inflating: Preparation/images/test/0030.JPEG  \n","  inflating: Preparation/images/test/0030.xml  \n","   creating: Preparation/images/train/\n","  inflating: Preparation/images/train/0001.JPEG  \n","  inflating: Preparation/images/train/0001.xml  \n","  inflating: Preparation/images/train/0002.JPEG  \n","  inflating: Preparation/images/train/0002.xml  \n","  inflating: Preparation/images/train/0003.JPEG  \n","  inflating: Preparation/images/train/0003.xml  \n","  inflating: Preparation/images/train/0004.JPEG  \n","  inflating: Preparation/images/train/0004.xml  \n","  inflating: Preparation/images/train/0005.JPEG  \n","  inflating: Preparation/images/train/0005.xml  \n","  inflating: Preparation/images/train/0006.JPEG  \n","  inflating: Preparation/images/train/0006.xml  \n","  inflating: Preparation/images/train/0007.JPEG  \n","  inflating: Preparation/images/train/0007.xml  \n","  inflating: Preparation/images/train/0008.JPEG  \n","  inflating: Preparation/images/train/0008.xml  \n","  inflating: Preparation/images/train/0009.JPEG  \n","  inflating: Preparation/images/train/0009.xml  \n","  inflating: Preparation/images/train/0010.JPEG  \n","  inflating: Preparation/images/train/0010.xml  \n","  inflating: Preparation/images/train/0011.JPEG  \n","  inflating: Preparation/images/train/0011.xml  \n","  inflating: Preparation/images/train/0012.JPEG  \n","  inflating: Preparation/images/train/0012.xml  \n","  inflating: Preparation/images/train/0013.JPEG  \n","  inflating: Preparation/images/train/0013.xml  \n","  inflating: Preparation/images/train/0014.JPEG  \n","  inflating: Preparation/images/train/0014.xml  \n","  inflating: Preparation/images/train/0015.JPEG  \n","  inflating: Preparation/images/train/0015.xml  \n","  inflating: Preparation/images/train/0016.JPEG  \n","  inflating: Preparation/images/train/0016.xml  \n","  inflating: Preparation/images/train/0017.JPEG  \n","  inflating: Preparation/images/train/0017.xml  \n","  inflating: Preparation/images/train/0018.JPEG  \n","  inflating: Preparation/images/train/0018.xml  \n","  inflating: Preparation/images/train/0019.JPEG  \n","  inflating: Preparation/images/train/0019.xml  \n","  inflating: Preparation/images/train/0020.JPEG  \n","  inflating: Preparation/images/train/0020.xml  \n","  inflating: Preparation/images/train/0021.JPEG  \n","  inflating: Preparation/images/train/0021.xml  \n","  inflating: Preparation/images/train/0022.JPEG  \n","  inflating: Preparation/images/train/0022.xml  \n","  inflating: Preparation/images/train/0023.JPEG  \n","  inflating: Preparation/images/train/0023.xml  \n","  inflating: Preparation/images/train/0024.JPEG  \n","  inflating: Preparation/images/train/0024.xml  \n","  inflating: Preparation/images/train/0025.JPEG  \n","  inflating: Preparation/images/train/0025.xml  \n","  inflating: Preparation/images/train/0026.JPEG  \n","  inflating: Preparation/images/train/0026.xml  \n","  inflating: Preparation/images/train/0027.JPEG  \n","  inflating: Preparation/images/train/0027.xml  \n","  inflating: Preparation/images/train/0028.JPEG  \n","  inflating: Preparation/images/train/0028.xml  \n","  inflating: Preparation/images/train/0029.JPEG  \n","  inflating: Preparation/images/train/0029.xml  \n","  inflating: Preparation/images/train/0030.JPEG  \n","  inflating: Preparation/images/train/0030.xml  \n","  inflating: Preparation/images/train/0031.JPEG  \n","  inflating: Preparation/images/train/0031.xml  \n","  inflating: Preparation/images/train/0032.JPEG  \n","  inflating: Preparation/images/train/0032.xml  \n","  inflating: Preparation/images/train/0033.JPEG  \n","  inflating: Preparation/images/train/0033.xml  \n","  inflating: Preparation/images/train/0034.JPEG  \n","  inflating: Preparation/images/train/0034.xml  \n","  inflating: Preparation/images/train/0035.JPEG  \n","  inflating: Preparation/images/train/0035.xml  \n","  inflating: Preparation/images/train/0036.JPEG  \n","  inflating: Preparation/images/train/0036.xml  \n","  inflating: Preparation/images/train/0037.JPEG  \n","  inflating: Preparation/images/train/0037.xml  \n","  inflating: Preparation/images/train/0038.JPEG  \n","  inflating: Preparation/images/train/0038.xml  \n","  inflating: Preparation/images/train/0039.JPEG  \n","  inflating: Preparation/images/train/0039.xml  \n","  inflating: Preparation/images/train/0040.JPEG  \n","  inflating: Preparation/images/train/0040.xml  \n","  inflating: Preparation/images/train/0041.JPEG  \n","  inflating: Preparation/images/train/0041.xml  \n","  inflating: Preparation/images/train/0042.JPEG  \n","  inflating: Preparation/images/train/0042.xml  \n","  inflating: Preparation/images/train/0043.JPEG  \n","  inflating: Preparation/images/train/0043.xml  \n","  inflating: Preparation/images/train/0044.JPEG  \n","  inflating: Preparation/images/train/0044.xml  \n","  inflating: Preparation/images/train/0045.JPEG  \n","  inflating: Preparation/images/train/0045.xml  \n","  inflating: Preparation/images/train/0046.JPEG  \n","  inflating: Preparation/images/train/0046.xml  \n","  inflating: Preparation/images/train/0047.JPEG  \n","  inflating: Preparation/images/train/0047.xml  \n","  inflating: Preparation/images/train/0048.JPEG  \n","  inflating: Preparation/images/train/0048.xml  \n","  inflating: Preparation/images/train/0049.JPEG  \n","  inflating: Preparation/images/train/0049.xml  \n","  inflating: Preparation/images/train/0050.JPEG  \n","  inflating: Preparation/images/train/0050.xml  \n","  inflating: Preparation/images/train/0051.JPEG  \n","  inflating: Preparation/images/train/0051.xml  \n","  inflating: Preparation/images/train/0052.JPEG  \n","  inflating: Preparation/images/train/0052.xml  \n","  inflating: Preparation/images/train/0053.JPEG  \n","  inflating: Preparation/images/train/0053.xml  \n","  inflating: Preparation/images/train/0054.JPEG  \n","  inflating: Preparation/images/train/0054.xml  \n","  inflating: Preparation/images/train/0055.JPEG  \n","  inflating: Preparation/images/train/0055.xml  \n","  inflating: Preparation/images/train/0056.JPEG  \n","  inflating: Preparation/images/train/0056.xml  \n","  inflating: Preparation/images/train/0057.JPEG  \n","  inflating: Preparation/images/train/0057.xml  \n","  inflating: Preparation/images/train/0058.JPEG  \n","  inflating: Preparation/images/train/0058.xml  \n","  inflating: Preparation/images/train/0059.JPEG  \n","  inflating: Preparation/images/train/0059.xml  \n","  inflating: Preparation/images/train/0060.JPEG  \n","  inflating: Preparation/images/train/0060.xml  \n","  inflating: Preparation/images/train/0061.JPEG  \n","  inflating: Preparation/images/train/0061.xml  \n","  inflating: Preparation/images/train/0062.JPEG  \n","  inflating: Preparation/images/train/0062.xml  \n","  inflating: Preparation/images/train/0063.JPEG  \n","  inflating: Preparation/images/train/0063.xml  \n","  inflating: Preparation/images/train/0064.JPEG  \n","  inflating: Preparation/images/train/0064.xml  \n","  inflating: Preparation/images/train/0065.JPEG  \n","  inflating: Preparation/images/train/0065.xml  \n","  inflating: Preparation/images/train/0066.JPEG  \n","  inflating: Preparation/images/train/0066.xml  \n","  inflating: Preparation/images/train/0067.JPEG  \n","  inflating: Preparation/images/train/0067.xml  \n","  inflating: Preparation/images/train/0068.JPEG  \n","  inflating: Preparation/images/train/0068.xml  \n","  inflating: Preparation/images/train/0069.JPEG  \n","  inflating: Preparation/images/train/0069.xml  \n","  inflating: Preparation/images/train/0070.JPEG  \n","  inflating: Preparation/images/train/0070.xml  \n","  inflating: Preparation/images/train/0071.JPEG  \n","  inflating: Preparation/images/train/0071.xml  \n","  inflating: Preparation/images/train/0072.JPEG  \n","  inflating: Preparation/images/train/0072.xml  \n","  inflating: Preparation/images/train/0073.JPEG  \n","  inflating: Preparation/images/train/0073.xml  \n","  inflating: Preparation/images/train/0074.JPEG  \n","  inflating: Preparation/images/train/0074.xml  \n","  inflating: Preparation/images/train/0075.JPEG  \n","  inflating: Preparation/images/train/0075.xml  \n","  inflating: Preparation/images/train/0076.JPEG  \n","  inflating: Preparation/images/train/0076.xml  \n","  inflating: Preparation/images/train/0077.JPEG  \n","  inflating: Preparation/images/train/0077.xml  \n","  inflating: Preparation/images/train/0078.JPEG  \n","  inflating: Preparation/images/train/0078.xml  \n","  inflating: Preparation/images/train/0079.JPEG  \n","  inflating: Preparation/images/train/0079.xml  \n","  inflating: Preparation/images/train/0080.JPEG  \n","  inflating: Preparation/images/train/0080.xml  \n","  inflating: Preparation/images/train/0081.JPEG  \n","  inflating: Preparation/images/train/0081.xml  \n","  inflating: Preparation/images/train/0082.JPEG  \n","  inflating: Preparation/images/train/0082.xml  \n","  inflating: Preparation/images/train/0083.JPEG  \n","  inflating: Preparation/images/train/0083.xml  \n","  inflating: Preparation/images/train/0084.JPEG  \n","  inflating: Preparation/images/train/0084.xml  \n","  inflating: Preparation/images/train/0085.JPEG  \n","  inflating: Preparation/images/train/0085.xml  \n","  inflating: Preparation/images/train/0086.JPEG  \n","  inflating: Preparation/images/train/0086.xml  \n","  inflating: Preparation/images/train/0087.JPEG  \n","  inflating: Preparation/images/train/0087.xml  \n","  inflating: Preparation/images/train/0088.JPEG  \n","  inflating: Preparation/images/train/0088.xml  \n","  inflating: Preparation/images/train/0089.JPEG  \n","  inflating: Preparation/images/train/0089.xml  \n","  inflating: Preparation/images/train/0090.JPEG  \n","  inflating: Preparation/images/train/0090.xml  \n","  inflating: Preparation/images/train/0091.JPEG  \n","  inflating: Preparation/images/train/0091.xml  \n","  inflating: Preparation/images/train/0092.JPEG  \n","  inflating: Preparation/images/train/0092.xml  \n","  inflating: Preparation/images/train/0093.JPEG  \n","  inflating: Preparation/images/train/0093.xml  \n","  inflating: Preparation/images/train/0094.JPEG  \n","  inflating: Preparation/images/train/0094.xml  \n","  inflating: Preparation/images/train/0095.JPEG  \n","  inflating: Preparation/images/train/0095.xml  \n","  inflating: Preparation/images/train/0096.JPEG  \n","  inflating: Preparation/images/train/0096.xml  \n","  inflating: Preparation/images/train/0097.JPEG  \n","  inflating: Preparation/images/train/0097.xml  \n","  inflating: Preparation/images/train/0098.JPEG  \n","  inflating: Preparation/images/train/0098.xml  \n","  inflating: Preparation/images/train/0099.JPEG  \n","  inflating: Preparation/images/train/0099.xml  \n","  inflating: Preparation/images/train/0100.JPEG  \n","  inflating: Preparation/images/train/0100.xml  \n","  inflating: Preparation/images/train/0101.JPEG  \n","  inflating: Preparation/images/train/0101.xml  \n","  inflating: Preparation/images/train/0102.JPEG  \n","  inflating: Preparation/images/train/0102.xml  \n","  inflating: Preparation/images/train/0103.JPEG  \n","  inflating: Preparation/images/train/0103.xml  \n","  inflating: Preparation/images/train/0104.JPEG  \n","  inflating: Preparation/images/train/0104.xml  \n","  inflating: Preparation/images/train/0105.JPEG  \n","  inflating: Preparation/images/train/0105.xml  \n","  inflating: Preparation/images/train/0106.JPEG  \n","  inflating: Preparation/images/train/0106.xml  \n","  inflating: Preparation/images/train/0107.JPEG  \n","  inflating: Preparation/images/train/0107.xml  \n","  inflating: Preparation/images/train/0108.jpeg  \n","  inflating: Preparation/images/train/0108.xml  \n","  inflating: Preparation/images/train/0109.JPEG  \n","  inflating: Preparation/images/train/0109.xml  \n","  inflating: Preparation/images/train/0110.JPEG  \n","  inflating: Preparation/images/train/0110.xml  \n","  inflating: Preparation/images/train/0111.JPEG  \n","  inflating: Preparation/images/train/0111.xml  \n","  inflating: Preparation/images/train/0112.JPEG  \n","  inflating: Preparation/images/train/0112.xml  \n","  inflating: Preparation/images/train/0113.JPEG  \n","  inflating: Preparation/images/train/0113.xml  \n","  inflating: Preparation/images/train/0114.JPEG  \n","  inflating: Preparation/images/train/0114.xml  \n","  inflating: Preparation/images/train/0115.JPEG  \n","  inflating: Preparation/images/train/0115.xml  \n","  inflating: Preparation/images/train/0116.JPEG  \n","  inflating: Preparation/images/train/0116.xml  \n","  inflating: Preparation/images/train/0117.JPEG  \n","  inflating: Preparation/images/train/0117.xml  \n","  inflating: Preparation/images/train/0118.JPEG  \n","  inflating: Preparation/images/train/0118.xml  \n","  inflating: Preparation/images/train/0119.JPEG  \n","  inflating: Preparation/images/train/0119.xml  \n","  inflating: Preparation/images/train/0120.JPEG  \n","  inflating: Preparation/images/train/0120.xml  \n","  inflating: Preparation/images/train/0121.JPEG  \n","  inflating: Preparation/images/train/0121.xml  \n","  inflating: Preparation/images/train/0122.JPEG  \n","  inflating: Preparation/images/train/0122.xml  \n","  inflating: Preparation/images/train/0123.JPEG  \n","  inflating: Preparation/images/train/0123.xml  \n","  inflating: Preparation/images/train/0124.JPEG  \n","  inflating: Preparation/images/train/0124.xml  \n","  inflating: Preparation/images/train/0125.JPEG  \n","  inflating: Preparation/images/train/0125.xml  \n","  inflating: Preparation/images/train/0126.JPEG  \n","  inflating: Preparation/images/train/0126.xml  \n","  inflating: Preparation/images/train/0127.jpeg  \n","  inflating: Preparation/images/train/0127.xml  \n","  inflating: Preparation/images/train/0128.jpeg  \n","  inflating: Preparation/images/train/0128.xml  \n","  inflating: Preparation/images/train/0129.jpeg  \n","  inflating: Preparation/images/train/0129.xml  \n","  inflating: Preparation/images/train/0130.JPEG  \n","  inflating: Preparation/images/train/0130.xml  \n","  inflating: Preparation/images/train/0131.JPEG  \n","  inflating: Preparation/images/train/0131.xml  \n","  inflating: Preparation/images/train/0132.JPEG  \n","  inflating: Preparation/images/train/0132.xml  \n","  inflating: Preparation/images/train/0133.JPEG  \n","  inflating: Preparation/images/train/0133.xml  \n","  inflating: Preparation/images/train/0134.JPEG  \n","  inflating: Preparation/images/train/0134.xml  \n","  inflating: Preparation/images/train/0135.JPEG  \n","  inflating: Preparation/images/train/0135.xml  \n","  inflating: Preparation/images/train/0136.JPEG  \n","  inflating: Preparation/images/train/0136.xml  \n","  inflating: Preparation/images/train/0137.JPEG  \n","  inflating: Preparation/images/train/0137.xml  \n","  inflating: Preparation/images/train/0138.JPEG  \n","  inflating: Preparation/images/train/0138.xml  \n","  inflating: Preparation/images/train/0139.JPEG  \n","  inflating: Preparation/images/train/0139.xml  \n","  inflating: Preparation/images/train/0140.JPEG  \n","  inflating: Preparation/images/train/0140.xml  \n","  inflating: Preparation/images/train/0141.JPEG  \n","  inflating: Preparation/images/train/0141.xml  \n","  inflating: Preparation/images/train/0142.JPEG  \n","  inflating: Preparation/images/train/0142.xml  \n","  inflating: Preparation/images/train/0143.jpeg  \n","  inflating: Preparation/images/train/0143.xml  \n","  inflating: Preparation/images/train/0144.JPEG  \n","  inflating: Preparation/images/train/0144.xml  \n","  inflating: Preparation/images/train/0145.JPEG  \n","  inflating: Preparation/images/train/0145.xml  \n","  inflating: Preparation/images/train/0146.JPEG  \n","  inflating: Preparation/images/train/0146.xml  \n","  inflating: Preparation/images/train/0147.JPEG  \n","  inflating: Preparation/images/train/0147.xml  \n","  inflating: Preparation/images/train/0148.jpeg  \n","  inflating: Preparation/images/train/0148.xml  \n","  inflating: Preparation/images/train/0149.JPEG  \n","  inflating: Preparation/images/train/0149.xml  \n","  inflating: Preparation/images/train/0150.JPEG  \n","  inflating: Preparation/images/train/0150.xml  \n","  inflating: Preparation/images/train/0151.JPEG  \n","  inflating: Preparation/images/train/0151.xml  \n","  inflating: Preparation/images/train/0152.jpeg  \n","  inflating: Preparation/images/train/0152.xml  \n","  inflating: Preparation/images/train/0153.JPEG  \n","  inflating: Preparation/images/train/0153.xml  \n","  inflating: Preparation/images/train/0154.JPEG  \n","  inflating: Preparation/images/train/0154.xml  \n","  inflating: Preparation/images/train/0155.jpeg  \n","  inflating: Preparation/images/train/0155.xml  \n","  inflating: Preparation/images/train/0156.JPEG  \n","  inflating: Preparation/images/train/0156.xml  \n","  inflating: Preparation/images/train/0157.jpeg  \n","  inflating: Preparation/images/train/0157.xml  \n","  inflating: Preparation/images/train/0158.jpeg  \n","  inflating: Preparation/images/train/0158.xml  \n","  inflating: Preparation/images/train/0159.JPEG  \n","  inflating: Preparation/images/train/0159.xml  \n","  inflating: Preparation/images/train/0160.JPEG  \n","  inflating: Preparation/images/train/0160.xml  \n","  inflating: Preparation/images/train/0161.jpeg  \n","  inflating: Preparation/images/train/0161.xml  \n","  inflating: Preparation/images/train/0162.jpeg  \n","  inflating: Preparation/images/train/0162.xml  \n","  inflating: Preparation/images/train/0163.JPEG  \n","  inflating: Preparation/images/train/0163.xml  \n","  inflating: Preparation/images/train/0164.JPEG  \n","  inflating: Preparation/images/train/0164.xml  \n","  inflating: Preparation/images/train/0165.JPEG  \n","  inflating: Preparation/images/train/0165.xml  \n","  inflating: Preparation/images/train/0166.JPEG  \n","  inflating: Preparation/images/train/0166.xml  \n","  inflating: Preparation/images/train/0167.JPEG  \n","  inflating: Preparation/images/train/0167.xml  \n","  inflating: Preparation/images/train/0168.JPEG  \n","  inflating: Preparation/images/train/0168.xml  \n","  inflating: Preparation/images/train/0169.jpeg  \n","  inflating: Preparation/images/train/0169.xml  \n","  inflating: Preparation/images/train/0170.JPEG  \n","  inflating: Preparation/images/train/0170.xml  \n","  inflating: Preparation/images/train/0171.JPEG  \n","  inflating: Preparation/images/train/0171.xml  \n","  inflating: Preparation/images/train/0172.jpeg  \n","  inflating: Preparation/images/train/0172.xml  \n","  inflating: Preparation/images/train/0173.JPEG  \n","  inflating: Preparation/images/train/0173.xml  \n","  inflating: Preparation/images/train/0174.JPEG  \n","  inflating: Preparation/images/train/0174.xml  \n","  inflating: Preparation/images/train/0175.JPEG  \n","  inflating: Preparation/images/train/0175.xml  \n","  inflating: Preparation/images/train/0176.JPEG  \n","  inflating: Preparation/images/train/0176.xml  \n","  inflating: Preparation/images/train/0177.JPEG  \n","  inflating: Preparation/images/train/0177.xml  \n","  inflating: Preparation/images/train/0178.JPEG  \n","  inflating: Preparation/images/train/0178.xml  \n","  inflating: Preparation/images/train/0179.JPEG  \n","  inflating: Preparation/images/train/0179.xml  \n","  inflating: Preparation/images/train/0180.jpeg  \n","  inflating: Preparation/images/train/0180.xml  \n","  inflating: Preparation/images/train/0181.JPEG  \n","  inflating: Preparation/images/train/0181.xml  \n","  inflating: Preparation/images/train/0182.JPEG  \n","  inflating: Preparation/images/train/0182.xml  \n","  inflating: Preparation/images/train/0183.JPEG  \n","  inflating: Preparation/images/train/0183.xml  \n","  inflating: Preparation/images/train/0184.jpeg  \n","  inflating: Preparation/images/train/0184.xml  \n","  inflating: Preparation/images/train/0185.JPEG  \n","  inflating: Preparation/images/train/0185.xml  \n","  inflating: Preparation/images/train/0186.JPEG  \n","  inflating: Preparation/images/train/0186.xml  \n","  inflating: Preparation/images/train/0187.JPEG  \n","  inflating: Preparation/images/train/0187.xml  \n","  inflating: Preparation/images/train/0188.jpeg  \n","  inflating: Preparation/images/train/0188.xml  \n","  inflating: Preparation/images/train/0189.JPEG  \n","  inflating: Preparation/images/train/0189.xml  \n","  inflating: Preparation/images/train/0190.JPEG  \n","  inflating: Preparation/images/train/0190.xml  \n","  inflating: Preparation/images/train/0191.JPEG  \n","  inflating: Preparation/images/train/0191.xml  \n","  inflating: Preparation/images/train/0192.JPEG  \n","  inflating: Preparation/images/train/0192.xml  \n","  inflating: Preparation/images/train/0193.JPEG  \n","  inflating: Preparation/images/train/0193.xml  \n","  inflating: Preparation/images/train/0194.JPEG  \n","  inflating: Preparation/images/train/0194.xml  \n","  inflating: Preparation/images/train/0195.JPEG  \n","  inflating: Preparation/images/train/0195.xml  \n","  inflating: Preparation/images/train/0196.JPEG  \n","  inflating: Preparation/images/train/0196.xml  \n","  inflating: Preparation/images/train/0197.JPEG  \n","  inflating: Preparation/images/train/0197.xml  \n","  inflating: Preparation/images/train/0198.JPEG  \n","  inflating: Preparation/images/train/0198.xml  \n","  inflating: Preparation/images/train/0199.jpeg  \n","  inflating: Preparation/images/train/0199.xml  \n","  inflating: Preparation/images/train/0200.JPEG  \n","  inflating: Preparation/images/train/0200.xml  \n","  inflating: Preparation/images/train/0201.JPEG  \n","  inflating: Preparation/images/train/0201.xml  \n","  inflating: Preparation/images/train/0202.JPEG  \n","  inflating: Preparation/images/train/0202.xml  \n","  inflating: Preparation/images/train/0203.JPEG  \n","  inflating: Preparation/images/train/0203.xml  \n","  inflating: Preparation/images/train/0204.JPEG  \n","  inflating: Preparation/images/train/0204.xml  \n","  inflating: Preparation/images/train/0205.JPEG  \n","  inflating: Preparation/images/train/0205.xml  \n","  inflating: Preparation/images/train/0206.JPEG  \n","  inflating: Preparation/images/train/0206.xml  \n","  inflating: Preparation/images/train/0207.JPEG  \n","  inflating: Preparation/images/train/0207.xml  \n","  inflating: Preparation/images/train/0208.JPEG  \n","  inflating: Preparation/images/train/0208.xml  \n","  inflating: Preparation/images/train/0209.jpeg  \n","  inflating: Preparation/images/train/0209.xml  \n","  inflating: Preparation/images/train/0210.JPEG  \n","  inflating: Preparation/images/train/0210.xml  \n","  inflating: Preparation/images/train/0211.JPEG  \n","  inflating: Preparation/images/train/0211.xml  \n","  inflating: Preparation/images/train/0212.JPEG  \n","  inflating: Preparation/images/train/0212.xml  \n","  inflating: Preparation/images/train/0213.JPEG  \n","  inflating: Preparation/images/train/0213.xml  \n","  inflating: Preparation/images/train/0214.JPEG  \n","  inflating: Preparation/images/train/0214.xml  \n","  inflating: Preparation/images/train/0215.JPEG  \n","  inflating: Preparation/images/train/0215.xml  \n","  inflating: Preparation/images/train/0216.JPEG  \n","  inflating: Preparation/images/train/0216.xml  \n","  inflating: Preparation/images/train/0217.JPEG  \n","  inflating: Preparation/images/train/0217.xml  \n","  inflating: Preparation/images/train/0218.JPEG  \n","  inflating: Preparation/images/train/0218.xml  \n","  inflating: Preparation/images/train/0219.JPEG  \n","  inflating: Preparation/images/train/0219.xml  \n","  inflating: Preparation/images/train/0220.JPEG  \n","  inflating: Preparation/images/train/0220.xml  \n","  inflating: Preparation/images/train/0221.JPEG  \n","  inflating: Preparation/images/train/0221.xml  \n","  inflating: Preparation/images/train/0222.JPEG  \n","  inflating: Preparation/images/train/0222.xml  \n","  inflating: Preparation/images/train/0223.JPEG  \n","  inflating: Preparation/images/train/0223.xml  \n","  inflating: Preparation/images/train/0224.JPEG  \n","  inflating: Preparation/images/train/0224.xml  \n","  inflating: Preparation/images/train/0225.JPEG  \n","  inflating: Preparation/images/train/0225.xml  \n","  inflating: Preparation/images/train/0226.JPEG  \n","  inflating: Preparation/images/train/0226.xml  \n","  inflating: Preparation/images/train/0227.JPEG  \n","  inflating: Preparation/images/train/0227.xml  \n","  inflating: Preparation/images/train/0228.JPEG  \n","  inflating: Preparation/images/train/0228.xml  \n","  inflating: Preparation/images/train/0229.JPEG  \n","  inflating: Preparation/images/train/0229.xml  \n","  inflating: Preparation/images/train/0230.JPEG  \n","  inflating: Preparation/images/train/0230.xml  \n","  inflating: Preparation/images/train/0231.JPEG  \n","  inflating: Preparation/images/train/0231.xml  \n","  inflating: Preparation/images/train/0232.JPEG  \n","  inflating: Preparation/images/train/0232.xml  \n","  inflating: Preparation/images/train/0233.JPEG  \n","  inflating: Preparation/images/train/0233.xml  \n","  inflating: Preparation/images/train/0234.JPEG  \n","  inflating: Preparation/images/train/0234.xml  \n","  inflating: Preparation/images/train/0235.JPEG  \n","  inflating: Preparation/images/train/0235.xml  \n","  inflating: Preparation/images/train/0236.JPEG  \n","  inflating: Preparation/images/train/0236.xml  \n","  inflating: Preparation/images/train/0237.JPEG  \n","  inflating: Preparation/images/train/0237.xml  \n","  inflating: Preparation/images/train/0238.JPEG  \n","  inflating: Preparation/images/train/0238.xml  \n","  inflating: Preparation/images/train/0239.JPEG  \n","  inflating: Preparation/images/train/0239.xml  \n","  inflating: Preparation/images/train/0240.JPEG  \n","  inflating: Preparation/images/train/0240.xml  \n","  inflating: Preparation/images/train/0241.JPEG  \n","  inflating: Preparation/images/train/0241.xml  \n","  inflating: Preparation/images/train/0242.JPEG  \n","  inflating: Preparation/images/train/0242.xml  \n","  inflating: Preparation/images/train/0243.JPEG  \n","  inflating: Preparation/images/train/0243.xml  \n","  inflating: Preparation/images/train/0244.JPEG  \n","  inflating: Preparation/images/train/0244.xml  \n","  inflating: Preparation/images/train/0245.JPEG  \n","  inflating: Preparation/images/train/0245.xml  \n","  inflating: Preparation/images/train/0246.JPEG  \n","  inflating: Preparation/images/train/0246.xml  \n","  inflating: Preparation/images/train/0247.JPEG  \n","  inflating: Preparation/images/train/0247.xml  \n","  inflating: Preparation/images/train/0248.JPEG  \n","  inflating: Preparation/images/train/0248.xml  \n","  inflating: Preparation/images/train/0249.JPEG  \n","  inflating: Preparation/images/train/0249.xml  \n","  inflating: Preparation/images/train/0250.JPEG  \n","  inflating: Preparation/images/train/0250.xml  \n","  inflating: Preparation/images/train/0251.JPEG  \n","  inflating: Preparation/images/train/0251.xml  \n","  inflating: Preparation/images/train/0252.JPEG  \n","  inflating: Preparation/images/train/0252.xml  \n","  inflating: Preparation/images/train/0253.JPEG  \n","  inflating: Preparation/images/train/0253.xml  \n","  inflating: Preparation/images/train/0254.JPEG  \n","  inflating: Preparation/images/train/0254.xml  \n","  inflating: Preparation/images/train/0255.JPEG  \n","  inflating: Preparation/images/train/0255.xml  \n","  inflating: Preparation/images/train/0256.JPEG  \n","  inflating: Preparation/images/train/0256.xml  \n","  inflating: Preparation/images/train/0257.JPEG  \n","  inflating: Preparation/images/train/0257.xml  \n","  inflating: Preparation/images/train/0258.JPEG  \n","  inflating: Preparation/images/train/0258.xml  \n","  inflating: Preparation/images/train/0259.JPEG  \n","  inflating: Preparation/images/train/0259.xml  \n","  inflating: Preparation/images/train/0260.JPEG  \n","  inflating: Preparation/images/train/0260.xml  \n","  inflating: Preparation/images/train/0261.JPEG  \n","  inflating: Preparation/images/train/0261.xml  \n","  inflating: Preparation/images/train/0262.JPEG  \n","  inflating: Preparation/images/train/0262.xml  \n","  inflating: Preparation/images/train/0263.JPEG  \n","  inflating: Preparation/images/train/0263.xml  \n","  inflating: Preparation/images/train/0264.JPEG  \n","  inflating: Preparation/images/train/0264.xml  \n","  inflating: Preparation/images/train/0265.JPEG  \n","  inflating: Preparation/images/train/0265.xml  \n","  inflating: Preparation/images/train/0266.JPEG  \n","  inflating: Preparation/images/train/0266.xml  \n","  inflating: Preparation/images/train/0267.JPEG  \n","  inflating: Preparation/images/train/0267.xml  \n","  inflating: Preparation/images/train/0268.JPEG  \n","  inflating: Preparation/images/train/0268.xml  \n","  inflating: Preparation/images/train/0269.JPEG  \n","  inflating: Preparation/images/train/0269.xml  \n","  inflating: Preparation/images/train/0270.JPEG  \n","  inflating: Preparation/images/train/0270.xml  \n","  inflating: Preparation/images/train/0271.JPEG  \n","  inflating: Preparation/images/train/0271.xml  \n","  inflating: Preparation/images/train/0272.JPEG  \n","  inflating: Preparation/images/train/0272.xml  \n","  inflating: Preparation/images/train/0273.JPEG  \n","  inflating: Preparation/images/train/0273.xml  \n","  inflating: Preparation/images/train/0274.JPEG  \n","  inflating: Preparation/images/train/0274.xml  \n","  inflating: Preparation/images/train/0275.JPEG  \n","  inflating: Preparation/images/train/0275.xml  \n","  inflating: Preparation/images/train/0276.JPEG  \n","  inflating: Preparation/images/train/0276.xml  \n","  inflating: Preparation/images/train/0277.JPEG  \n","  inflating: Preparation/images/train/0277.xml  \n","  inflating: Preparation/images/train/0278.JPEG  \n","  inflating: Preparation/images/train/0278.xml  \n","  inflating: Preparation/images/train/0279.JPEG  \n","  inflating: Preparation/images/train/0279.xml  \n","  inflating: Preparation/images/train/0280.JPEG  \n","  inflating: Preparation/images/train/0280.xml  \n","  inflating: Preparation/images/train/0281.JPEG  \n","  inflating: Preparation/images/train/0281.xml  \n","  inflating: Preparation/images/train/0282.JPEG  \n","  inflating: Preparation/images/train/0282.xml  \n","  inflating: Preparation/images/train/0283.JPEG  \n","  inflating: Preparation/images/train/0283.xml  \n","  inflating: Preparation/images/train/0284.JPEG  \n","  inflating: Preparation/images/train/0284.xml  \n","  inflating: Preparation/images/train/0285.JPEG  \n","  inflating: Preparation/images/train/0285.xml  \n","  inflating: Preparation/images/train/0286.JPEG  \n","  inflating: Preparation/images/train/0286.xml  \n","  inflating: Preparation/images/train/0287.JPEG  \n","  inflating: Preparation/images/train/0287.xml  \n","  inflating: Preparation/images/train/0288.JPEG  \n","  inflating: Preparation/images/train/0288.xml  \n","  inflating: Preparation/images/train/0289.jpeg  \n","  inflating: Preparation/images/train/0289.xml  \n","  inflating: Preparation/images/train/0290.JPEG  \n","  inflating: Preparation/images/train/0290.xml  \n","  inflating: Preparation/images/train/0291.JPEG  \n","  inflating: Preparation/images/train/0291.xml  \n","  inflating: Preparation/images/train/0292.JPEG  \n","  inflating: Preparation/images/train/0292.xml  \n","  inflating: Preparation/images/train/0293.JPEG  \n","  inflating: Preparation/images/train/0293.xml  \n","  inflating: Preparation/images/train/0294.JPEG  \n","  inflating: Preparation/images/train/0294.xml  \n","  inflating: Preparation/images/train/0295.JPEG  \n","  inflating: Preparation/images/train/0295.xml  \n","  inflating: Preparation/images/train/0296.JPEG  \n","  inflating: Preparation/images/train/0296.xml  \n","  inflating: Preparation/images/train/0297.JPEG  \n","  inflating: Preparation/images/train/0297.xml  \n","  inflating: Preparation/images/train/0298.JPEG  \n","  inflating: Preparation/images/train/0298.xml  \n","  inflating: Preparation/images/train/0299.JPEG  \n","  inflating: Preparation/images/train/0299.xml  \n","  inflating: Preparation/images/train/0300.JPEG  \n","  inflating: Preparation/images/train/0300.xml  \n","  inflating: Preparation/images/train/0301.JPEG  \n","  inflating: Preparation/images/train/0301.xml  \n","  inflating: Preparation/labelmap.pbtxt  \n","  inflating: Preparation/ssd_mobilenet_v2_quantized_300x300_coco.config  \n","  inflating: Preparation/train.py    \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HTUoLXwhyVbG","executionInfo":{"status":"ok","timestamp":1608055000614,"user_tz":-330,"elapsed":1280,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}}},"source":["!cp -a /content/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/Object_detection_image.py /content/models-master/research/object_detection/\n","\n","!cp -a /content/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/Object_detection_video.py /content/models-master/research/object_detection/\n","\n","!cp -a /content/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/Object_detection_webcam.py /content/models-master/research/object_detection/\n","\n","!cp -a /content/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10-master/xml_to_csv.py /content/models-master/research/object_detection/Preparation/\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSWp6B23NQQ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608055004595,"user_tz":-330,"elapsed":1627,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"9c6875eb-5801-4213-c758-411838bdf0dc"},"source":["%cd /content/models-master/research/object_detection/Preparation\n","!python xml_to_csv.py"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/models-master/research/object_detection/Preparation\n","Successfully converted xml to csv.\n","Successfully converted xml to csv.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9sQYQpc8EgYa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608055009390,"user_tz":-330,"elapsed":3409,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"5a0285ef-c29e-42e3-a735-b1b89028ce51"},"source":["%cd /content/models-master/research/object_detection/Preparation\n","!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/models-master/research/object_detection/Preparation\n","WARNING:tensorflow:From generate_tfrecord.py:103: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:89: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W1215 17:56:49.704102 139973803292544 module_wrapper.py:139] From generate_tfrecord.py:89: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:48: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W1215 17:56:49.719619 139973803292544 module_wrapper.py:139] From generate_tfrecord.py:48: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/models-master/research/object_detection/Preparation/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6AL0vFV3Egbx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608055013510,"user_tz":-330,"elapsed":2897,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"713b38b8-9b58-42c8-dcc1-3140d4ca72d1"},"source":["%cd /content/models-master/research/object_detection/Preparation\n","!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record "],"execution_count":12,"outputs":[{"output_type":"stream","text":["/content/models-master/research/object_detection/Preparation\n","WARNING:tensorflow:From generate_tfrecord.py:103: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:89: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W1215 17:56:54.314698 140119245879168 module_wrapper.py:139] From generate_tfrecord.py:89: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:48: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W1215 17:56:54.371920 140119245879168 module_wrapper.py:139] From generate_tfrecord.py:48: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/models-master/research/object_detection/Preparation/train.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lo8nytxQNVEn","executionInfo":{"status":"ok","timestamp":1608055100150,"user_tz":-330,"elapsed":1515,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}}},"source":["!cp -a /content/models-master/research/object_detection/Preparation/images /content/models-master/research/object_detection/\n","!cp -a /content/models-master/research/object_detection/Preparation/ssd_mobilenet_v2_quantized_300x300_coco.config /content/models-master/research/object_detection/\n","!cp -a /content/models-master/research/object_detection/Preparation/labelmap.pbtxt /content/models-master/research/object_detection/\n","!cp -a /content/models-master/research/object_detection/Preparation/test.record /content/models-master/research/object_detection/\n","!cp -a /content/models-master/research/object_detection/Preparation/train.record /content/models-master/research/object_detection/\n","!cp -a /content/models-master/research/object_detection/Preparation/train.py /content/models-master/research/object_detection/"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VOA1qhgXTrw4"},"source":["Check remaining GPU time"]},{"cell_type":"code","metadata":{"id":"GA7Fzh211CNU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608055104177,"user_tz":-330,"elapsed":1050,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"9b28b324-766d-4db8-973b-bd78723b89cb"},"source":["import time, psutil\n","Start = time.time()- psutil.boot_time()\n","Left= 12*3600 - Start \n","print('Time remaining for this session is: ', Left/3600)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Time remaining for this session is:  11.923556221591102\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jR_EHmf-WA4Z"},"source":["Start training"]},{"cell_type":"code","metadata":{"id":"1y0CPJuTcsGb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608055112030,"user_tz":-330,"elapsed":3843,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"6d118d06-7ffb-436d-81c1-68e43aa1b70f"},"source":["!pip install tf_slim\n","%cd  /content/models-master/research/object_detection/\n","os.environ['PYTHONPATH'] += ':/content/models-master/research/:/content/models-master/research/slim'\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Collecting tf_slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n","Installing collected packages: tf-slim\n","Successfully installed tf-slim-1.1.0\n","/content/models-master/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gUnGX3QTFGp2"},"source":["Click on the bottom cell if you want to start the training"]},{"cell_type":"code","metadata":{"id":"F9_qRuibV7gb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608062162579,"user_tz":-330,"elapsed":7047283,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"5bbd898b-9aa5-4332-92c3-d2f68cfa6479"},"source":["%cd /content/models-master/research/object_detection/\n","!python train.py --train_dir=training/ --pipeline_config_path=ssd_mobilenet_v2_quantized_300x300_coco.config\n","#!python train.py --train_dir=training/ --pipeline_config_path=faster_rcnn_inception_v2_pets.config"],"execution_count":18,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","INFO:tensorflow:global step 5084: loss = 4.5178 (0.888 sec/step)\n","I1215 19:18:36.303476 140303514462080 learning.py:512] global step 5084: loss = 4.5178 (0.888 sec/step)\n","INFO:tensorflow:global step 5085: loss = 4.3892 (0.899 sec/step)\n","I1215 19:18:37.204154 140303514462080 learning.py:512] global step 5085: loss = 4.3892 (0.899 sec/step)\n","INFO:tensorflow:global step 5086: loss = 5.6109 (0.893 sec/step)\n","I1215 19:18:38.098228 140303514462080 learning.py:512] global step 5086: loss = 5.6109 (0.893 sec/step)\n","INFO:tensorflow:global step 5087: loss = 5.9070 (0.918 sec/step)\n","I1215 19:18:39.018202 140303514462080 learning.py:512] global step 5087: loss = 5.9070 (0.918 sec/step)\n","INFO:tensorflow:global step 5088: loss = 4.6804 (0.883 sec/step)\n","I1215 19:18:39.903527 140303514462080 learning.py:512] global step 5088: loss = 4.6804 (0.883 sec/step)\n","INFO:tensorflow:global step 5089: loss = 5.0500 (0.894 sec/step)\n","I1215 19:18:40.798620 140303514462080 learning.py:512] global step 5089: loss = 5.0500 (0.894 sec/step)\n","INFO:tensorflow:global step 5090: loss = 5.2653 (0.888 sec/step)\n","I1215 19:18:41.687703 140303514462080 learning.py:512] global step 5090: loss = 5.2653 (0.888 sec/step)\n","INFO:tensorflow:global step 5091: loss = 5.1961 (0.881 sec/step)\n","I1215 19:18:42.570677 140303514462080 learning.py:512] global step 5091: loss = 5.1961 (0.881 sec/step)\n","INFO:tensorflow:global step 5092: loss = 5.1808 (0.895 sec/step)\n","I1215 19:18:43.466928 140303514462080 learning.py:512] global step 5092: loss = 5.1808 (0.895 sec/step)\n","INFO:tensorflow:global step 5093: loss = 7.0259 (0.898 sec/step)\n","I1215 19:18:44.366792 140303514462080 learning.py:512] global step 5093: loss = 7.0259 (0.898 sec/step)\n","INFO:tensorflow:global step 5094: loss = 5.8948 (0.904 sec/step)\n","I1215 19:18:45.272244 140303514462080 learning.py:512] global step 5094: loss = 5.8948 (0.904 sec/step)\n","INFO:tensorflow:global step 5095: loss = 6.4543 (0.876 sec/step)\n","I1215 19:18:46.149639 140303514462080 learning.py:512] global step 5095: loss = 6.4543 (0.876 sec/step)\n","INFO:tensorflow:global step 5096: loss = 4.1804 (0.890 sec/step)\n","I1215 19:18:47.040861 140303514462080 learning.py:512] global step 5096: loss = 4.1804 (0.890 sec/step)\n","INFO:tensorflow:global step 5097: loss = 3.9265 (0.908 sec/step)\n","I1215 19:18:47.950825 140303514462080 learning.py:512] global step 5097: loss = 3.9265 (0.908 sec/step)\n","INFO:tensorflow:global step 5098: loss = 3.8685 (0.891 sec/step)\n","I1215 19:18:48.842693 140303514462080 learning.py:512] global step 5098: loss = 3.8685 (0.891 sec/step)\n","INFO:tensorflow:global step 5099: loss = 4.9263 (0.876 sec/step)\n","I1215 19:18:49.720292 140303514462080 learning.py:512] global step 5099: loss = 4.9263 (0.876 sec/step)\n","INFO:tensorflow:global step 5100: loss = 5.3895 (0.872 sec/step)\n","I1215 19:18:50.593841 140303514462080 learning.py:512] global step 5100: loss = 5.3895 (0.872 sec/step)\n","INFO:tensorflow:global step 5101: loss = 4.1696 (0.881 sec/step)\n","I1215 19:18:51.476379 140303514462080 learning.py:512] global step 5101: loss = 4.1696 (0.881 sec/step)\n","INFO:tensorflow:global step 5102: loss = 3.3139 (0.890 sec/step)\n","I1215 19:18:52.368294 140303514462080 learning.py:512] global step 5102: loss = 3.3139 (0.890 sec/step)\n","INFO:tensorflow:global step 5103: loss = 4.1691 (0.897 sec/step)\n","I1215 19:18:53.266904 140303514462080 learning.py:512] global step 5103: loss = 4.1691 (0.897 sec/step)\n","INFO:tensorflow:global step 5104: loss = 5.0822 (0.900 sec/step)\n","I1215 19:18:54.168498 140303514462080 learning.py:512] global step 5104: loss = 5.0822 (0.900 sec/step)\n","INFO:tensorflow:global step 5105: loss = 4.2978 (0.906 sec/step)\n","I1215 19:18:55.076483 140303514462080 learning.py:512] global step 5105: loss = 4.2978 (0.906 sec/step)\n","INFO:tensorflow:global step 5106: loss = 4.0585 (0.905 sec/step)\n","I1215 19:18:55.982630 140303514462080 learning.py:512] global step 5106: loss = 4.0585 (0.905 sec/step)\n","INFO:tensorflow:global step 5107: loss = 5.3813 (0.888 sec/step)\n","I1215 19:18:56.872120 140303514462080 learning.py:512] global step 5107: loss = 5.3813 (0.888 sec/step)\n","INFO:tensorflow:global step 5108: loss = 5.2525 (0.906 sec/step)\n","I1215 19:18:57.779612 140303514462080 learning.py:512] global step 5108: loss = 5.2525 (0.906 sec/step)\n","INFO:tensorflow:global step 5109: loss = 3.9264 (0.902 sec/step)\n","I1215 19:18:58.683321 140303514462080 learning.py:512] global step 5109: loss = 3.9264 (0.902 sec/step)\n","INFO:tensorflow:global step 5110: loss = 4.2139 (0.891 sec/step)\n","I1215 19:18:59.575968 140303514462080 learning.py:512] global step 5110: loss = 4.2139 (0.891 sec/step)\n","INFO:tensorflow:global step 5111: loss = 3.4138 (0.887 sec/step)\n","I1215 19:19:00.464019 140303514462080 learning.py:512] global step 5111: loss = 3.4138 (0.887 sec/step)\n","INFO:tensorflow:global step 5112: loss = 3.7482 (0.920 sec/step)\n","I1215 19:19:01.385571 140303514462080 learning.py:512] global step 5112: loss = 3.7482 (0.920 sec/step)\n","INFO:tensorflow:global step 5113: loss = 6.0496 (0.903 sec/step)\n","I1215 19:19:02.289740 140303514462080 learning.py:512] global step 5113: loss = 6.0496 (0.903 sec/step)\n","INFO:tensorflow:global step 5114: loss = 4.2162 (0.888 sec/step)\n","I1215 19:19:03.179311 140303514462080 learning.py:512] global step 5114: loss = 4.2162 (0.888 sec/step)\n","INFO:tensorflow:global step 5115: loss = 6.5879 (0.905 sec/step)\n","I1215 19:19:04.086255 140303514462080 learning.py:512] global step 5115: loss = 6.5879 (0.905 sec/step)\n","INFO:tensorflow:global step 5116: loss = 4.1649 (0.896 sec/step)\n","I1215 19:19:04.984364 140303514462080 learning.py:512] global step 5116: loss = 4.1649 (0.896 sec/step)\n","INFO:tensorflow:global step 5117: loss = 4.3106 (0.913 sec/step)\n","I1215 19:19:05.898799 140303514462080 learning.py:512] global step 5117: loss = 4.3106 (0.913 sec/step)\n","INFO:tensorflow:global step 5118: loss = 5.0106 (0.899 sec/step)\n","I1215 19:19:06.799090 140303514462080 learning.py:512] global step 5118: loss = 5.0106 (0.899 sec/step)\n","INFO:tensorflow:global step 5119: loss = 5.2784 (0.891 sec/step)\n","I1215 19:19:07.691164 140303514462080 learning.py:512] global step 5119: loss = 5.2784 (0.891 sec/step)\n","INFO:tensorflow:global step 5120: loss = 4.1616 (0.920 sec/step)\n","I1215 19:19:08.612881 140303514462080 learning.py:512] global step 5120: loss = 4.1616 (0.920 sec/step)\n","INFO:tensorflow:global step 5121: loss = 4.7970 (0.921 sec/step)\n","I1215 19:19:09.535147 140303514462080 learning.py:512] global step 5121: loss = 4.7970 (0.921 sec/step)\n","INFO:tensorflow:global step 5122: loss = 3.2905 (0.925 sec/step)\n","I1215 19:19:10.461543 140303514462080 learning.py:512] global step 5122: loss = 3.2905 (0.925 sec/step)\n","INFO:tensorflow:global step 5123: loss = 4.5527 (0.911 sec/step)\n","I1215 19:19:11.374119 140303514462080 learning.py:512] global step 5123: loss = 4.5527 (0.911 sec/step)\n","INFO:tensorflow:global step 5124: loss = 4.2487 (0.924 sec/step)\n","I1215 19:19:12.299366 140303514462080 learning.py:512] global step 5124: loss = 4.2487 (0.924 sec/step)\n","INFO:tensorflow:global step 5125: loss = 5.4045 (0.875 sec/step)\n","I1215 19:19:13.175780 140303514462080 learning.py:512] global step 5125: loss = 5.4045 (0.875 sec/step)\n","INFO:tensorflow:global step 5126: loss = 4.0662 (0.887 sec/step)\n","I1215 19:19:14.064023 140303514462080 learning.py:512] global step 5126: loss = 4.0662 (0.887 sec/step)\n","INFO:tensorflow:global step 5127: loss = 5.5840 (0.913 sec/step)\n","I1215 19:19:14.978702 140303514462080 learning.py:512] global step 5127: loss = 5.5840 (0.913 sec/step)\n","INFO:tensorflow:global step 5128: loss = 4.2371 (0.892 sec/step)\n","I1215 19:19:15.872299 140303514462080 learning.py:512] global step 5128: loss = 4.2371 (0.892 sec/step)\n","INFO:tensorflow:global step 5129: loss = 6.2107 (0.894 sec/step)\n","I1215 19:19:16.768070 140303514462080 learning.py:512] global step 5129: loss = 6.2107 (0.894 sec/step)\n","INFO:tensorflow:global step 5130: loss = 5.5419 (0.892 sec/step)\n","I1215 19:19:17.661335 140303514462080 learning.py:512] global step 5130: loss = 5.5419 (0.892 sec/step)\n","INFO:tensorflow:global step 5131: loss = 4.9990 (0.887 sec/step)\n","I1215 19:19:18.549370 140303514462080 learning.py:512] global step 5131: loss = 4.9990 (0.887 sec/step)\n","INFO:tensorflow:global step 5132: loss = 3.8267 (0.902 sec/step)\n","I1215 19:19:19.452506 140303514462080 learning.py:512] global step 5132: loss = 3.8267 (0.902 sec/step)\n","INFO:tensorflow:global step 5133: loss = 3.6988 (0.909 sec/step)\n","I1215 19:19:20.363368 140303514462080 learning.py:512] global step 5133: loss = 3.6988 (0.909 sec/step)\n","INFO:tensorflow:global step 5134: loss = 4.4554 (0.887 sec/step)\n","I1215 19:19:21.251583 140303514462080 learning.py:512] global step 5134: loss = 4.4554 (0.887 sec/step)\n","INFO:tensorflow:global step 5135: loss = 4.8456 (0.894 sec/step)\n","I1215 19:19:22.147179 140303514462080 learning.py:512] global step 5135: loss = 4.8456 (0.894 sec/step)\n","INFO:tensorflow:global step 5136: loss = 6.8361 (0.895 sec/step)\n","I1215 19:19:23.043530 140303514462080 learning.py:512] global step 5136: loss = 6.8361 (0.895 sec/step)\n","INFO:tensorflow:global step 5137: loss = 4.4018 (0.901 sec/step)\n","I1215 19:19:23.946165 140303514462080 learning.py:512] global step 5137: loss = 4.4018 (0.901 sec/step)\n","INFO:tensorflow:global step 5138: loss = 4.2811 (0.898 sec/step)\n","I1215 19:19:24.845416 140303514462080 learning.py:512] global step 5138: loss = 4.2811 (0.898 sec/step)\n","INFO:tensorflow:global step 5139: loss = 3.4597 (0.901 sec/step)\n","I1215 19:19:25.747614 140303514462080 learning.py:512] global step 5139: loss = 3.4597 (0.901 sec/step)\n","INFO:tensorflow:global step 5140: loss = 3.8623 (0.908 sec/step)\n","I1215 19:19:26.657530 140303514462080 learning.py:512] global step 5140: loss = 3.8623 (0.908 sec/step)\n","INFO:tensorflow:global step 5141: loss = 5.4100 (0.913 sec/step)\n","I1215 19:19:27.571781 140303514462080 learning.py:512] global step 5141: loss = 5.4100 (0.913 sec/step)\n","INFO:tensorflow:global step 5142: loss = 3.4747 (0.899 sec/step)\n","I1215 19:19:28.472072 140303514462080 learning.py:512] global step 5142: loss = 3.4747 (0.899 sec/step)\n","INFO:tensorflow:global step 5143: loss = 5.5275 (0.904 sec/step)\n","I1215 19:19:29.377971 140303514462080 learning.py:512] global step 5143: loss = 5.5275 (0.904 sec/step)\n","INFO:tensorflow:global step 5144: loss = 3.6065 (0.901 sec/step)\n","I1215 19:19:30.280508 140303514462080 learning.py:512] global step 5144: loss = 3.6065 (0.901 sec/step)\n","INFO:tensorflow:global step 5145: loss = 4.0623 (0.912 sec/step)\n","I1215 19:19:31.193816 140303514462080 learning.py:512] global step 5145: loss = 4.0623 (0.912 sec/step)\n","INFO:tensorflow:global step 5146: loss = 4.9079 (0.904 sec/step)\n","I1215 19:19:32.099480 140303514462080 learning.py:512] global step 5146: loss = 4.9079 (0.904 sec/step)\n","INFO:tensorflow:global step 5147: loss = 5.6818 (0.899 sec/step)\n","I1215 19:19:32.999622 140303514462080 learning.py:512] global step 5147: loss = 5.6818 (0.899 sec/step)\n","INFO:tensorflow:global step 5148: loss = 5.1747 (0.902 sec/step)\n","I1215 19:19:33.902898 140303514462080 learning.py:512] global step 5148: loss = 5.1747 (0.902 sec/step)\n","INFO:tensorflow:global step 5149: loss = 4.6893 (0.891 sec/step)\n","I1215 19:19:34.795295 140303514462080 learning.py:512] global step 5149: loss = 4.6893 (0.891 sec/step)\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I1215 19:19:35.601238 140299865970432 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","INFO:tensorflow:global step 5150: loss = 5.5951 (0.892 sec/step)\n","I1215 19:19:35.773787 140303514462080 learning.py:512] global step 5150: loss = 5.5951 (0.892 sec/step)\n","INFO:tensorflow:global step 5151: loss = 4.4743 (1.763 sec/step)\n","I1215 19:19:37.547872 140303514462080 learning.py:512] global step 5151: loss = 4.4743 (1.763 sec/step)\n","INFO:tensorflow:Recording summary at step 5151.\n","I1215 19:19:37.664121 140299899541248 supervisor.py:1050] Recording summary at step 5151.\n","INFO:tensorflow:global step 5152: loss = 3.8933 (1.321 sec/step)\n","I1215 19:19:38.882225 140303514462080 learning.py:512] global step 5152: loss = 3.8933 (1.321 sec/step)\n","INFO:tensorflow:global step 5153: loss = 4.4313 (1.270 sec/step)\n","I1215 19:19:40.168823 140303514462080 learning.py:512] global step 5153: loss = 4.4313 (1.270 sec/step)\n","INFO:tensorflow:global step 5154: loss = 3.8711 (1.116 sec/step)\n","I1215 19:19:41.286777 140303514462080 learning.py:512] global step 5154: loss = 3.8711 (1.116 sec/step)\n","INFO:tensorflow:global step 5155: loss = 4.3477 (0.903 sec/step)\n","I1215 19:19:42.191251 140303514462080 learning.py:512] global step 5155: loss = 4.3477 (0.903 sec/step)\n","INFO:tensorflow:global step 5156: loss = 2.4164 (0.895 sec/step)\n","I1215 19:19:43.088268 140303514462080 learning.py:512] global step 5156: loss = 2.4164 (0.895 sec/step)\n","INFO:tensorflow:global step 5157: loss = 4.9645 (0.896 sec/step)\n","I1215 19:19:43.985477 140303514462080 learning.py:512] global step 5157: loss = 4.9645 (0.896 sec/step)\n","INFO:tensorflow:global step 5158: loss = 5.7205 (0.890 sec/step)\n","I1215 19:19:44.876498 140303514462080 learning.py:512] global step 5158: loss = 5.7205 (0.890 sec/step)\n","INFO:tensorflow:global step 5159: loss = 3.3742 (0.905 sec/step)\n","I1215 19:19:45.783027 140303514462080 learning.py:512] global step 5159: loss = 3.3742 (0.905 sec/step)\n","INFO:tensorflow:global step 5160: loss = 5.0302 (0.927 sec/step)\n","I1215 19:19:46.711026 140303514462080 learning.py:512] global step 5160: loss = 5.0302 (0.927 sec/step)\n","INFO:tensorflow:global step 5161: loss = 4.6887 (0.886 sec/step)\n","I1215 19:19:47.598881 140303514462080 learning.py:512] global step 5161: loss = 4.6887 (0.886 sec/step)\n","INFO:tensorflow:global step 5162: loss = 4.4177 (0.894 sec/step)\n","I1215 19:19:48.494163 140303514462080 learning.py:512] global step 5162: loss = 4.4177 (0.894 sec/step)\n","INFO:tensorflow:global step 5163: loss = 4.0363 (0.898 sec/step)\n","I1215 19:19:49.394136 140303514462080 learning.py:512] global step 5163: loss = 4.0363 (0.898 sec/step)\n","INFO:tensorflow:global step 5164: loss = 3.9661 (0.892 sec/step)\n","I1215 19:19:50.288093 140303514462080 learning.py:512] global step 5164: loss = 3.9661 (0.892 sec/step)\n","INFO:tensorflow:global step 5165: loss = 4.8803 (0.883 sec/step)\n","I1215 19:19:51.172530 140303514462080 learning.py:512] global step 5165: loss = 4.8803 (0.883 sec/step)\n","INFO:tensorflow:global step 5166: loss = 6.4564 (0.901 sec/step)\n","I1215 19:19:52.075098 140303514462080 learning.py:512] global step 5166: loss = 6.4564 (0.901 sec/step)\n","INFO:tensorflow:global step 5167: loss = 3.7740 (0.909 sec/step)\n","I1215 19:19:52.985516 140303514462080 learning.py:512] global step 5167: loss = 3.7740 (0.909 sec/step)\n","INFO:tensorflow:global step 5168: loss = 3.9096 (0.882 sec/step)\n","I1215 19:19:53.868492 140303514462080 learning.py:512] global step 5168: loss = 3.9096 (0.882 sec/step)\n","INFO:tensorflow:global step 5169: loss = 3.8323 (0.887 sec/step)\n","I1215 19:19:54.757402 140303514462080 learning.py:512] global step 5169: loss = 3.8323 (0.887 sec/step)\n","INFO:tensorflow:global step 5170: loss = 3.8325 (0.902 sec/step)\n","I1215 19:19:55.661206 140303514462080 learning.py:512] global step 5170: loss = 3.8325 (0.902 sec/step)\n","INFO:tensorflow:global step 5171: loss = 3.3640 (0.926 sec/step)\n","I1215 19:19:56.589028 140303514462080 learning.py:512] global step 5171: loss = 3.3640 (0.926 sec/step)\n","INFO:tensorflow:global step 5172: loss = 4.6210 (0.900 sec/step)\n","I1215 19:19:57.490293 140303514462080 learning.py:512] global step 5172: loss = 4.6210 (0.900 sec/step)\n","INFO:tensorflow:global step 5173: loss = 5.5821 (0.906 sec/step)\n","I1215 19:19:58.397768 140303514462080 learning.py:512] global step 5173: loss = 5.5821 (0.906 sec/step)\n","INFO:tensorflow:global step 5174: loss = 3.5621 (0.899 sec/step)\n","I1215 19:19:59.298027 140303514462080 learning.py:512] global step 5174: loss = 3.5621 (0.899 sec/step)\n","INFO:tensorflow:global step 5175: loss = 3.7878 (0.907 sec/step)\n","I1215 19:20:00.206523 140303514462080 learning.py:512] global step 5175: loss = 3.7878 (0.907 sec/step)\n","INFO:tensorflow:global step 5176: loss = 3.8985 (0.903 sec/step)\n","I1215 19:20:01.111502 140303514462080 learning.py:512] global step 5176: loss = 3.8985 (0.903 sec/step)\n","INFO:tensorflow:global step 5177: loss = 3.8565 (0.908 sec/step)\n","I1215 19:20:02.021343 140303514462080 learning.py:512] global step 5177: loss = 3.8565 (0.908 sec/step)\n","INFO:tensorflow:global step 5178: loss = 5.5577 (0.896 sec/step)\n","I1215 19:20:02.918442 140303514462080 learning.py:512] global step 5178: loss = 5.5577 (0.896 sec/step)\n","INFO:tensorflow:global step 5179: loss = 4.1150 (0.896 sec/step)\n","I1215 19:20:03.815768 140303514462080 learning.py:512] global step 5179: loss = 4.1150 (0.896 sec/step)\n","INFO:tensorflow:global step 5180: loss = 4.7545 (0.901 sec/step)\n","I1215 19:20:04.717797 140303514462080 learning.py:512] global step 5180: loss = 4.7545 (0.901 sec/step)\n","INFO:tensorflow:global step 5181: loss = 4.1591 (0.901 sec/step)\n","I1215 19:20:05.620635 140303514462080 learning.py:512] global step 5181: loss = 4.1591 (0.901 sec/step)\n","INFO:tensorflow:global step 5182: loss = 4.1840 (0.899 sec/step)\n","I1215 19:20:06.521496 140303514462080 learning.py:512] global step 5182: loss = 4.1840 (0.899 sec/step)\n","INFO:tensorflow:global step 5183: loss = 5.3792 (0.893 sec/step)\n","I1215 19:20:07.415529 140303514462080 learning.py:512] global step 5183: loss = 5.3792 (0.893 sec/step)\n","INFO:tensorflow:global step 5184: loss = 4.7195 (0.905 sec/step)\n","I1215 19:20:08.322382 140303514462080 learning.py:512] global step 5184: loss = 4.7195 (0.905 sec/step)\n","INFO:tensorflow:global step 5185: loss = 4.0048 (0.920 sec/step)\n","I1215 19:20:09.243884 140303514462080 learning.py:512] global step 5185: loss = 4.0048 (0.920 sec/step)\n","INFO:tensorflow:global step 5186: loss = 5.4156 (0.903 sec/step)\n","I1215 19:20:10.148618 140303514462080 learning.py:512] global step 5186: loss = 5.4156 (0.903 sec/step)\n","INFO:tensorflow:global step 5187: loss = 5.1563 (0.903 sec/step)\n","I1215 19:20:11.053041 140303514462080 learning.py:512] global step 5187: loss = 5.1563 (0.903 sec/step)\n","INFO:tensorflow:global step 5188: loss = 5.6593 (0.908 sec/step)\n","I1215 19:20:11.962610 140303514462080 learning.py:512] global step 5188: loss = 5.6593 (0.908 sec/step)\n","INFO:tensorflow:global step 5189: loss = 4.5606 (0.905 sec/step)\n","I1215 19:20:12.868753 140303514462080 learning.py:512] global step 5189: loss = 4.5606 (0.905 sec/step)\n","INFO:tensorflow:global step 5190: loss = 4.0752 (0.901 sec/step)\n","I1215 19:20:13.771569 140303514462080 learning.py:512] global step 5190: loss = 4.0752 (0.901 sec/step)\n","INFO:tensorflow:global step 5191: loss = 3.1189 (0.902 sec/step)\n","I1215 19:20:14.675218 140303514462080 learning.py:512] global step 5191: loss = 3.1189 (0.902 sec/step)\n","INFO:tensorflow:global step 5192: loss = 4.7534 (0.913 sec/step)\n","I1215 19:20:15.589477 140303514462080 learning.py:512] global step 5192: loss = 4.7534 (0.913 sec/step)\n","INFO:tensorflow:global step 5193: loss = 3.6681 (0.919 sec/step)\n","I1215 19:20:16.509590 140303514462080 learning.py:512] global step 5193: loss = 3.6681 (0.919 sec/step)\n","INFO:tensorflow:global step 5194: loss = 2.8074 (0.903 sec/step)\n","I1215 19:20:17.414244 140303514462080 learning.py:512] global step 5194: loss = 2.8074 (0.903 sec/step)\n","INFO:tensorflow:global step 5195: loss = 4.4312 (0.925 sec/step)\n","I1215 19:20:18.341032 140303514462080 learning.py:512] global step 5195: loss = 4.4312 (0.925 sec/step)\n","INFO:tensorflow:global step 5196: loss = 3.7280 (0.923 sec/step)\n","I1215 19:20:19.265697 140303514462080 learning.py:512] global step 5196: loss = 3.7280 (0.923 sec/step)\n","INFO:tensorflow:global step 5197: loss = 2.7087 (0.899 sec/step)\n","I1215 19:20:20.166089 140303514462080 learning.py:512] global step 5197: loss = 2.7087 (0.899 sec/step)\n","INFO:tensorflow:global step 5198: loss = 6.7484 (0.900 sec/step)\n","I1215 19:20:21.067224 140303514462080 learning.py:512] global step 5198: loss = 6.7484 (0.900 sec/step)\n","INFO:tensorflow:global step 5199: loss = 4.4344 (0.906 sec/step)\n","I1215 19:20:21.974532 140303514462080 learning.py:512] global step 5199: loss = 4.4344 (0.906 sec/step)\n","INFO:tensorflow:global step 5200: loss = 5.1842 (0.906 sec/step)\n","I1215 19:20:22.882012 140303514462080 learning.py:512] global step 5200: loss = 5.1842 (0.906 sec/step)\n","INFO:tensorflow:global step 5201: loss = 4.0558 (0.912 sec/step)\n","I1215 19:20:23.795801 140303514462080 learning.py:512] global step 5201: loss = 4.0558 (0.912 sec/step)\n","INFO:tensorflow:global step 5202: loss = 5.7135 (0.912 sec/step)\n","I1215 19:20:24.709018 140303514462080 learning.py:512] global step 5202: loss = 5.7135 (0.912 sec/step)\n","INFO:tensorflow:global step 5203: loss = 5.4805 (0.887 sec/step)\n","I1215 19:20:25.597805 140303514462080 learning.py:512] global step 5203: loss = 5.4805 (0.887 sec/step)\n","INFO:tensorflow:global step 5204: loss = 4.1644 (0.913 sec/step)\n","I1215 19:20:26.512616 140303514462080 learning.py:512] global step 5204: loss = 4.1644 (0.913 sec/step)\n","INFO:tensorflow:global step 5205: loss = 3.9137 (0.910 sec/step)\n","I1215 19:20:27.424166 140303514462080 learning.py:512] global step 5205: loss = 3.9137 (0.910 sec/step)\n","INFO:tensorflow:global step 5206: loss = 5.2726 (0.906 sec/step)\n","I1215 19:20:28.332031 140303514462080 learning.py:512] global step 5206: loss = 5.2726 (0.906 sec/step)\n","INFO:tensorflow:global step 5207: loss = 3.4304 (0.903 sec/step)\n","I1215 19:20:29.236518 140303514462080 learning.py:512] global step 5207: loss = 3.4304 (0.903 sec/step)\n","INFO:tensorflow:global step 5208: loss = 5.1105 (0.889 sec/step)\n","I1215 19:20:30.126915 140303514462080 learning.py:512] global step 5208: loss = 5.1105 (0.889 sec/step)\n","INFO:tensorflow:global step 5209: loss = 4.3203 (0.899 sec/step)\n","I1215 19:20:31.027285 140303514462080 learning.py:512] global step 5209: loss = 4.3203 (0.899 sec/step)\n","INFO:tensorflow:global step 5210: loss = 4.4237 (0.896 sec/step)\n","I1215 19:20:31.924998 140303514462080 learning.py:512] global step 5210: loss = 4.4237 (0.896 sec/step)\n","INFO:tensorflow:global step 5211: loss = 5.5239 (0.908 sec/step)\n","I1215 19:20:32.834037 140303514462080 learning.py:512] global step 5211: loss = 5.5239 (0.908 sec/step)\n","INFO:tensorflow:global step 5212: loss = 4.6186 (0.904 sec/step)\n","I1215 19:20:33.739367 140303514462080 learning.py:512] global step 5212: loss = 4.6186 (0.904 sec/step)\n","INFO:tensorflow:global step 5213: loss = 5.4792 (0.896 sec/step)\n","I1215 19:20:34.636629 140303514462080 learning.py:512] global step 5213: loss = 5.4792 (0.896 sec/step)\n","INFO:tensorflow:global step 5214: loss = 5.1797 (0.890 sec/step)\n","I1215 19:20:35.528463 140303514462080 learning.py:512] global step 5214: loss = 5.1797 (0.890 sec/step)\n","INFO:tensorflow:global step 5215: loss = 3.6923 (0.882 sec/step)\n","I1215 19:20:36.412016 140303514462080 learning.py:512] global step 5215: loss = 3.6923 (0.882 sec/step)\n","INFO:tensorflow:global step 5216: loss = 3.8397 (0.891 sec/step)\n","I1215 19:20:37.304414 140303514462080 learning.py:512] global step 5216: loss = 3.8397 (0.891 sec/step)\n","INFO:tensorflow:global step 5217: loss = 4.8396 (0.881 sec/step)\n","I1215 19:20:38.187022 140303514462080 learning.py:512] global step 5217: loss = 4.8396 (0.881 sec/step)\n","INFO:tensorflow:global step 5218: loss = 3.4722 (0.884 sec/step)\n","I1215 19:20:39.072885 140303514462080 learning.py:512] global step 5218: loss = 3.4722 (0.884 sec/step)\n","INFO:tensorflow:global step 5219: loss = 3.8077 (0.881 sec/step)\n","I1215 19:20:39.955851 140303514462080 learning.py:512] global step 5219: loss = 3.8077 (0.881 sec/step)\n","INFO:tensorflow:global step 5220: loss = 4.2734 (0.889 sec/step)\n","I1215 19:20:40.846408 140303514462080 learning.py:512] global step 5220: loss = 4.2734 (0.889 sec/step)\n","INFO:tensorflow:global step 5221: loss = 3.9418 (0.880 sec/step)\n","I1215 19:20:41.728386 140303514462080 learning.py:512] global step 5221: loss = 3.9418 (0.880 sec/step)\n","INFO:tensorflow:global step 5222: loss = 4.5647 (0.890 sec/step)\n","I1215 19:20:42.619719 140303514462080 learning.py:512] global step 5222: loss = 4.5647 (0.890 sec/step)\n","INFO:tensorflow:global step 5223: loss = 4.3605 (0.881 sec/step)\n","I1215 19:20:43.501840 140303514462080 learning.py:512] global step 5223: loss = 4.3605 (0.881 sec/step)\n","INFO:tensorflow:global step 5224: loss = 3.9429 (0.890 sec/step)\n","I1215 19:20:44.393677 140303514462080 learning.py:512] global step 5224: loss = 3.9429 (0.890 sec/step)\n","INFO:tensorflow:global step 5225: loss = 4.8514 (0.897 sec/step)\n","I1215 19:20:45.291885 140303514462080 learning.py:512] global step 5225: loss = 4.8514 (0.897 sec/step)\n","INFO:tensorflow:global step 5226: loss = 3.1708 (0.888 sec/step)\n","I1215 19:20:46.181265 140303514462080 learning.py:512] global step 5226: loss = 3.1708 (0.888 sec/step)\n","INFO:tensorflow:global step 5227: loss = 4.8735 (0.887 sec/step)\n","I1215 19:20:47.070404 140303514462080 learning.py:512] global step 5227: loss = 4.8735 (0.887 sec/step)\n","INFO:tensorflow:global step 5228: loss = 4.4913 (0.888 sec/step)\n","I1215 19:20:47.960293 140303514462080 learning.py:512] global step 5228: loss = 4.4913 (0.888 sec/step)\n","INFO:tensorflow:global step 5229: loss = 5.1443 (0.893 sec/step)\n","I1215 19:20:48.854607 140303514462080 learning.py:512] global step 5229: loss = 5.1443 (0.893 sec/step)\n","INFO:tensorflow:global step 5230: loss = 2.9259 (0.890 sec/step)\n","I1215 19:20:49.745870 140303514462080 learning.py:512] global step 5230: loss = 2.9259 (0.890 sec/step)\n","INFO:tensorflow:global step 5231: loss = 4.5346 (0.876 sec/step)\n","I1215 19:20:50.623753 140303514462080 learning.py:512] global step 5231: loss = 4.5346 (0.876 sec/step)\n","INFO:tensorflow:global step 5232: loss = 2.6813 (0.898 sec/step)\n","I1215 19:20:51.523435 140303514462080 learning.py:512] global step 5232: loss = 2.6813 (0.898 sec/step)\n","INFO:tensorflow:global step 5233: loss = 4.9712 (0.900 sec/step)\n","I1215 19:20:52.425490 140303514462080 learning.py:512] global step 5233: loss = 4.9712 (0.900 sec/step)\n","INFO:tensorflow:global step 5234: loss = 4.5925 (0.898 sec/step)\n","I1215 19:20:53.324795 140303514462080 learning.py:512] global step 5234: loss = 4.5925 (0.898 sec/step)\n","INFO:tensorflow:global step 5235: loss = 4.3997 (0.894 sec/step)\n","I1215 19:20:54.220667 140303514462080 learning.py:512] global step 5235: loss = 4.3997 (0.894 sec/step)\n","INFO:tensorflow:global step 5236: loss = 4.6680 (0.879 sec/step)\n","I1215 19:20:55.101301 140303514462080 learning.py:512] global step 5236: loss = 4.6680 (0.879 sec/step)\n","INFO:tensorflow:global step 5237: loss = 5.0843 (0.899 sec/step)\n","I1215 19:20:56.001619 140303514462080 learning.py:512] global step 5237: loss = 5.0843 (0.899 sec/step)\n","INFO:tensorflow:global step 5238: loss = 4.2062 (0.887 sec/step)\n","I1215 19:20:56.890725 140303514462080 learning.py:512] global step 5238: loss = 4.2062 (0.887 sec/step)\n","INFO:tensorflow:global step 5239: loss = 3.7546 (0.900 sec/step)\n","I1215 19:20:57.792815 140303514462080 learning.py:512] global step 5239: loss = 3.7546 (0.900 sec/step)\n","INFO:tensorflow:global step 5240: loss = 3.0756 (0.884 sec/step)\n","I1215 19:20:58.678245 140303514462080 learning.py:512] global step 5240: loss = 3.0756 (0.884 sec/step)\n","INFO:tensorflow:global step 5241: loss = 4.3840 (0.903 sec/step)\n","I1215 19:20:59.583294 140303514462080 learning.py:512] global step 5241: loss = 4.3840 (0.903 sec/step)\n","INFO:tensorflow:global step 5242: loss = 5.0595 (0.907 sec/step)\n","I1215 19:21:00.492041 140303514462080 learning.py:512] global step 5242: loss = 5.0595 (0.907 sec/step)\n","INFO:tensorflow:global step 5243: loss = 4.2701 (0.899 sec/step)\n","I1215 19:21:01.392575 140303514462080 learning.py:512] global step 5243: loss = 4.2701 (0.899 sec/step)\n","INFO:tensorflow:global step 5244: loss = 3.4787 (0.897 sec/step)\n","I1215 19:21:02.290991 140303514462080 learning.py:512] global step 5244: loss = 3.4787 (0.897 sec/step)\n","INFO:tensorflow:global step 5245: loss = 4.3603 (0.890 sec/step)\n","I1215 19:21:03.183208 140303514462080 learning.py:512] global step 5245: loss = 4.3603 (0.890 sec/step)\n","INFO:tensorflow:global step 5246: loss = 3.6748 (0.899 sec/step)\n","I1215 19:21:04.084081 140303514462080 learning.py:512] global step 5246: loss = 3.6748 (0.899 sec/step)\n","INFO:tensorflow:global step 5247: loss = 3.7319 (0.919 sec/step)\n","I1215 19:21:05.004508 140303514462080 learning.py:512] global step 5247: loss = 3.7319 (0.919 sec/step)\n","INFO:tensorflow:global step 5248: loss = 3.6419 (0.895 sec/step)\n","I1215 19:21:05.900519 140303514462080 learning.py:512] global step 5248: loss = 3.6419 (0.895 sec/step)\n","INFO:tensorflow:global step 5249: loss = 4.4472 (0.891 sec/step)\n","I1215 19:21:06.792556 140303514462080 learning.py:512] global step 5249: loss = 4.4472 (0.891 sec/step)\n","INFO:tensorflow:global step 5250: loss = 3.0532 (0.896 sec/step)\n","I1215 19:21:07.690369 140303514462080 learning.py:512] global step 5250: loss = 3.0532 (0.896 sec/step)\n","INFO:tensorflow:global step 5251: loss = 4.7773 (0.897 sec/step)\n","I1215 19:21:08.589149 140303514462080 learning.py:512] global step 5251: loss = 4.7773 (0.897 sec/step)\n","INFO:tensorflow:global step 5252: loss = 5.4545 (0.918 sec/step)\n","I1215 19:21:09.508588 140303514462080 learning.py:512] global step 5252: loss = 5.4545 (0.918 sec/step)\n","INFO:tensorflow:global step 5253: loss = 5.9344 (0.904 sec/step)\n","I1215 19:21:10.414259 140303514462080 learning.py:512] global step 5253: loss = 5.9344 (0.904 sec/step)\n","INFO:tensorflow:global step 5254: loss = 3.3545 (0.898 sec/step)\n","I1215 19:21:11.314157 140303514462080 learning.py:512] global step 5254: loss = 3.3545 (0.898 sec/step)\n","INFO:tensorflow:global step 5255: loss = 5.7991 (0.915 sec/step)\n","I1215 19:21:12.231026 140303514462080 learning.py:512] global step 5255: loss = 5.7991 (0.915 sec/step)\n","INFO:tensorflow:global step 5256: loss = 3.4530 (0.902 sec/step)\n","I1215 19:21:13.134272 140303514462080 learning.py:512] global step 5256: loss = 3.4530 (0.902 sec/step)\n","INFO:tensorflow:global step 5257: loss = 4.1479 (0.891 sec/step)\n","I1215 19:21:14.026818 140303514462080 learning.py:512] global step 5257: loss = 4.1479 (0.891 sec/step)\n","INFO:tensorflow:global step 5258: loss = 4.3990 (0.891 sec/step)\n","I1215 19:21:14.919458 140303514462080 learning.py:512] global step 5258: loss = 4.3990 (0.891 sec/step)\n","INFO:tensorflow:global step 5259: loss = 3.8668 (0.891 sec/step)\n","I1215 19:21:15.811469 140303514462080 learning.py:512] global step 5259: loss = 3.8668 (0.891 sec/step)\n","INFO:tensorflow:global step 5260: loss = 3.8229 (0.907 sec/step)\n","I1215 19:21:16.720319 140303514462080 learning.py:512] global step 5260: loss = 3.8229 (0.907 sec/step)\n","INFO:tensorflow:global step 5261: loss = 3.6337 (0.898 sec/step)\n","I1215 19:21:17.619811 140303514462080 learning.py:512] global step 5261: loss = 3.6337 (0.898 sec/step)\n","INFO:tensorflow:global step 5262: loss = 4.3755 (0.901 sec/step)\n","I1215 19:21:18.522880 140303514462080 learning.py:512] global step 5262: loss = 4.3755 (0.901 sec/step)\n","INFO:tensorflow:global step 5263: loss = 3.6420 (0.907 sec/step)\n","I1215 19:21:19.431954 140303514462080 learning.py:512] global step 5263: loss = 3.6420 (0.907 sec/step)\n","INFO:tensorflow:global step 5264: loss = 3.5329 (0.919 sec/step)\n","I1215 19:21:20.352596 140303514462080 learning.py:512] global step 5264: loss = 3.5329 (0.919 sec/step)\n","INFO:tensorflow:global step 5265: loss = 5.6291 (0.876 sec/step)\n","I1215 19:21:21.230740 140303514462080 learning.py:512] global step 5265: loss = 5.6291 (0.876 sec/step)\n","INFO:tensorflow:global step 5266: loss = 3.9701 (0.878 sec/step)\n","I1215 19:21:22.110110 140303514462080 learning.py:512] global step 5266: loss = 3.9701 (0.878 sec/step)\n","INFO:tensorflow:global step 5267: loss = 4.5367 (0.902 sec/step)\n","I1215 19:21:23.013444 140303514462080 learning.py:512] global step 5267: loss = 4.5367 (0.902 sec/step)\n","INFO:tensorflow:global step 5268: loss = 3.6070 (0.904 sec/step)\n","I1215 19:21:23.919056 140303514462080 learning.py:512] global step 5268: loss = 3.6070 (0.904 sec/step)\n","INFO:tensorflow:global step 5269: loss = 3.0273 (0.895 sec/step)\n","I1215 19:21:24.815848 140303514462080 learning.py:512] global step 5269: loss = 3.0273 (0.895 sec/step)\n","INFO:tensorflow:global step 5270: loss = 4.6546 (0.894 sec/step)\n","I1215 19:21:25.711171 140303514462080 learning.py:512] global step 5270: loss = 4.6546 (0.894 sec/step)\n","INFO:tensorflow:global step 5271: loss = 4.7276 (0.913 sec/step)\n","I1215 19:21:26.625366 140303514462080 learning.py:512] global step 5271: loss = 4.7276 (0.913 sec/step)\n","INFO:tensorflow:global step 5272: loss = 5.5893 (0.899 sec/step)\n","I1215 19:21:27.526313 140303514462080 learning.py:512] global step 5272: loss = 5.5893 (0.899 sec/step)\n","INFO:tensorflow:global step 5273: loss = 3.1247 (0.904 sec/step)\n","I1215 19:21:28.431795 140303514462080 learning.py:512] global step 5273: loss = 3.1247 (0.904 sec/step)\n","INFO:tensorflow:global step 5274: loss = 3.7522 (0.887 sec/step)\n","I1215 19:21:29.320497 140303514462080 learning.py:512] global step 5274: loss = 3.7522 (0.887 sec/step)\n","INFO:tensorflow:global step 5275: loss = 3.9066 (0.897 sec/step)\n","I1215 19:21:30.219355 140303514462080 learning.py:512] global step 5275: loss = 3.9066 (0.897 sec/step)\n","INFO:tensorflow:global step 5276: loss = 5.4491 (0.894 sec/step)\n","I1215 19:21:31.115177 140303514462080 learning.py:512] global step 5276: loss = 5.4491 (0.894 sec/step)\n","INFO:tensorflow:global step 5277: loss = 5.3027 (0.920 sec/step)\n","I1215 19:21:32.036672 140303514462080 learning.py:512] global step 5277: loss = 5.3027 (0.920 sec/step)\n","INFO:tensorflow:global step 5278: loss = 4.2777 (0.916 sec/step)\n","I1215 19:21:32.953958 140303514462080 learning.py:512] global step 5278: loss = 4.2777 (0.916 sec/step)\n","INFO:tensorflow:global step 5279: loss = 3.0501 (0.908 sec/step)\n","I1215 19:21:33.863839 140303514462080 learning.py:512] global step 5279: loss = 3.0501 (0.908 sec/step)\n","INFO:tensorflow:global step 5280: loss = 5.9822 (0.897 sec/step)\n","I1215 19:21:34.762456 140303514462080 learning.py:512] global step 5280: loss = 5.9822 (0.897 sec/step)\n","INFO:tensorflow:global step 5281: loss = 4.3884 (0.912 sec/step)\n","I1215 19:21:35.678339 140303514462080 learning.py:512] global step 5281: loss = 4.3884 (0.912 sec/step)\n","INFO:tensorflow:global step 5282: loss = 4.8223 (1.430 sec/step)\n","I1215 19:21:37.129232 140303514462080 learning.py:512] global step 5282: loss = 4.8223 (1.430 sec/step)\n","INFO:tensorflow:Recording summary at step 5282.\n","I1215 19:21:37.143945 140299899541248 supervisor.py:1050] Recording summary at step 5282.\n","INFO:tensorflow:global step 5283: loss = 4.0002 (0.908 sec/step)\n","I1215 19:21:38.039135 140303514462080 learning.py:512] global step 5283: loss = 4.0002 (0.908 sec/step)\n","INFO:tensorflow:global step 5284: loss = 5.6460 (0.903 sec/step)\n","I1215 19:21:38.944010 140303514462080 learning.py:512] global step 5284: loss = 5.6460 (0.903 sec/step)\n","INFO:tensorflow:global step 5285: loss = 5.5430 (0.903 sec/step)\n","I1215 19:21:39.848416 140303514462080 learning.py:512] global step 5285: loss = 5.5430 (0.903 sec/step)\n","INFO:tensorflow:global step 5286: loss = 2.2743 (0.894 sec/step)\n","I1215 19:21:40.743760 140303514462080 learning.py:512] global step 5286: loss = 2.2743 (0.894 sec/step)\n","INFO:tensorflow:global step 5287: loss = 5.9283 (0.907 sec/step)\n","I1215 19:21:41.652595 140303514462080 learning.py:512] global step 5287: loss = 5.9283 (0.907 sec/step)\n","INFO:tensorflow:global step 5288: loss = 4.3281 (0.922 sec/step)\n","I1215 19:21:42.575722 140303514462080 learning.py:512] global step 5288: loss = 4.3281 (0.922 sec/step)\n","INFO:tensorflow:global step 5289: loss = 3.7563 (0.892 sec/step)\n","I1215 19:21:43.469822 140303514462080 learning.py:512] global step 5289: loss = 3.7563 (0.892 sec/step)\n","INFO:tensorflow:global step 5290: loss = 4.6932 (0.900 sec/step)\n","I1215 19:21:44.371177 140303514462080 learning.py:512] global step 5290: loss = 4.6932 (0.900 sec/step)\n","INFO:tensorflow:global step 5291: loss = 2.7094 (0.917 sec/step)\n","I1215 19:21:45.289755 140303514462080 learning.py:512] global step 5291: loss = 2.7094 (0.917 sec/step)\n","INFO:tensorflow:global step 5292: loss = 4.5713 (0.911 sec/step)\n","I1215 19:21:46.202255 140303514462080 learning.py:512] global step 5292: loss = 4.5713 (0.911 sec/step)\n","INFO:tensorflow:global step 5293: loss = 3.4851 (0.918 sec/step)\n","I1215 19:21:47.122162 140303514462080 learning.py:512] global step 5293: loss = 3.4851 (0.918 sec/step)\n","INFO:tensorflow:global step 5294: loss = 5.4820 (0.893 sec/step)\n","I1215 19:21:48.016893 140303514462080 learning.py:512] global step 5294: loss = 5.4820 (0.893 sec/step)\n","INFO:tensorflow:global step 5295: loss = 4.8730 (0.899 sec/step)\n","I1215 19:21:48.917508 140303514462080 learning.py:512] global step 5295: loss = 4.8730 (0.899 sec/step)\n","INFO:tensorflow:global step 5296: loss = 6.1061 (0.913 sec/step)\n","I1215 19:21:49.831727 140303514462080 learning.py:512] global step 5296: loss = 6.1061 (0.913 sec/step)\n","INFO:tensorflow:global step 5297: loss = 5.8170 (0.913 sec/step)\n","I1215 19:21:50.746305 140303514462080 learning.py:512] global step 5297: loss = 5.8170 (0.913 sec/step)\n","INFO:tensorflow:global step 5298: loss = 3.9079 (0.919 sec/step)\n","I1215 19:21:51.666736 140303514462080 learning.py:512] global step 5298: loss = 3.9079 (0.919 sec/step)\n","INFO:tensorflow:global step 5299: loss = 4.9320 (0.889 sec/step)\n","I1215 19:21:52.557590 140303514462080 learning.py:512] global step 5299: loss = 4.9320 (0.889 sec/step)\n","INFO:tensorflow:global step 5300: loss = 4.6198 (0.878 sec/step)\n","I1215 19:21:53.437263 140303514462080 learning.py:512] global step 5300: loss = 4.6198 (0.878 sec/step)\n","INFO:tensorflow:global step 5301: loss = 3.6914 (0.911 sec/step)\n","I1215 19:21:54.350195 140303514462080 learning.py:512] global step 5301: loss = 3.6914 (0.911 sec/step)\n","INFO:tensorflow:global step 5302: loss = 3.8457 (0.907 sec/step)\n","I1215 19:21:55.258428 140303514462080 learning.py:512] global step 5302: loss = 3.8457 (0.907 sec/step)\n","INFO:tensorflow:global step 5303: loss = 4.9237 (0.903 sec/step)\n","I1215 19:21:56.163254 140303514462080 learning.py:512] global step 5303: loss = 4.9237 (0.903 sec/step)\n","INFO:tensorflow:global step 5304: loss = 3.9585 (0.909 sec/step)\n","I1215 19:21:57.073891 140303514462080 learning.py:512] global step 5304: loss = 3.9585 (0.909 sec/step)\n","INFO:tensorflow:global step 5305: loss = 4.6488 (0.895 sec/step)\n","I1215 19:21:57.970243 140303514462080 learning.py:512] global step 5305: loss = 4.6488 (0.895 sec/step)\n","INFO:tensorflow:global step 5306: loss = 2.7533 (0.902 sec/step)\n","I1215 19:21:58.873913 140303514462080 learning.py:512] global step 5306: loss = 2.7533 (0.902 sec/step)\n","INFO:tensorflow:global step 5307: loss = 4.9419 (0.893 sec/step)\n","I1215 19:21:59.768164 140303514462080 learning.py:512] global step 5307: loss = 4.9419 (0.893 sec/step)\n","INFO:tensorflow:global step 5308: loss = 4.0089 (0.889 sec/step)\n","I1215 19:22:00.659154 140303514462080 learning.py:512] global step 5308: loss = 4.0089 (0.889 sec/step)\n","INFO:tensorflow:global step 5309: loss = 3.3657 (0.900 sec/step)\n","I1215 19:22:01.561155 140303514462080 learning.py:512] global step 5309: loss = 3.3657 (0.900 sec/step)\n","INFO:tensorflow:global step 5310: loss = 4.7081 (0.917 sec/step)\n","I1215 19:22:02.479876 140303514462080 learning.py:512] global step 5310: loss = 4.7081 (0.917 sec/step)\n","INFO:tensorflow:global step 5311: loss = 4.2526 (0.910 sec/step)\n","I1215 19:22:03.391478 140303514462080 learning.py:512] global step 5311: loss = 4.2526 (0.910 sec/step)\n","INFO:tensorflow:global step 5312: loss = 3.5689 (0.907 sec/step)\n","I1215 19:22:04.299811 140303514462080 learning.py:512] global step 5312: loss = 3.5689 (0.907 sec/step)\n","INFO:tensorflow:global step 5313: loss = 6.0439 (0.898 sec/step)\n","I1215 19:22:05.199672 140303514462080 learning.py:512] global step 5313: loss = 6.0439 (0.898 sec/step)\n","INFO:tensorflow:global step 5314: loss = 4.4358 (0.881 sec/step)\n","I1215 19:22:06.082723 140303514462080 learning.py:512] global step 5314: loss = 4.4358 (0.881 sec/step)\n","INFO:tensorflow:global step 5315: loss = 5.3405 (0.890 sec/step)\n","I1215 19:22:06.974419 140303514462080 learning.py:512] global step 5315: loss = 5.3405 (0.890 sec/step)\n","INFO:tensorflow:global step 5316: loss = 5.5718 (0.898 sec/step)\n","I1215 19:22:07.874150 140303514462080 learning.py:512] global step 5316: loss = 5.5718 (0.898 sec/step)\n","INFO:tensorflow:global step 5317: loss = 3.6783 (0.893 sec/step)\n","I1215 19:22:08.768396 140303514462080 learning.py:512] global step 5317: loss = 3.6783 (0.893 sec/step)\n","INFO:tensorflow:global step 5318: loss = 5.2912 (0.917 sec/step)\n","I1215 19:22:09.686450 140303514462080 learning.py:512] global step 5318: loss = 5.2912 (0.917 sec/step)\n","INFO:tensorflow:global step 5319: loss = 5.1107 (0.894 sec/step)\n","I1215 19:22:10.582039 140303514462080 learning.py:512] global step 5319: loss = 5.1107 (0.894 sec/step)\n","INFO:tensorflow:global step 5320: loss = 6.2445 (0.895 sec/step)\n","I1215 19:22:11.478534 140303514462080 learning.py:512] global step 5320: loss = 6.2445 (0.895 sec/step)\n","INFO:tensorflow:global step 5321: loss = 5.9262 (0.911 sec/step)\n","I1215 19:22:12.390797 140303514462080 learning.py:512] global step 5321: loss = 5.9262 (0.911 sec/step)\n","INFO:tensorflow:global step 5322: loss = 4.1296 (0.897 sec/step)\n","I1215 19:22:13.290029 140303514462080 learning.py:512] global step 5322: loss = 4.1296 (0.897 sec/step)\n","INFO:tensorflow:global step 5323: loss = 3.8030 (0.911 sec/step)\n","I1215 19:22:14.202595 140303514462080 learning.py:512] global step 5323: loss = 3.8030 (0.911 sec/step)\n","INFO:tensorflow:global step 5324: loss = 3.8156 (0.918 sec/step)\n","I1215 19:22:15.121971 140303514462080 learning.py:512] global step 5324: loss = 3.8156 (0.918 sec/step)\n","INFO:tensorflow:global step 5325: loss = 2.8787 (0.901 sec/step)\n","I1215 19:22:16.024744 140303514462080 learning.py:512] global step 5325: loss = 2.8787 (0.901 sec/step)\n","INFO:tensorflow:global step 5326: loss = 4.4873 (0.902 sec/step)\n","I1215 19:22:16.928695 140303514462080 learning.py:512] global step 5326: loss = 4.4873 (0.902 sec/step)\n","INFO:tensorflow:global step 5327: loss = 3.6856 (0.896 sec/step)\n","I1215 19:22:17.826554 140303514462080 learning.py:512] global step 5327: loss = 3.6856 (0.896 sec/step)\n","INFO:tensorflow:global step 5328: loss = 3.3247 (0.916 sec/step)\n","I1215 19:22:18.743720 140303514462080 learning.py:512] global step 5328: loss = 3.3247 (0.916 sec/step)\n","INFO:tensorflow:global step 5329: loss = 4.7030 (0.893 sec/step)\n","I1215 19:22:19.637977 140303514462080 learning.py:512] global step 5329: loss = 4.7030 (0.893 sec/step)\n","INFO:tensorflow:global step 5330: loss = 4.9068 (0.898 sec/step)\n","I1215 19:22:20.537384 140303514462080 learning.py:512] global step 5330: loss = 4.9068 (0.898 sec/step)\n","INFO:tensorflow:global step 5331: loss = 4.9131 (0.884 sec/step)\n","I1215 19:22:21.422788 140303514462080 learning.py:512] global step 5331: loss = 4.9131 (0.884 sec/step)\n","INFO:tensorflow:global step 5332: loss = 3.7708 (0.901 sec/step)\n","I1215 19:22:22.325161 140303514462080 learning.py:512] global step 5332: loss = 3.7708 (0.901 sec/step)\n","INFO:tensorflow:global step 5333: loss = 4.6372 (0.908 sec/step)\n","I1215 19:22:23.234619 140303514462080 learning.py:512] global step 5333: loss = 4.6372 (0.908 sec/step)\n","INFO:tensorflow:global step 5334: loss = 4.6002 (0.898 sec/step)\n","I1215 19:22:24.133917 140303514462080 learning.py:512] global step 5334: loss = 4.6002 (0.898 sec/step)\n","INFO:tensorflow:global step 5335: loss = 4.9855 (0.909 sec/step)\n","I1215 19:22:25.044249 140303514462080 learning.py:512] global step 5335: loss = 4.9855 (0.909 sec/step)\n","INFO:tensorflow:global step 5336: loss = 5.2287 (0.892 sec/step)\n","I1215 19:22:25.937370 140303514462080 learning.py:512] global step 5336: loss = 5.2287 (0.892 sec/step)\n","INFO:tensorflow:global step 5337: loss = 5.6256 (0.892 sec/step)\n","I1215 19:22:26.830372 140303514462080 learning.py:512] global step 5337: loss = 5.6256 (0.892 sec/step)\n","INFO:tensorflow:global step 5338: loss = 4.0956 (0.876 sec/step)\n","I1215 19:22:27.707780 140303514462080 learning.py:512] global step 5338: loss = 4.0956 (0.876 sec/step)\n","INFO:tensorflow:global step 5339: loss = 3.7911 (0.882 sec/step)\n","I1215 19:22:28.591142 140303514462080 learning.py:512] global step 5339: loss = 3.7911 (0.882 sec/step)\n","INFO:tensorflow:global step 5340: loss = 3.6758 (0.893 sec/step)\n","I1215 19:22:29.485257 140303514462080 learning.py:512] global step 5340: loss = 3.6758 (0.893 sec/step)\n","INFO:tensorflow:global step 5341: loss = 6.8383 (0.909 sec/step)\n","I1215 19:22:30.395621 140303514462080 learning.py:512] global step 5341: loss = 6.8383 (0.909 sec/step)\n","INFO:tensorflow:global step 5342: loss = 3.7529 (0.882 sec/step)\n","I1215 19:22:31.279210 140303514462080 learning.py:512] global step 5342: loss = 3.7529 (0.882 sec/step)\n","INFO:tensorflow:global step 5343: loss = 3.8248 (0.905 sec/step)\n","I1215 19:22:32.185449 140303514462080 learning.py:512] global step 5343: loss = 3.8248 (0.905 sec/step)\n","INFO:tensorflow:global step 5344: loss = 5.9746 (0.891 sec/step)\n","I1215 19:22:33.077780 140303514462080 learning.py:512] global step 5344: loss = 5.9746 (0.891 sec/step)\n","INFO:tensorflow:global step 5345: loss = 5.8957 (0.900 sec/step)\n","I1215 19:22:33.978886 140303514462080 learning.py:512] global step 5345: loss = 5.8957 (0.900 sec/step)\n","INFO:tensorflow:global step 5346: loss = 6.1686 (0.890 sec/step)\n","I1215 19:22:34.870726 140303514462080 learning.py:512] global step 5346: loss = 6.1686 (0.890 sec/step)\n","INFO:tensorflow:global step 5347: loss = 5.7113 (0.877 sec/step)\n","I1215 19:22:35.749545 140303514462080 learning.py:512] global step 5347: loss = 5.7113 (0.877 sec/step)\n","INFO:tensorflow:global step 5348: loss = 3.8326 (0.884 sec/step)\n","I1215 19:22:36.635464 140303514462080 learning.py:512] global step 5348: loss = 3.8326 (0.884 sec/step)\n","INFO:tensorflow:global step 5349: loss = 3.7436 (0.891 sec/step)\n","I1215 19:22:37.527480 140303514462080 learning.py:512] global step 5349: loss = 3.7436 (0.891 sec/step)\n","INFO:tensorflow:global step 5350: loss = 4.6000 (0.879 sec/step)\n","I1215 19:22:38.407808 140303514462080 learning.py:512] global step 5350: loss = 4.6000 (0.879 sec/step)\n","INFO:tensorflow:global step 5351: loss = 4.5316 (0.889 sec/step)\n","I1215 19:22:39.298530 140303514462080 learning.py:512] global step 5351: loss = 4.5316 (0.889 sec/step)\n","INFO:tensorflow:global step 5352: loss = 4.2403 (0.884 sec/step)\n","I1215 19:22:40.184203 140303514462080 learning.py:512] global step 5352: loss = 4.2403 (0.884 sec/step)\n","INFO:tensorflow:global step 5353: loss = 3.6551 (0.914 sec/step)\n","I1215 19:22:41.099897 140303514462080 learning.py:512] global step 5353: loss = 3.6551 (0.914 sec/step)\n","INFO:tensorflow:global step 5354: loss = 4.1655 (0.898 sec/step)\n","I1215 19:22:41.999739 140303514462080 learning.py:512] global step 5354: loss = 4.1655 (0.898 sec/step)\n","INFO:tensorflow:global step 5355: loss = 4.7937 (0.902 sec/step)\n","I1215 19:22:42.902931 140303514462080 learning.py:512] global step 5355: loss = 4.7937 (0.902 sec/step)\n","INFO:tensorflow:global step 5356: loss = 5.0340 (0.893 sec/step)\n","I1215 19:22:43.797678 140303514462080 learning.py:512] global step 5356: loss = 5.0340 (0.893 sec/step)\n","INFO:tensorflow:global step 5357: loss = 3.9524 (0.933 sec/step)\n","I1215 19:22:44.731730 140303514462080 learning.py:512] global step 5357: loss = 3.9524 (0.933 sec/step)\n","INFO:tensorflow:global step 5358: loss = 6.6573 (0.906 sec/step)\n","I1215 19:22:45.639037 140303514462080 learning.py:512] global step 5358: loss = 6.6573 (0.906 sec/step)\n","INFO:tensorflow:global step 5359: loss = 6.5413 (0.906 sec/step)\n","I1215 19:22:46.547358 140303514462080 learning.py:512] global step 5359: loss = 6.5413 (0.906 sec/step)\n","INFO:tensorflow:global step 5360: loss = 3.6907 (0.903 sec/step)\n","I1215 19:22:47.451791 140303514462080 learning.py:512] global step 5360: loss = 3.6907 (0.903 sec/step)\n","INFO:tensorflow:global step 5361: loss = 3.8711 (0.887 sec/step)\n","I1215 19:22:48.339977 140303514462080 learning.py:512] global step 5361: loss = 3.8711 (0.887 sec/step)\n","INFO:tensorflow:global step 5362: loss = 3.7196 (0.882 sec/step)\n","I1215 19:22:49.223317 140303514462080 learning.py:512] global step 5362: loss = 3.7196 (0.882 sec/step)\n","INFO:tensorflow:global step 5363: loss = 4.1490 (0.900 sec/step)\n","I1215 19:22:50.125261 140303514462080 learning.py:512] global step 5363: loss = 4.1490 (0.900 sec/step)\n","INFO:tensorflow:global step 5364: loss = 6.3687 (0.898 sec/step)\n","I1215 19:22:51.024421 140303514462080 learning.py:512] global step 5364: loss = 6.3687 (0.898 sec/step)\n","INFO:tensorflow:global step 5365: loss = 4.1012 (0.895 sec/step)\n","I1215 19:22:51.921416 140303514462080 learning.py:512] global step 5365: loss = 4.1012 (0.895 sec/step)\n","INFO:tensorflow:global step 5366: loss = 5.4713 (0.895 sec/step)\n","I1215 19:22:52.817933 140303514462080 learning.py:512] global step 5366: loss = 5.4713 (0.895 sec/step)\n","INFO:tensorflow:global step 5367: loss = 4.0209 (0.889 sec/step)\n","I1215 19:22:53.708626 140303514462080 learning.py:512] global step 5367: loss = 4.0209 (0.889 sec/step)\n","INFO:tensorflow:global step 5368: loss = 4.5198 (0.904 sec/step)\n","I1215 19:22:54.614630 140303514462080 learning.py:512] global step 5368: loss = 4.5198 (0.904 sec/step)\n","INFO:tensorflow:global step 5369: loss = 3.6657 (0.892 sec/step)\n","I1215 19:22:55.508281 140303514462080 learning.py:512] global step 5369: loss = 3.6657 (0.892 sec/step)\n","INFO:tensorflow:global step 5370: loss = 3.7427 (0.898 sec/step)\n","I1215 19:22:56.408320 140303514462080 learning.py:512] global step 5370: loss = 3.7427 (0.898 sec/step)\n","INFO:tensorflow:global step 5371: loss = 3.7713 (0.898 sec/step)\n","I1215 19:22:57.308238 140303514462080 learning.py:512] global step 5371: loss = 3.7713 (0.898 sec/step)\n","INFO:tensorflow:global step 5372: loss = 4.0222 (0.893 sec/step)\n","I1215 19:22:58.202431 140303514462080 learning.py:512] global step 5372: loss = 4.0222 (0.893 sec/step)\n","INFO:tensorflow:global step 5373: loss = 4.5154 (0.914 sec/step)\n","I1215 19:22:59.117815 140303514462080 learning.py:512] global step 5373: loss = 4.5154 (0.914 sec/step)\n","INFO:tensorflow:global step 5374: loss = 3.9293 (0.895 sec/step)\n","I1215 19:23:00.014705 140303514462080 learning.py:512] global step 5374: loss = 3.9293 (0.895 sec/step)\n","INFO:tensorflow:global step 5375: loss = 5.4189 (0.904 sec/step)\n","I1215 19:23:00.919881 140303514462080 learning.py:512] global step 5375: loss = 5.4189 (0.904 sec/step)\n","INFO:tensorflow:global step 5376: loss = 5.2007 (0.904 sec/step)\n","I1215 19:23:01.825057 140303514462080 learning.py:512] global step 5376: loss = 5.2007 (0.904 sec/step)\n","INFO:tensorflow:global step 5377: loss = 4.5606 (0.904 sec/step)\n","I1215 19:23:02.730818 140303514462080 learning.py:512] global step 5377: loss = 4.5606 (0.904 sec/step)\n","INFO:tensorflow:global step 5378: loss = 5.3466 (0.899 sec/step)\n","I1215 19:23:03.631078 140303514462080 learning.py:512] global step 5378: loss = 5.3466 (0.899 sec/step)\n","INFO:tensorflow:global step 5379: loss = 4.3418 (0.882 sec/step)\n","I1215 19:23:04.514762 140303514462080 learning.py:512] global step 5379: loss = 4.3418 (0.882 sec/step)\n","INFO:tensorflow:global step 5380: loss = 5.2362 (0.910 sec/step)\n","I1215 19:23:05.426061 140303514462080 learning.py:512] global step 5380: loss = 5.2362 (0.910 sec/step)\n","INFO:tensorflow:global step 5381: loss = 3.4841 (0.912 sec/step)\n","I1215 19:23:06.339682 140303514462080 learning.py:512] global step 5381: loss = 3.4841 (0.912 sec/step)\n","INFO:tensorflow:global step 5382: loss = 4.6072 (0.902 sec/step)\n","I1215 19:23:07.243953 140303514462080 learning.py:512] global step 5382: loss = 4.6072 (0.902 sec/step)\n","INFO:tensorflow:global step 5383: loss = 3.4782 (0.930 sec/step)\n","I1215 19:23:08.175712 140303514462080 learning.py:512] global step 5383: loss = 3.4782 (0.930 sec/step)\n","INFO:tensorflow:global step 5384: loss = 5.0287 (0.917 sec/step)\n","I1215 19:23:09.094055 140303514462080 learning.py:512] global step 5384: loss = 5.0287 (0.917 sec/step)\n","INFO:tensorflow:global step 5385: loss = 6.4604 (0.901 sec/step)\n","I1215 19:23:09.996667 140303514462080 learning.py:512] global step 5385: loss = 6.4604 (0.901 sec/step)\n","INFO:tensorflow:global step 5386: loss = 5.1495 (0.902 sec/step)\n","I1215 19:23:10.900428 140303514462080 learning.py:512] global step 5386: loss = 5.1495 (0.902 sec/step)\n","INFO:tensorflow:global step 5387: loss = 3.6344 (0.906 sec/step)\n","I1215 19:23:11.807552 140303514462080 learning.py:512] global step 5387: loss = 3.6344 (0.906 sec/step)\n","INFO:tensorflow:global step 5388: loss = 3.9374 (0.909 sec/step)\n","I1215 19:23:12.718022 140303514462080 learning.py:512] global step 5388: loss = 3.9374 (0.909 sec/step)\n","INFO:tensorflow:global step 5389: loss = 4.1953 (0.879 sec/step)\n","I1215 19:23:13.598217 140303514462080 learning.py:512] global step 5389: loss = 4.1953 (0.879 sec/step)\n","INFO:tensorflow:global step 5390: loss = 4.6355 (0.903 sec/step)\n","I1215 19:23:14.503342 140303514462080 learning.py:512] global step 5390: loss = 4.6355 (0.903 sec/step)\n","INFO:tensorflow:global step 5391: loss = 5.1007 (0.901 sec/step)\n","I1215 19:23:15.405619 140303514462080 learning.py:512] global step 5391: loss = 5.1007 (0.901 sec/step)\n","INFO:tensorflow:global step 5392: loss = 5.5127 (0.882 sec/step)\n","I1215 19:23:16.288630 140303514462080 learning.py:512] global step 5392: loss = 5.5127 (0.882 sec/step)\n","INFO:tensorflow:global step 5393: loss = 4.2133 (0.899 sec/step)\n","I1215 19:23:17.189322 140303514462080 learning.py:512] global step 5393: loss = 4.2133 (0.899 sec/step)\n","INFO:tensorflow:global step 5394: loss = 5.0870 (0.901 sec/step)\n","I1215 19:23:18.091563 140303514462080 learning.py:512] global step 5394: loss = 5.0870 (0.901 sec/step)\n","INFO:tensorflow:global step 5395: loss = 4.4339 (0.914 sec/step)\n","I1215 19:23:19.006621 140303514462080 learning.py:512] global step 5395: loss = 4.4339 (0.914 sec/step)\n","INFO:tensorflow:global step 5396: loss = 4.4651 (0.879 sec/step)\n","I1215 19:23:19.887188 140303514462080 learning.py:512] global step 5396: loss = 4.4651 (0.879 sec/step)\n","INFO:tensorflow:global step 5397: loss = 7.0952 (0.897 sec/step)\n","I1215 19:23:20.786309 140303514462080 learning.py:512] global step 5397: loss = 7.0952 (0.897 sec/step)\n","INFO:tensorflow:global step 5398: loss = 3.9092 (0.917 sec/step)\n","I1215 19:23:21.704717 140303514462080 learning.py:512] global step 5398: loss = 3.9092 (0.917 sec/step)\n","INFO:tensorflow:global step 5399: loss = 3.2831 (0.962 sec/step)\n","I1215 19:23:22.668416 140303514462080 learning.py:512] global step 5399: loss = 3.2831 (0.962 sec/step)\n","INFO:tensorflow:global step 5400: loss = 6.0073 (0.911 sec/step)\n","I1215 19:23:23.581640 140303514462080 learning.py:512] global step 5400: loss = 6.0073 (0.911 sec/step)\n","INFO:tensorflow:global step 5401: loss = 6.1737 (0.916 sec/step)\n","I1215 19:23:24.499189 140303514462080 learning.py:512] global step 5401: loss = 6.1737 (0.916 sec/step)\n","INFO:tensorflow:global step 5402: loss = 4.6383 (0.923 sec/step)\n","I1215 19:23:25.423708 140303514462080 learning.py:512] global step 5402: loss = 4.6383 (0.923 sec/step)\n","INFO:tensorflow:global step 5403: loss = 7.6597 (0.922 sec/step)\n","I1215 19:23:26.347514 140303514462080 learning.py:512] global step 5403: loss = 7.6597 (0.922 sec/step)\n","INFO:tensorflow:global step 5404: loss = 4.4270 (0.917 sec/step)\n","I1215 19:23:27.266434 140303514462080 learning.py:512] global step 5404: loss = 4.4270 (0.917 sec/step)\n","INFO:tensorflow:global step 5405: loss = 3.6067 (0.916 sec/step)\n","I1215 19:23:28.184042 140303514462080 learning.py:512] global step 5405: loss = 3.6067 (0.916 sec/step)\n","INFO:tensorflow:global step 5406: loss = 3.8215 (0.923 sec/step)\n","I1215 19:23:29.109124 140303514462080 learning.py:512] global step 5406: loss = 3.8215 (0.923 sec/step)\n","INFO:tensorflow:global step 5407: loss = 4.3272 (0.907 sec/step)\n","I1215 19:23:30.017735 140303514462080 learning.py:512] global step 5407: loss = 4.3272 (0.907 sec/step)\n","INFO:tensorflow:global step 5408: loss = 5.4919 (0.927 sec/step)\n","I1215 19:23:30.946818 140303514462080 learning.py:512] global step 5408: loss = 5.4919 (0.927 sec/step)\n","INFO:tensorflow:global step 5409: loss = 4.5220 (0.907 sec/step)\n","I1215 19:23:31.855752 140303514462080 learning.py:512] global step 5409: loss = 4.5220 (0.907 sec/step)\n","INFO:tensorflow:global step 5410: loss = 3.8902 (0.933 sec/step)\n","I1215 19:23:32.790627 140303514462080 learning.py:512] global step 5410: loss = 3.8902 (0.933 sec/step)\n","INFO:tensorflow:global step 5411: loss = 4.2097 (0.919 sec/step)\n","I1215 19:23:33.711858 140303514462080 learning.py:512] global step 5411: loss = 4.2097 (0.919 sec/step)\n","INFO:tensorflow:global step 5412: loss = 3.5273 (0.894 sec/step)\n","I1215 19:23:34.607642 140303514462080 learning.py:512] global step 5412: loss = 3.5273 (0.894 sec/step)\n","INFO:tensorflow:global step 5413: loss = 4.1143 (0.904 sec/step)\n","I1215 19:23:35.513459 140303514462080 learning.py:512] global step 5413: loss = 4.1143 (0.904 sec/step)\n","INFO:tensorflow:Recording summary at step 5413.\n","I1215 19:23:36.874893 140299899541248 supervisor.py:1050] Recording summary at step 5413.\n","INFO:tensorflow:global step 5414: loss = 4.4244 (1.490 sec/step)\n","I1215 19:23:37.004711 140303514462080 learning.py:512] global step 5414: loss = 4.4244 (1.490 sec/step)\n","INFO:tensorflow:global step 5415: loss = 6.1186 (0.902 sec/step)\n","I1215 19:23:37.908159 140303514462080 learning.py:512] global step 5415: loss = 6.1186 (0.902 sec/step)\n","INFO:tensorflow:global step 5416: loss = 4.1398 (0.892 sec/step)\n","I1215 19:23:38.801959 140303514462080 learning.py:512] global step 5416: loss = 4.1398 (0.892 sec/step)\n","INFO:tensorflow:global step 5417: loss = 5.7401 (0.892 sec/step)\n","I1215 19:23:39.695638 140303514462080 learning.py:512] global step 5417: loss = 5.7401 (0.892 sec/step)\n","INFO:tensorflow:global step 5418: loss = 3.9879 (0.904 sec/step)\n","I1215 19:23:40.600764 140303514462080 learning.py:512] global step 5418: loss = 3.9879 (0.904 sec/step)\n","INFO:tensorflow:global step 5419: loss = 3.6330 (0.911 sec/step)\n","I1215 19:23:41.512915 140303514462080 learning.py:512] global step 5419: loss = 3.6330 (0.911 sec/step)\n","INFO:tensorflow:global step 5420: loss = 4.4581 (0.906 sec/step)\n","I1215 19:23:42.420382 140303514462080 learning.py:512] global step 5420: loss = 4.4581 (0.906 sec/step)\n","INFO:tensorflow:global step 5421: loss = 4.2992 (0.908 sec/step)\n","I1215 19:23:43.330209 140303514462080 learning.py:512] global step 5421: loss = 4.2992 (0.908 sec/step)\n","INFO:tensorflow:global step 5422: loss = 4.2202 (0.884 sec/step)\n","I1215 19:23:44.216105 140303514462080 learning.py:512] global step 5422: loss = 4.2202 (0.884 sec/step)\n","INFO:tensorflow:global step 5423: loss = 3.7261 (0.899 sec/step)\n","I1215 19:23:45.116362 140303514462080 learning.py:512] global step 5423: loss = 3.7261 (0.899 sec/step)\n","INFO:tensorflow:global step 5424: loss = 5.5556 (0.884 sec/step)\n","I1215 19:23:46.001891 140303514462080 learning.py:512] global step 5424: loss = 5.5556 (0.884 sec/step)\n","INFO:tensorflow:global step 5425: loss = 4.3894 (0.879 sec/step)\n","I1215 19:23:46.882292 140303514462080 learning.py:512] global step 5425: loss = 4.3894 (0.879 sec/step)\n","INFO:tensorflow:global step 5426: loss = 7.2132 (0.890 sec/step)\n","I1215 19:23:47.773435 140303514462080 learning.py:512] global step 5426: loss = 7.2132 (0.890 sec/step)\n","INFO:tensorflow:global step 5427: loss = 5.8424 (0.912 sec/step)\n","I1215 19:23:48.686763 140303514462080 learning.py:512] global step 5427: loss = 5.8424 (0.912 sec/step)\n","INFO:tensorflow:global step 5428: loss = 4.4495 (0.901 sec/step)\n","I1215 19:23:49.589046 140303514462080 learning.py:512] global step 5428: loss = 4.4495 (0.901 sec/step)\n","INFO:tensorflow:global step 5429: loss = 4.0494 (0.896 sec/step)\n","I1215 19:23:50.486810 140303514462080 learning.py:512] global step 5429: loss = 4.0494 (0.896 sec/step)\n","INFO:tensorflow:global step 5430: loss = 4.1995 (0.894 sec/step)\n","I1215 19:23:51.382518 140303514462080 learning.py:512] global step 5430: loss = 4.1995 (0.894 sec/step)\n","INFO:tensorflow:global step 5431: loss = 3.8619 (0.877 sec/step)\n","I1215 19:23:52.261410 140303514462080 learning.py:512] global step 5431: loss = 3.8619 (0.877 sec/step)\n","INFO:tensorflow:global step 5432: loss = 4.1952 (0.900 sec/step)\n","I1215 19:23:53.162494 140303514462080 learning.py:512] global step 5432: loss = 4.1952 (0.900 sec/step)\n","INFO:tensorflow:global step 5433: loss = 4.5970 (0.925 sec/step)\n","I1215 19:23:54.088775 140303514462080 learning.py:512] global step 5433: loss = 4.5970 (0.925 sec/step)\n","INFO:tensorflow:global step 5434: loss = 5.1514 (0.923 sec/step)\n","I1215 19:23:55.013413 140303514462080 learning.py:512] global step 5434: loss = 5.1514 (0.923 sec/step)\n","INFO:tensorflow:global step 5435: loss = 3.7211 (0.900 sec/step)\n","I1215 19:23:55.914573 140303514462080 learning.py:512] global step 5435: loss = 3.7211 (0.900 sec/step)\n","INFO:tensorflow:global step 5436: loss = 5.4814 (0.895 sec/step)\n","I1215 19:23:56.811568 140303514462080 learning.py:512] global step 5436: loss = 5.4814 (0.895 sec/step)\n","INFO:tensorflow:global step 5437: loss = 4.7547 (0.925 sec/step)\n","I1215 19:23:57.737953 140303514462080 learning.py:512] global step 5437: loss = 4.7547 (0.925 sec/step)\n","INFO:tensorflow:global step 5438: loss = 4.3814 (0.898 sec/step)\n","I1215 19:23:58.637954 140303514462080 learning.py:512] global step 5438: loss = 4.3814 (0.898 sec/step)\n","INFO:tensorflow:global step 5439: loss = 5.6430 (0.904 sec/step)\n","I1215 19:23:59.543761 140303514462080 learning.py:512] global step 5439: loss = 5.6430 (0.904 sec/step)\n","INFO:tensorflow:global step 5440: loss = 4.5730 (0.903 sec/step)\n","I1215 19:24:00.448394 140303514462080 learning.py:512] global step 5440: loss = 4.5730 (0.903 sec/step)\n","INFO:tensorflow:global step 5441: loss = 5.2208 (0.896 sec/step)\n","I1215 19:24:01.345796 140303514462080 learning.py:512] global step 5441: loss = 5.2208 (0.896 sec/step)\n","INFO:tensorflow:global step 5442: loss = 3.6734 (0.898 sec/step)\n","I1215 19:24:02.245312 140303514462080 learning.py:512] global step 5442: loss = 3.6734 (0.898 sec/step)\n","INFO:tensorflow:global step 5443: loss = 3.6418 (0.902 sec/step)\n","I1215 19:24:03.149354 140303514462080 learning.py:512] global step 5443: loss = 3.6418 (0.902 sec/step)\n","INFO:tensorflow:global step 5444: loss = 5.2883 (0.905 sec/step)\n","I1215 19:24:04.056414 140303514462080 learning.py:512] global step 5444: loss = 5.2883 (0.905 sec/step)\n","INFO:tensorflow:global step 5445: loss = 4.7302 (0.912 sec/step)\n","I1215 19:24:04.969753 140303514462080 learning.py:512] global step 5445: loss = 4.7302 (0.912 sec/step)\n","INFO:tensorflow:global step 5446: loss = 4.8341 (0.897 sec/step)\n","I1215 19:24:05.868461 140303514462080 learning.py:512] global step 5446: loss = 4.8341 (0.897 sec/step)\n","INFO:tensorflow:global step 5447: loss = 6.2903 (0.901 sec/step)\n","I1215 19:24:06.771056 140303514462080 learning.py:512] global step 5447: loss = 6.2903 (0.901 sec/step)\n","INFO:tensorflow:global step 5448: loss = 4.4432 (0.896 sec/step)\n","I1215 19:24:07.668209 140303514462080 learning.py:512] global step 5448: loss = 4.4432 (0.896 sec/step)\n","INFO:tensorflow:global step 5449: loss = 4.5961 (0.907 sec/step)\n","I1215 19:24:08.576841 140303514462080 learning.py:512] global step 5449: loss = 4.5961 (0.907 sec/step)\n","INFO:tensorflow:global step 5450: loss = 4.9129 (0.913 sec/step)\n","I1215 19:24:09.491161 140303514462080 learning.py:512] global step 5450: loss = 4.9129 (0.913 sec/step)\n","INFO:tensorflow:global step 5451: loss = 4.7303 (0.911 sec/step)\n","I1215 19:24:10.403381 140303514462080 learning.py:512] global step 5451: loss = 4.7303 (0.911 sec/step)\n","INFO:tensorflow:global step 5452: loss = 3.7685 (0.883 sec/step)\n","I1215 19:24:11.288563 140303514462080 learning.py:512] global step 5452: loss = 3.7685 (0.883 sec/step)\n","INFO:tensorflow:global step 5453: loss = 4.3935 (0.905 sec/step)\n","I1215 19:24:12.195614 140303514462080 learning.py:512] global step 5453: loss = 4.3935 (0.905 sec/step)\n","INFO:tensorflow:global step 5454: loss = 4.9255 (0.914 sec/step)\n","I1215 19:24:13.110716 140303514462080 learning.py:512] global step 5454: loss = 4.9255 (0.914 sec/step)\n","INFO:tensorflow:global step 5455: loss = 5.5138 (0.910 sec/step)\n","I1215 19:24:14.022555 140303514462080 learning.py:512] global step 5455: loss = 5.5138 (0.910 sec/step)\n","INFO:tensorflow:global step 5456: loss = 4.2780 (0.904 sec/step)\n","I1215 19:24:14.928238 140303514462080 learning.py:512] global step 5456: loss = 4.2780 (0.904 sec/step)\n","INFO:tensorflow:global step 5457: loss = 4.3643 (0.904 sec/step)\n","I1215 19:24:15.833706 140303514462080 learning.py:512] global step 5457: loss = 4.3643 (0.904 sec/step)\n","INFO:tensorflow:global step 5458: loss = 4.4954 (0.890 sec/step)\n","I1215 19:24:16.725760 140303514462080 learning.py:512] global step 5458: loss = 4.4954 (0.890 sec/step)\n","INFO:tensorflow:global step 5459: loss = 3.7527 (0.894 sec/step)\n","I1215 19:24:17.621533 140303514462080 learning.py:512] global step 5459: loss = 3.7527 (0.894 sec/step)\n","INFO:tensorflow:global step 5460: loss = 3.7105 (0.924 sec/step)\n","I1215 19:24:18.547606 140303514462080 learning.py:512] global step 5460: loss = 3.7105 (0.924 sec/step)\n","INFO:tensorflow:global step 5461: loss = 4.2159 (0.890 sec/step)\n","I1215 19:24:19.438900 140303514462080 learning.py:512] global step 5461: loss = 4.2159 (0.890 sec/step)\n","INFO:tensorflow:global step 5462: loss = 4.7072 (0.900 sec/step)\n","I1215 19:24:20.340678 140303514462080 learning.py:512] global step 5462: loss = 4.7072 (0.900 sec/step)\n","INFO:tensorflow:global step 5463: loss = 3.0673 (0.907 sec/step)\n","I1215 19:24:21.248693 140303514462080 learning.py:512] global step 5463: loss = 3.0673 (0.907 sec/step)\n","INFO:tensorflow:global step 5464: loss = 3.5952 (0.903 sec/step)\n","I1215 19:24:22.152873 140303514462080 learning.py:512] global step 5464: loss = 3.5952 (0.903 sec/step)\n","INFO:tensorflow:global step 5465: loss = 4.3549 (0.904 sec/step)\n","I1215 19:24:23.058311 140303514462080 learning.py:512] global step 5465: loss = 4.3549 (0.904 sec/step)\n","INFO:tensorflow:global step 5466: loss = 5.5314 (0.901 sec/step)\n","I1215 19:24:23.961191 140303514462080 learning.py:512] global step 5466: loss = 5.5314 (0.901 sec/step)\n","INFO:tensorflow:global step 5467: loss = 3.9771 (0.908 sec/step)\n","I1215 19:24:24.870319 140303514462080 learning.py:512] global step 5467: loss = 3.9771 (0.908 sec/step)\n","INFO:tensorflow:global step 5468: loss = 3.2756 (0.918 sec/step)\n","I1215 19:24:25.789515 140303514462080 learning.py:512] global step 5468: loss = 3.2756 (0.918 sec/step)\n","INFO:tensorflow:global step 5469: loss = 6.0714 (0.919 sec/step)\n","I1215 19:24:26.710210 140303514462080 learning.py:512] global step 5469: loss = 6.0714 (0.919 sec/step)\n","INFO:tensorflow:global step 5470: loss = 3.1920 (0.890 sec/step)\n","I1215 19:24:27.602175 140303514462080 learning.py:512] global step 5470: loss = 3.1920 (0.890 sec/step)\n","INFO:tensorflow:global step 5471: loss = 5.6092 (0.906 sec/step)\n","I1215 19:24:28.510025 140303514462080 learning.py:512] global step 5471: loss = 5.6092 (0.906 sec/step)\n","INFO:tensorflow:global step 5472: loss = 4.4060 (0.914 sec/step)\n","I1215 19:24:29.425258 140303514462080 learning.py:512] global step 5472: loss = 4.4060 (0.914 sec/step)\n","INFO:tensorflow:global step 5473: loss = 2.7262 (0.897 sec/step)\n","I1215 19:24:30.323678 140303514462080 learning.py:512] global step 5473: loss = 2.7262 (0.897 sec/step)\n","INFO:tensorflow:global step 5474: loss = 3.5780 (0.896 sec/step)\n","I1215 19:24:31.221396 140303514462080 learning.py:512] global step 5474: loss = 3.5780 (0.896 sec/step)\n","INFO:tensorflow:global step 5475: loss = 2.8364 (0.898 sec/step)\n","I1215 19:24:32.120601 140303514462080 learning.py:512] global step 5475: loss = 2.8364 (0.898 sec/step)\n","INFO:tensorflow:global step 5476: loss = 4.4525 (0.896 sec/step)\n","I1215 19:24:33.018511 140303514462080 learning.py:512] global step 5476: loss = 4.4525 (0.896 sec/step)\n","INFO:tensorflow:global step 5477: loss = 4.1273 (0.901 sec/step)\n","I1215 19:24:33.920843 140303514462080 learning.py:512] global step 5477: loss = 4.1273 (0.901 sec/step)\n","INFO:tensorflow:global step 5478: loss = 4.4511 (0.885 sec/step)\n","I1215 19:24:34.809167 140303514462080 learning.py:512] global step 5478: loss = 4.4511 (0.885 sec/step)\n","INFO:tensorflow:global step 5479: loss = 3.1709 (0.894 sec/step)\n","I1215 19:24:35.705488 140303514462080 learning.py:512] global step 5479: loss = 3.1709 (0.894 sec/step)\n","INFO:tensorflow:global step 5480: loss = 3.5632 (0.909 sec/step)\n","I1215 19:24:36.616569 140303514462080 learning.py:512] global step 5480: loss = 3.5632 (0.909 sec/step)\n","INFO:tensorflow:global step 5481: loss = 3.8183 (0.886 sec/step)\n","I1215 19:24:37.504132 140303514462080 learning.py:512] global step 5481: loss = 3.8183 (0.886 sec/step)\n","INFO:tensorflow:global step 5482: loss = 3.7739 (0.907 sec/step)\n","I1215 19:24:38.412457 140303514462080 learning.py:512] global step 5482: loss = 3.7739 (0.907 sec/step)\n","INFO:tensorflow:global step 5483: loss = 4.3858 (0.897 sec/step)\n","I1215 19:24:39.310857 140303514462080 learning.py:512] global step 5483: loss = 4.3858 (0.897 sec/step)\n","INFO:tensorflow:global step 5484: loss = 3.3786 (0.926 sec/step)\n","I1215 19:24:40.238798 140303514462080 learning.py:512] global step 5484: loss = 3.3786 (0.926 sec/step)\n","INFO:tensorflow:global step 5485: loss = 6.0335 (0.906 sec/step)\n","I1215 19:24:41.146373 140303514462080 learning.py:512] global step 5485: loss = 6.0335 (0.906 sec/step)\n","INFO:tensorflow:global step 5486: loss = 3.9235 (0.883 sec/step)\n","I1215 19:24:42.031391 140303514462080 learning.py:512] global step 5486: loss = 3.9235 (0.883 sec/step)\n","INFO:tensorflow:global step 5487: loss = 2.7621 (0.907 sec/step)\n","I1215 19:24:42.939729 140303514462080 learning.py:512] global step 5487: loss = 2.7621 (0.907 sec/step)\n","INFO:tensorflow:global step 5488: loss = 5.5970 (0.905 sec/step)\n","I1215 19:24:43.846046 140303514462080 learning.py:512] global step 5488: loss = 5.5970 (0.905 sec/step)\n","INFO:tensorflow:global step 5489: loss = 6.0465 (0.900 sec/step)\n","I1215 19:24:44.747382 140303514462080 learning.py:512] global step 5489: loss = 6.0465 (0.900 sec/step)\n","INFO:tensorflow:global step 5490: loss = 4.2135 (0.906 sec/step)\n","I1215 19:24:45.654691 140303514462080 learning.py:512] global step 5490: loss = 4.2135 (0.906 sec/step)\n","INFO:tensorflow:global step 5491: loss = 5.2213 (0.921 sec/step)\n","I1215 19:24:46.577635 140303514462080 learning.py:512] global step 5491: loss = 5.2213 (0.921 sec/step)\n","INFO:tensorflow:global step 5492: loss = 5.0782 (0.897 sec/step)\n","I1215 19:24:47.476057 140303514462080 learning.py:512] global step 5492: loss = 5.0782 (0.897 sec/step)\n","INFO:tensorflow:global step 5493: loss = 3.5532 (0.906 sec/step)\n","I1215 19:24:48.383259 140303514462080 learning.py:512] global step 5493: loss = 3.5532 (0.906 sec/step)\n","INFO:tensorflow:global step 5494: loss = 5.2702 (0.904 sec/step)\n","I1215 19:24:49.288931 140303514462080 learning.py:512] global step 5494: loss = 5.2702 (0.904 sec/step)\n","INFO:tensorflow:global step 5495: loss = 4.4200 (0.897 sec/step)\n","I1215 19:24:50.187142 140303514462080 learning.py:512] global step 5495: loss = 4.4200 (0.897 sec/step)\n","INFO:tensorflow:global step 5496: loss = 5.6258 (0.883 sec/step)\n","I1215 19:24:51.071792 140303514462080 learning.py:512] global step 5496: loss = 5.6258 (0.883 sec/step)\n","INFO:tensorflow:global step 5497: loss = 6.2780 (0.885 sec/step)\n","I1215 19:24:51.958550 140303514462080 learning.py:512] global step 5497: loss = 6.2780 (0.885 sec/step)\n","INFO:tensorflow:global step 5498: loss = 4.0070 (0.913 sec/step)\n","I1215 19:24:52.873571 140303514462080 learning.py:512] global step 5498: loss = 4.0070 (0.913 sec/step)\n","INFO:tensorflow:global step 5499: loss = 3.9424 (0.888 sec/step)\n","I1215 19:24:53.763514 140303514462080 learning.py:512] global step 5499: loss = 3.9424 (0.888 sec/step)\n","INFO:tensorflow:global step 5500: loss = 4.6063 (0.910 sec/step)\n","I1215 19:24:54.675176 140303514462080 learning.py:512] global step 5500: loss = 4.6063 (0.910 sec/step)\n","INFO:tensorflow:global step 5501: loss = 3.8962 (0.907 sec/step)\n","I1215 19:24:55.583236 140303514462080 learning.py:512] global step 5501: loss = 3.8962 (0.907 sec/step)\n","INFO:tensorflow:global step 5502: loss = 5.9446 (0.906 sec/step)\n","I1215 19:24:56.493608 140303514462080 learning.py:512] global step 5502: loss = 5.9446 (0.906 sec/step)\n","INFO:tensorflow:global step 5503: loss = 5.1935 (0.905 sec/step)\n","I1215 19:24:57.399521 140303514462080 learning.py:512] global step 5503: loss = 5.1935 (0.905 sec/step)\n","INFO:tensorflow:global step 5504: loss = 4.8047 (0.892 sec/step)\n","I1215 19:24:58.293186 140303514462080 learning.py:512] global step 5504: loss = 4.8047 (0.892 sec/step)\n","INFO:tensorflow:global step 5505: loss = 4.1066 (0.890 sec/step)\n","I1215 19:24:59.185218 140303514462080 learning.py:512] global step 5505: loss = 4.1066 (0.890 sec/step)\n","INFO:tensorflow:global step 5506: loss = 5.1302 (0.888 sec/step)\n","I1215 19:25:00.074448 140303514462080 learning.py:512] global step 5506: loss = 5.1302 (0.888 sec/step)\n","INFO:tensorflow:global step 5507: loss = 5.6459 (0.897 sec/step)\n","I1215 19:25:00.972811 140303514462080 learning.py:512] global step 5507: loss = 5.6459 (0.897 sec/step)\n","INFO:tensorflow:global step 5508: loss = 3.9122 (0.896 sec/step)\n","I1215 19:25:01.870379 140303514462080 learning.py:512] global step 5508: loss = 3.9122 (0.896 sec/step)\n","INFO:tensorflow:global step 5509: loss = 5.2695 (0.911 sec/step)\n","I1215 19:25:02.783621 140303514462080 learning.py:512] global step 5509: loss = 5.2695 (0.911 sec/step)\n","INFO:tensorflow:global step 5510: loss = 4.0448 (0.897 sec/step)\n","I1215 19:25:03.682605 140303514462080 learning.py:512] global step 5510: loss = 4.0448 (0.897 sec/step)\n","INFO:tensorflow:global step 5511: loss = 5.1576 (0.869 sec/step)\n","I1215 19:25:04.553351 140303514462080 learning.py:512] global step 5511: loss = 5.1576 (0.869 sec/step)\n","INFO:tensorflow:global step 5512: loss = 4.0839 (0.884 sec/step)\n","I1215 19:25:05.438357 140303514462080 learning.py:512] global step 5512: loss = 4.0839 (0.884 sec/step)\n","INFO:tensorflow:global step 5513: loss = 3.7624 (0.900 sec/step)\n","I1215 19:25:06.339799 140303514462080 learning.py:512] global step 5513: loss = 3.7624 (0.900 sec/step)\n","INFO:tensorflow:global step 5514: loss = 5.0514 (0.894 sec/step)\n","I1215 19:25:07.236232 140303514462080 learning.py:512] global step 5514: loss = 5.0514 (0.894 sec/step)\n","INFO:tensorflow:global step 5515: loss = 4.5098 (0.914 sec/step)\n","I1215 19:25:08.162723 140303514462080 learning.py:512] global step 5515: loss = 4.5098 (0.914 sec/step)\n","INFO:tensorflow:global step 5516: loss = 3.8104 (0.898 sec/step)\n","I1215 19:25:09.062605 140303514462080 learning.py:512] global step 5516: loss = 3.8104 (0.898 sec/step)\n","INFO:tensorflow:global step 5517: loss = 3.6026 (0.889 sec/step)\n","I1215 19:25:09.953108 140303514462080 learning.py:512] global step 5517: loss = 3.6026 (0.889 sec/step)\n","INFO:tensorflow:global step 5518: loss = 5.0855 (0.881 sec/step)\n","I1215 19:25:10.836066 140303514462080 learning.py:512] global step 5518: loss = 5.0855 (0.881 sec/step)\n","INFO:tensorflow:global step 5519: loss = 3.2948 (0.908 sec/step)\n","I1215 19:25:11.745333 140303514462080 learning.py:512] global step 5519: loss = 3.2948 (0.908 sec/step)\n","INFO:tensorflow:global step 5520: loss = 5.9012 (0.903 sec/step)\n","I1215 19:25:12.650025 140303514462080 learning.py:512] global step 5520: loss = 5.9012 (0.903 sec/step)\n","INFO:tensorflow:global step 5521: loss = 4.2806 (0.896 sec/step)\n","I1215 19:25:13.547693 140303514462080 learning.py:512] global step 5521: loss = 4.2806 (0.896 sec/step)\n","INFO:tensorflow:global step 5522: loss = 3.3123 (0.903 sec/step)\n","I1215 19:25:14.452322 140303514462080 learning.py:512] global step 5522: loss = 3.3123 (0.903 sec/step)\n","INFO:tensorflow:global step 5523: loss = 5.3036 (0.908 sec/step)\n","I1215 19:25:15.362187 140303514462080 learning.py:512] global step 5523: loss = 5.3036 (0.908 sec/step)\n","INFO:tensorflow:global step 5524: loss = 5.0081 (0.907 sec/step)\n","I1215 19:25:16.270698 140303514462080 learning.py:512] global step 5524: loss = 5.0081 (0.907 sec/step)\n","INFO:tensorflow:global step 5525: loss = 3.8752 (0.930 sec/step)\n","I1215 19:25:17.202281 140303514462080 learning.py:512] global step 5525: loss = 3.8752 (0.930 sec/step)\n","INFO:tensorflow:global step 5526: loss = 3.6019 (0.923 sec/step)\n","I1215 19:25:18.126584 140303514462080 learning.py:512] global step 5526: loss = 3.6019 (0.923 sec/step)\n","INFO:tensorflow:global step 5527: loss = 4.9324 (0.912 sec/step)\n","I1215 19:25:19.040915 140303514462080 learning.py:512] global step 5527: loss = 4.9324 (0.912 sec/step)\n","INFO:tensorflow:global step 5528: loss = 3.9093 (0.890 sec/step)\n","I1215 19:25:19.932153 140303514462080 learning.py:512] global step 5528: loss = 3.9093 (0.890 sec/step)\n","INFO:tensorflow:global step 5529: loss = 4.8714 (0.913 sec/step)\n","I1215 19:25:20.846568 140303514462080 learning.py:512] global step 5529: loss = 4.8714 (0.913 sec/step)\n","INFO:tensorflow:global step 5530: loss = 3.9087 (0.922 sec/step)\n","I1215 19:25:21.770237 140303514462080 learning.py:512] global step 5530: loss = 3.9087 (0.922 sec/step)\n","INFO:tensorflow:global step 5531: loss = 3.3109 (0.912 sec/step)\n","I1215 19:25:22.685898 140303514462080 learning.py:512] global step 5531: loss = 3.3109 (0.912 sec/step)\n","INFO:tensorflow:global step 5532: loss = 3.8914 (0.928 sec/step)\n","I1215 19:25:23.615586 140303514462080 learning.py:512] global step 5532: loss = 3.8914 (0.928 sec/step)\n","INFO:tensorflow:global step 5533: loss = 4.3675 (0.906 sec/step)\n","I1215 19:25:24.523376 140303514462080 learning.py:512] global step 5533: loss = 4.3675 (0.906 sec/step)\n","INFO:tensorflow:global step 5534: loss = 4.2745 (0.919 sec/step)\n","I1215 19:25:25.444193 140303514462080 learning.py:512] global step 5534: loss = 4.2745 (0.919 sec/step)\n","INFO:tensorflow:global step 5535: loss = 4.3016 (0.918 sec/step)\n","I1215 19:25:26.363965 140303514462080 learning.py:512] global step 5535: loss = 4.3016 (0.918 sec/step)\n","INFO:tensorflow:global step 5536: loss = 4.5505 (0.915 sec/step)\n","I1215 19:25:27.280552 140303514462080 learning.py:512] global step 5536: loss = 4.5505 (0.915 sec/step)\n","INFO:tensorflow:global step 5537: loss = 3.5821 (0.898 sec/step)\n","I1215 19:25:28.180154 140303514462080 learning.py:512] global step 5537: loss = 3.5821 (0.898 sec/step)\n","INFO:tensorflow:global step 5538: loss = 4.3885 (0.917 sec/step)\n","I1215 19:25:29.098981 140303514462080 learning.py:512] global step 5538: loss = 4.3885 (0.917 sec/step)\n","INFO:tensorflow:global step 5539: loss = 5.0577 (0.893 sec/step)\n","I1215 19:25:29.993910 140303514462080 learning.py:512] global step 5539: loss = 5.0577 (0.893 sec/step)\n","INFO:tensorflow:global step 5540: loss = 5.0136 (0.882 sec/step)\n","I1215 19:25:30.877849 140303514462080 learning.py:512] global step 5540: loss = 5.0136 (0.882 sec/step)\n","INFO:tensorflow:global step 5541: loss = 6.1852 (0.899 sec/step)\n","I1215 19:25:31.777929 140303514462080 learning.py:512] global step 5541: loss = 6.1852 (0.899 sec/step)\n","INFO:tensorflow:global step 5542: loss = 2.7450 (0.903 sec/step)\n","I1215 19:25:32.682216 140303514462080 learning.py:512] global step 5542: loss = 2.7450 (0.903 sec/step)\n","INFO:tensorflow:global step 5543: loss = 5.4222 (0.891 sec/step)\n","I1215 19:25:33.574964 140303514462080 learning.py:512] global step 5543: loss = 5.4222 (0.891 sec/step)\n","INFO:tensorflow:global step 5544: loss = 3.8934 (0.887 sec/step)\n","I1215 19:25:34.463761 140303514462080 learning.py:512] global step 5544: loss = 3.8934 (0.887 sec/step)\n","INFO:tensorflow:global step 5545: loss = 3.1698 (0.901 sec/step)\n","I1215 19:25:35.366102 140303514462080 learning.py:512] global step 5545: loss = 3.1698 (0.901 sec/step)\n","INFO:tensorflow:global step 5546: loss = 3.7678 (1.411 sec/step)\n","I1215 19:25:36.778357 140303514462080 learning.py:512] global step 5546: loss = 3.7678 (1.411 sec/step)\n","INFO:tensorflow:Recording summary at step 5546.\n","I1215 19:25:37.191723 140299899541248 supervisor.py:1050] Recording summary at step 5546.\n","INFO:tensorflow:global step 5547: loss = 3.2756 (1.009 sec/step)\n","I1215 19:25:37.789328 140303514462080 learning.py:512] global step 5547: loss = 3.2756 (1.009 sec/step)\n","INFO:tensorflow:global step 5548: loss = 4.0172 (0.890 sec/step)\n","I1215 19:25:38.680816 140303514462080 learning.py:512] global step 5548: loss = 4.0172 (0.890 sec/step)\n","INFO:tensorflow:global step 5549: loss = 3.5490 (0.892 sec/step)\n","I1215 19:25:39.574365 140303514462080 learning.py:512] global step 5549: loss = 3.5490 (0.892 sec/step)\n","INFO:tensorflow:global step 5550: loss = 3.1478 (0.889 sec/step)\n","I1215 19:25:40.464821 140303514462080 learning.py:512] global step 5550: loss = 3.1478 (0.889 sec/step)\n","INFO:tensorflow:global step 5551: loss = 3.1664 (0.902 sec/step)\n","I1215 19:25:41.368602 140303514462080 learning.py:512] global step 5551: loss = 3.1664 (0.902 sec/step)\n","INFO:tensorflow:global step 5552: loss = 3.9465 (0.897 sec/step)\n","I1215 19:25:42.267063 140303514462080 learning.py:512] global step 5552: loss = 3.9465 (0.897 sec/step)\n","INFO:tensorflow:global step 5553: loss = 4.4739 (0.917 sec/step)\n","I1215 19:25:43.185431 140303514462080 learning.py:512] global step 5553: loss = 4.4739 (0.917 sec/step)\n","INFO:tensorflow:global step 5554: loss = 3.8017 (0.899 sec/step)\n","I1215 19:25:44.086567 140303514462080 learning.py:512] global step 5554: loss = 3.8017 (0.899 sec/step)\n","INFO:tensorflow:global step 5555: loss = 5.4815 (0.907 sec/step)\n","I1215 19:25:44.999951 140303514462080 learning.py:512] global step 5555: loss = 5.4815 (0.907 sec/step)\n","INFO:tensorflow:global step 5556: loss = 4.6421 (0.942 sec/step)\n","I1215 19:25:45.943215 140303514462080 learning.py:512] global step 5556: loss = 4.6421 (0.942 sec/step)\n","INFO:tensorflow:global step 5557: loss = 3.3264 (0.914 sec/step)\n","I1215 19:25:46.858949 140303514462080 learning.py:512] global step 5557: loss = 3.3264 (0.914 sec/step)\n","INFO:tensorflow:global step 5558: loss = 3.5312 (0.906 sec/step)\n","I1215 19:25:47.766632 140303514462080 learning.py:512] global step 5558: loss = 3.5312 (0.906 sec/step)\n","INFO:tensorflow:global step 5559: loss = 3.3452 (0.926 sec/step)\n","I1215 19:25:48.694436 140303514462080 learning.py:512] global step 5559: loss = 3.3452 (0.926 sec/step)\n","INFO:tensorflow:global step 5560: loss = 4.6662 (0.908 sec/step)\n","I1215 19:25:49.603907 140303514462080 learning.py:512] global step 5560: loss = 4.6662 (0.908 sec/step)\n","INFO:tensorflow:global step 5561: loss = 5.0012 (0.910 sec/step)\n","I1215 19:25:50.515547 140303514462080 learning.py:512] global step 5561: loss = 5.0012 (0.910 sec/step)\n","INFO:tensorflow:global step 5562: loss = 5.2932 (0.915 sec/step)\n","I1215 19:25:51.431877 140303514462080 learning.py:512] global step 5562: loss = 5.2932 (0.915 sec/step)\n","INFO:tensorflow:global step 5563: loss = 2.9954 (0.928 sec/step)\n","I1215 19:25:52.361518 140303514462080 learning.py:512] global step 5563: loss = 2.9954 (0.928 sec/step)\n","INFO:tensorflow:global step 5564: loss = 5.6209 (0.907 sec/step)\n","I1215 19:25:53.269586 140303514462080 learning.py:512] global step 5564: loss = 5.6209 (0.907 sec/step)\n","INFO:tensorflow:global step 5565: loss = 7.3719 (0.904 sec/step)\n","I1215 19:25:54.175360 140303514462080 learning.py:512] global step 5565: loss = 7.3719 (0.904 sec/step)\n","INFO:tensorflow:global step 5566: loss = 4.1830 (0.897 sec/step)\n","I1215 19:25:55.073614 140303514462080 learning.py:512] global step 5566: loss = 4.1830 (0.897 sec/step)\n","INFO:tensorflow:global step 5567: loss = 6.0340 (0.915 sec/step)\n","I1215 19:25:55.990079 140303514462080 learning.py:512] global step 5567: loss = 6.0340 (0.915 sec/step)\n","INFO:tensorflow:global step 5568: loss = 5.0381 (0.911 sec/step)\n","I1215 19:25:56.902283 140303514462080 learning.py:512] global step 5568: loss = 5.0381 (0.911 sec/step)\n","INFO:tensorflow:global step 5569: loss = 3.3639 (0.906 sec/step)\n","I1215 19:25:57.810245 140303514462080 learning.py:512] global step 5569: loss = 3.3639 (0.906 sec/step)\n","INFO:tensorflow:global step 5570: loss = 4.8118 (0.893 sec/step)\n","I1215 19:25:58.705233 140303514462080 learning.py:512] global step 5570: loss = 4.8118 (0.893 sec/step)\n","INFO:tensorflow:global step 5571: loss = 4.6809 (0.896 sec/step)\n","I1215 19:25:59.602668 140303514462080 learning.py:512] global step 5571: loss = 4.6809 (0.896 sec/step)\n","INFO:tensorflow:global step 5572: loss = 3.1262 (0.894 sec/step)\n","I1215 19:26:00.497917 140303514462080 learning.py:512] global step 5572: loss = 3.1262 (0.894 sec/step)\n","INFO:tensorflow:global step 5573: loss = 5.6633 (0.913 sec/step)\n","I1215 19:26:01.412225 140303514462080 learning.py:512] global step 5573: loss = 5.6633 (0.913 sec/step)\n","INFO:tensorflow:global step 5574: loss = 3.5428 (0.895 sec/step)\n","I1215 19:26:02.308454 140303514462080 learning.py:512] global step 5574: loss = 3.5428 (0.895 sec/step)\n","INFO:tensorflow:global step 5575: loss = 3.3591 (0.901 sec/step)\n","I1215 19:26:03.210917 140303514462080 learning.py:512] global step 5575: loss = 3.3591 (0.901 sec/step)\n","INFO:tensorflow:global step 5576: loss = 4.8116 (0.881 sec/step)\n","I1215 19:26:04.093004 140303514462080 learning.py:512] global step 5576: loss = 4.8116 (0.881 sec/step)\n","INFO:tensorflow:global step 5577: loss = 3.5882 (0.896 sec/step)\n","I1215 19:26:04.990910 140303514462080 learning.py:512] global step 5577: loss = 3.5882 (0.896 sec/step)\n","INFO:tensorflow:global step 5578: loss = 7.2090 (0.913 sec/step)\n","I1215 19:26:05.905364 140303514462080 learning.py:512] global step 5578: loss = 7.2090 (0.913 sec/step)\n","INFO:tensorflow:global step 5579: loss = 4.2338 (0.908 sec/step)\n","I1215 19:26:06.815254 140303514462080 learning.py:512] global step 5579: loss = 4.2338 (0.908 sec/step)\n","INFO:tensorflow:global step 5580: loss = 4.3322 (0.892 sec/step)\n","I1215 19:26:07.709100 140303514462080 learning.py:512] global step 5580: loss = 4.3322 (0.892 sec/step)\n","INFO:tensorflow:global step 5581: loss = 4.0452 (0.895 sec/step)\n","I1215 19:26:08.605978 140303514462080 learning.py:512] global step 5581: loss = 4.0452 (0.895 sec/step)\n","INFO:tensorflow:global step 5582: loss = 5.6089 (0.904 sec/step)\n","I1215 19:26:09.511670 140303514462080 learning.py:512] global step 5582: loss = 5.6089 (0.904 sec/step)\n","INFO:tensorflow:global step 5583: loss = 5.5175 (0.896 sec/step)\n","I1215 19:26:10.409232 140303514462080 learning.py:512] global step 5583: loss = 5.5175 (0.896 sec/step)\n","INFO:tensorflow:global step 5584: loss = 3.5318 (0.911 sec/step)\n","I1215 19:26:11.321753 140303514462080 learning.py:512] global step 5584: loss = 3.5318 (0.911 sec/step)\n","INFO:tensorflow:global step 5585: loss = 6.0564 (0.908 sec/step)\n","I1215 19:26:12.230953 140303514462080 learning.py:512] global step 5585: loss = 6.0564 (0.908 sec/step)\n","INFO:tensorflow:global step 5586: loss = 6.2484 (0.886 sec/step)\n","I1215 19:26:13.118180 140303514462080 learning.py:512] global step 5586: loss = 6.2484 (0.886 sec/step)\n","INFO:tensorflow:global step 5587: loss = 6.6893 (0.900 sec/step)\n","I1215 19:26:14.019780 140303514462080 learning.py:512] global step 5587: loss = 6.6893 (0.900 sec/step)\n","INFO:tensorflow:global step 5588: loss = 4.0577 (0.912 sec/step)\n","I1215 19:26:14.932782 140303514462080 learning.py:512] global step 5588: loss = 4.0577 (0.912 sec/step)\n","INFO:tensorflow:global step 5589: loss = 4.1536 (0.911 sec/step)\n","I1215 19:26:15.845268 140303514462080 learning.py:512] global step 5589: loss = 4.1536 (0.911 sec/step)\n","INFO:tensorflow:global step 5590: loss = 2.5701 (0.910 sec/step)\n","I1215 19:26:16.756588 140303514462080 learning.py:512] global step 5590: loss = 2.5701 (0.910 sec/step)\n","INFO:tensorflow:global step 5591: loss = 3.2725 (0.895 sec/step)\n","I1215 19:26:17.653268 140303514462080 learning.py:512] global step 5591: loss = 3.2725 (0.895 sec/step)\n","INFO:tensorflow:global step 5592: loss = 5.5172 (0.909 sec/step)\n","I1215 19:26:18.563535 140303514462080 learning.py:512] global step 5592: loss = 5.5172 (0.909 sec/step)\n","INFO:tensorflow:global step 5593: loss = 4.2981 (0.906 sec/step)\n","I1215 19:26:19.471241 140303514462080 learning.py:512] global step 5593: loss = 4.2981 (0.906 sec/step)\n","INFO:tensorflow:global step 5594: loss = 3.9829 (0.909 sec/step)\n","I1215 19:26:20.382193 140303514462080 learning.py:512] global step 5594: loss = 3.9829 (0.909 sec/step)\n","INFO:tensorflow:global step 5595: loss = 3.8591 (0.914 sec/step)\n","I1215 19:26:21.297342 140303514462080 learning.py:512] global step 5595: loss = 3.8591 (0.914 sec/step)\n","INFO:tensorflow:global step 5596: loss = 5.9581 (0.892 sec/step)\n","I1215 19:26:22.191079 140303514462080 learning.py:512] global step 5596: loss = 5.9581 (0.892 sec/step)\n","INFO:tensorflow:global step 5597: loss = 4.3834 (0.893 sec/step)\n","I1215 19:26:23.085076 140303514462080 learning.py:512] global step 5597: loss = 4.3834 (0.893 sec/step)\n","INFO:tensorflow:global step 5598: loss = 4.1702 (0.911 sec/step)\n","I1215 19:26:23.997533 140303514462080 learning.py:512] global step 5598: loss = 4.1702 (0.911 sec/step)\n","INFO:tensorflow:global step 5599: loss = 4.4019 (0.907 sec/step)\n","I1215 19:26:24.905454 140303514462080 learning.py:512] global step 5599: loss = 4.4019 (0.907 sec/step)\n","INFO:tensorflow:global step 5600: loss = 4.6407 (0.902 sec/step)\n","I1215 19:26:25.808636 140303514462080 learning.py:512] global step 5600: loss = 4.6407 (0.902 sec/step)\n","INFO:tensorflow:global step 5601: loss = 4.1672 (0.875 sec/step)\n","I1215 19:26:26.685686 140303514462080 learning.py:512] global step 5601: loss = 4.1672 (0.875 sec/step)\n","INFO:tensorflow:global step 5602: loss = 7.8017 (0.900 sec/step)\n","I1215 19:26:27.586558 140303514462080 learning.py:512] global step 5602: loss = 7.8017 (0.900 sec/step)\n","INFO:tensorflow:global step 5603: loss = 5.5445 (0.898 sec/step)\n","I1215 19:26:28.485957 140303514462080 learning.py:512] global step 5603: loss = 5.5445 (0.898 sec/step)\n","INFO:tensorflow:global step 5604: loss = 5.4420 (0.910 sec/step)\n","I1215 19:26:29.397233 140303514462080 learning.py:512] global step 5604: loss = 5.4420 (0.910 sec/step)\n","INFO:tensorflow:global step 5605: loss = 5.4072 (0.905 sec/step)\n","I1215 19:26:30.303256 140303514462080 learning.py:512] global step 5605: loss = 5.4072 (0.905 sec/step)\n","INFO:tensorflow:global step 5606: loss = 3.4329 (0.898 sec/step)\n","I1215 19:26:31.202389 140303514462080 learning.py:512] global step 5606: loss = 3.4329 (0.898 sec/step)\n","INFO:tensorflow:global step 5607: loss = 4.6066 (0.897 sec/step)\n","I1215 19:26:32.100539 140303514462080 learning.py:512] global step 5607: loss = 4.6066 (0.897 sec/step)\n","INFO:tensorflow:global step 5608: loss = 3.9303 (0.898 sec/step)\n","I1215 19:26:33.000268 140303514462080 learning.py:512] global step 5608: loss = 3.9303 (0.898 sec/step)\n","INFO:tensorflow:global step 5609: loss = 5.1165 (0.887 sec/step)\n","I1215 19:26:33.889038 140303514462080 learning.py:512] global step 5609: loss = 5.1165 (0.887 sec/step)\n","INFO:tensorflow:global step 5610: loss = 4.6666 (0.901 sec/step)\n","I1215 19:26:34.791386 140303514462080 learning.py:512] global step 5610: loss = 4.6666 (0.901 sec/step)\n","INFO:tensorflow:global step 5611: loss = 5.7057 (0.888 sec/step)\n","I1215 19:26:35.680719 140303514462080 learning.py:512] global step 5611: loss = 5.7057 (0.888 sec/step)\n","INFO:tensorflow:global step 5612: loss = 4.6669 (0.894 sec/step)\n","I1215 19:26:36.576863 140303514462080 learning.py:512] global step 5612: loss = 4.6669 (0.894 sec/step)\n","INFO:tensorflow:global step 5613: loss = 5.6198 (0.888 sec/step)\n","I1215 19:26:37.466010 140303514462080 learning.py:512] global step 5613: loss = 5.6198 (0.888 sec/step)\n","INFO:tensorflow:global step 5614: loss = 5.6160 (0.901 sec/step)\n","I1215 19:26:38.368598 140303514462080 learning.py:512] global step 5614: loss = 5.6160 (0.901 sec/step)\n","INFO:tensorflow:global step 5615: loss = 3.6196 (0.879 sec/step)\n","I1215 19:26:39.248515 140303514462080 learning.py:512] global step 5615: loss = 3.6196 (0.879 sec/step)\n","INFO:tensorflow:global step 5616: loss = 5.5712 (0.899 sec/step)\n","I1215 19:26:40.149163 140303514462080 learning.py:512] global step 5616: loss = 5.5712 (0.899 sec/step)\n","INFO:tensorflow:global step 5617: loss = 4.3982 (0.906 sec/step)\n","I1215 19:26:41.056506 140303514462080 learning.py:512] global step 5617: loss = 4.3982 (0.906 sec/step)\n","INFO:tensorflow:global step 5618: loss = 4.0312 (0.881 sec/step)\n","I1215 19:26:41.939086 140303514462080 learning.py:512] global step 5618: loss = 4.0312 (0.881 sec/step)\n","INFO:tensorflow:global step 5619: loss = 4.5936 (0.901 sec/step)\n","I1215 19:26:42.841883 140303514462080 learning.py:512] global step 5619: loss = 4.5936 (0.901 sec/step)\n","INFO:tensorflow:global step 5620: loss = 5.2741 (0.897 sec/step)\n","I1215 19:26:43.740580 140303514462080 learning.py:512] global step 5620: loss = 5.2741 (0.897 sec/step)\n","INFO:tensorflow:global step 5621: loss = 5.2425 (0.893 sec/step)\n","I1215 19:26:44.635298 140303514462080 learning.py:512] global step 5621: loss = 5.2425 (0.893 sec/step)\n","INFO:tensorflow:global step 5622: loss = 3.6200 (0.887 sec/step)\n","I1215 19:26:45.523384 140303514462080 learning.py:512] global step 5622: loss = 3.6200 (0.887 sec/step)\n","INFO:tensorflow:global step 5623: loss = 5.2553 (0.895 sec/step)\n","I1215 19:26:46.420059 140303514462080 learning.py:512] global step 5623: loss = 5.2553 (0.895 sec/step)\n","INFO:tensorflow:global step 5624: loss = 3.8754 (0.899 sec/step)\n","I1215 19:26:47.320673 140303514462080 learning.py:512] global step 5624: loss = 3.8754 (0.899 sec/step)\n","INFO:tensorflow:global step 5625: loss = 8.7381 (0.888 sec/step)\n","I1215 19:26:48.210109 140303514462080 learning.py:512] global step 5625: loss = 8.7381 (0.888 sec/step)\n","INFO:tensorflow:global step 5626: loss = 3.7083 (0.904 sec/step)\n","I1215 19:26:49.115279 140303514462080 learning.py:512] global step 5626: loss = 3.7083 (0.904 sec/step)\n","INFO:tensorflow:global step 5627: loss = 4.1200 (0.908 sec/step)\n","I1215 19:26:50.024371 140303514462080 learning.py:512] global step 5627: loss = 4.1200 (0.908 sec/step)\n","INFO:tensorflow:global step 5628: loss = 3.3727 (0.898 sec/step)\n","I1215 19:26:50.923741 140303514462080 learning.py:512] global step 5628: loss = 3.3727 (0.898 sec/step)\n","INFO:tensorflow:global step 5629: loss = 4.2615 (0.906 sec/step)\n","I1215 19:26:51.831536 140303514462080 learning.py:512] global step 5629: loss = 4.2615 (0.906 sec/step)\n","INFO:tensorflow:global step 5630: loss = 3.0660 (0.892 sec/step)\n","I1215 19:26:52.725177 140303514462080 learning.py:512] global step 5630: loss = 3.0660 (0.892 sec/step)\n","INFO:tensorflow:global step 5631: loss = 4.8160 (0.877 sec/step)\n","I1215 19:26:53.603873 140303514462080 learning.py:512] global step 5631: loss = 4.8160 (0.877 sec/step)\n","INFO:tensorflow:global step 5632: loss = 3.8981 (0.899 sec/step)\n","I1215 19:26:54.504729 140303514462080 learning.py:512] global step 5632: loss = 3.8981 (0.899 sec/step)\n","INFO:tensorflow:global step 5633: loss = 5.8461 (0.895 sec/step)\n","I1215 19:26:55.400744 140303514462080 learning.py:512] global step 5633: loss = 5.8461 (0.895 sec/step)\n","INFO:tensorflow:global step 5634: loss = 3.6847 (0.884 sec/step)\n","I1215 19:26:56.285927 140303514462080 learning.py:512] global step 5634: loss = 3.6847 (0.884 sec/step)\n","INFO:tensorflow:global step 5635: loss = 3.4778 (0.898 sec/step)\n","I1215 19:26:57.185639 140303514462080 learning.py:512] global step 5635: loss = 3.4778 (0.898 sec/step)\n","INFO:tensorflow:global step 5636: loss = 4.2201 (0.887 sec/step)\n","I1215 19:26:58.073972 140303514462080 learning.py:512] global step 5636: loss = 4.2201 (0.887 sec/step)\n","INFO:tensorflow:global step 5637: loss = 5.8803 (0.893 sec/step)\n","I1215 19:26:58.968100 140303514462080 learning.py:512] global step 5637: loss = 5.8803 (0.893 sec/step)\n","INFO:tensorflow:global step 5638: loss = 3.8886 (0.909 sec/step)\n","I1215 19:26:59.878704 140303514462080 learning.py:512] global step 5638: loss = 3.8886 (0.909 sec/step)\n","INFO:tensorflow:global step 5639: loss = 3.4308 (0.911 sec/step)\n","I1215 19:27:00.791260 140303514462080 learning.py:512] global step 5639: loss = 3.4308 (0.911 sec/step)\n","INFO:tensorflow:global step 5640: loss = 5.6063 (0.887 sec/step)\n","I1215 19:27:01.680259 140303514462080 learning.py:512] global step 5640: loss = 5.6063 (0.887 sec/step)\n","INFO:tensorflow:global step 5641: loss = 4.6196 (0.899 sec/step)\n","I1215 19:27:02.580302 140303514462080 learning.py:512] global step 5641: loss = 4.6196 (0.899 sec/step)\n","INFO:tensorflow:global step 5642: loss = 3.8522 (0.903 sec/step)\n","I1215 19:27:03.484912 140303514462080 learning.py:512] global step 5642: loss = 3.8522 (0.903 sec/step)\n","INFO:tensorflow:global step 5643: loss = 5.7478 (0.886 sec/step)\n","I1215 19:27:04.372306 140303514462080 learning.py:512] global step 5643: loss = 5.7478 (0.886 sec/step)\n","INFO:tensorflow:global step 5644: loss = 6.3506 (0.908 sec/step)\n","I1215 19:27:05.281796 140303514462080 learning.py:512] global step 5644: loss = 6.3506 (0.908 sec/step)\n","INFO:tensorflow:global step 5645: loss = 4.0285 (0.886 sec/step)\n","I1215 19:27:06.168933 140303514462080 learning.py:512] global step 5645: loss = 4.0285 (0.886 sec/step)\n","INFO:tensorflow:global step 5646: loss = 5.2647 (0.920 sec/step)\n","I1215 19:27:07.090951 140303514462080 learning.py:512] global step 5646: loss = 5.2647 (0.920 sec/step)\n","INFO:tensorflow:global step 5647: loss = 3.8531 (0.904 sec/step)\n","I1215 19:27:07.996623 140303514462080 learning.py:512] global step 5647: loss = 3.8531 (0.904 sec/step)\n","INFO:tensorflow:global step 5648: loss = 3.6111 (0.903 sec/step)\n","I1215 19:27:08.900926 140303514462080 learning.py:512] global step 5648: loss = 3.6111 (0.903 sec/step)\n","INFO:tensorflow:global step 5649: loss = 5.5022 (0.930 sec/step)\n","I1215 19:27:09.832505 140303514462080 learning.py:512] global step 5649: loss = 5.5022 (0.930 sec/step)\n","INFO:tensorflow:global step 5650: loss = 4.7186 (0.912 sec/step)\n","I1215 19:27:10.746409 140303514462080 learning.py:512] global step 5650: loss = 4.7186 (0.912 sec/step)\n","INFO:tensorflow:global step 5651: loss = 5.9679 (0.898 sec/step)\n","I1215 19:27:11.645947 140303514462080 learning.py:512] global step 5651: loss = 5.9679 (0.898 sec/step)\n","INFO:tensorflow:global step 5652: loss = 3.9217 (0.926 sec/step)\n","I1215 19:27:12.573528 140303514462080 learning.py:512] global step 5652: loss = 3.9217 (0.926 sec/step)\n","INFO:tensorflow:global step 5653: loss = 3.4405 (0.891 sec/step)\n","I1215 19:27:13.466386 140303514462080 learning.py:512] global step 5653: loss = 3.4405 (0.891 sec/step)\n","INFO:tensorflow:global step 5654: loss = 6.6852 (0.890 sec/step)\n","I1215 19:27:14.357711 140303514462080 learning.py:512] global step 5654: loss = 6.6852 (0.890 sec/step)\n","INFO:tensorflow:global step 5655: loss = 5.5428 (0.890 sec/step)\n","I1215 19:27:15.249082 140303514462080 learning.py:512] global step 5655: loss = 5.5428 (0.890 sec/step)\n","INFO:tensorflow:global step 5656: loss = 4.9822 (0.900 sec/step)\n","I1215 19:27:16.150766 140303514462080 learning.py:512] global step 5656: loss = 4.9822 (0.900 sec/step)\n","INFO:tensorflow:global step 5657: loss = 3.7131 (0.884 sec/step)\n","I1215 19:27:17.036190 140303514462080 learning.py:512] global step 5657: loss = 3.7131 (0.884 sec/step)\n","INFO:tensorflow:global step 5658: loss = 4.6033 (0.902 sec/step)\n","I1215 19:27:17.939496 140303514462080 learning.py:512] global step 5658: loss = 4.6033 (0.902 sec/step)\n","INFO:tensorflow:global step 5659: loss = 4.7712 (0.914 sec/step)\n","I1215 19:27:18.855222 140303514462080 learning.py:512] global step 5659: loss = 4.7712 (0.914 sec/step)\n","INFO:tensorflow:global step 5660: loss = 4.3546 (0.904 sec/step)\n","I1215 19:27:19.760606 140303514462080 learning.py:512] global step 5660: loss = 4.3546 (0.904 sec/step)\n","INFO:tensorflow:global step 5661: loss = 3.1076 (0.895 sec/step)\n","I1215 19:27:20.656966 140303514462080 learning.py:512] global step 5661: loss = 3.1076 (0.895 sec/step)\n","INFO:tensorflow:global step 5662: loss = 5.6004 (0.904 sec/step)\n","I1215 19:27:21.561998 140303514462080 learning.py:512] global step 5662: loss = 5.6004 (0.904 sec/step)\n","INFO:tensorflow:global step 5663: loss = 3.9262 (0.885 sec/step)\n","I1215 19:27:22.448364 140303514462080 learning.py:512] global step 5663: loss = 3.9262 (0.885 sec/step)\n","INFO:tensorflow:global step 5664: loss = 4.3819 (0.910 sec/step)\n","I1215 19:27:23.359766 140303514462080 learning.py:512] global step 5664: loss = 4.3819 (0.910 sec/step)\n","INFO:tensorflow:global step 5665: loss = 4.2467 (0.893 sec/step)\n","I1215 19:27:24.254447 140303514462080 learning.py:512] global step 5665: loss = 4.2467 (0.893 sec/step)\n","INFO:tensorflow:global step 5666: loss = 4.2116 (0.895 sec/step)\n","I1215 19:27:25.150582 140303514462080 learning.py:512] global step 5666: loss = 4.2116 (0.895 sec/step)\n","INFO:tensorflow:global step 5667: loss = 3.0495 (0.882 sec/step)\n","I1215 19:27:26.033630 140303514462080 learning.py:512] global step 5667: loss = 3.0495 (0.882 sec/step)\n","INFO:tensorflow:global step 5668: loss = 4.0122 (0.895 sec/step)\n","I1215 19:27:26.930472 140303514462080 learning.py:512] global step 5668: loss = 4.0122 (0.895 sec/step)\n","INFO:tensorflow:global step 5669: loss = 4.2229 (0.907 sec/step)\n","I1215 19:27:27.839012 140303514462080 learning.py:512] global step 5669: loss = 4.2229 (0.907 sec/step)\n","INFO:tensorflow:global step 5670: loss = 5.7034 (0.895 sec/step)\n","I1215 19:27:28.735193 140303514462080 learning.py:512] global step 5670: loss = 5.7034 (0.895 sec/step)\n","INFO:tensorflow:global step 5671: loss = 4.2489 (0.892 sec/step)\n","I1215 19:27:29.628381 140303514462080 learning.py:512] global step 5671: loss = 4.2489 (0.892 sec/step)\n","INFO:tensorflow:global step 5672: loss = 3.1300 (0.884 sec/step)\n","I1215 19:27:30.514425 140303514462080 learning.py:512] global step 5672: loss = 3.1300 (0.884 sec/step)\n","INFO:tensorflow:global step 5673: loss = 4.1073 (0.893 sec/step)\n","I1215 19:27:31.409191 140303514462080 learning.py:512] global step 5673: loss = 4.1073 (0.893 sec/step)\n","INFO:tensorflow:global step 5674: loss = 3.0635 (0.926 sec/step)\n","I1215 19:27:32.336764 140303514462080 learning.py:512] global step 5674: loss = 3.0635 (0.926 sec/step)\n","INFO:tensorflow:global step 5675: loss = 5.5149 (0.903 sec/step)\n","I1215 19:27:33.241580 140303514462080 learning.py:512] global step 5675: loss = 5.5149 (0.903 sec/step)\n","INFO:tensorflow:global step 5676: loss = 6.0072 (0.897 sec/step)\n","I1215 19:27:34.140351 140303514462080 learning.py:512] global step 5676: loss = 6.0072 (0.897 sec/step)\n","INFO:tensorflow:global step 5677: loss = 4.4128 (0.893 sec/step)\n","I1215 19:27:35.034809 140303514462080 learning.py:512] global step 5677: loss = 4.4128 (0.893 sec/step)\n","INFO:tensorflow:global step 5678: loss = 5.2547 (1.075 sec/step)\n","I1215 19:27:36.112069 140303514462080 learning.py:512] global step 5678: loss = 5.2547 (1.075 sec/step)\n","INFO:tensorflow:Recording summary at step 5678.\n","I1215 19:27:37.207021 140299899541248 supervisor.py:1050] Recording summary at step 5678.\n","INFO:tensorflow:global step 5679: loss = 5.2420 (1.289 sec/step)\n","I1215 19:27:37.404890 140303514462080 learning.py:512] global step 5679: loss = 5.2420 (1.289 sec/step)\n","INFO:tensorflow:global step 5680: loss = 3.9882 (0.889 sec/step)\n","I1215 19:27:38.294956 140303514462080 learning.py:512] global step 5680: loss = 3.9882 (0.889 sec/step)\n","INFO:tensorflow:global step 5681: loss = 4.3578 (0.919 sec/step)\n","I1215 19:27:39.215487 140303514462080 learning.py:512] global step 5681: loss = 4.3578 (0.919 sec/step)\n","INFO:tensorflow:global step 5682: loss = 5.2978 (0.902 sec/step)\n","I1215 19:27:40.118968 140303514462080 learning.py:512] global step 5682: loss = 5.2978 (0.902 sec/step)\n","INFO:tensorflow:global step 5683: loss = 4.7963 (0.901 sec/step)\n","I1215 19:27:41.021158 140303514462080 learning.py:512] global step 5683: loss = 4.7963 (0.901 sec/step)\n","INFO:tensorflow:global step 5684: loss = 4.5018 (0.904 sec/step)\n","I1215 19:27:41.926697 140303514462080 learning.py:512] global step 5684: loss = 4.5018 (0.904 sec/step)\n","INFO:tensorflow:global step 5685: loss = 4.1261 (0.887 sec/step)\n","I1215 19:27:42.815226 140303514462080 learning.py:512] global step 5685: loss = 4.1261 (0.887 sec/step)\n","INFO:tensorflow:global step 5686: loss = 4.4175 (0.887 sec/step)\n","I1215 19:27:43.703847 140303514462080 learning.py:512] global step 5686: loss = 4.4175 (0.887 sec/step)\n","INFO:tensorflow:global step 5687: loss = 4.0680 (0.927 sec/step)\n","I1215 19:27:44.632725 140303514462080 learning.py:512] global step 5687: loss = 4.0680 (0.927 sec/step)\n","INFO:tensorflow:global step 5688: loss = 6.0191 (0.901 sec/step)\n","I1215 19:27:45.535495 140303514462080 learning.py:512] global step 5688: loss = 6.0191 (0.901 sec/step)\n","INFO:tensorflow:global step 5689: loss = 7.2598 (0.902 sec/step)\n","I1215 19:27:46.439357 140303514462080 learning.py:512] global step 5689: loss = 7.2598 (0.902 sec/step)\n","INFO:tensorflow:global step 5690: loss = 4.7188 (0.896 sec/step)\n","I1215 19:27:47.337363 140303514462080 learning.py:512] global step 5690: loss = 4.7188 (0.896 sec/step)\n","INFO:tensorflow:global step 5691: loss = 4.3742 (0.892 sec/step)\n","I1215 19:27:48.231101 140303514462080 learning.py:512] global step 5691: loss = 4.3742 (0.892 sec/step)\n","INFO:tensorflow:global step 5692: loss = 3.7425 (0.900 sec/step)\n","I1215 19:27:49.132321 140303514462080 learning.py:512] global step 5692: loss = 3.7425 (0.900 sec/step)\n","INFO:tensorflow:global step 5693: loss = 3.6931 (0.892 sec/step)\n","I1215 19:27:50.025976 140303514462080 learning.py:512] global step 5693: loss = 3.6931 (0.892 sec/step)\n","INFO:tensorflow:global step 5694: loss = 3.5504 (0.903 sec/step)\n","I1215 19:27:50.930388 140303514462080 learning.py:512] global step 5694: loss = 3.5504 (0.903 sec/step)\n","INFO:tensorflow:global step 5695: loss = 4.4232 (0.882 sec/step)\n","I1215 19:27:51.814274 140303514462080 learning.py:512] global step 5695: loss = 4.4232 (0.882 sec/step)\n","INFO:tensorflow:global step 5696: loss = 3.6203 (0.883 sec/step)\n","I1215 19:27:52.698783 140303514462080 learning.py:512] global step 5696: loss = 3.6203 (0.883 sec/step)\n","INFO:tensorflow:global step 5697: loss = 4.7651 (0.902 sec/step)\n","I1215 19:27:53.602578 140303514462080 learning.py:512] global step 5697: loss = 4.7651 (0.902 sec/step)\n","INFO:tensorflow:global step 5698: loss = 4.8533 (0.912 sec/step)\n","I1215 19:27:54.515785 140303514462080 learning.py:512] global step 5698: loss = 4.8533 (0.912 sec/step)\n","INFO:tensorflow:global step 5699: loss = 3.5209 (0.913 sec/step)\n","I1215 19:27:55.429946 140303514462080 learning.py:512] global step 5699: loss = 3.5209 (0.913 sec/step)\n","INFO:tensorflow:global step 5700: loss = 4.2221 (0.908 sec/step)\n","I1215 19:27:56.339749 140303514462080 learning.py:512] global step 5700: loss = 4.2221 (0.908 sec/step)\n","INFO:tensorflow:global step 5701: loss = 4.7564 (0.923 sec/step)\n","I1215 19:27:57.264790 140303514462080 learning.py:512] global step 5701: loss = 4.7564 (0.923 sec/step)\n","INFO:tensorflow:global step 5702: loss = 5.7577 (0.890 sec/step)\n","I1215 19:27:58.156750 140303514462080 learning.py:512] global step 5702: loss = 5.7577 (0.890 sec/step)\n","INFO:tensorflow:global step 5703: loss = 4.8337 (0.887 sec/step)\n","I1215 19:27:59.045431 140303514462080 learning.py:512] global step 5703: loss = 4.8337 (0.887 sec/step)\n","INFO:tensorflow:global step 5704: loss = 2.6644 (0.885 sec/step)\n","I1215 19:27:59.932264 140303514462080 learning.py:512] global step 5704: loss = 2.6644 (0.885 sec/step)\n","INFO:tensorflow:global step 5705: loss = 3.7183 (0.902 sec/step)\n","I1215 19:28:00.835972 140303514462080 learning.py:512] global step 5705: loss = 3.7183 (0.902 sec/step)\n","INFO:tensorflow:global step 5706: loss = 3.9616 (0.903 sec/step)\n","I1215 19:28:01.740886 140303514462080 learning.py:512] global step 5706: loss = 3.9616 (0.903 sec/step)\n","INFO:tensorflow:global step 5707: loss = 3.3859 (0.903 sec/step)\n","I1215 19:28:02.645713 140303514462080 learning.py:512] global step 5707: loss = 3.3859 (0.903 sec/step)\n","INFO:tensorflow:global step 5708: loss = 4.7808 (0.907 sec/step)\n","I1215 19:28:03.554052 140303514462080 learning.py:512] global step 5708: loss = 4.7808 (0.907 sec/step)\n","INFO:tensorflow:global step 5709: loss = 4.2395 (0.883 sec/step)\n","I1215 19:28:04.438420 140303514462080 learning.py:512] global step 5709: loss = 4.2395 (0.883 sec/step)\n","INFO:tensorflow:global step 5710: loss = 3.5543 (0.887 sec/step)\n","I1215 19:28:05.326723 140303514462080 learning.py:512] global step 5710: loss = 3.5543 (0.887 sec/step)\n","INFO:tensorflow:global step 5711: loss = 5.2348 (0.885 sec/step)\n","I1215 19:28:06.212729 140303514462080 learning.py:512] global step 5711: loss = 5.2348 (0.885 sec/step)\n","INFO:tensorflow:global step 5712: loss = 3.0395 (0.895 sec/step)\n","I1215 19:28:07.108609 140303514462080 learning.py:512] global step 5712: loss = 3.0395 (0.895 sec/step)\n","INFO:tensorflow:global step 5713: loss = 5.7454 (0.895 sec/step)\n","I1215 19:28:08.004718 140303514462080 learning.py:512] global step 5713: loss = 5.7454 (0.895 sec/step)\n","INFO:tensorflow:global step 5714: loss = 4.7104 (0.905 sec/step)\n","I1215 19:28:08.911758 140303514462080 learning.py:512] global step 5714: loss = 4.7104 (0.905 sec/step)\n","INFO:tensorflow:global step 5715: loss = 3.3388 (0.915 sec/step)\n","I1215 19:28:09.827873 140303514462080 learning.py:512] global step 5715: loss = 3.3388 (0.915 sec/step)\n","INFO:tensorflow:global step 5716: loss = 3.6979 (0.898 sec/step)\n","I1215 19:28:10.727821 140303514462080 learning.py:512] global step 5716: loss = 3.6979 (0.898 sec/step)\n","INFO:tensorflow:global step 5717: loss = 5.3135 (0.895 sec/step)\n","I1215 19:28:11.624334 140303514462080 learning.py:512] global step 5717: loss = 5.3135 (0.895 sec/step)\n","INFO:tensorflow:global step 5718: loss = 6.3988 (0.915 sec/step)\n","I1215 19:28:12.540529 140303514462080 learning.py:512] global step 5718: loss = 6.3988 (0.915 sec/step)\n","INFO:tensorflow:global step 5719: loss = 3.7909 (0.907 sec/step)\n","I1215 19:28:13.449365 140303514462080 learning.py:512] global step 5719: loss = 3.7909 (0.907 sec/step)\n","INFO:tensorflow:global step 5720: loss = 4.5236 (0.903 sec/step)\n","I1215 19:28:14.354362 140303514462080 learning.py:512] global step 5720: loss = 4.5236 (0.903 sec/step)\n","INFO:tensorflow:global step 5721: loss = 4.5696 (0.898 sec/step)\n","I1215 19:28:15.254448 140303514462080 learning.py:512] global step 5721: loss = 4.5696 (0.898 sec/step)\n","INFO:tensorflow:global step 5722: loss = 3.3264 (0.895 sec/step)\n","I1215 19:28:16.150758 140303514462080 learning.py:512] global step 5722: loss = 3.3264 (0.895 sec/step)\n","INFO:tensorflow:global step 5723: loss = 4.7023 (0.914 sec/step)\n","I1215 19:28:17.066391 140303514462080 learning.py:512] global step 5723: loss = 4.7023 (0.914 sec/step)\n","INFO:tensorflow:global step 5724: loss = 4.3681 (0.904 sec/step)\n","I1215 19:28:17.971899 140303514462080 learning.py:512] global step 5724: loss = 4.3681 (0.904 sec/step)\n","INFO:tensorflow:global step 5725: loss = 3.5776 (0.898 sec/step)\n","I1215 19:28:18.871206 140303514462080 learning.py:512] global step 5725: loss = 3.5776 (0.898 sec/step)\n","INFO:tensorflow:global step 5726: loss = 3.8866 (0.903 sec/step)\n","I1215 19:28:19.775414 140303514462080 learning.py:512] global step 5726: loss = 3.8866 (0.903 sec/step)\n","INFO:tensorflow:global step 5727: loss = 4.5453 (0.887 sec/step)\n","I1215 19:28:20.663774 140303514462080 learning.py:512] global step 5727: loss = 4.5453 (0.887 sec/step)\n","INFO:tensorflow:global step 5728: loss = 6.1609 (0.881 sec/step)\n","I1215 19:28:21.546058 140303514462080 learning.py:512] global step 5728: loss = 6.1609 (0.881 sec/step)\n","INFO:tensorflow:global step 5729: loss = 4.1256 (0.882 sec/step)\n","I1215 19:28:22.429401 140303514462080 learning.py:512] global step 5729: loss = 4.1256 (0.882 sec/step)\n","INFO:tensorflow:global step 5730: loss = 3.5168 (0.889 sec/step)\n","I1215 19:28:23.319903 140303514462080 learning.py:512] global step 5730: loss = 3.5168 (0.889 sec/step)\n","INFO:tensorflow:global step 5731: loss = 4.3817 (0.900 sec/step)\n","I1215 19:28:24.221423 140303514462080 learning.py:512] global step 5731: loss = 4.3817 (0.900 sec/step)\n","INFO:tensorflow:global step 5732: loss = 3.8567 (0.913 sec/step)\n","I1215 19:28:25.135610 140303514462080 learning.py:512] global step 5732: loss = 3.8567 (0.913 sec/step)\n","INFO:tensorflow:global step 5733: loss = 4.6435 (0.920 sec/step)\n","I1215 19:28:26.057537 140303514462080 learning.py:512] global step 5733: loss = 4.6435 (0.920 sec/step)\n","INFO:tensorflow:global step 5734: loss = 3.8482 (0.912 sec/step)\n","I1215 19:28:26.970900 140303514462080 learning.py:512] global step 5734: loss = 3.8482 (0.912 sec/step)\n","INFO:tensorflow:global step 5735: loss = 3.8926 (0.914 sec/step)\n","I1215 19:28:27.886740 140303514462080 learning.py:512] global step 5735: loss = 3.8926 (0.914 sec/step)\n","INFO:tensorflow:global step 5736: loss = 4.4979 (0.908 sec/step)\n","I1215 19:28:28.796820 140303514462080 learning.py:512] global step 5736: loss = 4.4979 (0.908 sec/step)\n","INFO:tensorflow:global step 5737: loss = 4.6140 (0.899 sec/step)\n","I1215 19:28:29.697296 140303514462080 learning.py:512] global step 5737: loss = 4.6140 (0.899 sec/step)\n","INFO:tensorflow:global step 5738: loss = 3.4569 (0.915 sec/step)\n","I1215 19:28:30.614162 140303514462080 learning.py:512] global step 5738: loss = 3.4569 (0.915 sec/step)\n","INFO:tensorflow:global step 5739: loss = 2.9133 (0.909 sec/step)\n","I1215 19:28:31.524532 140303514462080 learning.py:512] global step 5739: loss = 2.9133 (0.909 sec/step)\n","INFO:tensorflow:global step 5740: loss = 5.5158 (0.899 sec/step)\n","I1215 19:28:32.424975 140303514462080 learning.py:512] global step 5740: loss = 5.5158 (0.899 sec/step)\n","INFO:tensorflow:global step 5741: loss = 4.1332 (0.949 sec/step)\n","I1215 19:28:33.375710 140303514462080 learning.py:512] global step 5741: loss = 4.1332 (0.949 sec/step)\n","INFO:tensorflow:global step 5742: loss = 3.5893 (0.910 sec/step)\n","I1215 19:28:34.287636 140303514462080 learning.py:512] global step 5742: loss = 3.5893 (0.910 sec/step)\n","INFO:tensorflow:global step 5743: loss = 4.6591 (0.946 sec/step)\n","I1215 19:28:35.235750 140303514462080 learning.py:512] global step 5743: loss = 4.6591 (0.946 sec/step)\n","INFO:tensorflow:global step 5744: loss = 3.0183 (0.916 sec/step)\n","I1215 19:28:36.154071 140303514462080 learning.py:512] global step 5744: loss = 3.0183 (0.916 sec/step)\n","INFO:tensorflow:global step 5745: loss = 4.9035 (0.950 sec/step)\n","I1215 19:28:37.105766 140303514462080 learning.py:512] global step 5745: loss = 4.9035 (0.950 sec/step)\n","INFO:tensorflow:global step 5746: loss = 5.4347 (0.921 sec/step)\n","I1215 19:28:38.028021 140303514462080 learning.py:512] global step 5746: loss = 5.4347 (0.921 sec/step)\n","INFO:tensorflow:global step 5747: loss = 3.7496 (0.944 sec/step)\n","I1215 19:28:38.973172 140303514462080 learning.py:512] global step 5747: loss = 3.7496 (0.944 sec/step)\n","INFO:tensorflow:global step 5748: loss = 3.7132 (0.926 sec/step)\n","I1215 19:28:39.901269 140303514462080 learning.py:512] global step 5748: loss = 3.7132 (0.926 sec/step)\n","INFO:tensorflow:global step 5749: loss = 3.3512 (0.924 sec/step)\n","I1215 19:28:40.827313 140303514462080 learning.py:512] global step 5749: loss = 3.3512 (0.924 sec/step)\n","INFO:tensorflow:global step 5750: loss = 2.8710 (0.920 sec/step)\n","I1215 19:28:41.748909 140303514462080 learning.py:512] global step 5750: loss = 2.8710 (0.920 sec/step)\n","INFO:tensorflow:global step 5751: loss = 4.1653 (0.925 sec/step)\n","I1215 19:28:42.675638 140303514462080 learning.py:512] global step 5751: loss = 4.1653 (0.925 sec/step)\n","INFO:tensorflow:global step 5752: loss = 4.1845 (0.931 sec/step)\n","I1215 19:28:43.608834 140303514462080 learning.py:512] global step 5752: loss = 4.1845 (0.931 sec/step)\n","INFO:tensorflow:global step 5753: loss = 4.6137 (0.903 sec/step)\n","I1215 19:28:44.513305 140303514462080 learning.py:512] global step 5753: loss = 4.6137 (0.903 sec/step)\n","INFO:tensorflow:global step 5754: loss = 4.4412 (0.898 sec/step)\n","I1215 19:28:45.413088 140303514462080 learning.py:512] global step 5754: loss = 4.4412 (0.898 sec/step)\n","INFO:tensorflow:global step 5755: loss = 3.4907 (0.901 sec/step)\n","I1215 19:28:46.315630 140303514462080 learning.py:512] global step 5755: loss = 3.4907 (0.901 sec/step)\n","INFO:tensorflow:global step 5756: loss = 4.0089 (0.894 sec/step)\n","I1215 19:28:47.211052 140303514462080 learning.py:512] global step 5756: loss = 4.0089 (0.894 sec/step)\n","INFO:tensorflow:global step 5757: loss = 4.4277 (0.917 sec/step)\n","I1215 19:28:48.129536 140303514462080 learning.py:512] global step 5757: loss = 4.4277 (0.917 sec/step)\n","INFO:tensorflow:global step 5758: loss = 3.7138 (0.897 sec/step)\n","I1215 19:28:49.027708 140303514462080 learning.py:512] global step 5758: loss = 3.7138 (0.897 sec/step)\n","INFO:tensorflow:global step 5759: loss = 3.8277 (0.896 sec/step)\n","I1215 19:28:49.925271 140303514462080 learning.py:512] global step 5759: loss = 3.8277 (0.896 sec/step)\n","INFO:tensorflow:global step 5760: loss = 4.8721 (0.886 sec/step)\n","I1215 19:28:50.812299 140303514462080 learning.py:512] global step 5760: loss = 4.8721 (0.886 sec/step)\n","INFO:tensorflow:global step 5761: loss = 5.0337 (0.880 sec/step)\n","I1215 19:28:51.693346 140303514462080 learning.py:512] global step 5761: loss = 5.0337 (0.880 sec/step)\n","INFO:tensorflow:global step 5762: loss = 4.3208 (0.906 sec/step)\n","I1215 19:28:52.600694 140303514462080 learning.py:512] global step 5762: loss = 4.3208 (0.906 sec/step)\n","INFO:tensorflow:global step 5763: loss = 6.4300 (0.908 sec/step)\n","I1215 19:28:53.509962 140303514462080 learning.py:512] global step 5763: loss = 6.4300 (0.908 sec/step)\n","INFO:tensorflow:global step 5764: loss = 3.4164 (0.896 sec/step)\n","I1215 19:28:54.407591 140303514462080 learning.py:512] global step 5764: loss = 3.4164 (0.896 sec/step)\n","INFO:tensorflow:global step 5765: loss = 4.1125 (0.887 sec/step)\n","I1215 19:28:55.296569 140303514462080 learning.py:512] global step 5765: loss = 4.1125 (0.887 sec/step)\n","INFO:tensorflow:global step 5766: loss = 3.9185 (0.908 sec/step)\n","I1215 19:28:56.206359 140303514462080 learning.py:512] global step 5766: loss = 3.9185 (0.908 sec/step)\n","INFO:tensorflow:global step 5767: loss = 5.3722 (0.901 sec/step)\n","I1215 19:28:57.108732 140303514462080 learning.py:512] global step 5767: loss = 5.3722 (0.901 sec/step)\n","INFO:tensorflow:global step 5768: loss = 4.6388 (0.901 sec/step)\n","I1215 19:28:58.011519 140303514462080 learning.py:512] global step 5768: loss = 4.6388 (0.901 sec/step)\n","INFO:tensorflow:global step 5769: loss = 4.4433 (0.890 sec/step)\n","I1215 19:28:58.902730 140303514462080 learning.py:512] global step 5769: loss = 4.4433 (0.890 sec/step)\n","INFO:tensorflow:global step 5770: loss = 4.5657 (0.903 sec/step)\n","I1215 19:28:59.806845 140303514462080 learning.py:512] global step 5770: loss = 4.5657 (0.903 sec/step)\n","INFO:tensorflow:global step 5771: loss = 4.2727 (0.914 sec/step)\n","I1215 19:29:00.722637 140303514462080 learning.py:512] global step 5771: loss = 4.2727 (0.914 sec/step)\n","INFO:tensorflow:global step 5772: loss = 4.2640 (0.910 sec/step)\n","I1215 19:29:01.633952 140303514462080 learning.py:512] global step 5772: loss = 4.2640 (0.910 sec/step)\n","INFO:tensorflow:global step 5773: loss = 3.5347 (0.907 sec/step)\n","I1215 19:29:02.542040 140303514462080 learning.py:512] global step 5773: loss = 3.5347 (0.907 sec/step)\n","INFO:tensorflow:global step 5774: loss = 6.3934 (0.905 sec/step)\n","I1215 19:29:03.447980 140303514462080 learning.py:512] global step 5774: loss = 6.3934 (0.905 sec/step)\n","INFO:tensorflow:global step 5775: loss = 4.3400 (0.900 sec/step)\n","I1215 19:29:04.349076 140303514462080 learning.py:512] global step 5775: loss = 4.3400 (0.900 sec/step)\n","INFO:tensorflow:global step 5776: loss = 5.9804 (0.899 sec/step)\n","I1215 19:29:05.249859 140303514462080 learning.py:512] global step 5776: loss = 5.9804 (0.899 sec/step)\n","INFO:tensorflow:global step 5777: loss = 4.0519 (0.894 sec/step)\n","I1215 19:29:06.145635 140303514462080 learning.py:512] global step 5777: loss = 4.0519 (0.894 sec/step)\n","INFO:tensorflow:global step 5778: loss = 4.1851 (0.906 sec/step)\n","I1215 19:29:07.052730 140303514462080 learning.py:512] global step 5778: loss = 4.1851 (0.906 sec/step)\n","INFO:tensorflow:global step 5779: loss = 5.1454 (0.901 sec/step)\n","I1215 19:29:07.954976 140303514462080 learning.py:512] global step 5779: loss = 5.1454 (0.901 sec/step)\n","INFO:tensorflow:global step 5780: loss = 3.9465 (0.899 sec/step)\n","I1215 19:29:08.855556 140303514462080 learning.py:512] global step 5780: loss = 3.9465 (0.899 sec/step)\n","INFO:tensorflow:global step 5781: loss = 4.2685 (0.901 sec/step)\n","I1215 19:29:09.758318 140303514462080 learning.py:512] global step 5781: loss = 4.2685 (0.901 sec/step)\n","INFO:tensorflow:global step 5782: loss = 4.4061 (0.894 sec/step)\n","I1215 19:29:10.654092 140303514462080 learning.py:512] global step 5782: loss = 4.4061 (0.894 sec/step)\n","INFO:tensorflow:global step 5783: loss = 4.7759 (0.883 sec/step)\n","I1215 19:29:11.538431 140303514462080 learning.py:512] global step 5783: loss = 4.7759 (0.883 sec/step)\n","INFO:tensorflow:global step 5784: loss = 5.5629 (0.925 sec/step)\n","I1215 19:29:12.464584 140303514462080 learning.py:512] global step 5784: loss = 5.5629 (0.925 sec/step)\n","INFO:tensorflow:global step 5785: loss = 5.0515 (0.893 sec/step)\n","I1215 19:29:13.359407 140303514462080 learning.py:512] global step 5785: loss = 5.0515 (0.893 sec/step)\n","INFO:tensorflow:global step 5786: loss = 3.9503 (0.888 sec/step)\n","I1215 19:29:14.249390 140303514462080 learning.py:512] global step 5786: loss = 3.9503 (0.888 sec/step)\n","INFO:tensorflow:global step 5787: loss = 3.8563 (0.889 sec/step)\n","I1215 19:29:15.140123 140303514462080 learning.py:512] global step 5787: loss = 3.8563 (0.889 sec/step)\n","INFO:tensorflow:global step 5788: loss = 3.6863 (0.906 sec/step)\n","I1215 19:29:16.047288 140303514462080 learning.py:512] global step 5788: loss = 3.6863 (0.906 sec/step)\n","INFO:tensorflow:global step 5789: loss = 4.3967 (0.893 sec/step)\n","I1215 19:29:16.941744 140303514462080 learning.py:512] global step 5789: loss = 4.3967 (0.893 sec/step)\n","INFO:tensorflow:global step 5790: loss = 4.7271 (0.899 sec/step)\n","I1215 19:29:17.842199 140303514462080 learning.py:512] global step 5790: loss = 4.7271 (0.899 sec/step)\n","INFO:tensorflow:global step 5791: loss = 3.8290 (0.899 sec/step)\n","I1215 19:29:18.742228 140303514462080 learning.py:512] global step 5791: loss = 3.8290 (0.899 sec/step)\n","INFO:tensorflow:global step 5792: loss = 4.9332 (0.892 sec/step)\n","I1215 19:29:19.635223 140303514462080 learning.py:512] global step 5792: loss = 4.9332 (0.892 sec/step)\n","INFO:tensorflow:global step 5793: loss = 5.5262 (0.906 sec/step)\n","I1215 19:29:20.542755 140303514462080 learning.py:512] global step 5793: loss = 5.5262 (0.906 sec/step)\n","INFO:tensorflow:global step 5794: loss = 3.8016 (0.912 sec/step)\n","I1215 19:29:21.455806 140303514462080 learning.py:512] global step 5794: loss = 3.8016 (0.912 sec/step)\n","INFO:tensorflow:global step 5795: loss = 4.9627 (0.891 sec/step)\n","I1215 19:29:22.348216 140303514462080 learning.py:512] global step 5795: loss = 4.9627 (0.891 sec/step)\n","INFO:tensorflow:global step 5796: loss = 3.5139 (0.905 sec/step)\n","I1215 19:29:23.254671 140303514462080 learning.py:512] global step 5796: loss = 3.5139 (0.905 sec/step)\n","INFO:tensorflow:global step 5797: loss = 4.8591 (0.915 sec/step)\n","I1215 19:29:24.171225 140303514462080 learning.py:512] global step 5797: loss = 4.8591 (0.915 sec/step)\n","INFO:tensorflow:global step 5798: loss = 5.0552 (0.903 sec/step)\n","I1215 19:29:25.075959 140303514462080 learning.py:512] global step 5798: loss = 5.0552 (0.903 sec/step)\n","INFO:tensorflow:global step 5799: loss = 3.7627 (0.911 sec/step)\n","I1215 19:29:25.988228 140303514462080 learning.py:512] global step 5799: loss = 3.7627 (0.911 sec/step)\n","INFO:tensorflow:global step 5800: loss = 5.3314 (0.891 sec/step)\n","I1215 19:29:26.880488 140303514462080 learning.py:512] global step 5800: loss = 5.3314 (0.891 sec/step)\n","INFO:tensorflow:global step 5801: loss = 5.4343 (0.937 sec/step)\n","I1215 19:29:27.819275 140303514462080 learning.py:512] global step 5801: loss = 5.4343 (0.937 sec/step)\n","INFO:tensorflow:global step 5802: loss = 5.5532 (0.905 sec/step)\n","I1215 19:29:28.726527 140303514462080 learning.py:512] global step 5802: loss = 5.5532 (0.905 sec/step)\n","INFO:tensorflow:global step 5803: loss = 3.8266 (0.898 sec/step)\n","I1215 19:29:29.625880 140303514462080 learning.py:512] global step 5803: loss = 3.8266 (0.898 sec/step)\n","INFO:tensorflow:global step 5804: loss = 3.6109 (0.888 sec/step)\n","I1215 19:29:30.515887 140303514462080 learning.py:512] global step 5804: loss = 3.6109 (0.888 sec/step)\n","INFO:tensorflow:global step 5805: loss = 3.9972 (0.892 sec/step)\n","I1215 19:29:31.409033 140303514462080 learning.py:512] global step 5805: loss = 3.9972 (0.892 sec/step)\n","INFO:tensorflow:global step 5806: loss = 4.3702 (0.883 sec/step)\n","I1215 19:29:32.293696 140303514462080 learning.py:512] global step 5806: loss = 4.3702 (0.883 sec/step)\n","INFO:tensorflow:global step 5807: loss = 4.5908 (0.892 sec/step)\n","I1215 19:29:33.187077 140303514462080 learning.py:512] global step 5807: loss = 4.5908 (0.892 sec/step)\n","INFO:tensorflow:global step 5808: loss = 9.5078 (0.903 sec/step)\n","I1215 19:29:34.092020 140303514462080 learning.py:512] global step 5808: loss = 9.5078 (0.903 sec/step)\n","INFO:tensorflow:global step 5809: loss = 6.5596 (0.892 sec/step)\n","I1215 19:29:34.985450 140303514462080 learning.py:512] global step 5809: loss = 6.5596 (0.892 sec/step)\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I1215 19:29:35.600862 140299865970432 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","INFO:tensorflow:global step 5810: loss = 3.6270 (1.078 sec/step)\n","I1215 19:29:36.106624 140303514462080 learning.py:512] global step 5810: loss = 3.6270 (1.078 sec/step)\n","INFO:tensorflow:Recording summary at step 5810.\n","I1215 19:29:37.705337 140299899541248 supervisor.py:1050] Recording summary at step 5810.\n","INFO:tensorflow:global step 5811: loss = 4.1081 (1.899 sec/step)\n","I1215 19:29:38.012137 140303514462080 learning.py:512] global step 5811: loss = 4.1081 (1.899 sec/step)\n","INFO:tensorflow:global step 5812: loss = 4.5842 (1.658 sec/step)\n","I1215 19:29:39.682173 140303514462080 learning.py:512] global step 5812: loss = 4.5842 (1.658 sec/step)\n","INFO:tensorflow:global step 5813: loss = 4.3117 (1.088 sec/step)\n","I1215 19:29:40.777204 140303514462080 learning.py:512] global step 5813: loss = 4.3117 (1.088 sec/step)\n","INFO:tensorflow:global step 5814: loss = 3.9690 (0.911 sec/step)\n","I1215 19:29:41.689590 140303514462080 learning.py:512] global step 5814: loss = 3.9690 (0.911 sec/step)\n","INFO:tensorflow:global step 5815: loss = 4.0718 (0.896 sec/step)\n","I1215 19:29:42.586682 140303514462080 learning.py:512] global step 5815: loss = 4.0718 (0.896 sec/step)\n","INFO:tensorflow:global step 5816: loss = 7.9465 (0.920 sec/step)\n","I1215 19:29:43.508789 140303514462080 learning.py:512] global step 5816: loss = 7.9465 (0.920 sec/step)\n","INFO:tensorflow:global step 5817: loss = 5.0036 (0.933 sec/step)\n","I1215 19:29:44.443552 140303514462080 learning.py:512] global step 5817: loss = 5.0036 (0.933 sec/step)\n","INFO:tensorflow:global step 5818: loss = 5.3450 (0.933 sec/step)\n","I1215 19:29:45.377923 140303514462080 learning.py:512] global step 5818: loss = 5.3450 (0.933 sec/step)\n","INFO:tensorflow:global step 5819: loss = 3.6508 (0.910 sec/step)\n","I1215 19:29:46.289307 140303514462080 learning.py:512] global step 5819: loss = 3.6508 (0.910 sec/step)\n","INFO:tensorflow:global step 5820: loss = 5.0126 (0.903 sec/step)\n","I1215 19:29:47.193903 140303514462080 learning.py:512] global step 5820: loss = 5.0126 (0.903 sec/step)\n","INFO:tensorflow:global step 5821: loss = 3.6586 (0.922 sec/step)\n","I1215 19:29:48.118158 140303514462080 learning.py:512] global step 5821: loss = 3.6586 (0.922 sec/step)\n","INFO:tensorflow:global step 5822: loss = 3.7419 (0.904 sec/step)\n","I1215 19:29:49.023278 140303514462080 learning.py:512] global step 5822: loss = 3.7419 (0.904 sec/step)\n","INFO:tensorflow:global step 5823: loss = 6.6784 (0.934 sec/step)\n","I1215 19:29:49.959102 140303514462080 learning.py:512] global step 5823: loss = 6.6784 (0.934 sec/step)\n","INFO:tensorflow:global step 5824: loss = 3.6808 (0.917 sec/step)\n","I1215 19:29:50.877242 140303514462080 learning.py:512] global step 5824: loss = 3.6808 (0.917 sec/step)\n","INFO:tensorflow:global step 5825: loss = 4.9606 (0.911 sec/step)\n","I1215 19:29:51.790161 140303514462080 learning.py:512] global step 5825: loss = 4.9606 (0.911 sec/step)\n","INFO:tensorflow:global step 5826: loss = 3.5133 (0.907 sec/step)\n","I1215 19:29:52.701607 140303514462080 learning.py:512] global step 5826: loss = 3.5133 (0.907 sec/step)\n","INFO:tensorflow:global step 5827: loss = 3.3652 (0.899 sec/step)\n","I1215 19:29:53.602041 140303514462080 learning.py:512] global step 5827: loss = 3.3652 (0.899 sec/step)\n","INFO:tensorflow:global step 5828: loss = 3.9653 (0.921 sec/step)\n","I1215 19:29:54.524527 140303514462080 learning.py:512] global step 5828: loss = 3.9653 (0.921 sec/step)\n","INFO:tensorflow:global step 5829: loss = 2.9645 (0.910 sec/step)\n","I1215 19:29:55.435584 140303514462080 learning.py:512] global step 5829: loss = 2.9645 (0.910 sec/step)\n","INFO:tensorflow:global step 5830: loss = 3.5231 (0.900 sec/step)\n","I1215 19:29:56.337149 140303514462080 learning.py:512] global step 5830: loss = 3.5231 (0.900 sec/step)\n","INFO:tensorflow:global step 5831: loss = 5.3231 (0.896 sec/step)\n","I1215 19:29:57.234739 140303514462080 learning.py:512] global step 5831: loss = 5.3231 (0.896 sec/step)\n","INFO:tensorflow:global step 5832: loss = 5.6215 (0.894 sec/step)\n","I1215 19:29:58.129750 140303514462080 learning.py:512] global step 5832: loss = 5.6215 (0.894 sec/step)\n","INFO:tensorflow:global step 5833: loss = 3.6817 (0.917 sec/step)\n","I1215 19:29:59.048320 140303514462080 learning.py:512] global step 5833: loss = 3.6817 (0.917 sec/step)\n","INFO:tensorflow:global step 5834: loss = 7.0826 (0.889 sec/step)\n","I1215 19:29:59.938935 140303514462080 learning.py:512] global step 5834: loss = 7.0826 (0.889 sec/step)\n","INFO:tensorflow:global step 5835: loss = 3.9232 (0.908 sec/step)\n","I1215 19:30:00.848402 140303514462080 learning.py:512] global step 5835: loss = 3.9232 (0.908 sec/step)\n","INFO:tensorflow:global step 5836: loss = 4.4519 (0.906 sec/step)\n","I1215 19:30:01.755761 140303514462080 learning.py:512] global step 5836: loss = 4.4519 (0.906 sec/step)\n","INFO:tensorflow:global step 5837: loss = 5.5065 (0.902 sec/step)\n","I1215 19:30:02.658950 140303514462080 learning.py:512] global step 5837: loss = 5.5065 (0.902 sec/step)\n","INFO:tensorflow:global step 5838: loss = 4.9732 (0.904 sec/step)\n","I1215 19:30:03.564450 140303514462080 learning.py:512] global step 5838: loss = 4.9732 (0.904 sec/step)\n","INFO:tensorflow:global step 5839: loss = 4.5742 (0.889 sec/step)\n","I1215 19:30:04.455015 140303514462080 learning.py:512] global step 5839: loss = 4.5742 (0.889 sec/step)\n","INFO:tensorflow:global step 5840: loss = 8.0210 (0.901 sec/step)\n","I1215 19:30:05.357957 140303514462080 learning.py:512] global step 5840: loss = 8.0210 (0.901 sec/step)\n","INFO:tensorflow:global step 5841: loss = 6.0383 (0.902 sec/step)\n","I1215 19:30:06.261569 140303514462080 learning.py:512] global step 5841: loss = 6.0383 (0.902 sec/step)\n","INFO:tensorflow:global step 5842: loss = 7.7513 (0.909 sec/step)\n","I1215 19:30:07.171963 140303514462080 learning.py:512] global step 5842: loss = 7.7513 (0.909 sec/step)\n","INFO:tensorflow:global step 5843: loss = 3.8093 (0.896 sec/step)\n","I1215 19:30:08.069348 140303514462080 learning.py:512] global step 5843: loss = 3.8093 (0.896 sec/step)\n","INFO:tensorflow:global step 5844: loss = 3.5891 (0.901 sec/step)\n","I1215 19:30:08.971887 140303514462080 learning.py:512] global step 5844: loss = 3.5891 (0.901 sec/step)\n","INFO:tensorflow:global step 5845: loss = 4.4046 (0.937 sec/step)\n","I1215 19:30:09.910481 140303514462080 learning.py:512] global step 5845: loss = 4.4046 (0.937 sec/step)\n","INFO:tensorflow:global step 5846: loss = 4.0440 (0.924 sec/step)\n","I1215 19:30:10.836057 140303514462080 learning.py:512] global step 5846: loss = 4.0440 (0.924 sec/step)\n","INFO:tensorflow:global step 5847: loss = 5.7073 (0.882 sec/step)\n","I1215 19:30:11.719940 140303514462080 learning.py:512] global step 5847: loss = 5.7073 (0.882 sec/step)\n","INFO:tensorflow:global step 5848: loss = 4.0125 (0.912 sec/step)\n","I1215 19:30:12.633699 140303514462080 learning.py:512] global step 5848: loss = 4.0125 (0.912 sec/step)\n","INFO:tensorflow:global step 5849: loss = 4.3461 (0.906 sec/step)\n","I1215 19:30:13.541196 140303514462080 learning.py:512] global step 5849: loss = 4.3461 (0.906 sec/step)\n","INFO:tensorflow:global step 5850: loss = 4.3782 (0.880 sec/step)\n","I1215 19:30:14.422486 140303514462080 learning.py:512] global step 5850: loss = 4.3782 (0.880 sec/step)\n","INFO:tensorflow:global step 5851: loss = 4.1378 (0.902 sec/step)\n","I1215 19:30:15.326041 140303514462080 learning.py:512] global step 5851: loss = 4.1378 (0.902 sec/step)\n","INFO:tensorflow:global step 5852: loss = 4.3602 (0.920 sec/step)\n","I1215 19:30:16.249003 140303514462080 learning.py:512] global step 5852: loss = 4.3602 (0.920 sec/step)\n","INFO:tensorflow:global step 5853: loss = 3.6020 (0.886 sec/step)\n","I1215 19:30:17.135982 140303514462080 learning.py:512] global step 5853: loss = 3.6020 (0.886 sec/step)\n","INFO:tensorflow:global step 5854: loss = 3.7120 (0.883 sec/step)\n","I1215 19:30:18.020782 140303514462080 learning.py:512] global step 5854: loss = 3.7120 (0.883 sec/step)\n","INFO:tensorflow:global step 5855: loss = 5.1144 (0.899 sec/step)\n","I1215 19:30:18.921203 140303514462080 learning.py:512] global step 5855: loss = 5.1144 (0.899 sec/step)\n","INFO:tensorflow:global step 5856: loss = 3.8486 (0.912 sec/step)\n","I1215 19:30:19.834979 140303514462080 learning.py:512] global step 5856: loss = 3.8486 (0.912 sec/step)\n","INFO:tensorflow:global step 5857: loss = 4.2567 (0.900 sec/step)\n","I1215 19:30:20.736053 140303514462080 learning.py:512] global step 5857: loss = 4.2567 (0.900 sec/step)\n","INFO:tensorflow:global step 5858: loss = 4.1833 (0.902 sec/step)\n","I1215 19:30:21.639707 140303514462080 learning.py:512] global step 5858: loss = 4.1833 (0.902 sec/step)\n","INFO:tensorflow:global step 5859: loss = 5.8067 (0.888 sec/step)\n","I1215 19:30:22.529453 140303514462080 learning.py:512] global step 5859: loss = 5.8067 (0.888 sec/step)\n","INFO:tensorflow:global step 5860: loss = 3.9988 (0.907 sec/step)\n","I1215 19:30:23.437391 140303514462080 learning.py:512] global step 5860: loss = 3.9988 (0.907 sec/step)\n","INFO:tensorflow:global step 5861: loss = 6.0394 (0.894 sec/step)\n","I1215 19:30:24.332623 140303514462080 learning.py:512] global step 5861: loss = 6.0394 (0.894 sec/step)\n","INFO:tensorflow:global step 5862: loss = 5.2640 (0.892 sec/step)\n","I1215 19:30:25.226466 140303514462080 learning.py:512] global step 5862: loss = 5.2640 (0.892 sec/step)\n","INFO:tensorflow:global step 5863: loss = 6.0784 (0.922 sec/step)\n","I1215 19:30:26.149747 140303514462080 learning.py:512] global step 5863: loss = 6.0784 (0.922 sec/step)\n","INFO:tensorflow:global step 5864: loss = 4.0089 (0.931 sec/step)\n","I1215 19:30:27.082299 140303514462080 learning.py:512] global step 5864: loss = 4.0089 (0.931 sec/step)\n","INFO:tensorflow:global step 5865: loss = 3.9680 (0.926 sec/step)\n","I1215 19:30:28.009595 140303514462080 learning.py:512] global step 5865: loss = 3.9680 (0.926 sec/step)\n","INFO:tensorflow:global step 5866: loss = 3.7460 (0.928 sec/step)\n","I1215 19:30:28.938906 140303514462080 learning.py:512] global step 5866: loss = 3.7460 (0.928 sec/step)\n","INFO:tensorflow:global step 5867: loss = 5.9884 (0.912 sec/step)\n","I1215 19:30:29.852779 140303514462080 learning.py:512] global step 5867: loss = 5.9884 (0.912 sec/step)\n","INFO:tensorflow:global step 5868: loss = 4.3524 (0.918 sec/step)\n","I1215 19:30:30.772714 140303514462080 learning.py:512] global step 5868: loss = 4.3524 (0.918 sec/step)\n","INFO:tensorflow:global step 5869: loss = 5.2406 (0.912 sec/step)\n","I1215 19:30:31.686611 140303514462080 learning.py:512] global step 5869: loss = 5.2406 (0.912 sec/step)\n","INFO:tensorflow:global step 5870: loss = 4.1662 (0.913 sec/step)\n","I1215 19:30:32.600903 140303514462080 learning.py:512] global step 5870: loss = 4.1662 (0.913 sec/step)\n","INFO:tensorflow:global step 5871: loss = 4.5233 (0.900 sec/step)\n","I1215 19:30:33.502075 140303514462080 learning.py:512] global step 5871: loss = 4.5233 (0.900 sec/step)\n","INFO:tensorflow:global step 5872: loss = 4.6343 (0.900 sec/step)\n","I1215 19:30:34.404006 140303514462080 learning.py:512] global step 5872: loss = 4.6343 (0.900 sec/step)\n","INFO:tensorflow:global step 5873: loss = 5.1150 (0.887 sec/step)\n","I1215 19:30:35.292324 140303514462080 learning.py:512] global step 5873: loss = 5.1150 (0.887 sec/step)\n","INFO:tensorflow:global step 5874: loss = 4.8513 (0.887 sec/step)\n","I1215 19:30:36.180629 140303514462080 learning.py:512] global step 5874: loss = 4.8513 (0.887 sec/step)\n","INFO:tensorflow:global step 5875: loss = 3.3653 (0.902 sec/step)\n","I1215 19:30:37.083826 140303514462080 learning.py:512] global step 5875: loss = 3.3653 (0.902 sec/step)\n","INFO:tensorflow:global step 5876: loss = 5.9365 (0.896 sec/step)\n","I1215 19:30:37.981260 140303514462080 learning.py:512] global step 5876: loss = 5.9365 (0.896 sec/step)\n","INFO:tensorflow:global step 5877: loss = 6.0484 (0.889 sec/step)\n","I1215 19:30:38.871260 140303514462080 learning.py:512] global step 5877: loss = 6.0484 (0.889 sec/step)\n","INFO:tensorflow:global step 5878: loss = 4.3403 (0.887 sec/step)\n","I1215 19:30:39.759552 140303514462080 learning.py:512] global step 5878: loss = 4.3403 (0.887 sec/step)\n","INFO:tensorflow:global step 5879: loss = 4.0054 (0.903 sec/step)\n","I1215 19:30:40.663678 140303514462080 learning.py:512] global step 5879: loss = 4.0054 (0.903 sec/step)\n","INFO:tensorflow:global step 5880: loss = 2.8274 (0.897 sec/step)\n","I1215 19:30:41.562582 140303514462080 learning.py:512] global step 5880: loss = 2.8274 (0.897 sec/step)\n","INFO:tensorflow:global step 5881: loss = 3.7307 (0.892 sec/step)\n","I1215 19:30:42.455778 140303514462080 learning.py:512] global step 5881: loss = 3.7307 (0.892 sec/step)\n","INFO:tensorflow:global step 5882: loss = 5.1720 (0.902 sec/step)\n","I1215 19:30:43.359516 140303514462080 learning.py:512] global step 5882: loss = 5.1720 (0.902 sec/step)\n","INFO:tensorflow:global step 5883: loss = 4.6446 (0.892 sec/step)\n","I1215 19:30:44.253265 140303514462080 learning.py:512] global step 5883: loss = 4.6446 (0.892 sec/step)\n","INFO:tensorflow:global step 5884: loss = 3.8491 (0.899 sec/step)\n","I1215 19:30:45.153953 140303514462080 learning.py:512] global step 5884: loss = 3.8491 (0.899 sec/step)\n","INFO:tensorflow:global step 5885: loss = 4.9331 (0.897 sec/step)\n","I1215 19:30:46.052922 140303514462080 learning.py:512] global step 5885: loss = 4.9331 (0.897 sec/step)\n","INFO:tensorflow:global step 5886: loss = 5.2775 (0.909 sec/step)\n","I1215 19:30:46.963271 140303514462080 learning.py:512] global step 5886: loss = 5.2775 (0.909 sec/step)\n","INFO:tensorflow:global step 5887: loss = 4.9514 (0.898 sec/step)\n","I1215 19:30:47.862931 140303514462080 learning.py:512] global step 5887: loss = 4.9514 (0.898 sec/step)\n","INFO:tensorflow:global step 5888: loss = 4.4372 (0.908 sec/step)\n","I1215 19:30:48.772296 140303514462080 learning.py:512] global step 5888: loss = 4.4372 (0.908 sec/step)\n","INFO:tensorflow:global step 5889: loss = 6.4568 (0.903 sec/step)\n","I1215 19:30:49.676816 140303514462080 learning.py:512] global step 5889: loss = 6.4568 (0.903 sec/step)\n","INFO:tensorflow:global step 5890: loss = 4.4660 (0.893 sec/step)\n","I1215 19:30:50.571829 140303514462080 learning.py:512] global step 5890: loss = 4.4660 (0.893 sec/step)\n","INFO:tensorflow:global step 5891: loss = 4.6067 (0.899 sec/step)\n","I1215 19:30:51.472517 140303514462080 learning.py:512] global step 5891: loss = 4.6067 (0.899 sec/step)\n","INFO:tensorflow:global step 5892: loss = 4.3598 (0.900 sec/step)\n","I1215 19:30:52.373934 140303514462080 learning.py:512] global step 5892: loss = 4.3598 (0.900 sec/step)\n","INFO:tensorflow:global step 5893: loss = 5.4790 (0.910 sec/step)\n","I1215 19:30:53.285732 140303514462080 learning.py:512] global step 5893: loss = 5.4790 (0.910 sec/step)\n","INFO:tensorflow:global step 5894: loss = 4.0510 (0.904 sec/step)\n","I1215 19:30:54.191637 140303514462080 learning.py:512] global step 5894: loss = 4.0510 (0.904 sec/step)\n","INFO:tensorflow:global step 5895: loss = 5.9689 (0.912 sec/step)\n","I1215 19:30:55.105901 140303514462080 learning.py:512] global step 5895: loss = 5.9689 (0.912 sec/step)\n","INFO:tensorflow:global step 5896: loss = 4.7944 (0.912 sec/step)\n","I1215 19:30:56.019339 140303514462080 learning.py:512] global step 5896: loss = 4.7944 (0.912 sec/step)\n","INFO:tensorflow:global step 5897: loss = 3.8808 (0.912 sec/step)\n","I1215 19:30:56.933149 140303514462080 learning.py:512] global step 5897: loss = 3.8808 (0.912 sec/step)\n","INFO:tensorflow:global step 5898: loss = 6.8565 (0.908 sec/step)\n","I1215 19:30:57.843008 140303514462080 learning.py:512] global step 5898: loss = 6.8565 (0.908 sec/step)\n","INFO:tensorflow:global step 5899: loss = 3.9786 (0.907 sec/step)\n","I1215 19:30:58.751979 140303514462080 learning.py:512] global step 5899: loss = 3.9786 (0.907 sec/step)\n","INFO:tensorflow:global step 5900: loss = 3.7179 (0.908 sec/step)\n","I1215 19:30:59.661440 140303514462080 learning.py:512] global step 5900: loss = 3.7179 (0.908 sec/step)\n","INFO:tensorflow:global step 5901: loss = 5.0322 (0.896 sec/step)\n","I1215 19:31:00.559224 140303514462080 learning.py:512] global step 5901: loss = 5.0322 (0.896 sec/step)\n","INFO:tensorflow:global step 5902: loss = 4.1804 (0.911 sec/step)\n","I1215 19:31:01.472212 140303514462080 learning.py:512] global step 5902: loss = 4.1804 (0.911 sec/step)\n","INFO:tensorflow:global step 5903: loss = 4.2253 (0.917 sec/step)\n","I1215 19:31:02.390671 140303514462080 learning.py:512] global step 5903: loss = 4.2253 (0.917 sec/step)\n","INFO:tensorflow:global step 5904: loss = 4.3171 (0.913 sec/step)\n","I1215 19:31:03.305151 140303514462080 learning.py:512] global step 5904: loss = 4.3171 (0.913 sec/step)\n","INFO:tensorflow:global step 5905: loss = 3.4918 (0.917 sec/step)\n","I1215 19:31:04.223618 140303514462080 learning.py:512] global step 5905: loss = 3.4918 (0.917 sec/step)\n","INFO:tensorflow:global step 5906: loss = 3.5572 (0.933 sec/step)\n","I1215 19:31:05.158504 140303514462080 learning.py:512] global step 5906: loss = 3.5572 (0.933 sec/step)\n","INFO:tensorflow:global step 5907: loss = 3.8872 (0.907 sec/step)\n","I1215 19:31:06.067572 140303514462080 learning.py:512] global step 5907: loss = 3.8872 (0.907 sec/step)\n","INFO:tensorflow:global step 5908: loss = 3.6818 (0.915 sec/step)\n","I1215 19:31:06.984404 140303514462080 learning.py:512] global step 5908: loss = 3.6818 (0.915 sec/step)\n","INFO:tensorflow:global step 5909: loss = 4.2919 (0.911 sec/step)\n","I1215 19:31:07.898258 140303514462080 learning.py:512] global step 5909: loss = 4.2919 (0.911 sec/step)\n","INFO:tensorflow:global step 5910: loss = 5.2743 (0.905 sec/step)\n","I1215 19:31:08.804914 140303514462080 learning.py:512] global step 5910: loss = 5.2743 (0.905 sec/step)\n","INFO:tensorflow:global step 5911: loss = 5.4638 (0.919 sec/step)\n","I1215 19:31:09.725550 140303514462080 learning.py:512] global step 5911: loss = 5.4638 (0.919 sec/step)\n","INFO:tensorflow:global step 5912: loss = 5.4533 (0.902 sec/step)\n","I1215 19:31:10.629551 140303514462080 learning.py:512] global step 5912: loss = 5.4533 (0.902 sec/step)\n","INFO:tensorflow:global step 5913: loss = 4.4397 (0.904 sec/step)\n","I1215 19:31:11.535242 140303514462080 learning.py:512] global step 5913: loss = 4.4397 (0.904 sec/step)\n","INFO:tensorflow:global step 5914: loss = 3.7967 (0.925 sec/step)\n","I1215 19:31:12.462668 140303514462080 learning.py:512] global step 5914: loss = 3.7967 (0.925 sec/step)\n","INFO:tensorflow:global step 5915: loss = 4.8842 (0.894 sec/step)\n","I1215 19:31:13.358796 140303514462080 learning.py:512] global step 5915: loss = 4.8842 (0.894 sec/step)\n","INFO:tensorflow:global step 5916: loss = 5.2614 (0.915 sec/step)\n","I1215 19:31:14.275385 140303514462080 learning.py:512] global step 5916: loss = 5.2614 (0.915 sec/step)\n","INFO:tensorflow:global step 5917: loss = 4.4048 (0.902 sec/step)\n","I1215 19:31:15.178817 140303514462080 learning.py:512] global step 5917: loss = 4.4048 (0.902 sec/step)\n","INFO:tensorflow:global step 5918: loss = 4.9593 (0.887 sec/step)\n","I1215 19:31:16.066903 140303514462080 learning.py:512] global step 5918: loss = 4.9593 (0.887 sec/step)\n","INFO:tensorflow:global step 5919: loss = 4.0065 (0.887 sec/step)\n","I1215 19:31:16.955751 140303514462080 learning.py:512] global step 5919: loss = 4.0065 (0.887 sec/step)\n","INFO:tensorflow:global step 5920: loss = 3.3478 (0.886 sec/step)\n","I1215 19:31:17.843027 140303514462080 learning.py:512] global step 5920: loss = 3.3478 (0.886 sec/step)\n","INFO:tensorflow:global step 5921: loss = 4.8908 (0.902 sec/step)\n","I1215 19:31:18.746030 140303514462080 learning.py:512] global step 5921: loss = 4.8908 (0.902 sec/step)\n","INFO:tensorflow:global step 5922: loss = 5.3297 (0.889 sec/step)\n","I1215 19:31:19.636979 140303514462080 learning.py:512] global step 5922: loss = 5.3297 (0.889 sec/step)\n","INFO:tensorflow:global step 5923: loss = 4.9755 (0.880 sec/step)\n","I1215 19:31:20.518976 140303514462080 learning.py:512] global step 5923: loss = 4.9755 (0.880 sec/step)\n","INFO:tensorflow:global step 5924: loss = 3.5127 (0.880 sec/step)\n","I1215 19:31:21.400056 140303514462080 learning.py:512] global step 5924: loss = 3.5127 (0.880 sec/step)\n","INFO:tensorflow:global step 5925: loss = 3.8080 (0.905 sec/step)\n","I1215 19:31:22.306897 140303514462080 learning.py:512] global step 5925: loss = 3.8080 (0.905 sec/step)\n","INFO:tensorflow:global step 5926: loss = 3.8449 (0.884 sec/step)\n","I1215 19:31:23.192507 140303514462080 learning.py:512] global step 5926: loss = 3.8449 (0.884 sec/step)\n","INFO:tensorflow:global step 5927: loss = 5.4899 (0.894 sec/step)\n","I1215 19:31:24.087718 140303514462080 learning.py:512] global step 5927: loss = 5.4899 (0.894 sec/step)\n","INFO:tensorflow:global step 5928: loss = 5.0347 (0.898 sec/step)\n","I1215 19:31:24.987126 140303514462080 learning.py:512] global step 5928: loss = 5.0347 (0.898 sec/step)\n","INFO:tensorflow:global step 5929: loss = 4.0647 (0.906 sec/step)\n","I1215 19:31:25.894602 140303514462080 learning.py:512] global step 5929: loss = 4.0647 (0.906 sec/step)\n","INFO:tensorflow:global step 5930: loss = 4.6331 (0.878 sec/step)\n","I1215 19:31:26.773752 140303514462080 learning.py:512] global step 5930: loss = 4.6331 (0.878 sec/step)\n","INFO:tensorflow:global step 5931: loss = 3.3560 (0.884 sec/step)\n","I1215 19:31:27.659698 140303514462080 learning.py:512] global step 5931: loss = 3.3560 (0.884 sec/step)\n","INFO:tensorflow:global step 5932: loss = 3.1690 (0.874 sec/step)\n","I1215 19:31:28.535819 140303514462080 learning.py:512] global step 5932: loss = 3.1690 (0.874 sec/step)\n","INFO:tensorflow:global step 5933: loss = 4.4805 (0.912 sec/step)\n","I1215 19:31:29.449145 140303514462080 learning.py:512] global step 5933: loss = 4.4805 (0.912 sec/step)\n","INFO:tensorflow:global step 5934: loss = 3.8403 (0.921 sec/step)\n","I1215 19:31:30.372137 140303514462080 learning.py:512] global step 5934: loss = 3.8403 (0.921 sec/step)\n","INFO:tensorflow:global step 5935: loss = 4.1650 (0.901 sec/step)\n","I1215 19:31:31.274886 140303514462080 learning.py:512] global step 5935: loss = 4.1650 (0.901 sec/step)\n","INFO:tensorflow:global step 5936: loss = 4.2944 (0.888 sec/step)\n","I1215 19:31:32.165038 140303514462080 learning.py:512] global step 5936: loss = 4.2944 (0.888 sec/step)\n","INFO:tensorflow:global step 5937: loss = 5.6070 (0.936 sec/step)\n","I1215 19:31:33.102586 140303514462080 learning.py:512] global step 5937: loss = 5.6070 (0.936 sec/step)\n","INFO:tensorflow:global step 5938: loss = 4.3176 (0.916 sec/step)\n","I1215 19:31:34.020421 140303514462080 learning.py:512] global step 5938: loss = 4.3176 (0.916 sec/step)\n","INFO:tensorflow:global step 5939: loss = 5.0246 (0.906 sec/step)\n","I1215 19:31:34.927443 140303514462080 learning.py:512] global step 5939: loss = 5.0246 (0.906 sec/step)\n","INFO:tensorflow:global step 5940: loss = 5.4633 (0.983 sec/step)\n","I1215 19:31:35.912055 140303514462080 learning.py:512] global step 5940: loss = 5.4633 (0.983 sec/step)\n","INFO:tensorflow:Recording summary at step 5940.\n","I1215 19:31:37.148307 140299899541248 supervisor.py:1050] Recording summary at step 5940.\n","INFO:tensorflow:global step 5941: loss = 4.4335 (1.412 sec/step)\n","I1215 19:31:37.325905 140303514462080 learning.py:512] global step 5941: loss = 4.4335 (1.412 sec/step)\n","INFO:tensorflow:global step 5942: loss = 3.6855 (0.890 sec/step)\n","I1215 19:31:38.217706 140303514462080 learning.py:512] global step 5942: loss = 3.6855 (0.890 sec/step)\n","INFO:tensorflow:global step 5943: loss = 5.6880 (0.895 sec/step)\n","I1215 19:31:39.114690 140303514462080 learning.py:512] global step 5943: loss = 5.6880 (0.895 sec/step)\n","INFO:tensorflow:global step 5944: loss = 4.8066 (0.890 sec/step)\n","I1215 19:31:40.006668 140303514462080 learning.py:512] global step 5944: loss = 4.8066 (0.890 sec/step)\n","INFO:tensorflow:global step 5945: loss = 3.5310 (0.899 sec/step)\n","I1215 19:31:40.907573 140303514462080 learning.py:512] global step 5945: loss = 3.5310 (0.899 sec/step)\n","INFO:tensorflow:global step 5946: loss = 3.2391 (0.919 sec/step)\n","I1215 19:31:41.827896 140303514462080 learning.py:512] global step 5946: loss = 3.2391 (0.919 sec/step)\n","INFO:tensorflow:global step 5947: loss = 6.3862 (0.893 sec/step)\n","I1215 19:31:42.722660 140303514462080 learning.py:512] global step 5947: loss = 6.3862 (0.893 sec/step)\n","INFO:tensorflow:global step 5948: loss = 4.9104 (0.913 sec/step)\n","I1215 19:31:43.637341 140303514462080 learning.py:512] global step 5948: loss = 4.9104 (0.913 sec/step)\n","INFO:tensorflow:global step 5949: loss = 4.2885 (0.893 sec/step)\n","I1215 19:31:44.531570 140303514462080 learning.py:512] global step 5949: loss = 4.2885 (0.893 sec/step)\n","INFO:tensorflow:global step 5950: loss = 4.3445 (0.887 sec/step)\n","I1215 19:31:45.419570 140303514462080 learning.py:512] global step 5950: loss = 4.3445 (0.887 sec/step)\n","INFO:tensorflow:global step 5951: loss = 5.1682 (0.896 sec/step)\n","I1215 19:31:46.316949 140303514462080 learning.py:512] global step 5951: loss = 5.1682 (0.896 sec/step)\n","INFO:tensorflow:global step 5952: loss = 3.7856 (0.886 sec/step)\n","I1215 19:31:47.204869 140303514462080 learning.py:512] global step 5952: loss = 3.7856 (0.886 sec/step)\n","INFO:tensorflow:global step 5953: loss = 3.9085 (0.909 sec/step)\n","I1215 19:31:48.115582 140303514462080 learning.py:512] global step 5953: loss = 3.9085 (0.909 sec/step)\n","INFO:tensorflow:global step 5954: loss = 4.6336 (0.909 sec/step)\n","I1215 19:31:49.026310 140303514462080 learning.py:512] global step 5954: loss = 4.6336 (0.909 sec/step)\n","INFO:tensorflow:global step 5955: loss = 4.4737 (0.906 sec/step)\n","I1215 19:31:49.934128 140303514462080 learning.py:512] global step 5955: loss = 4.4737 (0.906 sec/step)\n","INFO:tensorflow:global step 5956: loss = 5.8838 (0.892 sec/step)\n","I1215 19:31:50.827756 140303514462080 learning.py:512] global step 5956: loss = 5.8838 (0.892 sec/step)\n","INFO:tensorflow:global step 5957: loss = 4.1510 (0.897 sec/step)\n","I1215 19:31:51.726524 140303514462080 learning.py:512] global step 5957: loss = 4.1510 (0.897 sec/step)\n","INFO:tensorflow:global step 5958: loss = 4.1796 (0.900 sec/step)\n","I1215 19:31:52.628087 140303514462080 learning.py:512] global step 5958: loss = 4.1796 (0.900 sec/step)\n","INFO:tensorflow:global step 5959: loss = 3.2285 (0.885 sec/step)\n","I1215 19:31:53.514272 140303514462080 learning.py:512] global step 5959: loss = 3.2285 (0.885 sec/step)\n","INFO:tensorflow:global step 5960: loss = 4.6735 (0.877 sec/step)\n","I1215 19:31:54.392856 140303514462080 learning.py:512] global step 5960: loss = 4.6735 (0.877 sec/step)\n","INFO:tensorflow:global step 5961: loss = 4.2200 (0.905 sec/step)\n","I1215 19:31:55.299461 140303514462080 learning.py:512] global step 5961: loss = 4.2200 (0.905 sec/step)\n","INFO:tensorflow:global step 5962: loss = 5.3489 (0.898 sec/step)\n","I1215 19:31:56.199225 140303514462080 learning.py:512] global step 5962: loss = 5.3489 (0.898 sec/step)\n","INFO:tensorflow:global step 5963: loss = 7.5225 (0.920 sec/step)\n","I1215 19:31:57.120748 140303514462080 learning.py:512] global step 5963: loss = 7.5225 (0.920 sec/step)\n","INFO:tensorflow:global step 5964: loss = 3.7459 (0.917 sec/step)\n","I1215 19:31:58.038981 140303514462080 learning.py:512] global step 5964: loss = 3.7459 (0.917 sec/step)\n","INFO:tensorflow:global step 5965: loss = 3.1661 (0.902 sec/step)\n","I1215 19:31:58.942908 140303514462080 learning.py:512] global step 5965: loss = 3.1661 (0.902 sec/step)\n","INFO:tensorflow:global step 5966: loss = 3.6593 (0.896 sec/step)\n","I1215 19:31:59.839977 140303514462080 learning.py:512] global step 5966: loss = 3.6593 (0.896 sec/step)\n","INFO:tensorflow:global step 5967: loss = 4.4900 (0.909 sec/step)\n","I1215 19:32:00.750246 140303514462080 learning.py:512] global step 5967: loss = 4.4900 (0.909 sec/step)\n","INFO:tensorflow:global step 5968: loss = 6.1343 (0.904 sec/step)\n","I1215 19:32:01.655967 140303514462080 learning.py:512] global step 5968: loss = 6.1343 (0.904 sec/step)\n","INFO:tensorflow:global step 5969: loss = 4.3503 (0.886 sec/step)\n","I1215 19:32:02.543285 140303514462080 learning.py:512] global step 5969: loss = 4.3503 (0.886 sec/step)\n","INFO:tensorflow:global step 5970: loss = 5.8215 (0.891 sec/step)\n","I1215 19:32:03.435319 140303514462080 learning.py:512] global step 5970: loss = 5.8215 (0.891 sec/step)\n","INFO:tensorflow:global step 5971: loss = 4.7058 (0.913 sec/step)\n","I1215 19:32:04.349988 140303514462080 learning.py:512] global step 5971: loss = 4.7058 (0.913 sec/step)\n","INFO:tensorflow:global step 5972: loss = 4.3297 (0.904 sec/step)\n","I1215 19:32:05.255860 140303514462080 learning.py:512] global step 5972: loss = 4.3297 (0.904 sec/step)\n","INFO:tensorflow:global step 5973: loss = 4.7379 (0.882 sec/step)\n","I1215 19:32:06.139585 140303514462080 learning.py:512] global step 5973: loss = 4.7379 (0.882 sec/step)\n","INFO:tensorflow:global step 5974: loss = 5.4615 (0.891 sec/step)\n","I1215 19:32:07.032191 140303514462080 learning.py:512] global step 5974: loss = 5.4615 (0.891 sec/step)\n","INFO:tensorflow:global step 5975: loss = 4.5573 (0.896 sec/step)\n","I1215 19:32:07.930147 140303514462080 learning.py:512] global step 5975: loss = 4.5573 (0.896 sec/step)\n","INFO:tensorflow:global step 5976: loss = 3.3375 (0.890 sec/step)\n","I1215 19:32:08.821603 140303514462080 learning.py:512] global step 5976: loss = 3.3375 (0.890 sec/step)\n","INFO:tensorflow:global step 5977: loss = 4.4551 (0.899 sec/step)\n","I1215 19:32:09.722209 140303514462080 learning.py:512] global step 5977: loss = 4.4551 (0.899 sec/step)\n","INFO:tensorflow:global step 5978: loss = 3.3473 (0.889 sec/step)\n","I1215 19:32:10.612607 140303514462080 learning.py:512] global step 5978: loss = 3.3473 (0.889 sec/step)\n","INFO:tensorflow:global step 5979: loss = 3.0145 (0.900 sec/step)\n","I1215 19:32:11.514392 140303514462080 learning.py:512] global step 5979: loss = 3.0145 (0.900 sec/step)\n","INFO:tensorflow:global step 5980: loss = 3.6945 (0.900 sec/step)\n","I1215 19:32:12.415593 140303514462080 learning.py:512] global step 5980: loss = 3.6945 (0.900 sec/step)\n","INFO:tensorflow:global step 5981: loss = 3.0824 (0.895 sec/step)\n","I1215 19:32:13.312070 140303514462080 learning.py:512] global step 5981: loss = 3.0824 (0.895 sec/step)\n","INFO:tensorflow:global step 5982: loss = 4.8320 (0.887 sec/step)\n","I1215 19:32:14.200960 140303514462080 learning.py:512] global step 5982: loss = 4.8320 (0.887 sec/step)\n","INFO:tensorflow:global step 5983: loss = 4.1814 (0.917 sec/step)\n","I1215 19:32:15.120000 140303514462080 learning.py:512] global step 5983: loss = 4.1814 (0.917 sec/step)\n","INFO:tensorflow:global step 5984: loss = 4.6968 (0.895 sec/step)\n","I1215 19:32:16.016941 140303514462080 learning.py:512] global step 5984: loss = 4.6968 (0.895 sec/step)\n","INFO:tensorflow:global step 5985: loss = 4.0291 (0.890 sec/step)\n","I1215 19:32:16.908241 140303514462080 learning.py:512] global step 5985: loss = 4.0291 (0.890 sec/step)\n","INFO:tensorflow:global step 5986: loss = 5.1012 (0.889 sec/step)\n","I1215 19:32:17.798674 140303514462080 learning.py:512] global step 5986: loss = 5.1012 (0.889 sec/step)\n","INFO:tensorflow:global step 5987: loss = 3.9787 (0.901 sec/step)\n","I1215 19:32:18.701177 140303514462080 learning.py:512] global step 5987: loss = 3.9787 (0.901 sec/step)\n","INFO:tensorflow:global step 5988: loss = 4.5460 (0.884 sec/step)\n","I1215 19:32:19.587095 140303514462080 learning.py:512] global step 5988: loss = 4.5460 (0.884 sec/step)\n","INFO:tensorflow:global step 5989: loss = 3.1998 (0.898 sec/step)\n","I1215 19:32:20.486289 140303514462080 learning.py:512] global step 5989: loss = 3.1998 (0.898 sec/step)\n","INFO:tensorflow:global step 5990: loss = 4.2956 (0.911 sec/step)\n","I1215 19:32:21.398632 140303514462080 learning.py:512] global step 5990: loss = 4.2956 (0.911 sec/step)\n","INFO:tensorflow:global step 5991: loss = 5.1956 (0.895 sec/step)\n","I1215 19:32:22.294548 140303514462080 learning.py:512] global step 5991: loss = 5.1956 (0.895 sec/step)\n","INFO:tensorflow:global step 5992: loss = 5.9411 (0.903 sec/step)\n","I1215 19:32:23.198511 140303514462080 learning.py:512] global step 5992: loss = 5.9411 (0.903 sec/step)\n","INFO:tensorflow:global step 5993: loss = 5.6936 (0.899 sec/step)\n","I1215 19:32:24.098859 140303514462080 learning.py:512] global step 5993: loss = 5.6936 (0.899 sec/step)\n","INFO:tensorflow:global step 5994: loss = 5.5723 (0.900 sec/step)\n","I1215 19:32:25.000708 140303514462080 learning.py:512] global step 5994: loss = 5.5723 (0.900 sec/step)\n","INFO:tensorflow:global step 5995: loss = 3.3871 (0.895 sec/step)\n","I1215 19:32:25.897360 140303514462080 learning.py:512] global step 5995: loss = 3.3871 (0.895 sec/step)\n","INFO:tensorflow:global step 5996: loss = 4.1677 (0.909 sec/step)\n","I1215 19:32:26.807603 140303514462080 learning.py:512] global step 5996: loss = 4.1677 (0.909 sec/step)\n","INFO:tensorflow:global step 5997: loss = 6.0436 (0.912 sec/step)\n","I1215 19:32:27.721374 140303514462080 learning.py:512] global step 5997: loss = 6.0436 (0.912 sec/step)\n","INFO:tensorflow:global step 5998: loss = 4.5734 (0.922 sec/step)\n","I1215 19:32:28.645771 140303514462080 learning.py:512] global step 5998: loss = 4.5734 (0.922 sec/step)\n","INFO:tensorflow:global step 5999: loss = 4.2657 (0.921 sec/step)\n","I1215 19:32:29.568256 140303514462080 learning.py:512] global step 5999: loss = 4.2657 (0.921 sec/step)\n","INFO:tensorflow:global step 6000: loss = 3.9864 (0.914 sec/step)\n","I1215 19:32:30.483701 140303514462080 learning.py:512] global step 6000: loss = 3.9864 (0.914 sec/step)\n","INFO:tensorflow:global step 6001: loss = 5.6944 (0.929 sec/step)\n","I1215 19:32:31.414264 140303514462080 learning.py:512] global step 6001: loss = 5.6944 (0.929 sec/step)\n","INFO:tensorflow:global step 6002: loss = 4.5479 (0.916 sec/step)\n","I1215 19:32:32.331761 140303514462080 learning.py:512] global step 6002: loss = 4.5479 (0.916 sec/step)\n","INFO:tensorflow:global step 6003: loss = 4.4788 (0.911 sec/step)\n","I1215 19:32:33.244283 140303514462080 learning.py:512] global step 6003: loss = 4.4788 (0.911 sec/step)\n","INFO:tensorflow:global step 6004: loss = 5.4159 (0.894 sec/step)\n","I1215 19:32:34.140318 140303514462080 learning.py:512] global step 6004: loss = 5.4159 (0.894 sec/step)\n","INFO:tensorflow:global step 6005: loss = 4.5504 (0.916 sec/step)\n","I1215 19:32:35.058665 140303514462080 learning.py:512] global step 6005: loss = 4.5504 (0.916 sec/step)\n","INFO:tensorflow:global step 6006: loss = 4.5246 (0.895 sec/step)\n","I1215 19:32:35.955493 140303514462080 learning.py:512] global step 6006: loss = 4.5246 (0.895 sec/step)\n","INFO:tensorflow:global step 6007: loss = 3.2067 (0.905 sec/step)\n","I1215 19:32:36.862303 140303514462080 learning.py:512] global step 6007: loss = 3.2067 (0.905 sec/step)\n","INFO:tensorflow:global step 6008: loss = 3.1281 (0.905 sec/step)\n","I1215 19:32:37.769177 140303514462080 learning.py:512] global step 6008: loss = 3.1281 (0.905 sec/step)\n","INFO:tensorflow:global step 6009: loss = 4.5056 (0.905 sec/step)\n","I1215 19:32:38.676030 140303514462080 learning.py:512] global step 6009: loss = 4.5056 (0.905 sec/step)\n","INFO:tensorflow:global step 6010: loss = 6.2439 (0.901 sec/step)\n","I1215 19:32:39.578250 140303514462080 learning.py:512] global step 6010: loss = 6.2439 (0.901 sec/step)\n","INFO:tensorflow:global step 6011: loss = 3.1021 (0.886 sec/step)\n","I1215 19:32:40.465924 140303514462080 learning.py:512] global step 6011: loss = 3.1021 (0.886 sec/step)\n","INFO:tensorflow:global step 6012: loss = 4.5262 (0.900 sec/step)\n","I1215 19:32:41.367137 140303514462080 learning.py:512] global step 6012: loss = 4.5262 (0.900 sec/step)\n","INFO:tensorflow:global step 6013: loss = 5.3076 (0.887 sec/step)\n","I1215 19:32:42.255433 140303514462080 learning.py:512] global step 6013: loss = 5.3076 (0.887 sec/step)\n","INFO:tensorflow:global step 6014: loss = 3.1067 (0.888 sec/step)\n","I1215 19:32:43.145283 140303514462080 learning.py:512] global step 6014: loss = 3.1067 (0.888 sec/step)\n","INFO:tensorflow:global step 6015: loss = 4.1650 (0.911 sec/step)\n","I1215 19:32:44.057919 140303514462080 learning.py:512] global step 6015: loss = 4.1650 (0.911 sec/step)\n","INFO:tensorflow:global step 6016: loss = 4.1237 (0.908 sec/step)\n","I1215 19:32:44.967051 140303514462080 learning.py:512] global step 6016: loss = 4.1237 (0.908 sec/step)\n","INFO:tensorflow:global step 6017: loss = 5.7193 (0.913 sec/step)\n","I1215 19:32:45.881142 140303514462080 learning.py:512] global step 6017: loss = 5.7193 (0.913 sec/step)\n","INFO:tensorflow:global step 6018: loss = 7.2541 (0.895 sec/step)\n","I1215 19:32:46.777987 140303514462080 learning.py:512] global step 6018: loss = 7.2541 (0.895 sec/step)\n","INFO:tensorflow:global step 6019: loss = 3.5304 (0.909 sec/step)\n","I1215 19:32:47.688121 140303514462080 learning.py:512] global step 6019: loss = 3.5304 (0.909 sec/step)\n","INFO:tensorflow:global step 6020: loss = 3.7950 (0.903 sec/step)\n","I1215 19:32:48.592664 140303514462080 learning.py:512] global step 6020: loss = 3.7950 (0.903 sec/step)\n","INFO:tensorflow:global step 6021: loss = 4.6194 (0.901 sec/step)\n","I1215 19:32:49.496005 140303514462080 learning.py:512] global step 6021: loss = 4.6194 (0.901 sec/step)\n","INFO:tensorflow:global step 6022: loss = 3.3513 (0.891 sec/step)\n","I1215 19:32:50.388563 140303514462080 learning.py:512] global step 6022: loss = 3.3513 (0.891 sec/step)\n","INFO:tensorflow:global step 6023: loss = 3.5656 (0.896 sec/step)\n","I1215 19:32:51.286006 140303514462080 learning.py:512] global step 6023: loss = 3.5656 (0.896 sec/step)\n","INFO:tensorflow:global step 6024: loss = 3.2611 (0.890 sec/step)\n","I1215 19:32:52.177067 140303514462080 learning.py:512] global step 6024: loss = 3.2611 (0.890 sec/step)\n","INFO:tensorflow:global step 6025: loss = 2.7086 (0.913 sec/step)\n","I1215 19:32:53.091421 140303514462080 learning.py:512] global step 6025: loss = 2.7086 (0.913 sec/step)\n","INFO:tensorflow:global step 6026: loss = 3.6960 (0.891 sec/step)\n","I1215 19:32:53.984668 140303514462080 learning.py:512] global step 6026: loss = 3.6960 (0.891 sec/step)\n","INFO:tensorflow:global step 6027: loss = 4.2836 (0.912 sec/step)\n","I1215 19:32:54.898332 140303514462080 learning.py:512] global step 6027: loss = 4.2836 (0.912 sec/step)\n","INFO:tensorflow:global step 6028: loss = 2.7277 (0.897 sec/step)\n","I1215 19:32:55.796889 140303514462080 learning.py:512] global step 6028: loss = 2.7277 (0.897 sec/step)\n","INFO:tensorflow:global step 6029: loss = 3.7276 (0.934 sec/step)\n","I1215 19:32:56.732140 140303514462080 learning.py:512] global step 6029: loss = 3.7276 (0.934 sec/step)\n","INFO:tensorflow:global step 6030: loss = 4.5776 (0.931 sec/step)\n","I1215 19:32:57.664511 140303514462080 learning.py:512] global step 6030: loss = 4.5776 (0.931 sec/step)\n","INFO:tensorflow:global step 6031: loss = 3.5017 (0.908 sec/step)\n","I1215 19:32:58.574461 140303514462080 learning.py:512] global step 6031: loss = 3.5017 (0.908 sec/step)\n","INFO:tensorflow:global step 6032: loss = 4.1922 (0.893 sec/step)\n","I1215 19:32:59.469053 140303514462080 learning.py:512] global step 6032: loss = 4.1922 (0.893 sec/step)\n","INFO:tensorflow:global step 6033: loss = 4.4560 (0.918 sec/step)\n","I1215 19:33:00.388391 140303514462080 learning.py:512] global step 6033: loss = 4.4560 (0.918 sec/step)\n","INFO:tensorflow:global step 6034: loss = 6.5173 (0.896 sec/step)\n","I1215 19:33:01.286254 140303514462080 learning.py:512] global step 6034: loss = 6.5173 (0.896 sec/step)\n","INFO:tensorflow:global step 6035: loss = 4.1603 (0.908 sec/step)\n","I1215 19:33:02.196353 140303514462080 learning.py:512] global step 6035: loss = 4.1603 (0.908 sec/step)\n","INFO:tensorflow:global step 6036: loss = 6.3655 (0.924 sec/step)\n","I1215 19:33:03.122054 140303514462080 learning.py:512] global step 6036: loss = 6.3655 (0.924 sec/step)\n","INFO:tensorflow:global step 6037: loss = 4.3742 (0.909 sec/step)\n","I1215 19:33:04.032922 140303514462080 learning.py:512] global step 6037: loss = 4.3742 (0.909 sec/step)\n","INFO:tensorflow:global step 6038: loss = 3.7619 (0.894 sec/step)\n","I1215 19:33:04.928388 140303514462080 learning.py:512] global step 6038: loss = 3.7619 (0.894 sec/step)\n","INFO:tensorflow:global step 6039: loss = 3.3510 (0.914 sec/step)\n","I1215 19:33:05.844496 140303514462080 learning.py:512] global step 6039: loss = 3.3510 (0.914 sec/step)\n","INFO:tensorflow:global step 6040: loss = 3.4563 (0.923 sec/step)\n","I1215 19:33:06.768990 140303514462080 learning.py:512] global step 6040: loss = 3.4563 (0.923 sec/step)\n","INFO:tensorflow:global step 6041: loss = 3.7560 (0.900 sec/step)\n","I1215 19:33:07.670296 140303514462080 learning.py:512] global step 6041: loss = 3.7560 (0.900 sec/step)\n","INFO:tensorflow:global step 6042: loss = 5.5384 (0.897 sec/step)\n","I1215 19:33:08.568736 140303514462080 learning.py:512] global step 6042: loss = 5.5384 (0.897 sec/step)\n","INFO:tensorflow:global step 6043: loss = 3.8614 (0.920 sec/step)\n","I1215 19:33:09.490599 140303514462080 learning.py:512] global step 6043: loss = 3.8614 (0.920 sec/step)\n","INFO:tensorflow:global step 6044: loss = 3.9985 (0.921 sec/step)\n","I1215 19:33:10.413622 140303514462080 learning.py:512] global step 6044: loss = 3.9985 (0.921 sec/step)\n","INFO:tensorflow:global step 6045: loss = 4.5462 (0.905 sec/step)\n","I1215 19:33:11.319725 140303514462080 learning.py:512] global step 6045: loss = 4.5462 (0.905 sec/step)\n","INFO:tensorflow:global step 6046: loss = 3.7077 (0.923 sec/step)\n","I1215 19:33:12.244145 140303514462080 learning.py:512] global step 6046: loss = 3.7077 (0.923 sec/step)\n","INFO:tensorflow:global step 6047: loss = 4.0127 (0.904 sec/step)\n","I1215 19:33:13.149466 140303514462080 learning.py:512] global step 6047: loss = 4.0127 (0.904 sec/step)\n","INFO:tensorflow:global step 6048: loss = 3.1927 (0.903 sec/step)\n","I1215 19:33:14.053771 140303514462080 learning.py:512] global step 6048: loss = 3.1927 (0.903 sec/step)\n","INFO:tensorflow:global step 6049: loss = 4.5905 (0.895 sec/step)\n","I1215 19:33:14.950617 140303514462080 learning.py:512] global step 6049: loss = 4.5905 (0.895 sec/step)\n","INFO:tensorflow:global step 6050: loss = 3.4120 (0.906 sec/step)\n","I1215 19:33:15.857800 140303514462080 learning.py:512] global step 6050: loss = 3.4120 (0.906 sec/step)\n","INFO:tensorflow:global step 6051: loss = 4.5110 (0.912 sec/step)\n","I1215 19:33:16.771663 140303514462080 learning.py:512] global step 6051: loss = 4.5110 (0.912 sec/step)\n","INFO:tensorflow:global step 6052: loss = 4.6855 (0.899 sec/step)\n","I1215 19:33:17.671970 140303514462080 learning.py:512] global step 6052: loss = 4.6855 (0.899 sec/step)\n","INFO:tensorflow:global step 6053: loss = 2.9747 (0.906 sec/step)\n","I1215 19:33:18.582447 140303514462080 learning.py:512] global step 6053: loss = 2.9747 (0.906 sec/step)\n","INFO:tensorflow:global step 6054: loss = 3.3721 (0.901 sec/step)\n","I1215 19:33:19.484980 140303514462080 learning.py:512] global step 6054: loss = 3.3721 (0.901 sec/step)\n","INFO:tensorflow:global step 6055: loss = 3.5342 (0.909 sec/step)\n","I1215 19:33:20.395887 140303514462080 learning.py:512] global step 6055: loss = 3.5342 (0.909 sec/step)\n","INFO:tensorflow:global step 6056: loss = 4.6828 (0.909 sec/step)\n","I1215 19:33:21.306457 140303514462080 learning.py:512] global step 6056: loss = 4.6828 (0.909 sec/step)\n","INFO:tensorflow:global step 6057: loss = 4.6474 (0.905 sec/step)\n","I1215 19:33:22.213138 140303514462080 learning.py:512] global step 6057: loss = 4.6474 (0.905 sec/step)\n","INFO:tensorflow:global step 6058: loss = 3.9272 (0.898 sec/step)\n","I1215 19:33:23.112414 140303514462080 learning.py:512] global step 6058: loss = 3.9272 (0.898 sec/step)\n","INFO:tensorflow:global step 6059: loss = 4.0437 (0.888 sec/step)\n","I1215 19:33:24.002186 140303514462080 learning.py:512] global step 6059: loss = 4.0437 (0.888 sec/step)\n","INFO:tensorflow:global step 6060: loss = 5.8350 (0.907 sec/step)\n","I1215 19:33:24.910375 140303514462080 learning.py:512] global step 6060: loss = 5.8350 (0.907 sec/step)\n","INFO:tensorflow:global step 6061: loss = 4.0613 (0.891 sec/step)\n","I1215 19:33:25.803567 140303514462080 learning.py:512] global step 6061: loss = 4.0613 (0.891 sec/step)\n","INFO:tensorflow:global step 6062: loss = 6.4947 (0.897 sec/step)\n","I1215 19:33:26.702075 140303514462080 learning.py:512] global step 6062: loss = 6.4947 (0.897 sec/step)\n","INFO:tensorflow:global step 6063: loss = 3.7072 (0.941 sec/step)\n","I1215 19:33:27.645097 140303514462080 learning.py:512] global step 6063: loss = 3.7072 (0.941 sec/step)\n","INFO:tensorflow:global step 6064: loss = 2.5612 (0.925 sec/step)\n","I1215 19:33:28.571445 140303514462080 learning.py:512] global step 6064: loss = 2.5612 (0.925 sec/step)\n","INFO:tensorflow:global step 6065: loss = 3.2947 (0.925 sec/step)\n","I1215 19:33:29.497860 140303514462080 learning.py:512] global step 6065: loss = 3.2947 (0.925 sec/step)\n","INFO:tensorflow:global step 6066: loss = 3.0784 (0.919 sec/step)\n","I1215 19:33:30.418494 140303514462080 learning.py:512] global step 6066: loss = 3.0784 (0.919 sec/step)\n","INFO:tensorflow:global step 6067: loss = 3.0314 (0.888 sec/step)\n","I1215 19:33:31.307762 140303514462080 learning.py:512] global step 6067: loss = 3.0314 (0.888 sec/step)\n","INFO:tensorflow:global step 6068: loss = 3.9954 (0.903 sec/step)\n","I1215 19:33:32.211935 140303514462080 learning.py:512] global step 6068: loss = 3.9954 (0.903 sec/step)\n","INFO:tensorflow:global step 6069: loss = 3.0181 (0.914 sec/step)\n","I1215 19:33:33.127334 140303514462080 learning.py:512] global step 6069: loss = 3.0181 (0.914 sec/step)\n","INFO:tensorflow:global step 6070: loss = 4.3257 (0.913 sec/step)\n","I1215 19:33:34.041577 140303514462080 learning.py:512] global step 6070: loss = 4.3257 (0.913 sec/step)\n","INFO:tensorflow:global step 6071: loss = 3.2226 (0.898 sec/step)\n","I1215 19:33:34.941486 140303514462080 learning.py:512] global step 6071: loss = 3.2226 (0.898 sec/step)\n","INFO:tensorflow:global step 6072: loss = 3.9423 (1.038 sec/step)\n","I1215 19:33:35.980903 140303514462080 learning.py:512] global step 6072: loss = 3.9423 (1.038 sec/step)\n","INFO:tensorflow:Recording summary at step 6072.\n","I1215 19:33:37.090407 140299899541248 supervisor.py:1050] Recording summary at step 6072.\n","INFO:tensorflow:global step 6073: loss = 5.2072 (1.351 sec/step)\n","I1215 19:33:37.334027 140303514462080 learning.py:512] global step 6073: loss = 5.2072 (1.351 sec/step)\n","INFO:tensorflow:global step 6074: loss = 4.1806 (0.930 sec/step)\n","I1215 19:33:38.266059 140303514462080 learning.py:512] global step 6074: loss = 4.1806 (0.930 sec/step)\n","INFO:tensorflow:global step 6075: loss = 4.0754 (0.910 sec/step)\n","I1215 19:33:39.177688 140303514462080 learning.py:512] global step 6075: loss = 4.0754 (0.910 sec/step)\n","INFO:tensorflow:global step 6076: loss = 4.7917 (0.899 sec/step)\n","I1215 19:33:40.077825 140303514462080 learning.py:512] global step 6076: loss = 4.7917 (0.899 sec/step)\n","INFO:tensorflow:global step 6077: loss = 4.8633 (0.892 sec/step)\n","I1215 19:33:40.971492 140303514462080 learning.py:512] global step 6077: loss = 4.8633 (0.892 sec/step)\n","INFO:tensorflow:global step 6078: loss = 4.0141 (0.911 sec/step)\n","I1215 19:33:41.884468 140303514462080 learning.py:512] global step 6078: loss = 4.0141 (0.911 sec/step)\n","INFO:tensorflow:global step 6079: loss = 6.9819 (0.908 sec/step)\n","I1215 19:33:42.794428 140303514462080 learning.py:512] global step 6079: loss = 6.9819 (0.908 sec/step)\n","INFO:tensorflow:global step 6080: loss = 5.4585 (0.927 sec/step)\n","I1215 19:33:43.722405 140303514462080 learning.py:512] global step 6080: loss = 5.4585 (0.927 sec/step)\n","INFO:tensorflow:global step 6081: loss = 3.1030 (0.967 sec/step)\n","I1215 19:33:44.691202 140303514462080 learning.py:512] global step 6081: loss = 3.1030 (0.967 sec/step)\n","INFO:tensorflow:global step 6082: loss = 3.2578 (0.906 sec/step)\n","I1215 19:33:45.599066 140303514462080 learning.py:512] global step 6082: loss = 3.2578 (0.906 sec/step)\n","INFO:tensorflow:global step 6083: loss = 4.0754 (0.918 sec/step)\n","I1215 19:33:46.518698 140303514462080 learning.py:512] global step 6083: loss = 4.0754 (0.918 sec/step)\n","INFO:tensorflow:global step 6084: loss = 3.5834 (0.938 sec/step)\n","I1215 19:33:47.459111 140303514462080 learning.py:512] global step 6084: loss = 3.5834 (0.938 sec/step)\n","INFO:tensorflow:global step 6085: loss = 3.4774 (0.933 sec/step)\n","I1215 19:33:48.394489 140303514462080 learning.py:512] global step 6085: loss = 3.4774 (0.933 sec/step)\n","INFO:tensorflow:global step 6086: loss = 4.7245 (0.945 sec/step)\n","I1215 19:33:49.341150 140303514462080 learning.py:512] global step 6086: loss = 4.7245 (0.945 sec/step)\n","INFO:tensorflow:global step 6087: loss = 6.3654 (0.935 sec/step)\n","I1215 19:33:50.277881 140303514462080 learning.py:512] global step 6087: loss = 6.3654 (0.935 sec/step)\n","INFO:tensorflow:global step 6088: loss = 4.1739 (0.928 sec/step)\n","I1215 19:33:51.207628 140303514462080 learning.py:512] global step 6088: loss = 4.1739 (0.928 sec/step)\n","INFO:tensorflow:global step 6089: loss = 5.6018 (0.923 sec/step)\n","I1215 19:33:52.132380 140303514462080 learning.py:512] global step 6089: loss = 5.6018 (0.923 sec/step)\n","INFO:tensorflow:global step 6090: loss = 3.1059 (0.925 sec/step)\n","I1215 19:33:53.058635 140303514462080 learning.py:512] global step 6090: loss = 3.1059 (0.925 sec/step)\n","INFO:tensorflow:global step 6091: loss = 3.8063 (0.923 sec/step)\n","I1215 19:33:53.983399 140303514462080 learning.py:512] global step 6091: loss = 3.8063 (0.923 sec/step)\n","INFO:tensorflow:global step 6092: loss = 4.9891 (0.947 sec/step)\n","I1215 19:33:54.931715 140303514462080 learning.py:512] global step 6092: loss = 4.9891 (0.947 sec/step)\n","INFO:tensorflow:global step 6093: loss = 3.2590 (0.914 sec/step)\n","I1215 19:33:55.846905 140303514462080 learning.py:512] global step 6093: loss = 3.2590 (0.914 sec/step)\n","INFO:tensorflow:global step 6094: loss = 4.6823 (0.913 sec/step)\n","I1215 19:33:56.761613 140303514462080 learning.py:512] global step 6094: loss = 4.6823 (0.913 sec/step)\n","INFO:tensorflow:global step 6095: loss = 4.3958 (0.947 sec/step)\n","I1215 19:33:57.709795 140303514462080 learning.py:512] global step 6095: loss = 4.3958 (0.947 sec/step)\n","INFO:tensorflow:global step 6096: loss = 6.6684 (0.901 sec/step)\n","I1215 19:33:58.612632 140303514462080 learning.py:512] global step 6096: loss = 6.6684 (0.901 sec/step)\n","INFO:tensorflow:global step 6097: loss = 3.6369 (0.913 sec/step)\n","I1215 19:33:59.526591 140303514462080 learning.py:512] global step 6097: loss = 3.6369 (0.913 sec/step)\n","INFO:tensorflow:global step 6098: loss = 4.1610 (0.900 sec/step)\n","I1215 19:34:00.427915 140303514462080 learning.py:512] global step 6098: loss = 4.1610 (0.900 sec/step)\n","INFO:tensorflow:global step 6099: loss = 3.6760 (0.909 sec/step)\n","I1215 19:34:01.338890 140303514462080 learning.py:512] global step 6099: loss = 3.6760 (0.909 sec/step)\n","INFO:tensorflow:global step 6100: loss = 3.6858 (0.882 sec/step)\n","I1215 19:34:02.222942 140303514462080 learning.py:512] global step 6100: loss = 3.6858 (0.882 sec/step)\n","INFO:tensorflow:global step 6101: loss = 5.0121 (0.908 sec/step)\n","I1215 19:34:03.132709 140303514462080 learning.py:512] global step 6101: loss = 5.0121 (0.908 sec/step)\n","INFO:tensorflow:global step 6102: loss = 3.3447 (0.903 sec/step)\n","I1215 19:34:04.037532 140303514462080 learning.py:512] global step 6102: loss = 3.3447 (0.903 sec/step)\n","INFO:tensorflow:global step 6103: loss = 4.1020 (0.914 sec/step)\n","I1215 19:34:04.952760 140303514462080 learning.py:512] global step 6103: loss = 4.1020 (0.914 sec/step)\n","INFO:tensorflow:global step 6104: loss = 5.5917 (0.908 sec/step)\n","I1215 19:34:05.862413 140303514462080 learning.py:512] global step 6104: loss = 5.5917 (0.908 sec/step)\n","INFO:tensorflow:global step 6105: loss = 3.6857 (0.906 sec/step)\n","I1215 19:34:06.769548 140303514462080 learning.py:512] global step 6105: loss = 3.6857 (0.906 sec/step)\n","INFO:tensorflow:global step 6106: loss = 6.8795 (0.909 sec/step)\n","I1215 19:34:07.679796 140303514462080 learning.py:512] global step 6106: loss = 6.8795 (0.909 sec/step)\n","INFO:tensorflow:global step 6107: loss = 4.6045 (0.907 sec/step)\n","I1215 19:34:08.588305 140303514462080 learning.py:512] global step 6107: loss = 4.6045 (0.907 sec/step)\n","INFO:tensorflow:global step 6108: loss = 3.6956 (0.937 sec/step)\n","I1215 19:34:09.526860 140303514462080 learning.py:512] global step 6108: loss = 3.6956 (0.937 sec/step)\n","INFO:tensorflow:global step 6109: loss = 4.2169 (0.916 sec/step)\n","I1215 19:34:10.444744 140303514462080 learning.py:512] global step 6109: loss = 4.2169 (0.916 sec/step)\n","INFO:tensorflow:global step 6110: loss = 4.3987 (0.913 sec/step)\n","I1215 19:34:11.359096 140303514462080 learning.py:512] global step 6110: loss = 4.3987 (0.913 sec/step)\n","INFO:tensorflow:global step 6111: loss = 6.6035 (0.905 sec/step)\n","I1215 19:34:12.266118 140303514462080 learning.py:512] global step 6111: loss = 6.6035 (0.905 sec/step)\n","INFO:tensorflow:global step 6112: loss = 4.5014 (0.913 sec/step)\n","I1215 19:34:13.180963 140303514462080 learning.py:512] global step 6112: loss = 4.5014 (0.913 sec/step)\n","INFO:tensorflow:global step 6113: loss = 5.1407 (0.922 sec/step)\n","I1215 19:34:14.104566 140303514462080 learning.py:512] global step 6113: loss = 5.1407 (0.922 sec/step)\n","INFO:tensorflow:global step 6114: loss = 5.2861 (0.917 sec/step)\n","I1215 19:34:15.022809 140303514462080 learning.py:512] global step 6114: loss = 5.2861 (0.917 sec/step)\n","INFO:tensorflow:global step 6115: loss = 4.0164 (0.907 sec/step)\n","I1215 19:34:15.931291 140303514462080 learning.py:512] global step 6115: loss = 4.0164 (0.907 sec/step)\n","INFO:tensorflow:global step 6116: loss = 4.6022 (0.904 sec/step)\n","I1215 19:34:16.837160 140303514462080 learning.py:512] global step 6116: loss = 4.6022 (0.904 sec/step)\n","INFO:tensorflow:global step 6117: loss = 3.0120 (0.907 sec/step)\n","I1215 19:34:17.746090 140303514462080 learning.py:512] global step 6117: loss = 3.0120 (0.907 sec/step)\n","INFO:tensorflow:global step 6118: loss = 4.9157 (0.903 sec/step)\n","I1215 19:34:18.650315 140303514462080 learning.py:512] global step 6118: loss = 4.9157 (0.903 sec/step)\n","INFO:tensorflow:global step 6119: loss = 3.5277 (0.896 sec/step)\n","I1215 19:34:19.549241 140303514462080 learning.py:512] global step 6119: loss = 3.5277 (0.896 sec/step)\n","INFO:tensorflow:global step 6120: loss = 6.1261 (0.913 sec/step)\n","I1215 19:34:20.465492 140303514462080 learning.py:512] global step 6120: loss = 6.1261 (0.913 sec/step)\n","INFO:tensorflow:global step 6121: loss = 4.3085 (0.904 sec/step)\n","I1215 19:34:21.371261 140303514462080 learning.py:512] global step 6121: loss = 4.3085 (0.904 sec/step)\n","INFO:tensorflow:global step 6122: loss = 6.1301 (0.893 sec/step)\n","I1215 19:34:22.266371 140303514462080 learning.py:512] global step 6122: loss = 6.1301 (0.893 sec/step)\n","INFO:tensorflow:global step 6123: loss = 3.8189 (0.896 sec/step)\n","I1215 19:34:23.163850 140303514462080 learning.py:512] global step 6123: loss = 3.8189 (0.896 sec/step)\n","INFO:tensorflow:global step 6124: loss = 4.6070 (0.915 sec/step)\n","I1215 19:34:24.080143 140303514462080 learning.py:512] global step 6124: loss = 4.6070 (0.915 sec/step)\n","INFO:tensorflow:global step 6125: loss = 4.4396 (0.904 sec/step)\n","I1215 19:34:24.985375 140303514462080 learning.py:512] global step 6125: loss = 4.4396 (0.904 sec/step)\n","INFO:tensorflow:global step 6126: loss = 4.8674 (0.906 sec/step)\n","I1215 19:34:25.892966 140303514462080 learning.py:512] global step 6126: loss = 4.8674 (0.906 sec/step)\n","INFO:tensorflow:global step 6127: loss = 3.5898 (0.900 sec/step)\n","I1215 19:34:26.794559 140303514462080 learning.py:512] global step 6127: loss = 3.5898 (0.900 sec/step)\n","INFO:tensorflow:global step 6128: loss = 4.9741 (0.901 sec/step)\n","I1215 19:34:27.696638 140303514462080 learning.py:512] global step 6128: loss = 4.9741 (0.901 sec/step)\n","INFO:tensorflow:global step 6129: loss = 4.2198 (0.920 sec/step)\n","I1215 19:34:28.618405 140303514462080 learning.py:512] global step 6129: loss = 4.2198 (0.920 sec/step)\n","INFO:tensorflow:global step 6130: loss = 3.4940 (0.900 sec/step)\n","I1215 19:34:29.519747 140303514462080 learning.py:512] global step 6130: loss = 3.4940 (0.900 sec/step)\n","INFO:tensorflow:global step 6131: loss = 3.1139 (0.930 sec/step)\n","I1215 19:34:30.451670 140303514462080 learning.py:512] global step 6131: loss = 3.1139 (0.930 sec/step)\n","INFO:tensorflow:global step 6132: loss = 3.1488 (0.913 sec/step)\n","I1215 19:34:31.365819 140303514462080 learning.py:512] global step 6132: loss = 3.1488 (0.913 sec/step)\n","INFO:tensorflow:global step 6133: loss = 4.2617 (0.883 sec/step)\n","I1215 19:34:32.250824 140303514462080 learning.py:512] global step 6133: loss = 4.2617 (0.883 sec/step)\n","INFO:tensorflow:global step 6134: loss = 3.8173 (0.910 sec/step)\n","I1215 19:34:33.162526 140303514462080 learning.py:512] global step 6134: loss = 3.8173 (0.910 sec/step)\n","INFO:tensorflow:global step 6135: loss = 4.6449 (0.892 sec/step)\n","I1215 19:34:34.055669 140303514462080 learning.py:512] global step 6135: loss = 4.6449 (0.892 sec/step)\n","INFO:tensorflow:global step 6136: loss = 4.4804 (0.899 sec/step)\n","I1215 19:34:34.955705 140303514462080 learning.py:512] global step 6136: loss = 4.4804 (0.899 sec/step)\n","INFO:tensorflow:global step 6137: loss = 3.4304 (0.905 sec/step)\n","I1215 19:34:35.862578 140303514462080 learning.py:512] global step 6137: loss = 3.4304 (0.905 sec/step)\n","INFO:tensorflow:global step 6138: loss = 2.7569 (0.916 sec/step)\n","I1215 19:34:36.780003 140303514462080 learning.py:512] global step 6138: loss = 2.7569 (0.916 sec/step)\n","INFO:tensorflow:global step 6139: loss = 6.8922 (0.911 sec/step)\n","I1215 19:34:37.692842 140303514462080 learning.py:512] global step 6139: loss = 6.8922 (0.911 sec/step)\n","INFO:tensorflow:global step 6140: loss = 5.4383 (0.934 sec/step)\n","I1215 19:34:38.628545 140303514462080 learning.py:512] global step 6140: loss = 5.4383 (0.934 sec/step)\n","INFO:tensorflow:global step 6141: loss = 3.9080 (0.908 sec/step)\n","I1215 19:34:39.538404 140303514462080 learning.py:512] global step 6141: loss = 3.9080 (0.908 sec/step)\n","INFO:tensorflow:global step 6142: loss = 3.6157 (0.900 sec/step)\n","I1215 19:34:40.440297 140303514462080 learning.py:512] global step 6142: loss = 3.6157 (0.900 sec/step)\n","INFO:tensorflow:global step 6143: loss = 3.7534 (0.921 sec/step)\n","I1215 19:34:41.363078 140303514462080 learning.py:512] global step 6143: loss = 3.7534 (0.921 sec/step)\n","INFO:tensorflow:global step 6144: loss = 6.1019 (0.912 sec/step)\n","I1215 19:34:42.276695 140303514462080 learning.py:512] global step 6144: loss = 6.1019 (0.912 sec/step)\n","INFO:tensorflow:global step 6145: loss = 5.0633 (0.910 sec/step)\n","I1215 19:34:43.188463 140303514462080 learning.py:512] global step 6145: loss = 5.0633 (0.910 sec/step)\n","INFO:tensorflow:global step 6146: loss = 4.3195 (0.918 sec/step)\n","I1215 19:34:44.107414 140303514462080 learning.py:512] global step 6146: loss = 4.3195 (0.918 sec/step)\n","INFO:tensorflow:global step 6147: loss = 3.7238 (0.891 sec/step)\n","I1215 19:34:44.999825 140303514462080 learning.py:512] global step 6147: loss = 3.7238 (0.891 sec/step)\n","INFO:tensorflow:global step 6148: loss = 4.2203 (0.913 sec/step)\n","I1215 19:34:45.914582 140303514462080 learning.py:512] global step 6148: loss = 4.2203 (0.913 sec/step)\n","INFO:tensorflow:global step 6149: loss = 3.6582 (0.903 sec/step)\n","I1215 19:34:46.818862 140303514462080 learning.py:512] global step 6149: loss = 3.6582 (0.903 sec/step)\n","INFO:tensorflow:global step 6150: loss = 3.4742 (0.907 sec/step)\n","I1215 19:34:47.727068 140303514462080 learning.py:512] global step 6150: loss = 3.4742 (0.907 sec/step)\n","INFO:tensorflow:global step 6151: loss = 4.2433 (0.883 sec/step)\n","I1215 19:34:48.612049 140303514462080 learning.py:512] global step 6151: loss = 4.2433 (0.883 sec/step)\n","INFO:tensorflow:global step 6152: loss = 4.5338 (0.924 sec/step)\n","I1215 19:34:49.537368 140303514462080 learning.py:512] global step 6152: loss = 4.5338 (0.924 sec/step)\n","INFO:tensorflow:global step 6153: loss = 3.7679 (0.887 sec/step)\n","I1215 19:34:50.425678 140303514462080 learning.py:512] global step 6153: loss = 3.7679 (0.887 sec/step)\n","INFO:tensorflow:global step 6154: loss = 3.9910 (0.907 sec/step)\n","I1215 19:34:51.334290 140303514462080 learning.py:512] global step 6154: loss = 3.9910 (0.907 sec/step)\n","INFO:tensorflow:global step 6155: loss = 4.6360 (0.886 sec/step)\n","I1215 19:34:52.221980 140303514462080 learning.py:512] global step 6155: loss = 4.6360 (0.886 sec/step)\n","INFO:tensorflow:global step 6156: loss = 4.4174 (0.894 sec/step)\n","I1215 19:34:53.117920 140303514462080 learning.py:512] global step 6156: loss = 4.4174 (0.894 sec/step)\n","INFO:tensorflow:global step 6157: loss = 3.9316 (0.905 sec/step)\n","I1215 19:34:54.024823 140303514462080 learning.py:512] global step 6157: loss = 3.9316 (0.905 sec/step)\n","INFO:tensorflow:global step 6158: loss = 3.2698 (0.910 sec/step)\n","I1215 19:34:54.936134 140303514462080 learning.py:512] global step 6158: loss = 3.2698 (0.910 sec/step)\n","INFO:tensorflow:global step 6159: loss = 4.1715 (0.905 sec/step)\n","I1215 19:34:55.842780 140303514462080 learning.py:512] global step 6159: loss = 4.1715 (0.905 sec/step)\n","INFO:tensorflow:global step 6160: loss = 3.4731 (0.899 sec/step)\n","I1215 19:34:56.743389 140303514462080 learning.py:512] global step 6160: loss = 3.4731 (0.899 sec/step)\n","INFO:tensorflow:global step 6161: loss = 8.2133 (0.897 sec/step)\n","I1215 19:34:57.641850 140303514462080 learning.py:512] global step 6161: loss = 8.2133 (0.897 sec/step)\n","INFO:tensorflow:global step 6162: loss = 4.6285 (0.917 sec/step)\n","I1215 19:34:58.560634 140303514462080 learning.py:512] global step 6162: loss = 4.6285 (0.917 sec/step)\n","INFO:tensorflow:global step 6163: loss = 3.5145 (0.922 sec/step)\n","I1215 19:34:59.484604 140303514462080 learning.py:512] global step 6163: loss = 3.5145 (0.922 sec/step)\n","INFO:tensorflow:global step 6164: loss = 3.6265 (0.909 sec/step)\n","I1215 19:35:00.395209 140303514462080 learning.py:512] global step 6164: loss = 3.6265 (0.909 sec/step)\n","INFO:tensorflow:global step 6165: loss = 4.8859 (0.912 sec/step)\n","I1215 19:35:01.308641 140303514462080 learning.py:512] global step 6165: loss = 4.8859 (0.912 sec/step)\n","INFO:tensorflow:global step 6166: loss = 3.8221 (0.909 sec/step)\n","I1215 19:35:02.218884 140303514462080 learning.py:512] global step 6166: loss = 3.8221 (0.909 sec/step)\n","INFO:tensorflow:global step 6167: loss = 5.3731 (0.907 sec/step)\n","I1215 19:35:03.127705 140303514462080 learning.py:512] global step 6167: loss = 5.3731 (0.907 sec/step)\n","INFO:tensorflow:global step 6168: loss = 4.5377 (0.908 sec/step)\n","I1215 19:35:04.036832 140303514462080 learning.py:512] global step 6168: loss = 4.5377 (0.908 sec/step)\n","INFO:tensorflow:global step 6169: loss = 2.9673 (0.894 sec/step)\n","I1215 19:35:04.932267 140303514462080 learning.py:512] global step 6169: loss = 2.9673 (0.894 sec/step)\n","INFO:tensorflow:global step 6170: loss = 4.1967 (0.893 sec/step)\n","I1215 19:35:05.826590 140303514462080 learning.py:512] global step 6170: loss = 4.1967 (0.893 sec/step)\n","INFO:tensorflow:global step 6171: loss = 4.5077 (0.905 sec/step)\n","I1215 19:35:06.733073 140303514462080 learning.py:512] global step 6171: loss = 4.5077 (0.905 sec/step)\n","INFO:tensorflow:global step 6172: loss = 5.0564 (0.894 sec/step)\n","I1215 19:35:07.629052 140303514462080 learning.py:512] global step 6172: loss = 5.0564 (0.894 sec/step)\n","INFO:tensorflow:global step 6173: loss = 6.4067 (0.905 sec/step)\n","I1215 19:35:08.535880 140303514462080 learning.py:512] global step 6173: loss = 6.4067 (0.905 sec/step)\n","INFO:tensorflow:global step 6174: loss = 3.2768 (0.903 sec/step)\n","I1215 19:35:09.440444 140303514462080 learning.py:512] global step 6174: loss = 3.2768 (0.903 sec/step)\n","INFO:tensorflow:global step 6175: loss = 3.8332 (0.909 sec/step)\n","I1215 19:35:10.350595 140303514462080 learning.py:512] global step 6175: loss = 3.8332 (0.909 sec/step)\n","INFO:tensorflow:global step 6176: loss = 3.2400 (0.909 sec/step)\n","I1215 19:35:11.260790 140303514462080 learning.py:512] global step 6176: loss = 3.2400 (0.909 sec/step)\n","INFO:tensorflow:global step 6177: loss = 3.0381 (0.923 sec/step)\n","I1215 19:35:12.185534 140303514462080 learning.py:512] global step 6177: loss = 3.0381 (0.923 sec/step)\n","INFO:tensorflow:global step 6178: loss = 4.5294 (0.902 sec/step)\n","I1215 19:35:13.088711 140303514462080 learning.py:512] global step 6178: loss = 4.5294 (0.902 sec/step)\n","INFO:tensorflow:global step 6179: loss = 3.2551 (0.904 sec/step)\n","I1215 19:35:13.994538 140303514462080 learning.py:512] global step 6179: loss = 3.2551 (0.904 sec/step)\n","INFO:tensorflow:global step 6180: loss = 4.8686 (0.908 sec/step)\n","I1215 19:35:14.904270 140303514462080 learning.py:512] global step 6180: loss = 4.8686 (0.908 sec/step)\n","INFO:tensorflow:global step 6181: loss = 4.0139 (0.914 sec/step)\n","I1215 19:35:15.819713 140303514462080 learning.py:512] global step 6181: loss = 4.0139 (0.914 sec/step)\n","INFO:tensorflow:global step 6182: loss = 3.0581 (0.912 sec/step)\n","I1215 19:35:16.733471 140303514462080 learning.py:512] global step 6182: loss = 3.0581 (0.912 sec/step)\n","INFO:tensorflow:global step 6183: loss = 3.9455 (0.893 sec/step)\n","I1215 19:35:17.627813 140303514462080 learning.py:512] global step 6183: loss = 3.9455 (0.893 sec/step)\n","INFO:tensorflow:global step 6184: loss = 4.9860 (0.891 sec/step)\n","I1215 19:35:18.520453 140303514462080 learning.py:512] global step 6184: loss = 4.9860 (0.891 sec/step)\n","INFO:tensorflow:global step 6185: loss = 4.5690 (0.896 sec/step)\n","I1215 19:35:19.418347 140303514462080 learning.py:512] global step 6185: loss = 4.5690 (0.896 sec/step)\n","INFO:tensorflow:global step 6186: loss = 5.2982 (0.895 sec/step)\n","I1215 19:35:20.314717 140303514462080 learning.py:512] global step 6186: loss = 5.2982 (0.895 sec/step)\n","INFO:tensorflow:global step 6187: loss = 5.2741 (0.884 sec/step)\n","I1215 19:35:21.200324 140303514462080 learning.py:512] global step 6187: loss = 5.2741 (0.884 sec/step)\n","INFO:tensorflow:global step 6188: loss = 5.7904 (0.905 sec/step)\n","I1215 19:35:22.106477 140303514462080 learning.py:512] global step 6188: loss = 5.7904 (0.905 sec/step)\n","INFO:tensorflow:global step 6189: loss = 2.3759 (0.926 sec/step)\n","I1215 19:35:23.033685 140303514462080 learning.py:512] global step 6189: loss = 2.3759 (0.926 sec/step)\n","INFO:tensorflow:global step 6190: loss = 4.6366 (0.899 sec/step)\n","I1215 19:35:23.933929 140303514462080 learning.py:512] global step 6190: loss = 4.6366 (0.899 sec/step)\n","INFO:tensorflow:global step 6191: loss = 5.2279 (0.899 sec/step)\n","I1215 19:35:24.833906 140303514462080 learning.py:512] global step 6191: loss = 5.2279 (0.899 sec/step)\n","INFO:tensorflow:global step 6192: loss = 3.5672 (0.910 sec/step)\n","I1215 19:35:25.745385 140303514462080 learning.py:512] global step 6192: loss = 3.5672 (0.910 sec/step)\n","INFO:tensorflow:global step 6193: loss = 3.5370 (0.883 sec/step)\n","I1215 19:35:26.630279 140303514462080 learning.py:512] global step 6193: loss = 3.5370 (0.883 sec/step)\n","INFO:tensorflow:global step 6194: loss = 5.3935 (0.910 sec/step)\n","I1215 19:35:27.542041 140303514462080 learning.py:512] global step 6194: loss = 5.3935 (0.910 sec/step)\n","INFO:tensorflow:global step 6195: loss = 3.5059 (0.903 sec/step)\n","I1215 19:35:28.446797 140303514462080 learning.py:512] global step 6195: loss = 3.5059 (0.903 sec/step)\n","INFO:tensorflow:global step 6196: loss = 4.5826 (0.902 sec/step)\n","I1215 19:35:29.350798 140303514462080 learning.py:512] global step 6196: loss = 4.5826 (0.902 sec/step)\n","INFO:tensorflow:global step 6197: loss = 4.1912 (0.904 sec/step)\n","I1215 19:35:30.256609 140303514462080 learning.py:512] global step 6197: loss = 4.1912 (0.904 sec/step)\n","INFO:tensorflow:global step 6198: loss = 4.7194 (0.888 sec/step)\n","I1215 19:35:31.146261 140303514462080 learning.py:512] global step 6198: loss = 4.7194 (0.888 sec/step)\n","INFO:tensorflow:global step 6199: loss = 3.3164 (0.920 sec/step)\n","I1215 19:35:32.068059 140303514462080 learning.py:512] global step 6199: loss = 3.3164 (0.920 sec/step)\n","INFO:tensorflow:global step 6200: loss = 4.2050 (0.921 sec/step)\n","I1215 19:35:32.990719 140303514462080 learning.py:512] global step 6200: loss = 4.2050 (0.921 sec/step)\n","INFO:tensorflow:global step 6201: loss = 4.2931 (0.944 sec/step)\n","I1215 19:35:33.937063 140303514462080 learning.py:512] global step 6201: loss = 4.2931 (0.944 sec/step)\n","INFO:tensorflow:global step 6202: loss = 6.3991 (0.901 sec/step)\n","I1215 19:35:34.839600 140303514462080 learning.py:512] global step 6202: loss = 6.3991 (0.901 sec/step)\n","INFO:tensorflow:global step 6203: loss = 3.6420 (0.914 sec/step)\n","I1215 19:35:35.761188 140303514462080 learning.py:512] global step 6203: loss = 3.6420 (0.914 sec/step)\n","INFO:tensorflow:Recording summary at step 6203.\n","I1215 19:35:37.048121 140299899541248 supervisor.py:1050] Recording summary at step 6203.\n","INFO:tensorflow:global step 6204: loss = 5.7109 (1.451 sec/step)\n","I1215 19:35:37.213569 140303514462080 learning.py:512] global step 6204: loss = 5.7109 (1.451 sec/step)\n","INFO:tensorflow:global step 6205: loss = 3.5958 (0.893 sec/step)\n","I1215 19:35:38.107747 140303514462080 learning.py:512] global step 6205: loss = 3.5958 (0.893 sec/step)\n","INFO:tensorflow:global step 6206: loss = 4.8465 (0.908 sec/step)\n","I1215 19:35:39.017569 140303514462080 learning.py:512] global step 6206: loss = 4.8465 (0.908 sec/step)\n","INFO:tensorflow:global step 6207: loss = 3.8708 (0.890 sec/step)\n","I1215 19:35:39.909152 140303514462080 learning.py:512] global step 6207: loss = 3.8708 (0.890 sec/step)\n","INFO:tensorflow:global step 6208: loss = 4.2416 (0.888 sec/step)\n","I1215 19:35:40.798061 140303514462080 learning.py:512] global step 6208: loss = 4.2416 (0.888 sec/step)\n","INFO:tensorflow:global step 6209: loss = 4.2275 (0.884 sec/step)\n","I1215 19:35:41.683863 140303514462080 learning.py:512] global step 6209: loss = 4.2275 (0.884 sec/step)\n","INFO:tensorflow:global step 6210: loss = 4.4783 (0.892 sec/step)\n","I1215 19:35:42.577249 140303514462080 learning.py:512] global step 6210: loss = 4.4783 (0.892 sec/step)\n","INFO:tensorflow:global step 6211: loss = 5.4052 (0.915 sec/step)\n","I1215 19:35:43.493830 140303514462080 learning.py:512] global step 6211: loss = 5.4052 (0.915 sec/step)\n","INFO:tensorflow:global step 6212: loss = 4.0724 (0.890 sec/step)\n","I1215 19:35:44.385291 140303514462080 learning.py:512] global step 6212: loss = 4.0724 (0.890 sec/step)\n","INFO:tensorflow:global step 6213: loss = 4.4080 (0.901 sec/step)\n","I1215 19:35:45.288174 140303514462080 learning.py:512] global step 6213: loss = 4.4080 (0.901 sec/step)\n","INFO:tensorflow:global step 6214: loss = 3.2545 (0.898 sec/step)\n","I1215 19:35:46.187549 140303514462080 learning.py:512] global step 6214: loss = 3.2545 (0.898 sec/step)\n","INFO:tensorflow:global step 6215: loss = 3.3536 (0.896 sec/step)\n","I1215 19:35:47.085122 140303514462080 learning.py:512] global step 6215: loss = 3.3536 (0.896 sec/step)\n","INFO:tensorflow:global step 6216: loss = 3.3737 (0.899 sec/step)\n","I1215 19:35:47.985275 140303514462080 learning.py:512] global step 6216: loss = 3.3737 (0.899 sec/step)\n","INFO:tensorflow:global step 6217: loss = 4.0231 (0.910 sec/step)\n","I1215 19:35:48.897152 140303514462080 learning.py:512] global step 6217: loss = 4.0231 (0.910 sec/step)\n","INFO:tensorflow:global step 6218: loss = 5.9412 (0.908 sec/step)\n","I1215 19:35:49.806780 140303514462080 learning.py:512] global step 6218: loss = 5.9412 (0.908 sec/step)\n","INFO:tensorflow:global step 6219: loss = 5.1951 (0.903 sec/step)\n","I1215 19:35:50.710611 140303514462080 learning.py:512] global step 6219: loss = 5.1951 (0.903 sec/step)\n","INFO:tensorflow:global step 6220: loss = 4.1331 (0.891 sec/step)\n","I1215 19:35:51.603439 140303514462080 learning.py:512] global step 6220: loss = 4.1331 (0.891 sec/step)\n","INFO:tensorflow:global step 6221: loss = 5.4378 (0.894 sec/step)\n","I1215 19:35:52.499301 140303514462080 learning.py:512] global step 6221: loss = 5.4378 (0.894 sec/step)\n","INFO:tensorflow:global step 6222: loss = 4.2295 (0.902 sec/step)\n","I1215 19:35:53.402487 140303514462080 learning.py:512] global step 6222: loss = 4.2295 (0.902 sec/step)\n","INFO:tensorflow:global step 6223: loss = 4.9083 (0.942 sec/step)\n","I1215 19:35:54.346133 140303514462080 learning.py:512] global step 6223: loss = 4.9083 (0.942 sec/step)\n","INFO:tensorflow:global step 6224: loss = 5.6919 (0.910 sec/step)\n","I1215 19:35:55.257545 140303514462080 learning.py:512] global step 6224: loss = 5.6919 (0.910 sec/step)\n","INFO:tensorflow:global step 6225: loss = 4.8399 (0.884 sec/step)\n","I1215 19:35:56.143438 140303514462080 learning.py:512] global step 6225: loss = 4.8399 (0.884 sec/step)\n","INFO:tensorflow:global step 6226: loss = 5.4078 (0.900 sec/step)\n","I1215 19:35:57.045423 140303514462080 learning.py:512] global step 6226: loss = 5.4078 (0.900 sec/step)\n","INFO:tensorflow:global step 6227: loss = 3.2621 (0.890 sec/step)\n","I1215 19:35:57.937220 140303514462080 learning.py:512] global step 6227: loss = 3.2621 (0.890 sec/step)\n","INFO:tensorflow:global step 6228: loss = 4.5083 (0.915 sec/step)\n","I1215 19:35:58.853522 140303514462080 learning.py:512] global step 6228: loss = 4.5083 (0.915 sec/step)\n","INFO:tensorflow:global step 6229: loss = 4.2761 (0.896 sec/step)\n","I1215 19:35:59.750674 140303514462080 learning.py:512] global step 6229: loss = 4.2761 (0.896 sec/step)\n","INFO:tensorflow:global step 6230: loss = 3.6040 (0.896 sec/step)\n","I1215 19:36:00.648498 140303514462080 learning.py:512] global step 6230: loss = 3.6040 (0.896 sec/step)\n","INFO:tensorflow:global step 6231: loss = 4.8318 (0.897 sec/step)\n","I1215 19:36:01.546425 140303514462080 learning.py:512] global step 6231: loss = 4.8318 (0.897 sec/step)\n","INFO:tensorflow:global step 6232: loss = 4.4614 (0.905 sec/step)\n","I1215 19:36:02.452470 140303514462080 learning.py:512] global step 6232: loss = 4.4614 (0.905 sec/step)\n","INFO:tensorflow:global step 6233: loss = 4.8637 (0.915 sec/step)\n","I1215 19:36:03.368744 140303514462080 learning.py:512] global step 6233: loss = 4.8637 (0.915 sec/step)\n","INFO:tensorflow:global step 6234: loss = 4.4909 (0.891 sec/step)\n","I1215 19:36:04.260742 140303514462080 learning.py:512] global step 6234: loss = 4.4909 (0.891 sec/step)\n","INFO:tensorflow:global step 6235: loss = 4.2672 (0.896 sec/step)\n","I1215 19:36:05.157964 140303514462080 learning.py:512] global step 6235: loss = 4.2672 (0.896 sec/step)\n","INFO:tensorflow:global step 6236: loss = 3.7071 (0.908 sec/step)\n","I1215 19:36:06.067038 140303514462080 learning.py:512] global step 6236: loss = 3.7071 (0.908 sec/step)\n","INFO:tensorflow:global step 6237: loss = 5.7285 (0.895 sec/step)\n","I1215 19:36:06.963046 140303514462080 learning.py:512] global step 6237: loss = 5.7285 (0.895 sec/step)\n","INFO:tensorflow:global step 6238: loss = 3.7246 (0.875 sec/step)\n","I1215 19:36:07.839348 140303514462080 learning.py:512] global step 6238: loss = 3.7246 (0.875 sec/step)\n","INFO:tensorflow:global step 6239: loss = 4.8277 (0.899 sec/step)\n","I1215 19:36:08.739897 140303514462080 learning.py:512] global step 6239: loss = 4.8277 (0.899 sec/step)\n","INFO:tensorflow:global step 6240: loss = 3.5982 (0.902 sec/step)\n","I1215 19:36:09.643227 140303514462080 learning.py:512] global step 6240: loss = 3.5982 (0.902 sec/step)\n","INFO:tensorflow:global step 6241: loss = 2.7105 (0.907 sec/step)\n","I1215 19:36:10.551890 140303514462080 learning.py:512] global step 6241: loss = 2.7105 (0.907 sec/step)\n","INFO:tensorflow:global step 6242: loss = 6.0174 (0.900 sec/step)\n","I1215 19:36:11.453540 140303514462080 learning.py:512] global step 6242: loss = 6.0174 (0.900 sec/step)\n","INFO:tensorflow:global step 6243: loss = 3.7957 (0.914 sec/step)\n","I1215 19:36:12.369570 140303514462080 learning.py:512] global step 6243: loss = 3.7957 (0.914 sec/step)\n","INFO:tensorflow:global step 6244: loss = 4.0066 (0.883 sec/step)\n","I1215 19:36:13.253829 140303514462080 learning.py:512] global step 6244: loss = 4.0066 (0.883 sec/step)\n","INFO:tensorflow:global step 6245: loss = 4.4531 (0.903 sec/step)\n","I1215 19:36:14.159096 140303514462080 learning.py:512] global step 6245: loss = 4.4531 (0.903 sec/step)\n","INFO:tensorflow:global step 6246: loss = 3.8697 (0.920 sec/step)\n","I1215 19:36:15.080360 140303514462080 learning.py:512] global step 6246: loss = 3.8697 (0.920 sec/step)\n","INFO:tensorflow:global step 6247: loss = 3.8146 (0.916 sec/step)\n","I1215 19:36:15.997762 140303514462080 learning.py:512] global step 6247: loss = 3.8146 (0.916 sec/step)\n","INFO:tensorflow:global step 6248: loss = 5.6257 (0.897 sec/step)\n","I1215 19:36:16.896428 140303514462080 learning.py:512] global step 6248: loss = 5.6257 (0.897 sec/step)\n","INFO:tensorflow:global step 6249: loss = 3.3685 (0.898 sec/step)\n","I1215 19:36:17.795630 140303514462080 learning.py:512] global step 6249: loss = 3.3685 (0.898 sec/step)\n","INFO:tensorflow:global step 6250: loss = 5.2693 (0.904 sec/step)\n","I1215 19:36:18.700881 140303514462080 learning.py:512] global step 6250: loss = 5.2693 (0.904 sec/step)\n","INFO:tensorflow:global step 6251: loss = 5.0861 (0.889 sec/step)\n","I1215 19:36:19.591737 140303514462080 learning.py:512] global step 6251: loss = 5.0861 (0.889 sec/step)\n","INFO:tensorflow:global step 6252: loss = 3.5025 (0.904 sec/step)\n","I1215 19:36:20.497268 140303514462080 learning.py:512] global step 6252: loss = 3.5025 (0.904 sec/step)\n","INFO:tensorflow:global step 6253: loss = 3.7521 (0.901 sec/step)\n","I1215 19:36:21.399217 140303514462080 learning.py:512] global step 6253: loss = 3.7521 (0.901 sec/step)\n","INFO:tensorflow:global step 6254: loss = 4.3431 (0.899 sec/step)\n","I1215 19:36:22.299727 140303514462080 learning.py:512] global step 6254: loss = 4.3431 (0.899 sec/step)\n","INFO:tensorflow:global step 6255: loss = 3.9365 (0.897 sec/step)\n","I1215 19:36:23.198001 140303514462080 learning.py:512] global step 6255: loss = 3.9365 (0.897 sec/step)\n","INFO:tensorflow:global step 6256: loss = 3.3602 (0.915 sec/step)\n","I1215 19:36:24.114443 140303514462080 learning.py:512] global step 6256: loss = 3.3602 (0.915 sec/step)\n","INFO:tensorflow:global step 6257: loss = 4.1253 (0.910 sec/step)\n","I1215 19:36:25.026228 140303514462080 learning.py:512] global step 6257: loss = 4.1253 (0.910 sec/step)\n","INFO:tensorflow:global step 6258: loss = 4.3358 (0.922 sec/step)\n","I1215 19:36:25.949335 140303514462080 learning.py:512] global step 6258: loss = 4.3358 (0.922 sec/step)\n","INFO:tensorflow:global step 6259: loss = 3.4472 (0.917 sec/step)\n","I1215 19:36:26.868129 140303514462080 learning.py:512] global step 6259: loss = 3.4472 (0.917 sec/step)\n","INFO:tensorflow:global step 6260: loss = 4.1596 (0.895 sec/step)\n","I1215 19:36:27.764765 140303514462080 learning.py:512] global step 6260: loss = 4.1596 (0.895 sec/step)\n","INFO:tensorflow:global step 6261: loss = 4.5938 (0.919 sec/step)\n","I1215 19:36:28.685280 140303514462080 learning.py:512] global step 6261: loss = 4.5938 (0.919 sec/step)\n","INFO:tensorflow:global step 6262: loss = 3.9602 (0.902 sec/step)\n","I1215 19:36:29.589202 140303514462080 learning.py:512] global step 6262: loss = 3.9602 (0.902 sec/step)\n","INFO:tensorflow:global step 6263: loss = 2.7940 (0.904 sec/step)\n","I1215 19:36:30.494230 140303514462080 learning.py:512] global step 6263: loss = 2.7940 (0.904 sec/step)\n","INFO:tensorflow:global step 6264: loss = 3.9691 (0.887 sec/step)\n","I1215 19:36:31.383036 140303514462080 learning.py:512] global step 6264: loss = 3.9691 (0.887 sec/step)\n","INFO:tensorflow:global step 6265: loss = 4.6557 (0.920 sec/step)\n","I1215 19:36:32.304883 140303514462080 learning.py:512] global step 6265: loss = 4.6557 (0.920 sec/step)\n","INFO:tensorflow:global step 6266: loss = 6.1804 (0.893 sec/step)\n","I1215 19:36:33.199408 140303514462080 learning.py:512] global step 6266: loss = 6.1804 (0.893 sec/step)\n","INFO:tensorflow:global step 6267: loss = 3.7995 (0.898 sec/step)\n","I1215 19:36:34.099395 140303514462080 learning.py:512] global step 6267: loss = 3.7995 (0.898 sec/step)\n","INFO:tensorflow:global step 6268: loss = 3.5257 (0.894 sec/step)\n","I1215 19:36:34.994558 140303514462080 learning.py:512] global step 6268: loss = 3.5257 (0.894 sec/step)\n","INFO:tensorflow:global step 6269: loss = 4.0225 (0.944 sec/step)\n","I1215 19:36:35.939681 140303514462080 learning.py:512] global step 6269: loss = 4.0225 (0.944 sec/step)\n","INFO:tensorflow:global step 6270: loss = 3.8316 (0.919 sec/step)\n","I1215 19:36:36.859734 140303514462080 learning.py:512] global step 6270: loss = 3.8316 (0.919 sec/step)\n","INFO:tensorflow:global step 6271: loss = 3.6464 (0.887 sec/step)\n","I1215 19:36:37.748563 140303514462080 learning.py:512] global step 6271: loss = 3.6464 (0.887 sec/step)\n","INFO:tensorflow:global step 6272: loss = 2.7548 (0.891 sec/step)\n","I1215 19:36:38.641148 140303514462080 learning.py:512] global step 6272: loss = 2.7548 (0.891 sec/step)\n","INFO:tensorflow:global step 6273: loss = 6.1446 (0.911 sec/step)\n","I1215 19:36:39.553992 140303514462080 learning.py:512] global step 6273: loss = 6.1446 (0.911 sec/step)\n","INFO:tensorflow:global step 6274: loss = 3.3377 (0.917 sec/step)\n","I1215 19:36:40.472213 140303514462080 learning.py:512] global step 6274: loss = 3.3377 (0.917 sec/step)\n","INFO:tensorflow:global step 6275: loss = 4.5966 (0.893 sec/step)\n","I1215 19:36:41.367112 140303514462080 learning.py:512] global step 6275: loss = 4.5966 (0.893 sec/step)\n","INFO:tensorflow:global step 6276: loss = 3.5537 (0.908 sec/step)\n","I1215 19:36:42.276378 140303514462080 learning.py:512] global step 6276: loss = 3.5537 (0.908 sec/step)\n","INFO:tensorflow:global step 6277: loss = 6.9758 (0.934 sec/step)\n","I1215 19:36:43.211960 140303514462080 learning.py:512] global step 6277: loss = 6.9758 (0.934 sec/step)\n","INFO:tensorflow:global step 6278: loss = 5.3889 (0.907 sec/step)\n","I1215 19:36:44.120847 140303514462080 learning.py:512] global step 6278: loss = 5.3889 (0.907 sec/step)\n","INFO:tensorflow:global step 6279: loss = 4.6520 (0.912 sec/step)\n","I1215 19:36:45.034451 140303514462080 learning.py:512] global step 6279: loss = 4.6520 (0.912 sec/step)\n","INFO:tensorflow:global step 6280: loss = 4.1050 (0.906 sec/step)\n","I1215 19:36:45.941860 140303514462080 learning.py:512] global step 6280: loss = 4.1050 (0.906 sec/step)\n","INFO:tensorflow:global step 6281: loss = 6.1530 (0.919 sec/step)\n","I1215 19:36:46.862060 140303514462080 learning.py:512] global step 6281: loss = 6.1530 (0.919 sec/step)\n","INFO:tensorflow:global step 6282: loss = 2.7303 (0.910 sec/step)\n","I1215 19:36:47.773349 140303514462080 learning.py:512] global step 6282: loss = 2.7303 (0.910 sec/step)\n","INFO:tensorflow:global step 6283: loss = 2.6714 (0.901 sec/step)\n","I1215 19:36:48.676039 140303514462080 learning.py:512] global step 6283: loss = 2.6714 (0.901 sec/step)\n","INFO:tensorflow:global step 6284: loss = 4.7200 (0.902 sec/step)\n","I1215 19:36:49.579447 140303514462080 learning.py:512] global step 6284: loss = 4.7200 (0.902 sec/step)\n","INFO:tensorflow:global step 6285: loss = 4.1548 (0.910 sec/step)\n","I1215 19:36:50.491215 140303514462080 learning.py:512] global step 6285: loss = 4.1548 (0.910 sec/step)\n","INFO:tensorflow:global step 6286: loss = 6.1314 (0.905 sec/step)\n","I1215 19:36:51.397377 140303514462080 learning.py:512] global step 6286: loss = 6.1314 (0.905 sec/step)\n","INFO:tensorflow:global step 6287: loss = 5.0544 (0.896 sec/step)\n","I1215 19:36:52.294903 140303514462080 learning.py:512] global step 6287: loss = 5.0544 (0.896 sec/step)\n","INFO:tensorflow:global step 6288: loss = 4.8437 (0.925 sec/step)\n","I1215 19:36:53.221360 140303514462080 learning.py:512] global step 6288: loss = 4.8437 (0.925 sec/step)\n","INFO:tensorflow:global step 6289: loss = 4.2662 (0.892 sec/step)\n","I1215 19:36:54.115085 140303514462080 learning.py:512] global step 6289: loss = 4.2662 (0.892 sec/step)\n","INFO:tensorflow:global step 6290: loss = 4.0082 (0.896 sec/step)\n","I1215 19:36:55.012326 140303514462080 learning.py:512] global step 6290: loss = 4.0082 (0.896 sec/step)\n","INFO:tensorflow:global step 6291: loss = 2.5340 (0.893 sec/step)\n","I1215 19:36:55.907021 140303514462080 learning.py:512] global step 6291: loss = 2.5340 (0.893 sec/step)\n","INFO:tensorflow:global step 6292: loss = 5.7185 (0.930 sec/step)\n","I1215 19:36:56.838942 140303514462080 learning.py:512] global step 6292: loss = 5.7185 (0.930 sec/step)\n","INFO:tensorflow:global step 6293: loss = 3.3756 (0.904 sec/step)\n","I1215 19:36:57.744579 140303514462080 learning.py:512] global step 6293: loss = 3.3756 (0.904 sec/step)\n","INFO:tensorflow:global step 6294: loss = 3.6343 (0.894 sec/step)\n","I1215 19:36:58.639932 140303514462080 learning.py:512] global step 6294: loss = 3.6343 (0.894 sec/step)\n","INFO:tensorflow:global step 6295: loss = 6.5165 (0.907 sec/step)\n","I1215 19:36:59.548721 140303514462080 learning.py:512] global step 6295: loss = 6.5165 (0.907 sec/step)\n","INFO:tensorflow:global step 6296: loss = 3.1809 (0.919 sec/step)\n","I1215 19:37:00.469608 140303514462080 learning.py:512] global step 6296: loss = 3.1809 (0.919 sec/step)\n","INFO:tensorflow:global step 6297: loss = 4.0888 (0.906 sec/step)\n","I1215 19:37:01.377402 140303514462080 learning.py:512] global step 6297: loss = 4.0888 (0.906 sec/step)\n","INFO:tensorflow:global step 6298: loss = 3.2285 (0.896 sec/step)\n","I1215 19:37:02.274798 140303514462080 learning.py:512] global step 6298: loss = 3.2285 (0.896 sec/step)\n","INFO:tensorflow:global step 6299: loss = 6.7476 (0.890 sec/step)\n","I1215 19:37:03.165995 140303514462080 learning.py:512] global step 6299: loss = 6.7476 (0.890 sec/step)\n","INFO:tensorflow:global step 6300: loss = 3.8678 (0.894 sec/step)\n","I1215 19:37:04.061766 140303514462080 learning.py:512] global step 6300: loss = 3.8678 (0.894 sec/step)\n","INFO:tensorflow:global step 6301: loss = 3.4509 (0.896 sec/step)\n","I1215 19:37:04.958713 140303514462080 learning.py:512] global step 6301: loss = 3.4509 (0.896 sec/step)\n","INFO:tensorflow:global step 6302: loss = 4.0368 (0.892 sec/step)\n","I1215 19:37:05.852233 140303514462080 learning.py:512] global step 6302: loss = 4.0368 (0.892 sec/step)\n","INFO:tensorflow:global step 6303: loss = 5.1233 (0.892 sec/step)\n","I1215 19:37:06.746099 140303514462080 learning.py:512] global step 6303: loss = 5.1233 (0.892 sec/step)\n","INFO:tensorflow:global step 6304: loss = 5.1117 (0.903 sec/step)\n","I1215 19:37:07.651548 140303514462080 learning.py:512] global step 6304: loss = 5.1117 (0.903 sec/step)\n","INFO:tensorflow:global step 6305: loss = 5.1600 (0.891 sec/step)\n","I1215 19:37:08.544490 140303514462080 learning.py:512] global step 6305: loss = 5.1600 (0.891 sec/step)\n","INFO:tensorflow:global step 6306: loss = 5.9101 (0.912 sec/step)\n","I1215 19:37:09.458346 140303514462080 learning.py:512] global step 6306: loss = 5.9101 (0.912 sec/step)\n","INFO:tensorflow:global step 6307: loss = 4.6834 (0.889 sec/step)\n","I1215 19:37:10.349153 140303514462080 learning.py:512] global step 6307: loss = 4.6834 (0.889 sec/step)\n","INFO:tensorflow:global step 6308: loss = 4.1885 (0.894 sec/step)\n","I1215 19:37:11.244293 140303514462080 learning.py:512] global step 6308: loss = 4.1885 (0.894 sec/step)\n","INFO:tensorflow:global step 6309: loss = 3.2233 (0.907 sec/step)\n","I1215 19:37:12.152862 140303514462080 learning.py:512] global step 6309: loss = 3.2233 (0.907 sec/step)\n","INFO:tensorflow:global step 6310: loss = 4.5891 (0.883 sec/step)\n","I1215 19:37:13.036990 140303514462080 learning.py:512] global step 6310: loss = 4.5891 (0.883 sec/step)\n","INFO:tensorflow:global step 6311: loss = 4.7376 (0.895 sec/step)\n","I1215 19:37:13.933623 140303514462080 learning.py:512] global step 6311: loss = 4.7376 (0.895 sec/step)\n","INFO:tensorflow:global step 6312: loss = 4.7373 (0.889 sec/step)\n","I1215 19:37:14.824329 140303514462080 learning.py:512] global step 6312: loss = 4.7373 (0.889 sec/step)\n","INFO:tensorflow:global step 6313: loss = 3.2181 (0.886 sec/step)\n","I1215 19:37:15.711619 140303514462080 learning.py:512] global step 6313: loss = 3.2181 (0.886 sec/step)\n","INFO:tensorflow:global step 6314: loss = 3.3762 (0.912 sec/step)\n","I1215 19:37:16.625451 140303514462080 learning.py:512] global step 6314: loss = 3.3762 (0.912 sec/step)\n","INFO:tensorflow:global step 6315: loss = 4.8371 (0.899 sec/step)\n","I1215 19:37:17.525893 140303514462080 learning.py:512] global step 6315: loss = 4.8371 (0.899 sec/step)\n","INFO:tensorflow:global step 6316: loss = 4.8445 (0.922 sec/step)\n","I1215 19:37:18.450540 140303514462080 learning.py:512] global step 6316: loss = 4.8445 (0.922 sec/step)\n","INFO:tensorflow:global step 6317: loss = 5.1478 (0.893 sec/step)\n","I1215 19:37:19.344621 140303514462080 learning.py:512] global step 6317: loss = 5.1478 (0.893 sec/step)\n","INFO:tensorflow:global step 6318: loss = 6.1174 (0.899 sec/step)\n","I1215 19:37:20.244881 140303514462080 learning.py:512] global step 6318: loss = 6.1174 (0.899 sec/step)\n","INFO:tensorflow:global step 6319: loss = 5.2996 (0.903 sec/step)\n","I1215 19:37:21.149224 140303514462080 learning.py:512] global step 6319: loss = 5.2996 (0.903 sec/step)\n","INFO:tensorflow:global step 6320: loss = 5.4261 (0.912 sec/step)\n","I1215 19:37:22.062386 140303514462080 learning.py:512] global step 6320: loss = 5.4261 (0.912 sec/step)\n","INFO:tensorflow:global step 6321: loss = 4.1542 (0.912 sec/step)\n","I1215 19:37:22.976141 140303514462080 learning.py:512] global step 6321: loss = 4.1542 (0.912 sec/step)\n","INFO:tensorflow:global step 6322: loss = 3.2099 (0.895 sec/step)\n","I1215 19:37:23.873061 140303514462080 learning.py:512] global step 6322: loss = 3.2099 (0.895 sec/step)\n","INFO:tensorflow:global step 6323: loss = 3.7101 (0.885 sec/step)\n","I1215 19:37:24.759392 140303514462080 learning.py:512] global step 6323: loss = 3.7101 (0.885 sec/step)\n","INFO:tensorflow:global step 6324: loss = 6.0075 (0.906 sec/step)\n","I1215 19:37:25.666424 140303514462080 learning.py:512] global step 6324: loss = 6.0075 (0.906 sec/step)\n","INFO:tensorflow:global step 6325: loss = 3.6545 (0.889 sec/step)\n","I1215 19:37:26.557419 140303514462080 learning.py:512] global step 6325: loss = 3.6545 (0.889 sec/step)\n","INFO:tensorflow:global step 6326: loss = 4.5241 (0.882 sec/step)\n","I1215 19:37:27.441218 140303514462080 learning.py:512] global step 6326: loss = 4.5241 (0.882 sec/step)\n","INFO:tensorflow:global step 6327: loss = 3.7148 (0.889 sec/step)\n","I1215 19:37:28.331278 140303514462080 learning.py:512] global step 6327: loss = 3.7148 (0.889 sec/step)\n","INFO:tensorflow:global step 6328: loss = 4.0450 (0.917 sec/step)\n","I1215 19:37:29.249402 140303514462080 learning.py:512] global step 6328: loss = 4.0450 (0.917 sec/step)\n","INFO:tensorflow:global step 6329: loss = 4.7443 (0.909 sec/step)\n","I1215 19:37:30.160184 140303514462080 learning.py:512] global step 6329: loss = 4.7443 (0.909 sec/step)\n","INFO:tensorflow:global step 6330: loss = 2.8462 (0.908 sec/step)\n","I1215 19:37:31.069772 140303514462080 learning.py:512] global step 6330: loss = 2.8462 (0.908 sec/step)\n","INFO:tensorflow:global step 6331: loss = 3.8932 (0.889 sec/step)\n","I1215 19:37:31.960376 140303514462080 learning.py:512] global step 6331: loss = 3.8932 (0.889 sec/step)\n","INFO:tensorflow:global step 6332: loss = 4.7294 (0.892 sec/step)\n","I1215 19:37:32.853909 140303514462080 learning.py:512] global step 6332: loss = 4.7294 (0.892 sec/step)\n","INFO:tensorflow:global step 6333: loss = 3.9204 (0.902 sec/step)\n","I1215 19:37:33.757612 140303514462080 learning.py:512] global step 6333: loss = 3.9204 (0.902 sec/step)\n","INFO:tensorflow:global step 6334: loss = 3.4679 (0.878 sec/step)\n","I1215 19:37:34.637221 140303514462080 learning.py:512] global step 6334: loss = 3.4679 (0.878 sec/step)\n","INFO:tensorflow:global step 6335: loss = 3.1259 (0.900 sec/step)\n","I1215 19:37:35.539047 140303514462080 learning.py:512] global step 6335: loss = 3.1259 (0.900 sec/step)\n","INFO:tensorflow:global step 6336: loss = 3.6355 (1.484 sec/step)\n","I1215 19:37:37.024779 140303514462080 learning.py:512] global step 6336: loss = 3.6355 (1.484 sec/step)\n","INFO:tensorflow:Recording summary at step 6336.\n","I1215 19:37:37.057843 140299899541248 supervisor.py:1050] Recording summary at step 6336.\n","INFO:tensorflow:global step 6337: loss = 3.3271 (0.907 sec/step)\n","I1215 19:37:37.933874 140303514462080 learning.py:512] global step 6337: loss = 3.3271 (0.907 sec/step)\n","INFO:tensorflow:global step 6338: loss = 3.9808 (0.922 sec/step)\n","I1215 19:37:38.857690 140303514462080 learning.py:512] global step 6338: loss = 3.9808 (0.922 sec/step)\n","INFO:tensorflow:global step 6339: loss = 3.8468 (0.884 sec/step)\n","I1215 19:37:39.743584 140303514462080 learning.py:512] global step 6339: loss = 3.8468 (0.884 sec/step)\n","INFO:tensorflow:global step 6340: loss = 5.5564 (0.904 sec/step)\n","I1215 19:37:40.649109 140303514462080 learning.py:512] global step 6340: loss = 5.5564 (0.904 sec/step)\n","INFO:tensorflow:global step 6341: loss = 4.9456 (0.886 sec/step)\n","I1215 19:37:41.536425 140303514462080 learning.py:512] global step 6341: loss = 4.9456 (0.886 sec/step)\n","INFO:tensorflow:global step 6342: loss = 3.6505 (0.917 sec/step)\n","I1215 19:37:42.455109 140303514462080 learning.py:512] global step 6342: loss = 3.6505 (0.917 sec/step)\n","INFO:tensorflow:global step 6343: loss = 6.4228 (0.905 sec/step)\n","I1215 19:37:43.361786 140303514462080 learning.py:512] global step 6343: loss = 6.4228 (0.905 sec/step)\n","INFO:tensorflow:global step 6344: loss = 3.6432 (0.898 sec/step)\n","I1215 19:37:44.260765 140303514462080 learning.py:512] global step 6344: loss = 3.6432 (0.898 sec/step)\n","INFO:tensorflow:global step 6345: loss = 2.9178 (0.921 sec/step)\n","I1215 19:37:45.183375 140303514462080 learning.py:512] global step 6345: loss = 2.9178 (0.921 sec/step)\n","INFO:tensorflow:global step 6346: loss = 4.2088 (0.903 sec/step)\n","I1215 19:37:46.087717 140303514462080 learning.py:512] global step 6346: loss = 4.2088 (0.903 sec/step)\n","INFO:tensorflow:global step 6347: loss = 4.3182 (0.900 sec/step)\n","I1215 19:37:46.989487 140303514462080 learning.py:512] global step 6347: loss = 4.3182 (0.900 sec/step)\n","INFO:tensorflow:global step 6348: loss = 4.4793 (0.926 sec/step)\n","I1215 19:37:47.916942 140303514462080 learning.py:512] global step 6348: loss = 4.4793 (0.926 sec/step)\n","INFO:tensorflow:global step 6349: loss = 4.6865 (0.899 sec/step)\n","I1215 19:37:48.817805 140303514462080 learning.py:512] global step 6349: loss = 4.6865 (0.899 sec/step)\n","INFO:tensorflow:global step 6350: loss = 4.6165 (0.928 sec/step)\n","I1215 19:37:49.746980 140303514462080 learning.py:512] global step 6350: loss = 4.6165 (0.928 sec/step)\n","INFO:tensorflow:global step 6351: loss = 3.8325 (0.908 sec/step)\n","I1215 19:37:50.656616 140303514462080 learning.py:512] global step 6351: loss = 3.8325 (0.908 sec/step)\n","INFO:tensorflow:global step 6352: loss = 4.4776 (0.904 sec/step)\n","I1215 19:37:51.562291 140303514462080 learning.py:512] global step 6352: loss = 4.4776 (0.904 sec/step)\n","INFO:tensorflow:global step 6353: loss = 4.0099 (0.925 sec/step)\n","I1215 19:37:52.488255 140303514462080 learning.py:512] global step 6353: loss = 4.0099 (0.925 sec/step)\n","INFO:tensorflow:global step 6354: loss = 3.7669 (0.911 sec/step)\n","I1215 19:37:53.400884 140303514462080 learning.py:512] global step 6354: loss = 3.7669 (0.911 sec/step)\n","INFO:tensorflow:global step 6355: loss = 4.1618 (0.910 sec/step)\n","I1215 19:37:54.312190 140303514462080 learning.py:512] global step 6355: loss = 4.1618 (0.910 sec/step)\n","INFO:tensorflow:global step 6356: loss = 2.7069 (0.902 sec/step)\n","I1215 19:37:55.215540 140303514462080 learning.py:512] global step 6356: loss = 2.7069 (0.902 sec/step)\n","INFO:tensorflow:global step 6357: loss = 3.5169 (0.910 sec/step)\n","I1215 19:37:56.127313 140303514462080 learning.py:512] global step 6357: loss = 3.5169 (0.910 sec/step)\n","INFO:tensorflow:global step 6358: loss = 2.8461 (0.921 sec/step)\n","I1215 19:37:57.049550 140303514462080 learning.py:512] global step 6358: loss = 2.8461 (0.921 sec/step)\n","INFO:tensorflow:global step 6359: loss = 4.2161 (0.892 sec/step)\n","I1215 19:37:57.943219 140303514462080 learning.py:512] global step 6359: loss = 4.2161 (0.892 sec/step)\n","INFO:tensorflow:global step 6360: loss = 3.6267 (0.915 sec/step)\n","I1215 19:37:58.859487 140303514462080 learning.py:512] global step 6360: loss = 3.6267 (0.915 sec/step)\n","INFO:tensorflow:global step 6361: loss = 3.3682 (0.905 sec/step)\n","I1215 19:37:59.766530 140303514462080 learning.py:512] global step 6361: loss = 3.3682 (0.905 sec/step)\n","INFO:tensorflow:global step 6362: loss = 5.2207 (0.904 sec/step)\n","I1215 19:38:00.672188 140303514462080 learning.py:512] global step 6362: loss = 5.2207 (0.904 sec/step)\n","INFO:tensorflow:global step 6363: loss = 5.0141 (0.903 sec/step)\n","I1215 19:38:01.576517 140303514462080 learning.py:512] global step 6363: loss = 5.0141 (0.903 sec/step)\n","INFO:tensorflow:global step 6364: loss = 3.9822 (0.896 sec/step)\n","I1215 19:38:02.473811 140303514462080 learning.py:512] global step 6364: loss = 3.9822 (0.896 sec/step)\n","INFO:tensorflow:global step 6365: loss = 3.4345 (0.912 sec/step)\n","I1215 19:38:03.387385 140303514462080 learning.py:512] global step 6365: loss = 3.4345 (0.912 sec/step)\n","INFO:tensorflow:global step 6366: loss = 5.3778 (0.910 sec/step)\n","I1215 19:38:04.298724 140303514462080 learning.py:512] global step 6366: loss = 5.3778 (0.910 sec/step)\n","INFO:tensorflow:global step 6367: loss = 3.4182 (0.921 sec/step)\n","I1215 19:38:05.221246 140303514462080 learning.py:512] global step 6367: loss = 3.4182 (0.921 sec/step)\n","INFO:tensorflow:global step 6368: loss = 5.6521 (0.904 sec/step)\n","I1215 19:38:06.126859 140303514462080 learning.py:512] global step 6368: loss = 5.6521 (0.904 sec/step)\n","INFO:tensorflow:global step 6369: loss = 4.5130 (0.906 sec/step)\n","I1215 19:38:07.034371 140303514462080 learning.py:512] global step 6369: loss = 4.5130 (0.906 sec/step)\n","INFO:tensorflow:global step 6370: loss = 2.9584 (0.884 sec/step)\n","I1215 19:38:07.920012 140303514462080 learning.py:512] global step 6370: loss = 2.9584 (0.884 sec/step)\n","INFO:tensorflow:global step 6371: loss = 2.9126 (0.901 sec/step)\n","I1215 19:38:08.822892 140303514462080 learning.py:512] global step 6371: loss = 2.9126 (0.901 sec/step)\n","INFO:tensorflow:global step 6372: loss = 4.6843 (0.909 sec/step)\n","I1215 19:38:09.733493 140303514462080 learning.py:512] global step 6372: loss = 4.6843 (0.909 sec/step)\n","INFO:tensorflow:global step 6373: loss = 5.4716 (0.916 sec/step)\n","I1215 19:38:10.650533 140303514462080 learning.py:512] global step 6373: loss = 5.4716 (0.916 sec/step)\n","INFO:tensorflow:global step 6374: loss = 2.8019 (0.911 sec/step)\n","I1215 19:38:11.563157 140303514462080 learning.py:512] global step 6374: loss = 2.8019 (0.911 sec/step)\n","INFO:tensorflow:global step 6375: loss = 4.1427 (0.906 sec/step)\n","I1215 19:38:12.470674 140303514462080 learning.py:512] global step 6375: loss = 4.1427 (0.906 sec/step)\n","INFO:tensorflow:global step 6376: loss = 4.6231 (0.897 sec/step)\n","I1215 19:38:13.368994 140303514462080 learning.py:512] global step 6376: loss = 4.6231 (0.897 sec/step)\n","INFO:tensorflow:global step 6377: loss = 3.3244 (0.893 sec/step)\n","I1215 19:38:14.263382 140303514462080 learning.py:512] global step 6377: loss = 3.3244 (0.893 sec/step)\n","INFO:tensorflow:global step 6378: loss = 3.8548 (0.905 sec/step)\n","I1215 19:38:15.170484 140303514462080 learning.py:512] global step 6378: loss = 3.8548 (0.905 sec/step)\n","INFO:tensorflow:global step 6379: loss = 4.5086 (0.898 sec/step)\n","I1215 19:38:16.070065 140303514462080 learning.py:512] global step 6379: loss = 4.5086 (0.898 sec/step)\n","INFO:tensorflow:global step 6380: loss = 4.2850 (0.901 sec/step)\n","I1215 19:38:16.972078 140303514462080 learning.py:512] global step 6380: loss = 4.2850 (0.901 sec/step)\n","INFO:tensorflow:global step 6381: loss = 2.9618 (0.891 sec/step)\n","I1215 19:38:17.864751 140303514462080 learning.py:512] global step 6381: loss = 2.9618 (0.891 sec/step)\n","INFO:tensorflow:global step 6382: loss = 5.9207 (0.898 sec/step)\n","I1215 19:38:18.764122 140303514462080 learning.py:512] global step 6382: loss = 5.9207 (0.898 sec/step)\n","INFO:tensorflow:global step 6383: loss = 3.7054 (0.900 sec/step)\n","I1215 19:38:19.666021 140303514462080 learning.py:512] global step 6383: loss = 3.7054 (0.900 sec/step)\n","INFO:tensorflow:global step 6384: loss = 3.8098 (0.915 sec/step)\n","I1215 19:38:20.582228 140303514462080 learning.py:512] global step 6384: loss = 3.8098 (0.915 sec/step)\n","INFO:tensorflow:global step 6385: loss = 3.5221 (0.908 sec/step)\n","I1215 19:38:21.492131 140303514462080 learning.py:512] global step 6385: loss = 3.5221 (0.908 sec/step)\n","INFO:tensorflow:global step 6386: loss = 3.6911 (0.904 sec/step)\n","I1215 19:38:22.397364 140303514462080 learning.py:512] global step 6386: loss = 3.6911 (0.904 sec/step)\n","INFO:tensorflow:global step 6387: loss = 4.7322 (0.899 sec/step)\n","I1215 19:38:23.298036 140303514462080 learning.py:512] global step 6387: loss = 4.7322 (0.899 sec/step)\n","INFO:tensorflow:global step 6388: loss = 3.5505 (0.898 sec/step)\n","I1215 19:38:24.197285 140303514462080 learning.py:512] global step 6388: loss = 3.5505 (0.898 sec/step)\n","INFO:tensorflow:global step 6389: loss = 3.4380 (0.919 sec/step)\n","I1215 19:38:25.117908 140303514462080 learning.py:512] global step 6389: loss = 3.4380 (0.919 sec/step)\n","INFO:tensorflow:global step 6390: loss = 5.3276 (0.906 sec/step)\n","I1215 19:38:26.025739 140303514462080 learning.py:512] global step 6390: loss = 5.3276 (0.906 sec/step)\n","INFO:tensorflow:global step 6391: loss = 3.1199 (0.916 sec/step)\n","I1215 19:38:26.943435 140303514462080 learning.py:512] global step 6391: loss = 3.1199 (0.916 sec/step)\n","INFO:tensorflow:global step 6392: loss = 4.1206 (0.905 sec/step)\n","I1215 19:38:27.850430 140303514462080 learning.py:512] global step 6392: loss = 4.1206 (0.905 sec/step)\n","INFO:tensorflow:global step 6393: loss = 3.6672 (0.903 sec/step)\n","I1215 19:38:28.754524 140303514462080 learning.py:512] global step 6393: loss = 3.6672 (0.903 sec/step)\n","INFO:tensorflow:global step 6394: loss = 3.2370 (0.922 sec/step)\n","I1215 19:38:29.677582 140303514462080 learning.py:512] global step 6394: loss = 3.2370 (0.922 sec/step)\n","INFO:tensorflow:global step 6395: loss = 2.8265 (0.913 sec/step)\n","I1215 19:38:30.591853 140303514462080 learning.py:512] global step 6395: loss = 2.8265 (0.913 sec/step)\n","INFO:tensorflow:global step 6396: loss = 3.7222 (0.913 sec/step)\n","I1215 19:38:31.506077 140303514462080 learning.py:512] global step 6396: loss = 3.7222 (0.913 sec/step)\n","INFO:tensorflow:global step 6397: loss = 5.2402 (0.890 sec/step)\n","I1215 19:38:32.397450 140303514462080 learning.py:512] global step 6397: loss = 5.2402 (0.890 sec/step)\n","INFO:tensorflow:global step 6398: loss = 5.0229 (0.888 sec/step)\n","I1215 19:38:33.286933 140303514462080 learning.py:512] global step 6398: loss = 5.0229 (0.888 sec/step)\n","INFO:tensorflow:global step 6399: loss = 4.1473 (0.886 sec/step)\n","I1215 19:38:34.174371 140303514462080 learning.py:512] global step 6399: loss = 4.1473 (0.886 sec/step)\n","INFO:tensorflow:global step 6400: loss = 4.1742 (0.888 sec/step)\n","I1215 19:38:35.063525 140303514462080 learning.py:512] global step 6400: loss = 4.1742 (0.888 sec/step)\n","INFO:tensorflow:global step 6401: loss = 3.5632 (0.901 sec/step)\n","I1215 19:38:35.965869 140303514462080 learning.py:512] global step 6401: loss = 3.5632 (0.901 sec/step)\n","INFO:tensorflow:global step 6402: loss = 3.5990 (0.896 sec/step)\n","I1215 19:38:36.863724 140303514462080 learning.py:512] global step 6402: loss = 3.5990 (0.896 sec/step)\n","INFO:tensorflow:global step 6403: loss = 4.1597 (0.900 sec/step)\n","I1215 19:38:37.764784 140303514462080 learning.py:512] global step 6403: loss = 4.1597 (0.900 sec/step)\n","INFO:tensorflow:global step 6404: loss = 5.0775 (0.907 sec/step)\n","I1215 19:38:38.673599 140303514462080 learning.py:512] global step 6404: loss = 5.0775 (0.907 sec/step)\n","INFO:tensorflow:global step 6405: loss = 2.9993 (0.904 sec/step)\n","I1215 19:38:39.579115 140303514462080 learning.py:512] global step 6405: loss = 2.9993 (0.904 sec/step)\n","INFO:tensorflow:global step 6406: loss = 3.8244 (0.901 sec/step)\n","I1215 19:38:40.482138 140303514462080 learning.py:512] global step 6406: loss = 3.8244 (0.901 sec/step)\n","INFO:tensorflow:global step 6407: loss = 4.2869 (0.911 sec/step)\n","I1215 19:38:41.394397 140303514462080 learning.py:512] global step 6407: loss = 4.2869 (0.911 sec/step)\n","INFO:tensorflow:global step 6408: loss = 5.2846 (0.915 sec/step)\n","I1215 19:38:42.310487 140303514462080 learning.py:512] global step 6408: loss = 5.2846 (0.915 sec/step)\n","INFO:tensorflow:global step 6409: loss = 5.6026 (0.895 sec/step)\n","I1215 19:38:43.207063 140303514462080 learning.py:512] global step 6409: loss = 5.6026 (0.895 sec/step)\n","INFO:tensorflow:global step 6410: loss = 3.3729 (0.896 sec/step)\n","I1215 19:38:44.104362 140303514462080 learning.py:512] global step 6410: loss = 3.3729 (0.896 sec/step)\n","INFO:tensorflow:global step 6411: loss = 3.3157 (0.912 sec/step)\n","I1215 19:38:45.017851 140303514462080 learning.py:512] global step 6411: loss = 3.3157 (0.912 sec/step)\n","INFO:tensorflow:global step 6412: loss = 3.3586 (0.904 sec/step)\n","I1215 19:38:45.923678 140303514462080 learning.py:512] global step 6412: loss = 3.3586 (0.904 sec/step)\n","INFO:tensorflow:global step 6413: loss = 3.8079 (0.905 sec/step)\n","I1215 19:38:46.830425 140303514462080 learning.py:512] global step 6413: loss = 3.8079 (0.905 sec/step)\n","INFO:tensorflow:global step 6414: loss = 4.8149 (0.917 sec/step)\n","I1215 19:38:47.748629 140303514462080 learning.py:512] global step 6414: loss = 4.8149 (0.917 sec/step)\n","INFO:tensorflow:global step 6415: loss = 3.5277 (0.913 sec/step)\n","I1215 19:38:48.663336 140303514462080 learning.py:512] global step 6415: loss = 3.5277 (0.913 sec/step)\n","INFO:tensorflow:global step 6416: loss = 3.9591 (0.904 sec/step)\n","I1215 19:38:49.569246 140303514462080 learning.py:512] global step 6416: loss = 3.9591 (0.904 sec/step)\n","INFO:tensorflow:global step 6417: loss = 5.4194 (0.903 sec/step)\n","I1215 19:38:50.473980 140303514462080 learning.py:512] global step 6417: loss = 5.4194 (0.903 sec/step)\n","INFO:tensorflow:global step 6418: loss = 3.6503 (0.905 sec/step)\n","I1215 19:38:51.379922 140303514462080 learning.py:512] global step 6418: loss = 3.6503 (0.905 sec/step)\n","INFO:tensorflow:global step 6419: loss = 4.7474 (0.907 sec/step)\n","I1215 19:38:52.288255 140303514462080 learning.py:512] global step 6419: loss = 4.7474 (0.907 sec/step)\n","INFO:tensorflow:global step 6420: loss = 4.5407 (0.905 sec/step)\n","I1215 19:38:53.194621 140303514462080 learning.py:512] global step 6420: loss = 4.5407 (0.905 sec/step)\n","INFO:tensorflow:global step 6421: loss = 6.1914 (0.901 sec/step)\n","I1215 19:38:54.096938 140303514462080 learning.py:512] global step 6421: loss = 6.1914 (0.901 sec/step)\n","INFO:tensorflow:global step 6422: loss = 4.3792 (0.943 sec/step)\n","I1215 19:38:55.041921 140303514462080 learning.py:512] global step 6422: loss = 4.3792 (0.943 sec/step)\n","INFO:tensorflow:global step 6423: loss = 4.1910 (0.920 sec/step)\n","I1215 19:38:55.963950 140303514462080 learning.py:512] global step 6423: loss = 4.1910 (0.920 sec/step)\n","INFO:tensorflow:global step 6424: loss = 4.7104 (0.905 sec/step)\n","I1215 19:38:56.870404 140303514462080 learning.py:512] global step 6424: loss = 4.7104 (0.905 sec/step)\n","INFO:tensorflow:global step 6425: loss = 4.8032 (0.908 sec/step)\n","I1215 19:38:57.779745 140303514462080 learning.py:512] global step 6425: loss = 4.8032 (0.908 sec/step)\n","INFO:tensorflow:global step 6426: loss = 5.6716 (0.926 sec/step)\n","I1215 19:38:58.707145 140303514462080 learning.py:512] global step 6426: loss = 5.6716 (0.926 sec/step)\n","INFO:tensorflow:global step 6427: loss = 4.4322 (0.926 sec/step)\n","I1215 19:38:59.634613 140303514462080 learning.py:512] global step 6427: loss = 4.4322 (0.926 sec/step)\n","INFO:tensorflow:global step 6428: loss = 3.9128 (0.939 sec/step)\n","I1215 19:39:00.575024 140303514462080 learning.py:512] global step 6428: loss = 3.9128 (0.939 sec/step)\n","INFO:tensorflow:global step 6429: loss = 5.8024 (0.903 sec/step)\n","I1215 19:39:01.479852 140303514462080 learning.py:512] global step 6429: loss = 5.8024 (0.903 sec/step)\n","INFO:tensorflow:global step 6430: loss = 3.6681 (0.928 sec/step)\n","I1215 19:39:02.409874 140303514462080 learning.py:512] global step 6430: loss = 3.6681 (0.928 sec/step)\n","INFO:tensorflow:global step 6431: loss = 3.6400 (0.912 sec/step)\n","I1215 19:39:03.323558 140303514462080 learning.py:512] global step 6431: loss = 3.6400 (0.912 sec/step)\n","INFO:tensorflow:global step 6432: loss = 4.5868 (0.911 sec/step)\n","I1215 19:39:04.236717 140303514462080 learning.py:512] global step 6432: loss = 4.5868 (0.911 sec/step)\n","INFO:tensorflow:global step 6433: loss = 4.9951 (0.932 sec/step)\n","I1215 19:39:05.170423 140303514462080 learning.py:512] global step 6433: loss = 4.9951 (0.932 sec/step)\n","INFO:tensorflow:global step 6434: loss = 5.1191 (0.905 sec/step)\n","I1215 19:39:06.077403 140303514462080 learning.py:512] global step 6434: loss = 5.1191 (0.905 sec/step)\n","INFO:tensorflow:global step 6435: loss = 5.7693 (0.883 sec/step)\n","I1215 19:39:06.962114 140303514462080 learning.py:512] global step 6435: loss = 5.7693 (0.883 sec/step)\n","INFO:tensorflow:global step 6436: loss = 4.2162 (0.898 sec/step)\n","I1215 19:39:07.861439 140303514462080 learning.py:512] global step 6436: loss = 4.2162 (0.898 sec/step)\n","INFO:tensorflow:global step 6437: loss = 3.1039 (0.905 sec/step)\n","I1215 19:39:08.768244 140303514462080 learning.py:512] global step 6437: loss = 3.1039 (0.905 sec/step)\n","INFO:tensorflow:global step 6438: loss = 2.7596 (0.934 sec/step)\n","I1215 19:39:09.704001 140303514462080 learning.py:512] global step 6438: loss = 2.7596 (0.934 sec/step)\n","INFO:tensorflow:global step 6439: loss = 4.6532 (0.903 sec/step)\n","I1215 19:39:10.608368 140303514462080 learning.py:512] global step 6439: loss = 4.6532 (0.903 sec/step)\n","INFO:tensorflow:global step 6440: loss = 4.6831 (0.905 sec/step)\n","I1215 19:39:11.514746 140303514462080 learning.py:512] global step 6440: loss = 4.6831 (0.905 sec/step)\n","INFO:tensorflow:global step 6441: loss = 3.8238 (0.912 sec/step)\n","I1215 19:39:12.428765 140303514462080 learning.py:512] global step 6441: loss = 3.8238 (0.912 sec/step)\n","INFO:tensorflow:global step 6442: loss = 5.0190 (0.913 sec/step)\n","I1215 19:39:13.343185 140303514462080 learning.py:512] global step 6442: loss = 5.0190 (0.913 sec/step)\n","INFO:tensorflow:global step 6443: loss = 3.8871 (0.915 sec/step)\n","I1215 19:39:14.260045 140303514462080 learning.py:512] global step 6443: loss = 3.8871 (0.915 sec/step)\n","INFO:tensorflow:global step 6444: loss = 3.5878 (0.909 sec/step)\n","I1215 19:39:15.170732 140303514462080 learning.py:512] global step 6444: loss = 3.5878 (0.909 sec/step)\n","INFO:tensorflow:global step 6445: loss = 3.2598 (0.883 sec/step)\n","I1215 19:39:16.055772 140303514462080 learning.py:512] global step 6445: loss = 3.2598 (0.883 sec/step)\n","INFO:tensorflow:global step 6446: loss = 3.0095 (0.888 sec/step)\n","I1215 19:39:16.945227 140303514462080 learning.py:512] global step 6446: loss = 3.0095 (0.888 sec/step)\n","INFO:tensorflow:global step 6447: loss = 7.5972 (0.901 sec/step)\n","I1215 19:39:17.848155 140303514462080 learning.py:512] global step 6447: loss = 7.5972 (0.901 sec/step)\n","INFO:tensorflow:global step 6448: loss = 4.9301 (0.902 sec/step)\n","I1215 19:39:18.751898 140303514462080 learning.py:512] global step 6448: loss = 4.9301 (0.902 sec/step)\n","INFO:tensorflow:global step 6449: loss = 3.3103 (0.886 sec/step)\n","I1215 19:39:19.639757 140303514462080 learning.py:512] global step 6449: loss = 3.3103 (0.886 sec/step)\n","INFO:tensorflow:global step 6450: loss = 3.8462 (0.903 sec/step)\n","I1215 19:39:20.544830 140303514462080 learning.py:512] global step 6450: loss = 3.8462 (0.903 sec/step)\n","INFO:tensorflow:global step 6451: loss = 4.7801 (0.902 sec/step)\n","I1215 19:39:21.448167 140303514462080 learning.py:512] global step 6451: loss = 4.7801 (0.902 sec/step)\n","INFO:tensorflow:global step 6452: loss = 3.5950 (0.906 sec/step)\n","I1215 19:39:22.355437 140303514462080 learning.py:512] global step 6452: loss = 3.5950 (0.906 sec/step)\n","INFO:tensorflow:global step 6453: loss = 6.0969 (0.911 sec/step)\n","I1215 19:39:23.267505 140303514462080 learning.py:512] global step 6453: loss = 6.0969 (0.911 sec/step)\n","INFO:tensorflow:global step 6454: loss = 3.8212 (0.908 sec/step)\n","I1215 19:39:24.177100 140303514462080 learning.py:512] global step 6454: loss = 3.8212 (0.908 sec/step)\n","INFO:tensorflow:global step 6455: loss = 3.3893 (0.900 sec/step)\n","I1215 19:39:25.078849 140303514462080 learning.py:512] global step 6455: loss = 3.3893 (0.900 sec/step)\n","INFO:tensorflow:global step 6456: loss = 3.7607 (0.909 sec/step)\n","I1215 19:39:25.989200 140303514462080 learning.py:512] global step 6456: loss = 3.7607 (0.909 sec/step)\n","INFO:tensorflow:global step 6457: loss = 3.0079 (0.902 sec/step)\n","I1215 19:39:26.892541 140303514462080 learning.py:512] global step 6457: loss = 3.0079 (0.902 sec/step)\n","INFO:tensorflow:global step 6458: loss = 5.9842 (0.922 sec/step)\n","I1215 19:39:27.816507 140303514462080 learning.py:512] global step 6458: loss = 5.9842 (0.922 sec/step)\n","INFO:tensorflow:global step 6459: loss = 3.9300 (0.897 sec/step)\n","I1215 19:39:28.714992 140303514462080 learning.py:512] global step 6459: loss = 3.9300 (0.897 sec/step)\n","INFO:tensorflow:global step 6460: loss = 3.2288 (0.899 sec/step)\n","I1215 19:39:29.615943 140303514462080 learning.py:512] global step 6460: loss = 3.2288 (0.899 sec/step)\n","INFO:tensorflow:global step 6461: loss = 4.8515 (0.912 sec/step)\n","I1215 19:39:30.529514 140303514462080 learning.py:512] global step 6461: loss = 4.8515 (0.912 sec/step)\n","INFO:tensorflow:global step 6462: loss = 4.5225 (0.902 sec/step)\n","I1215 19:39:31.433389 140303514462080 learning.py:512] global step 6462: loss = 4.5225 (0.902 sec/step)\n","INFO:tensorflow:global step 6463: loss = 5.6620 (0.896 sec/step)\n","I1215 19:39:32.330570 140303514462080 learning.py:512] global step 6463: loss = 5.6620 (0.896 sec/step)\n","INFO:tensorflow:global step 6464: loss = 3.0637 (0.911 sec/step)\n","I1215 19:39:33.243110 140303514462080 learning.py:512] global step 6464: loss = 3.0637 (0.911 sec/step)\n","INFO:tensorflow:global step 6465: loss = 4.2946 (0.911 sec/step)\n","I1215 19:39:34.155473 140303514462080 learning.py:512] global step 6465: loss = 4.2946 (0.911 sec/step)\n","INFO:tensorflow:global step 6466: loss = 2.9822 (0.915 sec/step)\n","I1215 19:39:35.072397 140303514462080 learning.py:512] global step 6466: loss = 2.9822 (0.915 sec/step)\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I1215 19:39:35.600721 140299865970432 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","INFO:tensorflow:global step 6467: loss = 3.8951 (1.651 sec/step)\n","I1215 19:39:36.730690 140303514462080 learning.py:512] global step 6467: loss = 3.8951 (1.651 sec/step)\n","INFO:tensorflow:Recording summary at step 6467.\n","I1215 19:39:37.523576 140299899541248 supervisor.py:1050] Recording summary at step 6467.\n","INFO:tensorflow:global step 6468: loss = 4.9304 (1.688 sec/step)\n","I1215 19:39:38.431773 140303514462080 learning.py:512] global step 6468: loss = 4.9304 (1.688 sec/step)\n","INFO:tensorflow:global step 6469: loss = 4.1725 (1.292 sec/step)\n","I1215 19:39:39.734616 140303514462080 learning.py:512] global step 6469: loss = 4.1725 (1.292 sec/step)\n","INFO:tensorflow:global step 6470: loss = 2.9944 (1.086 sec/step)\n","I1215 19:39:40.822274 140303514462080 learning.py:512] global step 6470: loss = 2.9944 (1.086 sec/step)\n","INFO:tensorflow:global step 6471: loss = 5.2216 (0.890 sec/step)\n","I1215 19:39:41.713516 140303514462080 learning.py:512] global step 6471: loss = 5.2216 (0.890 sec/step)\n","INFO:tensorflow:global step 6472: loss = 4.3819 (0.904 sec/step)\n","I1215 19:39:42.619118 140303514462080 learning.py:512] global step 6472: loss = 4.3819 (0.904 sec/step)\n","INFO:tensorflow:global step 6473: loss = 3.6720 (0.903 sec/step)\n","I1215 19:39:43.523279 140303514462080 learning.py:512] global step 6473: loss = 3.6720 (0.903 sec/step)\n","INFO:tensorflow:global step 6474: loss = 3.7446 (0.912 sec/step)\n","I1215 19:39:44.436704 140303514462080 learning.py:512] global step 6474: loss = 3.7446 (0.912 sec/step)\n","INFO:tensorflow:global step 6475: loss = 4.4412 (0.911 sec/step)\n","I1215 19:39:45.352804 140303514462080 learning.py:512] global step 6475: loss = 4.4412 (0.911 sec/step)\n","INFO:tensorflow:global step 6476: loss = 4.2117 (0.892 sec/step)\n","I1215 19:39:46.246939 140303514462080 learning.py:512] global step 6476: loss = 4.2117 (0.892 sec/step)\n","INFO:tensorflow:global step 6477: loss = 4.3646 (0.920 sec/step)\n","I1215 19:39:47.168026 140303514462080 learning.py:512] global step 6477: loss = 4.3646 (0.920 sec/step)\n","INFO:tensorflow:global step 6478: loss = 4.2316 (0.929 sec/step)\n","I1215 19:39:48.098594 140303514462080 learning.py:512] global step 6478: loss = 4.2316 (0.929 sec/step)\n","INFO:tensorflow:global step 6479: loss = 3.4155 (0.898 sec/step)\n","I1215 19:39:48.997993 140303514462080 learning.py:512] global step 6479: loss = 3.4155 (0.898 sec/step)\n","INFO:tensorflow:global step 6480: loss = 6.8859 (0.931 sec/step)\n","I1215 19:39:49.930269 140303514462080 learning.py:512] global step 6480: loss = 6.8859 (0.931 sec/step)\n","INFO:tensorflow:global step 6481: loss = 4.9211 (0.897 sec/step)\n","I1215 19:39:50.828245 140303514462080 learning.py:512] global step 6481: loss = 4.9211 (0.897 sec/step)\n","INFO:tensorflow:global step 6482: loss = 3.2494 (0.887 sec/step)\n","I1215 19:39:51.716408 140303514462080 learning.py:512] global step 6482: loss = 3.2494 (0.887 sec/step)\n","INFO:tensorflow:global step 6483: loss = 5.8234 (0.897 sec/step)\n","I1215 19:39:52.614773 140303514462080 learning.py:512] global step 6483: loss = 5.8234 (0.897 sec/step)\n","INFO:tensorflow:global step 6484: loss = 5.3174 (0.915 sec/step)\n","I1215 19:39:53.531139 140303514462080 learning.py:512] global step 6484: loss = 5.3174 (0.915 sec/step)\n","INFO:tensorflow:global step 6485: loss = 4.1266 (0.921 sec/step)\n","I1215 19:39:54.453274 140303514462080 learning.py:512] global step 6485: loss = 4.1266 (0.921 sec/step)\n","INFO:tensorflow:global step 6486: loss = 4.9232 (0.925 sec/step)\n","I1215 19:39:55.379934 140303514462080 learning.py:512] global step 6486: loss = 4.9232 (0.925 sec/step)\n","INFO:tensorflow:global step 6487: loss = 3.8018 (0.905 sec/step)\n","I1215 19:39:56.286121 140303514462080 learning.py:512] global step 6487: loss = 3.8018 (0.905 sec/step)\n","INFO:tensorflow:global step 6488: loss = 4.2950 (0.904 sec/step)\n","I1215 19:39:57.191801 140303514462080 learning.py:512] global step 6488: loss = 4.2950 (0.904 sec/step)\n","INFO:tensorflow:global step 6489: loss = 3.5310 (0.900 sec/step)\n","I1215 19:39:58.092825 140303514462080 learning.py:512] global step 6489: loss = 3.5310 (0.900 sec/step)\n","INFO:tensorflow:global step 6490: loss = 4.5937 (0.905 sec/step)\n","I1215 19:39:58.999418 140303514462080 learning.py:512] global step 6490: loss = 4.5937 (0.905 sec/step)\n","INFO:tensorflow:global step 6491: loss = 4.2183 (0.897 sec/step)\n","I1215 19:39:59.897746 140303514462080 learning.py:512] global step 6491: loss = 4.2183 (0.897 sec/step)\n","INFO:tensorflow:global step 6492: loss = 5.6193 (0.903 sec/step)\n","I1215 19:40:00.802460 140303514462080 learning.py:512] global step 6492: loss = 5.6193 (0.903 sec/step)\n","INFO:tensorflow:global step 6493: loss = 5.0952 (0.898 sec/step)\n","I1215 19:40:01.702204 140303514462080 learning.py:512] global step 6493: loss = 5.0952 (0.898 sec/step)\n","INFO:tensorflow:global step 6494: loss = 4.2700 (0.901 sec/step)\n","I1215 19:40:02.604782 140303514462080 learning.py:512] global step 6494: loss = 4.2700 (0.901 sec/step)\n","INFO:tensorflow:global step 6495: loss = 3.8534 (0.909 sec/step)\n","I1215 19:40:03.515270 140303514462080 learning.py:512] global step 6495: loss = 3.8534 (0.909 sec/step)\n","INFO:tensorflow:global step 6496: loss = 4.0097 (0.907 sec/step)\n","I1215 19:40:04.424242 140303514462080 learning.py:512] global step 6496: loss = 4.0097 (0.907 sec/step)\n","INFO:tensorflow:global step 6497: loss = 5.1917 (0.896 sec/step)\n","I1215 19:40:05.322101 140303514462080 learning.py:512] global step 6497: loss = 5.1917 (0.896 sec/step)\n","INFO:tensorflow:global step 6498: loss = 4.2957 (0.887 sec/step)\n","I1215 19:40:06.210588 140303514462080 learning.py:512] global step 6498: loss = 4.2957 (0.887 sec/step)\n","INFO:tensorflow:global step 6499: loss = 4.4577 (0.897 sec/step)\n","I1215 19:40:07.109500 140303514462080 learning.py:512] global step 6499: loss = 4.4577 (0.897 sec/step)\n","INFO:tensorflow:global step 6500: loss = 3.6641 (0.890 sec/step)\n","I1215 19:40:08.001272 140303514462080 learning.py:512] global step 6500: loss = 3.6641 (0.890 sec/step)\n","INFO:tensorflow:global step 6501: loss = 3.9163 (0.900 sec/step)\n","I1215 19:40:08.903302 140303514462080 learning.py:512] global step 6501: loss = 3.9163 (0.900 sec/step)\n","INFO:tensorflow:global step 6502: loss = 5.8538 (0.901 sec/step)\n","I1215 19:40:09.806286 140303514462080 learning.py:512] global step 6502: loss = 5.8538 (0.901 sec/step)\n","INFO:tensorflow:global step 6503: loss = 4.5072 (0.901 sec/step)\n","I1215 19:40:10.709258 140303514462080 learning.py:512] global step 6503: loss = 4.5072 (0.901 sec/step)\n","INFO:tensorflow:global step 6504: loss = 3.5699 (0.912 sec/step)\n","I1215 19:40:11.622555 140303514462080 learning.py:512] global step 6504: loss = 3.5699 (0.912 sec/step)\n","INFO:tensorflow:global step 6505: loss = 4.3246 (0.923 sec/step)\n","I1215 19:40:12.547563 140303514462080 learning.py:512] global step 6505: loss = 4.3246 (0.923 sec/step)\n","INFO:tensorflow:global step 6506: loss = 4.1893 (0.901 sec/step)\n","I1215 19:40:13.450253 140303514462080 learning.py:512] global step 6506: loss = 4.1893 (0.901 sec/step)\n","INFO:tensorflow:global step 6507: loss = 4.3421 (0.902 sec/step)\n","I1215 19:40:14.354151 140303514462080 learning.py:512] global step 6507: loss = 4.3421 (0.902 sec/step)\n","INFO:tensorflow:global step 6508: loss = 5.0443 (0.930 sec/step)\n","I1215 19:40:15.285373 140303514462080 learning.py:512] global step 6508: loss = 5.0443 (0.930 sec/step)\n","INFO:tensorflow:global step 6509: loss = 3.4707 (0.916 sec/step)\n","I1215 19:40:16.202839 140303514462080 learning.py:512] global step 6509: loss = 3.4707 (0.916 sec/step)\n","INFO:tensorflow:global step 6510: loss = 6.2402 (0.917 sec/step)\n","I1215 19:40:17.121369 140303514462080 learning.py:512] global step 6510: loss = 6.2402 (0.917 sec/step)\n","INFO:tensorflow:global step 6511: loss = 2.8917 (0.907 sec/step)\n","I1215 19:40:18.029530 140303514462080 learning.py:512] global step 6511: loss = 2.8917 (0.907 sec/step)\n","INFO:tensorflow:global step 6512: loss = 4.7205 (0.895 sec/step)\n","I1215 19:40:18.926251 140303514462080 learning.py:512] global step 6512: loss = 4.7205 (0.895 sec/step)\n","INFO:tensorflow:global step 6513: loss = 4.5960 (0.912 sec/step)\n","I1215 19:40:19.839982 140303514462080 learning.py:512] global step 6513: loss = 4.5960 (0.912 sec/step)\n","INFO:tensorflow:global step 6514: loss = 4.9387 (0.931 sec/step)\n","I1215 19:40:20.771956 140303514462080 learning.py:512] global step 6514: loss = 4.9387 (0.931 sec/step)\n","INFO:tensorflow:global step 6515: loss = 3.2703 (0.912 sec/step)\n","I1215 19:40:21.685030 140303514462080 learning.py:512] global step 6515: loss = 3.2703 (0.912 sec/step)\n","INFO:tensorflow:global step 6516: loss = 4.2031 (0.903 sec/step)\n","I1215 19:40:22.589681 140303514462080 learning.py:512] global step 6516: loss = 4.2031 (0.903 sec/step)\n","INFO:tensorflow:global step 6517: loss = 6.6408 (0.903 sec/step)\n","I1215 19:40:23.494383 140303514462080 learning.py:512] global step 6517: loss = 6.6408 (0.903 sec/step)\n","INFO:tensorflow:global step 6518: loss = 5.1382 (0.905 sec/step)\n","I1215 19:40:24.400392 140303514462080 learning.py:512] global step 6518: loss = 5.1382 (0.905 sec/step)\n","INFO:tensorflow:global step 6519: loss = 4.7448 (0.885 sec/step)\n","I1215 19:40:25.286435 140303514462080 learning.py:512] global step 6519: loss = 4.7448 (0.885 sec/step)\n","INFO:tensorflow:global step 6520: loss = 4.7330 (0.904 sec/step)\n","I1215 19:40:26.192388 140303514462080 learning.py:512] global step 6520: loss = 4.7330 (0.904 sec/step)\n","INFO:tensorflow:global step 6521: loss = 3.0134 (0.892 sec/step)\n","I1215 19:40:27.086100 140303514462080 learning.py:512] global step 6521: loss = 3.0134 (0.892 sec/step)\n","INFO:tensorflow:global step 6522: loss = 3.9133 (0.912 sec/step)\n","I1215 19:40:27.999817 140303514462080 learning.py:512] global step 6522: loss = 3.9133 (0.912 sec/step)\n","INFO:tensorflow:global step 6523: loss = 4.4412 (0.912 sec/step)\n","I1215 19:40:28.913527 140303514462080 learning.py:512] global step 6523: loss = 4.4412 (0.912 sec/step)\n","INFO:tensorflow:global step 6524: loss = 4.9700 (0.918 sec/step)\n","I1215 19:40:29.833662 140303514462080 learning.py:512] global step 6524: loss = 4.9700 (0.918 sec/step)\n","INFO:tensorflow:global step 6525: loss = 4.3025 (0.927 sec/step)\n","I1215 19:40:30.762353 140303514462080 learning.py:512] global step 6525: loss = 4.3025 (0.927 sec/step)\n","INFO:tensorflow:global step 6526: loss = 3.6377 (0.925 sec/step)\n","I1215 19:40:31.689293 140303514462080 learning.py:512] global step 6526: loss = 3.6377 (0.925 sec/step)\n","INFO:tensorflow:global step 6527: loss = 3.6174 (0.890 sec/step)\n","I1215 19:40:32.580966 140303514462080 learning.py:512] global step 6527: loss = 3.6174 (0.890 sec/step)\n","INFO:tensorflow:global step 6528: loss = 4.1306 (0.897 sec/step)\n","I1215 19:40:33.479588 140303514462080 learning.py:512] global step 6528: loss = 4.1306 (0.897 sec/step)\n","INFO:tensorflow:global step 6529: loss = 5.3526 (0.914 sec/step)\n","I1215 19:40:34.395494 140303514462080 learning.py:512] global step 6529: loss = 5.3526 (0.914 sec/step)\n","INFO:tensorflow:global step 6530: loss = 3.3908 (0.892 sec/step)\n","I1215 19:40:35.288836 140303514462080 learning.py:512] global step 6530: loss = 3.3908 (0.892 sec/step)\n","INFO:tensorflow:global step 6531: loss = 3.6758 (0.891 sec/step)\n","I1215 19:40:36.181583 140303514462080 learning.py:512] global step 6531: loss = 3.6758 (0.891 sec/step)\n","INFO:tensorflow:global step 6532: loss = 4.2648 (0.950 sec/step)\n","I1215 19:40:37.133756 140303514462080 learning.py:512] global step 6532: loss = 4.2648 (0.950 sec/step)\n","INFO:tensorflow:global step 6533: loss = 3.7232 (0.903 sec/step)\n","I1215 19:40:38.038566 140303514462080 learning.py:512] global step 6533: loss = 3.7232 (0.903 sec/step)\n","INFO:tensorflow:global step 6534: loss = 5.1131 (0.897 sec/step)\n","I1215 19:40:38.937099 140303514462080 learning.py:512] global step 6534: loss = 5.1131 (0.897 sec/step)\n","INFO:tensorflow:global step 6535: loss = 3.9775 (0.913 sec/step)\n","I1215 19:40:39.852001 140303514462080 learning.py:512] global step 6535: loss = 3.9775 (0.913 sec/step)\n","INFO:tensorflow:global step 6536: loss = 4.2247 (0.912 sec/step)\n","I1215 19:40:40.765428 140303514462080 learning.py:512] global step 6536: loss = 4.2247 (0.912 sec/step)\n","INFO:tensorflow:global step 6537: loss = 3.2904 (0.906 sec/step)\n","I1215 19:40:41.672770 140303514462080 learning.py:512] global step 6537: loss = 3.2904 (0.906 sec/step)\n","INFO:tensorflow:global step 6538: loss = 4.7405 (0.908 sec/step)\n","I1215 19:40:42.582700 140303514462080 learning.py:512] global step 6538: loss = 4.7405 (0.908 sec/step)\n","INFO:tensorflow:global step 6539: loss = 3.7185 (0.899 sec/step)\n","I1215 19:40:43.483389 140303514462080 learning.py:512] global step 6539: loss = 3.7185 (0.899 sec/step)\n","INFO:tensorflow:global step 6540: loss = 3.5191 (0.901 sec/step)\n","I1215 19:40:44.386178 140303514462080 learning.py:512] global step 6540: loss = 3.5191 (0.901 sec/step)\n","INFO:tensorflow:global step 6541: loss = 4.1600 (0.908 sec/step)\n","I1215 19:40:45.296337 140303514462080 learning.py:512] global step 6541: loss = 4.1600 (0.908 sec/step)\n","INFO:tensorflow:global step 6542: loss = 4.1280 (0.911 sec/step)\n","I1215 19:40:46.209303 140303514462080 learning.py:512] global step 6542: loss = 4.1280 (0.911 sec/step)\n","INFO:tensorflow:global step 6543: loss = 3.2057 (0.897 sec/step)\n","I1215 19:40:47.108315 140303514462080 learning.py:512] global step 6543: loss = 3.2057 (0.897 sec/step)\n","INFO:tensorflow:global step 6544: loss = 4.1613 (0.906 sec/step)\n","I1215 19:40:48.015619 140303514462080 learning.py:512] global step 6544: loss = 4.1613 (0.906 sec/step)\n","INFO:tensorflow:global step 6545: loss = 4.7749 (0.895 sec/step)\n","I1215 19:40:48.912432 140303514462080 learning.py:512] global step 6545: loss = 4.7749 (0.895 sec/step)\n","INFO:tensorflow:global step 6546: loss = 4.3841 (0.887 sec/step)\n","I1215 19:40:49.800845 140303514462080 learning.py:512] global step 6546: loss = 4.3841 (0.887 sec/step)\n","INFO:tensorflow:global step 6547: loss = 4.7349 (0.889 sec/step)\n","I1215 19:40:50.691593 140303514462080 learning.py:512] global step 6547: loss = 4.7349 (0.889 sec/step)\n","INFO:tensorflow:global step 6548: loss = 3.3964 (0.898 sec/step)\n","I1215 19:40:51.591116 140303514462080 learning.py:512] global step 6548: loss = 3.3964 (0.898 sec/step)\n","INFO:tensorflow:global step 6549: loss = 4.1996 (0.893 sec/step)\n","I1215 19:40:52.486199 140303514462080 learning.py:512] global step 6549: loss = 4.1996 (0.893 sec/step)\n","INFO:tensorflow:global step 6550: loss = 5.0930 (0.917 sec/step)\n","I1215 19:40:53.404632 140303514462080 learning.py:512] global step 6550: loss = 5.0930 (0.917 sec/step)\n","INFO:tensorflow:global step 6551: loss = 4.5712 (0.892 sec/step)\n","I1215 19:40:54.297709 140303514462080 learning.py:512] global step 6551: loss = 4.5712 (0.892 sec/step)\n","INFO:tensorflow:global step 6552: loss = 3.4210 (0.890 sec/step)\n","I1215 19:40:55.188739 140303514462080 learning.py:512] global step 6552: loss = 3.4210 (0.890 sec/step)\n","INFO:tensorflow:global step 6553: loss = 5.1663 (0.887 sec/step)\n","I1215 19:40:56.077762 140303514462080 learning.py:512] global step 6553: loss = 5.1663 (0.887 sec/step)\n","INFO:tensorflow:global step 6554: loss = 3.7625 (0.893 sec/step)\n","I1215 19:40:56.972015 140303514462080 learning.py:512] global step 6554: loss = 3.7625 (0.893 sec/step)\n","INFO:tensorflow:global step 6555: loss = 5.3544 (0.911 sec/step)\n","I1215 19:40:57.884373 140303514462080 learning.py:512] global step 6555: loss = 5.3544 (0.911 sec/step)\n","INFO:tensorflow:global step 6556: loss = 6.8676 (0.914 sec/step)\n","I1215 19:40:58.800584 140303514462080 learning.py:512] global step 6556: loss = 6.8676 (0.914 sec/step)\n","INFO:tensorflow:global step 6557: loss = 4.5272 (0.902 sec/step)\n","I1215 19:40:59.704278 140303514462080 learning.py:512] global step 6557: loss = 4.5272 (0.902 sec/step)\n","INFO:tensorflow:global step 6558: loss = 4.2945 (0.885 sec/step)\n","I1215 19:41:00.590756 140303514462080 learning.py:512] global step 6558: loss = 4.2945 (0.885 sec/step)\n","INFO:tensorflow:global step 6559: loss = 4.4655 (0.900 sec/step)\n","I1215 19:41:01.492256 140303514462080 learning.py:512] global step 6559: loss = 4.4655 (0.900 sec/step)\n","INFO:tensorflow:global step 6560: loss = 4.7242 (0.901 sec/step)\n","I1215 19:41:02.394929 140303514462080 learning.py:512] global step 6560: loss = 4.7242 (0.901 sec/step)\n","INFO:tensorflow:global step 6561: loss = 4.5121 (0.906 sec/step)\n","I1215 19:41:03.302171 140303514462080 learning.py:512] global step 6561: loss = 4.5121 (0.906 sec/step)\n","INFO:tensorflow:global step 6562: loss = 3.3373 (0.890 sec/step)\n","I1215 19:41:04.193224 140303514462080 learning.py:512] global step 6562: loss = 3.3373 (0.890 sec/step)\n","INFO:tensorflow:global step 6563: loss = 4.2952 (0.892 sec/step)\n","I1215 19:41:05.086756 140303514462080 learning.py:512] global step 6563: loss = 4.2952 (0.892 sec/step)\n","INFO:tensorflow:global step 6564: loss = 5.2966 (0.881 sec/step)\n","I1215 19:41:05.969190 140303514462080 learning.py:512] global step 6564: loss = 5.2966 (0.881 sec/step)\n","INFO:tensorflow:global step 6565: loss = 3.7562 (0.901 sec/step)\n","I1215 19:41:06.871670 140303514462080 learning.py:512] global step 6565: loss = 3.7562 (0.901 sec/step)\n","INFO:tensorflow:global step 6566: loss = 5.4063 (0.895 sec/step)\n","I1215 19:41:07.767750 140303514462080 learning.py:512] global step 6566: loss = 5.4063 (0.895 sec/step)\n","INFO:tensorflow:global step 6567: loss = 2.6601 (0.908 sec/step)\n","I1215 19:41:08.677157 140303514462080 learning.py:512] global step 6567: loss = 2.6601 (0.908 sec/step)\n","INFO:tensorflow:global step 6568: loss = 5.4536 (0.922 sec/step)\n","I1215 19:41:09.601216 140303514462080 learning.py:512] global step 6568: loss = 5.4536 (0.922 sec/step)\n","INFO:tensorflow:global step 6569: loss = 4.9770 (0.909 sec/step)\n","I1215 19:41:10.511439 140303514462080 learning.py:512] global step 6569: loss = 4.9770 (0.909 sec/step)\n","INFO:tensorflow:global step 6570: loss = 5.4163 (0.890 sec/step)\n","I1215 19:41:11.403140 140303514462080 learning.py:512] global step 6570: loss = 5.4163 (0.890 sec/step)\n","INFO:tensorflow:global step 6571: loss = 5.0858 (0.906 sec/step)\n","I1215 19:41:12.310859 140303514462080 learning.py:512] global step 6571: loss = 5.0858 (0.906 sec/step)\n","INFO:tensorflow:global step 6572: loss = 4.3873 (0.900 sec/step)\n","I1215 19:41:13.212641 140303514462080 learning.py:512] global step 6572: loss = 4.3873 (0.900 sec/step)\n","INFO:tensorflow:global step 6573: loss = 4.1026 (0.890 sec/step)\n","I1215 19:41:14.103858 140303514462080 learning.py:512] global step 6573: loss = 4.1026 (0.890 sec/step)\n","INFO:tensorflow:global step 6574: loss = 5.4972 (0.903 sec/step)\n","I1215 19:41:15.008203 140303514462080 learning.py:512] global step 6574: loss = 5.4972 (0.903 sec/step)\n","INFO:tensorflow:global step 6575: loss = 4.3719 (0.891 sec/step)\n","I1215 19:41:15.900905 140303514462080 learning.py:512] global step 6575: loss = 4.3719 (0.891 sec/step)\n","INFO:tensorflow:global step 6576: loss = 4.0851 (0.894 sec/step)\n","I1215 19:41:16.796059 140303514462080 learning.py:512] global step 6576: loss = 4.0851 (0.894 sec/step)\n","INFO:tensorflow:global step 6577: loss = 4.0590 (0.892 sec/step)\n","I1215 19:41:17.689802 140303514462080 learning.py:512] global step 6577: loss = 4.0590 (0.892 sec/step)\n","INFO:tensorflow:global step 6578: loss = 2.6337 (0.910 sec/step)\n","I1215 19:41:18.601439 140303514462080 learning.py:512] global step 6578: loss = 2.6337 (0.910 sec/step)\n","INFO:tensorflow:global step 6579: loss = 4.2511 (0.904 sec/step)\n","I1215 19:41:19.507176 140303514462080 learning.py:512] global step 6579: loss = 4.2511 (0.904 sec/step)\n","INFO:tensorflow:global step 6580: loss = 4.0356 (0.910 sec/step)\n","I1215 19:41:20.418856 140303514462080 learning.py:512] global step 6580: loss = 4.0356 (0.910 sec/step)\n","INFO:tensorflow:global step 6581: loss = 3.8888 (0.905 sec/step)\n","I1215 19:41:21.325858 140303514462080 learning.py:512] global step 6581: loss = 3.8888 (0.905 sec/step)\n","INFO:tensorflow:global step 6582: loss = 4.0495 (0.900 sec/step)\n","I1215 19:41:22.227310 140303514462080 learning.py:512] global step 6582: loss = 4.0495 (0.900 sec/step)\n","INFO:tensorflow:global step 6583: loss = 5.0584 (0.895 sec/step)\n","I1215 19:41:23.124137 140303514462080 learning.py:512] global step 6583: loss = 5.0584 (0.895 sec/step)\n","INFO:tensorflow:global step 6584: loss = 3.3033 (0.892 sec/step)\n","I1215 19:41:24.017493 140303514462080 learning.py:512] global step 6584: loss = 3.3033 (0.892 sec/step)\n","INFO:tensorflow:global step 6585: loss = 3.1566 (0.885 sec/step)\n","I1215 19:41:24.904072 140303514462080 learning.py:512] global step 6585: loss = 3.1566 (0.885 sec/step)\n","INFO:tensorflow:global step 6586: loss = 4.6917 (0.898 sec/step)\n","I1215 19:41:25.803450 140303514462080 learning.py:512] global step 6586: loss = 4.6917 (0.898 sec/step)\n","INFO:tensorflow:global step 6587: loss = 4.1434 (0.892 sec/step)\n","I1215 19:41:26.696980 140303514462080 learning.py:512] global step 6587: loss = 4.1434 (0.892 sec/step)\n","INFO:tensorflow:global step 6588: loss = 3.2617 (0.906 sec/step)\n","I1215 19:41:27.604868 140303514462080 learning.py:512] global step 6588: loss = 3.2617 (0.906 sec/step)\n","INFO:tensorflow:global step 6589: loss = 4.7563 (0.900 sec/step)\n","I1215 19:41:28.506018 140303514462080 learning.py:512] global step 6589: loss = 4.7563 (0.900 sec/step)\n","INFO:tensorflow:global step 6590: loss = 4.0108 (0.910 sec/step)\n","I1215 19:41:29.417374 140303514462080 learning.py:512] global step 6590: loss = 4.0108 (0.910 sec/step)\n","INFO:tensorflow:global step 6591: loss = 2.4627 (0.917 sec/step)\n","I1215 19:41:30.336140 140303514462080 learning.py:512] global step 6591: loss = 2.4627 (0.917 sec/step)\n","INFO:tensorflow:global step 6592: loss = 3.7793 (0.893 sec/step)\n","I1215 19:41:31.230755 140303514462080 learning.py:512] global step 6592: loss = 3.7793 (0.893 sec/step)\n","INFO:tensorflow:global step 6593: loss = 3.7458 (0.904 sec/step)\n","I1215 19:41:32.136087 140303514462080 learning.py:512] global step 6593: loss = 3.7458 (0.904 sec/step)\n","INFO:tensorflow:global step 6594: loss = 3.2384 (0.886 sec/step)\n","I1215 19:41:33.023351 140303514462080 learning.py:512] global step 6594: loss = 3.2384 (0.886 sec/step)\n","INFO:tensorflow:global step 6595: loss = 4.6002 (0.898 sec/step)\n","I1215 19:41:33.922506 140303514462080 learning.py:512] global step 6595: loss = 4.6002 (0.898 sec/step)\n","INFO:tensorflow:global step 6596: loss = 4.1727 (0.908 sec/step)\n","I1215 19:41:34.832008 140303514462080 learning.py:512] global step 6596: loss = 4.1727 (0.908 sec/step)\n","INFO:tensorflow:global step 6597: loss = 4.6510 (0.922 sec/step)\n","I1215 19:41:35.778968 140303514462080 learning.py:512] global step 6597: loss = 4.6510 (0.922 sec/step)\n","INFO:tensorflow:Recording summary at step 6597.\n","I1215 19:41:37.027696 140299899541248 supervisor.py:1050] Recording summary at step 6597.\n","INFO:tensorflow:global step 6598: loss = 4.8914 (1.435 sec/step)\n","I1215 19:41:37.215591 140303514462080 learning.py:512] global step 6598: loss = 4.8914 (1.435 sec/step)\n","INFO:tensorflow:global step 6599: loss = 3.5498 (0.881 sec/step)\n","I1215 19:41:38.097907 140303514462080 learning.py:512] global step 6599: loss = 3.5498 (0.881 sec/step)\n","INFO:tensorflow:global step 6600: loss = 7.8782 (0.917 sec/step)\n","I1215 19:41:39.016382 140303514462080 learning.py:512] global step 6600: loss = 7.8782 (0.917 sec/step)\n","INFO:tensorflow:global step 6601: loss = 3.5632 (0.905 sec/step)\n","I1215 19:41:39.922370 140303514462080 learning.py:512] global step 6601: loss = 3.5632 (0.905 sec/step)\n","INFO:tensorflow:global step 6602: loss = 3.9421 (0.910 sec/step)\n","I1215 19:41:40.833934 140303514462080 learning.py:512] global step 6602: loss = 3.9421 (0.910 sec/step)\n","INFO:tensorflow:global step 6603: loss = 4.7204 (0.896 sec/step)\n","I1215 19:41:41.731032 140303514462080 learning.py:512] global step 6603: loss = 4.7204 (0.896 sec/step)\n","INFO:tensorflow:global step 6604: loss = 7.1457 (0.883 sec/step)\n","I1215 19:41:42.616128 140303514462080 learning.py:512] global step 6604: loss = 7.1457 (0.883 sec/step)\n","INFO:tensorflow:global step 6605: loss = 4.1416 (0.893 sec/step)\n","I1215 19:41:43.510575 140303514462080 learning.py:512] global step 6605: loss = 4.1416 (0.893 sec/step)\n","INFO:tensorflow:global step 6606: loss = 5.1471 (0.911 sec/step)\n","I1215 19:41:44.423801 140303514462080 learning.py:512] global step 6606: loss = 5.1471 (0.911 sec/step)\n","INFO:tensorflow:global step 6607: loss = 3.0304 (0.897 sec/step)\n","I1215 19:41:45.322426 140303514462080 learning.py:512] global step 6607: loss = 3.0304 (0.897 sec/step)\n","INFO:tensorflow:global step 6608: loss = 4.5314 (0.897 sec/step)\n","I1215 19:41:46.221300 140303514462080 learning.py:512] global step 6608: loss = 4.5314 (0.897 sec/step)\n","INFO:tensorflow:global step 6609: loss = 4.4239 (0.903 sec/step)\n","I1215 19:41:47.125365 140303514462080 learning.py:512] global step 6609: loss = 4.4239 (0.903 sec/step)\n","INFO:tensorflow:global step 6610: loss = 2.9650 (0.905 sec/step)\n","I1215 19:41:48.032299 140303514462080 learning.py:512] global step 6610: loss = 2.9650 (0.905 sec/step)\n","INFO:tensorflow:global step 6611: loss = 3.3483 (0.911 sec/step)\n","I1215 19:41:48.944464 140303514462080 learning.py:512] global step 6611: loss = 3.3483 (0.911 sec/step)\n","INFO:tensorflow:global step 6612: loss = 2.9764 (0.922 sec/step)\n","I1215 19:41:49.867769 140303514462080 learning.py:512] global step 6612: loss = 2.9764 (0.922 sec/step)\n","INFO:tensorflow:global step 6613: loss = 3.0590 (0.911 sec/step)\n","I1215 19:41:50.780260 140303514462080 learning.py:512] global step 6613: loss = 3.0590 (0.911 sec/step)\n","INFO:tensorflow:global step 6614: loss = 4.5735 (0.901 sec/step)\n","I1215 19:41:51.683053 140303514462080 learning.py:512] global step 6614: loss = 4.5735 (0.901 sec/step)\n","INFO:tensorflow:global step 6615: loss = 3.7964 (0.919 sec/step)\n","I1215 19:41:52.603432 140303514462080 learning.py:512] global step 6615: loss = 3.7964 (0.919 sec/step)\n","INFO:tensorflow:global step 6616: loss = 5.0763 (0.925 sec/step)\n","I1215 19:41:53.529837 140303514462080 learning.py:512] global step 6616: loss = 5.0763 (0.925 sec/step)\n","INFO:tensorflow:global step 6617: loss = 3.1174 (0.915 sec/step)\n","I1215 19:41:54.446490 140303514462080 learning.py:512] global step 6617: loss = 3.1174 (0.915 sec/step)\n","INFO:tensorflow:global step 6618: loss = 4.0648 (0.911 sec/step)\n","I1215 19:41:55.359035 140303514462080 learning.py:512] global step 6618: loss = 4.0648 (0.911 sec/step)\n","INFO:tensorflow:global step 6619: loss = 3.2822 (0.926 sec/step)\n","I1215 19:41:56.287052 140303514462080 learning.py:512] global step 6619: loss = 3.2822 (0.926 sec/step)\n","INFO:tensorflow:global step 6620: loss = 3.5240 (0.905 sec/step)\n","I1215 19:41:57.193075 140303514462080 learning.py:512] global step 6620: loss = 3.5240 (0.905 sec/step)\n","INFO:tensorflow:global step 6621: loss = 4.2218 (0.904 sec/step)\n","I1215 19:41:58.099769 140303514462080 learning.py:512] global step 6621: loss = 4.2218 (0.904 sec/step)\n","INFO:tensorflow:global step 6622: loss = 4.5658 (0.915 sec/step)\n","I1215 19:41:59.016109 140303514462080 learning.py:512] global step 6622: loss = 4.5658 (0.915 sec/step)\n","INFO:tensorflow:global step 6623: loss = 4.1316 (0.904 sec/step)\n","I1215 19:41:59.922037 140303514462080 learning.py:512] global step 6623: loss = 4.1316 (0.904 sec/step)\n","INFO:tensorflow:global step 6624: loss = 5.9842 (0.914 sec/step)\n","I1215 19:42:00.837543 140303514462080 learning.py:512] global step 6624: loss = 5.9842 (0.914 sec/step)\n","INFO:tensorflow:global step 6625: loss = 5.3730 (0.905 sec/step)\n","I1215 19:42:01.743527 140303514462080 learning.py:512] global step 6625: loss = 5.3730 (0.905 sec/step)\n","INFO:tensorflow:global step 6626: loss = 4.4621 (0.896 sec/step)\n","I1215 19:42:02.641074 140303514462080 learning.py:512] global step 6626: loss = 4.4621 (0.896 sec/step)\n","INFO:tensorflow:global step 6627: loss = 5.2869 (0.887 sec/step)\n","I1215 19:42:03.529467 140303514462080 learning.py:512] global step 6627: loss = 5.2869 (0.887 sec/step)\n","INFO:tensorflow:global step 6628: loss = 5.5982 (0.890 sec/step)\n","I1215 19:42:04.421305 140303514462080 learning.py:512] global step 6628: loss = 5.5982 (0.890 sec/step)\n","INFO:tensorflow:global step 6629: loss = 5.3588 (0.903 sec/step)\n","I1215 19:42:05.326076 140303514462080 learning.py:512] global step 6629: loss = 5.3588 (0.903 sec/step)\n","INFO:tensorflow:global step 6630: loss = 2.7083 (0.906 sec/step)\n","I1215 19:42:06.233804 140303514462080 learning.py:512] global step 6630: loss = 2.7083 (0.906 sec/step)\n","INFO:tensorflow:global step 6631: loss = 4.9224 (0.905 sec/step)\n","I1215 19:42:07.140693 140303514462080 learning.py:512] global step 6631: loss = 4.9224 (0.905 sec/step)\n","INFO:tensorflow:global step 6632: loss = 4.1357 (0.901 sec/step)\n","I1215 19:42:08.043551 140303514462080 learning.py:512] global step 6632: loss = 4.1357 (0.901 sec/step)\n","INFO:tensorflow:global step 6633: loss = 3.1499 (0.911 sec/step)\n","I1215 19:42:08.956382 140303514462080 learning.py:512] global step 6633: loss = 3.1499 (0.911 sec/step)\n","INFO:tensorflow:global step 6634: loss = 3.7749 (0.911 sec/step)\n","I1215 19:42:09.868604 140303514462080 learning.py:512] global step 6634: loss = 3.7749 (0.911 sec/step)\n","INFO:tensorflow:global step 6635: loss = 3.6250 (0.907 sec/step)\n","I1215 19:42:10.777502 140303514462080 learning.py:512] global step 6635: loss = 3.6250 (0.907 sec/step)\n","INFO:tensorflow:global step 6636: loss = 6.4542 (0.891 sec/step)\n","I1215 19:42:11.670216 140303514462080 learning.py:512] global step 6636: loss = 6.4542 (0.891 sec/step)\n","INFO:tensorflow:global step 6637: loss = 3.0526 (0.905 sec/step)\n","I1215 19:42:12.576399 140303514462080 learning.py:512] global step 6637: loss = 3.0526 (0.905 sec/step)\n","INFO:tensorflow:global step 6638: loss = 4.4800 (0.892 sec/step)\n","I1215 19:42:13.470099 140303514462080 learning.py:512] global step 6638: loss = 4.4800 (0.892 sec/step)\n","INFO:tensorflow:global step 6639: loss = 3.6274 (0.897 sec/step)\n","I1215 19:42:14.367947 140303514462080 learning.py:512] global step 6639: loss = 3.6274 (0.897 sec/step)\n","INFO:tensorflow:global step 6640: loss = 3.8902 (0.914 sec/step)\n","I1215 19:42:15.283160 140303514462080 learning.py:512] global step 6640: loss = 3.8902 (0.914 sec/step)\n","INFO:tensorflow:global step 6641: loss = 3.8444 (0.905 sec/step)\n","I1215 19:42:16.189864 140303514462080 learning.py:512] global step 6641: loss = 3.8444 (0.905 sec/step)\n","INFO:tensorflow:global step 6642: loss = 5.4726 (0.907 sec/step)\n","I1215 19:42:17.098161 140303514462080 learning.py:512] global step 6642: loss = 5.4726 (0.907 sec/step)\n","INFO:tensorflow:global step 6643: loss = 3.4236 (0.909 sec/step)\n","I1215 19:42:18.008282 140303514462080 learning.py:512] global step 6643: loss = 3.4236 (0.909 sec/step)\n","INFO:tensorflow:global step 6644: loss = 3.9426 (0.916 sec/step)\n","I1215 19:42:18.925757 140303514462080 learning.py:512] global step 6644: loss = 3.9426 (0.916 sec/step)\n","INFO:tensorflow:global step 6645: loss = 3.4860 (0.903 sec/step)\n","I1215 19:42:19.830710 140303514462080 learning.py:512] global step 6645: loss = 3.4860 (0.903 sec/step)\n","INFO:tensorflow:global step 6646: loss = 4.6144 (0.910 sec/step)\n","I1215 19:42:20.742788 140303514462080 learning.py:512] global step 6646: loss = 4.6144 (0.910 sec/step)\n","INFO:tensorflow:global step 6647: loss = 5.1025 (0.904 sec/step)\n","I1215 19:42:21.648497 140303514462080 learning.py:512] global step 6647: loss = 5.1025 (0.904 sec/step)\n","INFO:tensorflow:global step 6648: loss = 4.3118 (0.889 sec/step)\n","I1215 19:42:22.538684 140303514462080 learning.py:512] global step 6648: loss = 4.3118 (0.889 sec/step)\n","INFO:tensorflow:global step 6649: loss = 3.6270 (0.905 sec/step)\n","I1215 19:42:23.445393 140303514462080 learning.py:512] global step 6649: loss = 3.6270 (0.905 sec/step)\n","INFO:tensorflow:global step 6650: loss = 3.5071 (0.908 sec/step)\n","I1215 19:42:24.355107 140303514462080 learning.py:512] global step 6650: loss = 3.5071 (0.908 sec/step)\n","INFO:tensorflow:global step 6651: loss = 4.6837 (0.896 sec/step)\n","I1215 19:42:25.252774 140303514462080 learning.py:512] global step 6651: loss = 4.6837 (0.896 sec/step)\n","INFO:tensorflow:global step 6652: loss = 2.9621 (0.911 sec/step)\n","I1215 19:42:26.165076 140303514462080 learning.py:512] global step 6652: loss = 2.9621 (0.911 sec/step)\n","INFO:tensorflow:global step 6653: loss = 4.6938 (0.892 sec/step)\n","I1215 19:42:27.058362 140303514462080 learning.py:512] global step 6653: loss = 4.6938 (0.892 sec/step)\n","INFO:tensorflow:global step 6654: loss = 4.1698 (0.893 sec/step)\n","I1215 19:42:27.952885 140303514462080 learning.py:512] global step 6654: loss = 4.1698 (0.893 sec/step)\n","INFO:tensorflow:global step 6655: loss = 4.6688 (0.905 sec/step)\n","I1215 19:42:28.859675 140303514462080 learning.py:512] global step 6655: loss = 4.6688 (0.905 sec/step)\n","INFO:tensorflow:global step 6656: loss = 4.4117 (0.894 sec/step)\n","I1215 19:42:29.755116 140303514462080 learning.py:512] global step 6656: loss = 4.4117 (0.894 sec/step)\n","INFO:tensorflow:global step 6657: loss = 5.5410 (0.915 sec/step)\n","I1215 19:42:30.671735 140303514462080 learning.py:512] global step 6657: loss = 5.5410 (0.915 sec/step)\n","INFO:tensorflow:global step 6658: loss = 3.9631 (0.940 sec/step)\n","I1215 19:42:31.612954 140303514462080 learning.py:512] global step 6658: loss = 3.9631 (0.940 sec/step)\n","INFO:tensorflow:global step 6659: loss = 4.6666 (0.918 sec/step)\n","I1215 19:42:32.532843 140303514462080 learning.py:512] global step 6659: loss = 4.6666 (0.918 sec/step)\n","INFO:tensorflow:global step 6660: loss = 4.7454 (0.912 sec/step)\n","I1215 19:42:33.446606 140303514462080 learning.py:512] global step 6660: loss = 4.7454 (0.912 sec/step)\n","INFO:tensorflow:global step 6661: loss = 4.7830 (0.913 sec/step)\n","I1215 19:42:34.361248 140303514462080 learning.py:512] global step 6661: loss = 4.7830 (0.913 sec/step)\n","INFO:tensorflow:global step 6662: loss = 2.9726 (0.914 sec/step)\n","I1215 19:42:35.276707 140303514462080 learning.py:512] global step 6662: loss = 2.9726 (0.914 sec/step)\n","INFO:tensorflow:global step 6663: loss = 4.6334 (0.919 sec/step)\n","I1215 19:42:36.197013 140303514462080 learning.py:512] global step 6663: loss = 4.6334 (0.919 sec/step)\n","INFO:tensorflow:global step 6664: loss = 3.4251 (0.940 sec/step)\n","I1215 19:42:37.138694 140303514462080 learning.py:512] global step 6664: loss = 3.4251 (0.940 sec/step)\n","INFO:tensorflow:global step 6665: loss = 3.6666 (0.901 sec/step)\n","I1215 19:42:38.041010 140303514462080 learning.py:512] global step 6665: loss = 3.6666 (0.901 sec/step)\n","INFO:tensorflow:global step 6666: loss = 2.8557 (0.903 sec/step)\n","I1215 19:42:38.945951 140303514462080 learning.py:512] global step 6666: loss = 2.8557 (0.903 sec/step)\n","INFO:tensorflow:global step 6667: loss = 2.4474 (0.899 sec/step)\n","I1215 19:42:39.846135 140303514462080 learning.py:512] global step 6667: loss = 2.4474 (0.899 sec/step)\n","INFO:tensorflow:global step 6668: loss = 4.5062 (0.900 sec/step)\n","I1215 19:42:40.747602 140303514462080 learning.py:512] global step 6668: loss = 4.5062 (0.900 sec/step)\n","INFO:tensorflow:global step 6669: loss = 3.7002 (0.894 sec/step)\n","I1215 19:42:41.643271 140303514462080 learning.py:512] global step 6669: loss = 3.7002 (0.894 sec/step)\n","INFO:tensorflow:global step 6670: loss = 3.9732 (0.916 sec/step)\n","I1215 19:42:42.560856 140303514462080 learning.py:512] global step 6670: loss = 3.9732 (0.916 sec/step)\n","INFO:tensorflow:global step 6671: loss = 3.6869 (0.903 sec/step)\n","I1215 19:42:43.465750 140303514462080 learning.py:512] global step 6671: loss = 3.6869 (0.903 sec/step)\n","INFO:tensorflow:global step 6672: loss = 4.1700 (0.919 sec/step)\n","I1215 19:42:44.386046 140303514462080 learning.py:512] global step 6672: loss = 4.1700 (0.919 sec/step)\n","INFO:tensorflow:global step 6673: loss = 4.8519 (0.899 sec/step)\n","I1215 19:42:45.286572 140303514462080 learning.py:512] global step 6673: loss = 4.8519 (0.899 sec/step)\n","INFO:tensorflow:global step 6674: loss = 5.2384 (0.902 sec/step)\n","I1215 19:42:46.190508 140303514462080 learning.py:512] global step 6674: loss = 5.2384 (0.902 sec/step)\n","INFO:tensorflow:global step 6675: loss = 6.3874 (0.895 sec/step)\n","I1215 19:42:47.087165 140303514462080 learning.py:512] global step 6675: loss = 6.3874 (0.895 sec/step)\n","INFO:tensorflow:global step 6676: loss = 3.8061 (0.906 sec/step)\n","I1215 19:42:47.994961 140303514462080 learning.py:512] global step 6676: loss = 3.8061 (0.906 sec/step)\n","INFO:tensorflow:global step 6677: loss = 3.0981 (0.901 sec/step)\n","I1215 19:42:48.897233 140303514462080 learning.py:512] global step 6677: loss = 3.0981 (0.901 sec/step)\n","INFO:tensorflow:global step 6678: loss = 3.0499 (0.892 sec/step)\n","I1215 19:42:49.790798 140303514462080 learning.py:512] global step 6678: loss = 3.0499 (0.892 sec/step)\n","INFO:tensorflow:global step 6679: loss = 3.7291 (0.886 sec/step)\n","I1215 19:42:50.677926 140303514462080 learning.py:512] global step 6679: loss = 3.7291 (0.886 sec/step)\n","INFO:tensorflow:global step 6680: loss = 4.0093 (0.883 sec/step)\n","I1215 19:42:51.562511 140303514462080 learning.py:512] global step 6680: loss = 4.0093 (0.883 sec/step)\n","INFO:tensorflow:global step 6681: loss = 5.5291 (0.921 sec/step)\n","I1215 19:42:52.485048 140303514462080 learning.py:512] global step 6681: loss = 5.5291 (0.921 sec/step)\n","INFO:tensorflow:global step 6682: loss = 3.1570 (0.909 sec/step)\n","I1215 19:42:53.395893 140303514462080 learning.py:512] global step 6682: loss = 3.1570 (0.909 sec/step)\n","INFO:tensorflow:global step 6683: loss = 5.1610 (0.906 sec/step)\n","I1215 19:42:54.303499 140303514462080 learning.py:512] global step 6683: loss = 5.1610 (0.906 sec/step)\n","INFO:tensorflow:global step 6684: loss = 4.5816 (0.885 sec/step)\n","I1215 19:42:55.190266 140303514462080 learning.py:512] global step 6684: loss = 4.5816 (0.885 sec/step)\n","INFO:tensorflow:global step 6685: loss = 2.8776 (0.903 sec/step)\n","I1215 19:42:56.094575 140303514462080 learning.py:512] global step 6685: loss = 2.8776 (0.903 sec/step)\n","INFO:tensorflow:global step 6686: loss = 3.4180 (0.922 sec/step)\n","I1215 19:42:57.018819 140303514462080 learning.py:512] global step 6686: loss = 3.4180 (0.922 sec/step)\n","INFO:tensorflow:global step 6687: loss = 3.4949 (0.893 sec/step)\n","I1215 19:42:57.913248 140303514462080 learning.py:512] global step 6687: loss = 3.4949 (0.893 sec/step)\n","INFO:tensorflow:global step 6688: loss = 4.2199 (0.917 sec/step)\n","I1215 19:42:58.831862 140303514462080 learning.py:512] global step 6688: loss = 4.2199 (0.917 sec/step)\n","INFO:tensorflow:global step 6689: loss = 3.8900 (0.876 sec/step)\n","I1215 19:42:59.709847 140303514462080 learning.py:512] global step 6689: loss = 3.8900 (0.876 sec/step)\n","INFO:tensorflow:global step 6690: loss = 2.9811 (0.909 sec/step)\n","I1215 19:43:00.620275 140303514462080 learning.py:512] global step 6690: loss = 2.9811 (0.909 sec/step)\n","INFO:tensorflow:global step 6691: loss = 4.0119 (0.890 sec/step)\n","I1215 19:43:01.511455 140303514462080 learning.py:512] global step 6691: loss = 4.0119 (0.890 sec/step)\n","INFO:tensorflow:global step 6692: loss = 3.7177 (0.902 sec/step)\n","I1215 19:43:02.414818 140303514462080 learning.py:512] global step 6692: loss = 3.7177 (0.902 sec/step)\n","INFO:tensorflow:global step 6693: loss = 3.2126 (0.918 sec/step)\n","I1215 19:43:03.333968 140303514462080 learning.py:512] global step 6693: loss = 3.2126 (0.918 sec/step)\n","INFO:tensorflow:global step 6694: loss = 3.1276 (0.898 sec/step)\n","I1215 19:43:04.233445 140303514462080 learning.py:512] global step 6694: loss = 3.1276 (0.898 sec/step)\n","INFO:tensorflow:global step 6695: loss = 3.3093 (0.894 sec/step)\n","I1215 19:43:05.128993 140303514462080 learning.py:512] global step 6695: loss = 3.3093 (0.894 sec/step)\n","INFO:tensorflow:global step 6696: loss = 3.2703 (0.905 sec/step)\n","I1215 19:43:06.035141 140303514462080 learning.py:512] global step 6696: loss = 3.2703 (0.905 sec/step)\n","INFO:tensorflow:global step 6697: loss = 4.1545 (0.901 sec/step)\n","I1215 19:43:06.937374 140303514462080 learning.py:512] global step 6697: loss = 4.1545 (0.901 sec/step)\n","INFO:tensorflow:global step 6698: loss = 4.3693 (0.884 sec/step)\n","I1215 19:43:07.822662 140303514462080 learning.py:512] global step 6698: loss = 4.3693 (0.884 sec/step)\n","INFO:tensorflow:global step 6699: loss = 5.1017 (0.889 sec/step)\n","I1215 19:43:08.712922 140303514462080 learning.py:512] global step 6699: loss = 5.1017 (0.889 sec/step)\n","INFO:tensorflow:global step 6700: loss = 4.6888 (0.910 sec/step)\n","I1215 19:43:09.624365 140303514462080 learning.py:512] global step 6700: loss = 4.6888 (0.910 sec/step)\n","INFO:tensorflow:global step 6701: loss = 4.1599 (0.899 sec/step)\n","I1215 19:43:10.524638 140303514462080 learning.py:512] global step 6701: loss = 4.1599 (0.899 sec/step)\n","INFO:tensorflow:global step 6702: loss = 4.2167 (0.900 sec/step)\n","I1215 19:43:11.426479 140303514462080 learning.py:512] global step 6702: loss = 4.2167 (0.900 sec/step)\n","INFO:tensorflow:global step 6703: loss = 4.1196 (0.927 sec/step)\n","I1215 19:43:12.354476 140303514462080 learning.py:512] global step 6703: loss = 4.1196 (0.927 sec/step)\n","INFO:tensorflow:global step 6704: loss = 3.5614 (0.918 sec/step)\n","I1215 19:43:13.274027 140303514462080 learning.py:512] global step 6704: loss = 3.5614 (0.918 sec/step)\n","INFO:tensorflow:global step 6705: loss = 3.4546 (0.891 sec/step)\n","I1215 19:43:14.166538 140303514462080 learning.py:512] global step 6705: loss = 3.4546 (0.891 sec/step)\n","INFO:tensorflow:global step 6706: loss = 3.5882 (0.900 sec/step)\n","I1215 19:43:15.067675 140303514462080 learning.py:512] global step 6706: loss = 3.5882 (0.900 sec/step)\n","INFO:tensorflow:global step 6707: loss = 4.4163 (0.907 sec/step)\n","I1215 19:43:15.976037 140303514462080 learning.py:512] global step 6707: loss = 4.4163 (0.907 sec/step)\n","INFO:tensorflow:global step 6708: loss = 3.4649 (0.905 sec/step)\n","I1215 19:43:16.882632 140303514462080 learning.py:512] global step 6708: loss = 3.4649 (0.905 sec/step)\n","INFO:tensorflow:global step 6709: loss = 3.6295 (0.893 sec/step)\n","I1215 19:43:17.777316 140303514462080 learning.py:512] global step 6709: loss = 3.6295 (0.893 sec/step)\n","INFO:tensorflow:global step 6710: loss = 3.6625 (0.892 sec/step)\n","I1215 19:43:18.670632 140303514462080 learning.py:512] global step 6710: loss = 3.6625 (0.892 sec/step)\n","INFO:tensorflow:global step 6711: loss = 5.1977 (0.889 sec/step)\n","I1215 19:43:19.561258 140303514462080 learning.py:512] global step 6711: loss = 5.1977 (0.889 sec/step)\n","INFO:tensorflow:global step 6712: loss = 2.9379 (0.901 sec/step)\n","I1215 19:43:20.464224 140303514462080 learning.py:512] global step 6712: loss = 2.9379 (0.901 sec/step)\n","INFO:tensorflow:global step 6713: loss = 5.9277 (0.889 sec/step)\n","I1215 19:43:21.354412 140303514462080 learning.py:512] global step 6713: loss = 5.9277 (0.889 sec/step)\n","INFO:tensorflow:global step 6714: loss = 4.9955 (0.878 sec/step)\n","I1215 19:43:22.234073 140303514462080 learning.py:512] global step 6714: loss = 4.9955 (0.878 sec/step)\n","INFO:tensorflow:global step 6715: loss = 3.2482 (0.893 sec/step)\n","I1215 19:43:23.128774 140303514462080 learning.py:512] global step 6715: loss = 3.2482 (0.893 sec/step)\n","INFO:tensorflow:global step 6716: loss = 4.9242 (0.898 sec/step)\n","I1215 19:43:24.028481 140303514462080 learning.py:512] global step 6716: loss = 4.9242 (0.898 sec/step)\n","INFO:tensorflow:global step 6717: loss = 3.3280 (0.896 sec/step)\n","I1215 19:43:24.926140 140303514462080 learning.py:512] global step 6717: loss = 3.3280 (0.896 sec/step)\n","INFO:tensorflow:global step 6718: loss = 2.6986 (0.879 sec/step)\n","I1215 19:43:25.807040 140303514462080 learning.py:512] global step 6718: loss = 2.6986 (0.879 sec/step)\n","INFO:tensorflow:global step 6719: loss = 3.7023 (0.893 sec/step)\n","I1215 19:43:26.701569 140303514462080 learning.py:512] global step 6719: loss = 3.7023 (0.893 sec/step)\n","INFO:tensorflow:global step 6720: loss = 5.9358 (0.894 sec/step)\n","I1215 19:43:27.596782 140303514462080 learning.py:512] global step 6720: loss = 5.9358 (0.894 sec/step)\n","INFO:tensorflow:global step 6721: loss = 3.2532 (0.906 sec/step)\n","I1215 19:43:28.504491 140303514462080 learning.py:512] global step 6721: loss = 3.2532 (0.906 sec/step)\n","INFO:tensorflow:global step 6722: loss = 4.1259 (0.909 sec/step)\n","I1215 19:43:29.414837 140303514462080 learning.py:512] global step 6722: loss = 4.1259 (0.909 sec/step)\n","INFO:tensorflow:global step 6723: loss = 4.1360 (0.909 sec/step)\n","I1215 19:43:30.325596 140303514462080 learning.py:512] global step 6723: loss = 4.1360 (0.909 sec/step)\n","INFO:tensorflow:global step 6724: loss = 4.9669 (0.909 sec/step)\n","I1215 19:43:31.235754 140303514462080 learning.py:512] global step 6724: loss = 4.9669 (0.909 sec/step)\n","INFO:tensorflow:global step 6725: loss = 5.2217 (0.905 sec/step)\n","I1215 19:43:32.142035 140303514462080 learning.py:512] global step 6725: loss = 5.2217 (0.905 sec/step)\n","INFO:tensorflow:global step 6726: loss = 3.3048 (0.895 sec/step)\n","I1215 19:43:33.038289 140303514462080 learning.py:512] global step 6726: loss = 3.3048 (0.895 sec/step)\n","INFO:tensorflow:global step 6727: loss = 3.8180 (0.892 sec/step)\n","I1215 19:43:33.931524 140303514462080 learning.py:512] global step 6727: loss = 3.8180 (0.892 sec/step)\n","INFO:tensorflow:global step 6728: loss = 3.1296 (0.907 sec/step)\n","I1215 19:43:34.839777 140303514462080 learning.py:512] global step 6728: loss = 3.1296 (0.907 sec/step)\n","INFO:tensorflow:global step 6729: loss = 5.6214 (0.904 sec/step)\n","I1215 19:43:35.744821 140303514462080 learning.py:512] global step 6729: loss = 5.6214 (0.904 sec/step)\n","INFO:tensorflow:Recording summary at step 6729.\n","I1215 19:43:37.085686 140299899541248 supervisor.py:1050] Recording summary at step 6729.\n","INFO:tensorflow:global step 6730: loss = 3.9751 (1.448 sec/step)\n","I1215 19:43:37.194414 140303514462080 learning.py:512] global step 6730: loss = 3.9751 (1.448 sec/step)\n","INFO:tensorflow:global step 6731: loss = 3.2769 (0.885 sec/step)\n","I1215 19:43:38.080934 140303514462080 learning.py:512] global step 6731: loss = 3.2769 (0.885 sec/step)\n","INFO:tensorflow:global step 6732: loss = 4.5538 (0.889 sec/step)\n","I1215 19:43:38.970869 140303514462080 learning.py:512] global step 6732: loss = 4.5538 (0.889 sec/step)\n","INFO:tensorflow:global step 6733: loss = 4.5853 (0.881 sec/step)\n","I1215 19:43:39.853623 140303514462080 learning.py:512] global step 6733: loss = 4.5853 (0.881 sec/step)\n","INFO:tensorflow:global step 6734: loss = 4.1813 (0.888 sec/step)\n","I1215 19:43:40.742952 140303514462080 learning.py:512] global step 6734: loss = 4.1813 (0.888 sec/step)\n","INFO:tensorflow:global step 6735: loss = 4.4908 (0.900 sec/step)\n","I1215 19:43:41.644665 140303514462080 learning.py:512] global step 6735: loss = 4.4908 (0.900 sec/step)\n","INFO:tensorflow:global step 6736: loss = 4.0051 (0.908 sec/step)\n","I1215 19:43:42.553894 140303514462080 learning.py:512] global step 6736: loss = 4.0051 (0.908 sec/step)\n","INFO:tensorflow:global step 6737: loss = 3.2214 (0.902 sec/step)\n","I1215 19:43:43.457068 140303514462080 learning.py:512] global step 6737: loss = 3.2214 (0.902 sec/step)\n","INFO:tensorflow:global step 6738: loss = 3.1436 (0.914 sec/step)\n","I1215 19:43:44.372542 140303514462080 learning.py:512] global step 6738: loss = 3.1436 (0.914 sec/step)\n","INFO:tensorflow:global step 6739: loss = 5.2968 (0.892 sec/step)\n","I1215 19:43:45.266588 140303514462080 learning.py:512] global step 6739: loss = 5.2968 (0.892 sec/step)\n","INFO:tensorflow:global step 6740: loss = 3.0131 (0.888 sec/step)\n","I1215 19:43:46.155923 140303514462080 learning.py:512] global step 6740: loss = 3.0131 (0.888 sec/step)\n","INFO:tensorflow:global step 6741: loss = 3.6281 (0.897 sec/step)\n","I1215 19:43:47.058423 140303514462080 learning.py:512] global step 6741: loss = 3.6281 (0.897 sec/step)\n","INFO:tensorflow:global step 6742: loss = 3.3901 (0.891 sec/step)\n","I1215 19:43:47.953726 140303514462080 learning.py:512] global step 6742: loss = 3.3901 (0.891 sec/step)\n","INFO:tensorflow:global step 6743: loss = 4.4047 (0.897 sec/step)\n","I1215 19:43:48.852139 140303514462080 learning.py:512] global step 6743: loss = 4.4047 (0.897 sec/step)\n","INFO:tensorflow:global step 6744: loss = 3.8844 (0.894 sec/step)\n","I1215 19:43:49.747572 140303514462080 learning.py:512] global step 6744: loss = 3.8844 (0.894 sec/step)\n","INFO:tensorflow:global step 6745: loss = 4.0983 (0.896 sec/step)\n","I1215 19:43:50.645467 140303514462080 learning.py:512] global step 6745: loss = 4.0983 (0.896 sec/step)\n","INFO:tensorflow:global step 6746: loss = 3.1406 (0.884 sec/step)\n","I1215 19:43:51.530819 140303514462080 learning.py:512] global step 6746: loss = 3.1406 (0.884 sec/step)\n","INFO:tensorflow:global step 6747: loss = 2.7121 (0.880 sec/step)\n","I1215 19:43:52.412299 140303514462080 learning.py:512] global step 6747: loss = 2.7121 (0.880 sec/step)\n","INFO:tensorflow:global step 6748: loss = 3.2997 (0.898 sec/step)\n","I1215 19:43:53.311734 140303514462080 learning.py:512] global step 6748: loss = 3.2997 (0.898 sec/step)\n","INFO:tensorflow:global step 6749: loss = 5.3392 (0.888 sec/step)\n","I1215 19:43:54.201392 140303514462080 learning.py:512] global step 6749: loss = 5.3392 (0.888 sec/step)\n","INFO:tensorflow:global step 6750: loss = 3.3909 (0.907 sec/step)\n","I1215 19:43:55.109448 140303514462080 learning.py:512] global step 6750: loss = 3.3909 (0.907 sec/step)\n","INFO:tensorflow:global step 6751: loss = 4.2194 (0.884 sec/step)\n","I1215 19:43:55.995132 140303514462080 learning.py:512] global step 6751: loss = 4.2194 (0.884 sec/step)\n","INFO:tensorflow:global step 6752: loss = 5.2933 (0.904 sec/step)\n","I1215 19:43:56.900941 140303514462080 learning.py:512] global step 6752: loss = 5.2933 (0.904 sec/step)\n","INFO:tensorflow:global step 6753: loss = 3.1629 (0.913 sec/step)\n","I1215 19:43:57.815847 140303514462080 learning.py:512] global step 6753: loss = 3.1629 (0.913 sec/step)\n","INFO:tensorflow:global step 6754: loss = 7.0572 (0.898 sec/step)\n","I1215 19:43:58.714924 140303514462080 learning.py:512] global step 6754: loss = 7.0572 (0.898 sec/step)\n","INFO:tensorflow:global step 6755: loss = 3.3766 (0.880 sec/step)\n","I1215 19:43:59.596793 140303514462080 learning.py:512] global step 6755: loss = 3.3766 (0.880 sec/step)\n","INFO:tensorflow:global step 6756: loss = 7.4435 (0.900 sec/step)\n","I1215 19:44:00.497946 140303514462080 learning.py:512] global step 6756: loss = 7.4435 (0.900 sec/step)\n","INFO:tensorflow:global step 6757: loss = 6.2524 (0.890 sec/step)\n","I1215 19:44:01.389828 140303514462080 learning.py:512] global step 6757: loss = 6.2524 (0.890 sec/step)\n","INFO:tensorflow:global step 6758: loss = 3.7798 (0.893 sec/step)\n","I1215 19:44:02.284014 140303514462080 learning.py:512] global step 6758: loss = 3.7798 (0.893 sec/step)\n","INFO:tensorflow:global step 6759: loss = 5.0312 (0.896 sec/step)\n","I1215 19:44:03.181489 140303514462080 learning.py:512] global step 6759: loss = 5.0312 (0.896 sec/step)\n","INFO:tensorflow:global step 6760: loss = 3.1241 (0.902 sec/step)\n","I1215 19:44:04.084743 140303514462080 learning.py:512] global step 6760: loss = 3.1241 (0.902 sec/step)\n","INFO:tensorflow:global step 6761: loss = 3.4161 (0.902 sec/step)\n","I1215 19:44:04.988520 140303514462080 learning.py:512] global step 6761: loss = 3.4161 (0.902 sec/step)\n","INFO:tensorflow:global step 6762: loss = 4.7703 (0.948 sec/step)\n","I1215 19:44:05.938348 140303514462080 learning.py:512] global step 6762: loss = 4.7703 (0.948 sec/step)\n","INFO:tensorflow:global step 6763: loss = 4.2405 (0.930 sec/step)\n","I1215 19:44:06.869585 140303514462080 learning.py:512] global step 6763: loss = 4.2405 (0.930 sec/step)\n","INFO:tensorflow:global step 6764: loss = 3.9376 (0.914 sec/step)\n","I1215 19:44:07.785207 140303514462080 learning.py:512] global step 6764: loss = 3.9376 (0.914 sec/step)\n","INFO:tensorflow:global step 6765: loss = 5.3350 (0.914 sec/step)\n","I1215 19:44:08.701292 140303514462080 learning.py:512] global step 6765: loss = 5.3350 (0.914 sec/step)\n","INFO:tensorflow:global step 6766: loss = 3.6472 (0.937 sec/step)\n","I1215 19:44:09.639936 140303514462080 learning.py:512] global step 6766: loss = 3.6472 (0.937 sec/step)\n","INFO:tensorflow:global step 6767: loss = 3.2114 (0.929 sec/step)\n","I1215 19:44:10.570463 140303514462080 learning.py:512] global step 6767: loss = 3.2114 (0.929 sec/step)\n","INFO:tensorflow:global step 6768: loss = 3.3666 (0.912 sec/step)\n","I1215 19:44:11.484314 140303514462080 learning.py:512] global step 6768: loss = 3.3666 (0.912 sec/step)\n","INFO:tensorflow:global step 6769: loss = 5.7575 (0.945 sec/step)\n","I1215 19:44:12.430677 140303514462080 learning.py:512] global step 6769: loss = 5.7575 (0.945 sec/step)\n","INFO:tensorflow:global step 6770: loss = 3.7146 (0.914 sec/step)\n","I1215 19:44:13.346779 140303514462080 learning.py:512] global step 6770: loss = 3.7146 (0.914 sec/step)\n","INFO:tensorflow:global step 6771: loss = 2.9962 (0.925 sec/step)\n","I1215 19:44:14.273221 140303514462080 learning.py:512] global step 6771: loss = 2.9962 (0.925 sec/step)\n","INFO:tensorflow:global step 6772: loss = 3.5800 (0.941 sec/step)\n","I1215 19:44:15.216114 140303514462080 learning.py:512] global step 6772: loss = 3.5800 (0.941 sec/step)\n","INFO:tensorflow:global step 6773: loss = 5.0282 (0.926 sec/step)\n","I1215 19:44:16.144032 140303514462080 learning.py:512] global step 6773: loss = 5.0282 (0.926 sec/step)\n","INFO:tensorflow:global step 6774: loss = 4.9718 (0.901 sec/step)\n","I1215 19:44:17.046090 140303514462080 learning.py:512] global step 6774: loss = 4.9718 (0.901 sec/step)\n","INFO:tensorflow:global step 6775: loss = 4.5713 (0.892 sec/step)\n","I1215 19:44:17.939480 140303514462080 learning.py:512] global step 6775: loss = 4.5713 (0.892 sec/step)\n","INFO:tensorflow:global step 6776: loss = 3.9777 (0.907 sec/step)\n","I1215 19:44:18.847664 140303514462080 learning.py:512] global step 6776: loss = 3.9777 (0.907 sec/step)\n","INFO:tensorflow:global step 6777: loss = 3.5032 (0.899 sec/step)\n","I1215 19:44:19.747967 140303514462080 learning.py:512] global step 6777: loss = 3.5032 (0.899 sec/step)\n","INFO:tensorflow:global step 6778: loss = 4.1338 (0.919 sec/step)\n","I1215 19:44:20.668438 140303514462080 learning.py:512] global step 6778: loss = 4.1338 (0.919 sec/step)\n","INFO:tensorflow:global step 6779: loss = 6.3615 (0.887 sec/step)\n","I1215 19:44:21.557068 140303514462080 learning.py:512] global step 6779: loss = 6.3615 (0.887 sec/step)\n","INFO:tensorflow:global step 6780: loss = 4.8681 (0.899 sec/step)\n","I1215 19:44:22.458007 140303514462080 learning.py:512] global step 6780: loss = 4.8681 (0.899 sec/step)\n","INFO:tensorflow:global step 6781: loss = 4.1589 (0.905 sec/step)\n","I1215 19:44:23.365051 140303514462080 learning.py:512] global step 6781: loss = 4.1589 (0.905 sec/step)\n","INFO:tensorflow:global step 6782: loss = 4.1382 (0.890 sec/step)\n","I1215 19:44:24.256817 140303514462080 learning.py:512] global step 6782: loss = 4.1382 (0.890 sec/step)\n","INFO:tensorflow:global step 6783: loss = 4.8015 (0.900 sec/step)\n","I1215 19:44:25.158093 140303514462080 learning.py:512] global step 6783: loss = 4.8015 (0.900 sec/step)\n","INFO:tensorflow:global step 6784: loss = 4.1498 (0.909 sec/step)\n","I1215 19:44:26.068528 140303514462080 learning.py:512] global step 6784: loss = 4.1498 (0.909 sec/step)\n","INFO:tensorflow:global step 6785: loss = 3.0119 (0.902 sec/step)\n","I1215 19:44:26.971857 140303514462080 learning.py:512] global step 6785: loss = 3.0119 (0.902 sec/step)\n","INFO:tensorflow:global step 6786: loss = 3.1699 (0.890 sec/step)\n","I1215 19:44:27.863556 140303514462080 learning.py:512] global step 6786: loss = 3.1699 (0.890 sec/step)\n","INFO:tensorflow:global step 6787: loss = 5.9284 (0.899 sec/step)\n","I1215 19:44:28.763624 140303514462080 learning.py:512] global step 6787: loss = 5.9284 (0.899 sec/step)\n","INFO:tensorflow:global step 6788: loss = 4.7339 (0.902 sec/step)\n","I1215 19:44:29.666570 140303514462080 learning.py:512] global step 6788: loss = 4.7339 (0.902 sec/step)\n","INFO:tensorflow:global step 6789: loss = 4.2394 (0.901 sec/step)\n","I1215 19:44:30.568545 140303514462080 learning.py:512] global step 6789: loss = 4.2394 (0.901 sec/step)\n","INFO:tensorflow:global step 6790: loss = 4.0043 (0.898 sec/step)\n","I1215 19:44:31.468349 140303514462080 learning.py:512] global step 6790: loss = 4.0043 (0.898 sec/step)\n","INFO:tensorflow:global step 6791: loss = 5.1181 (0.909 sec/step)\n","I1215 19:44:32.379314 140303514462080 learning.py:512] global step 6791: loss = 5.1181 (0.909 sec/step)\n","INFO:tensorflow:global step 6792: loss = 4.2749 (0.901 sec/step)\n","I1215 19:44:33.282246 140303514462080 learning.py:512] global step 6792: loss = 4.2749 (0.901 sec/step)\n","INFO:tensorflow:global step 6793: loss = 3.8837 (0.894 sec/step)\n","I1215 19:44:34.178067 140303514462080 learning.py:512] global step 6793: loss = 3.8837 (0.894 sec/step)\n","INFO:tensorflow:global step 6794: loss = 4.1612 (0.910 sec/step)\n","I1215 19:44:35.089666 140303514462080 learning.py:512] global step 6794: loss = 4.1612 (0.910 sec/step)\n","INFO:tensorflow:global step 6795: loss = 4.0880 (0.896 sec/step)\n","I1215 19:44:35.986892 140303514462080 learning.py:512] global step 6795: loss = 4.0880 (0.896 sec/step)\n","INFO:tensorflow:global step 6796: loss = 4.3442 (0.938 sec/step)\n","I1215 19:44:36.926912 140303514462080 learning.py:512] global step 6796: loss = 4.3442 (0.938 sec/step)\n","INFO:tensorflow:global step 6797: loss = 4.1627 (0.899 sec/step)\n","I1215 19:44:37.827499 140303514462080 learning.py:512] global step 6797: loss = 4.1627 (0.899 sec/step)\n","INFO:tensorflow:global step 6798: loss = 5.2169 (0.893 sec/step)\n","I1215 19:44:38.722415 140303514462080 learning.py:512] global step 6798: loss = 5.2169 (0.893 sec/step)\n","INFO:tensorflow:global step 6799: loss = 3.2219 (0.909 sec/step)\n","I1215 19:44:39.632809 140303514462080 learning.py:512] global step 6799: loss = 3.2219 (0.909 sec/step)\n","INFO:tensorflow:global step 6800: loss = 4.7367 (0.901 sec/step)\n","I1215 19:44:40.535575 140303514462080 learning.py:512] global step 6800: loss = 4.7367 (0.901 sec/step)\n","INFO:tensorflow:global step 6801: loss = 4.5469 (0.891 sec/step)\n","I1215 19:44:41.427953 140303514462080 learning.py:512] global step 6801: loss = 4.5469 (0.891 sec/step)\n","INFO:tensorflow:global step 6802: loss = 3.6864 (0.905 sec/step)\n","I1215 19:44:42.334980 140303514462080 learning.py:512] global step 6802: loss = 3.6864 (0.905 sec/step)\n","INFO:tensorflow:global step 6803: loss = 3.8667 (0.903 sec/step)\n","I1215 19:44:43.239581 140303514462080 learning.py:512] global step 6803: loss = 3.8667 (0.903 sec/step)\n","INFO:tensorflow:global step 6804: loss = 4.8679 (0.899 sec/step)\n","I1215 19:44:44.140339 140303514462080 learning.py:512] global step 6804: loss = 4.8679 (0.899 sec/step)\n","INFO:tensorflow:global step 6805: loss = 3.5929 (0.887 sec/step)\n","I1215 19:44:45.029107 140303514462080 learning.py:512] global step 6805: loss = 3.5929 (0.887 sec/step)\n","INFO:tensorflow:global step 6806: loss = 3.8545 (0.889 sec/step)\n","I1215 19:44:45.920027 140303514462080 learning.py:512] global step 6806: loss = 3.8545 (0.889 sec/step)\n","INFO:tensorflow:global step 6807: loss = 2.8178 (0.875 sec/step)\n","I1215 19:44:46.796661 140303514462080 learning.py:512] global step 6807: loss = 2.8178 (0.875 sec/step)\n","INFO:tensorflow:global step 6808: loss = 2.8010 (0.914 sec/step)\n","I1215 19:44:47.712423 140303514462080 learning.py:512] global step 6808: loss = 2.8010 (0.914 sec/step)\n","INFO:tensorflow:global step 6809: loss = 5.1009 (0.915 sec/step)\n","I1215 19:44:48.629155 140303514462080 learning.py:512] global step 6809: loss = 5.1009 (0.915 sec/step)\n","INFO:tensorflow:global step 6810: loss = 4.0507 (0.894 sec/step)\n","I1215 19:44:49.524253 140303514462080 learning.py:512] global step 6810: loss = 4.0507 (0.894 sec/step)\n","INFO:tensorflow:global step 6811: loss = 4.5561 (0.897 sec/step)\n","I1215 19:44:50.422545 140303514462080 learning.py:512] global step 6811: loss = 4.5561 (0.897 sec/step)\n","INFO:tensorflow:global step 6812: loss = 4.5317 (0.900 sec/step)\n","I1215 19:44:51.324341 140303514462080 learning.py:512] global step 6812: loss = 4.5317 (0.900 sec/step)\n","INFO:tensorflow:global step 6813: loss = 3.6687 (0.900 sec/step)\n","I1215 19:44:52.225675 140303514462080 learning.py:512] global step 6813: loss = 3.6687 (0.900 sec/step)\n","INFO:tensorflow:global step 6814: loss = 3.5944 (0.908 sec/step)\n","I1215 19:44:53.135007 140303514462080 learning.py:512] global step 6814: loss = 3.5944 (0.908 sec/step)\n","INFO:tensorflow:global step 6815: loss = 4.8708 (0.888 sec/step)\n","I1215 19:44:54.024410 140303514462080 learning.py:512] global step 6815: loss = 4.8708 (0.888 sec/step)\n","INFO:tensorflow:global step 6816: loss = 4.9042 (0.899 sec/step)\n","I1215 19:44:54.925474 140303514462080 learning.py:512] global step 6816: loss = 4.9042 (0.899 sec/step)\n","INFO:tensorflow:global step 6817: loss = 4.5250 (0.893 sec/step)\n","I1215 19:44:55.820484 140303514462080 learning.py:512] global step 6817: loss = 4.5250 (0.893 sec/step)\n","INFO:tensorflow:global step 6818: loss = 3.4761 (0.898 sec/step)\n","I1215 19:44:56.720520 140303514462080 learning.py:512] global step 6818: loss = 3.4761 (0.898 sec/step)\n","INFO:tensorflow:global step 6819: loss = 4.2497 (0.883 sec/step)\n","I1215 19:44:57.604940 140303514462080 learning.py:512] global step 6819: loss = 4.2497 (0.883 sec/step)\n","INFO:tensorflow:global step 6820: loss = 4.2335 (0.900 sec/step)\n","I1215 19:44:58.506789 140303514462080 learning.py:512] global step 6820: loss = 4.2335 (0.900 sec/step)\n","INFO:tensorflow:global step 6821: loss = 3.3146 (0.883 sec/step)\n","I1215 19:44:59.391715 140303514462080 learning.py:512] global step 6821: loss = 3.3146 (0.883 sec/step)\n","INFO:tensorflow:global step 6822: loss = 2.9965 (0.887 sec/step)\n","I1215 19:45:00.280641 140303514462080 learning.py:512] global step 6822: loss = 2.9965 (0.887 sec/step)\n","INFO:tensorflow:global step 6823: loss = 4.1622 (0.879 sec/step)\n","I1215 19:45:01.161885 140303514462080 learning.py:512] global step 6823: loss = 4.1622 (0.879 sec/step)\n","INFO:tensorflow:global step 6824: loss = 2.6863 (0.877 sec/step)\n","I1215 19:45:02.040811 140303514462080 learning.py:512] global step 6824: loss = 2.6863 (0.877 sec/step)\n","INFO:tensorflow:global step 6825: loss = 3.0689 (0.910 sec/step)\n","I1215 19:45:02.952522 140303514462080 learning.py:512] global step 6825: loss = 3.0689 (0.910 sec/step)\n","INFO:tensorflow:global step 6826: loss = 4.2831 (0.911 sec/step)\n","I1215 19:45:03.864980 140303514462080 learning.py:512] global step 6826: loss = 4.2831 (0.911 sec/step)\n","INFO:tensorflow:global step 6827: loss = 4.4141 (0.892 sec/step)\n","I1215 19:45:04.758406 140303514462080 learning.py:512] global step 6827: loss = 4.4141 (0.892 sec/step)\n","INFO:tensorflow:global step 6828: loss = 2.6332 (0.903 sec/step)\n","I1215 19:45:05.662970 140303514462080 learning.py:512] global step 6828: loss = 2.6332 (0.903 sec/step)\n","INFO:tensorflow:global step 6829: loss = 4.0119 (0.900 sec/step)\n","I1215 19:45:06.564592 140303514462080 learning.py:512] global step 6829: loss = 4.0119 (0.900 sec/step)\n","INFO:tensorflow:global step 6830: loss = 3.7385 (0.907 sec/step)\n","I1215 19:45:07.472844 140303514462080 learning.py:512] global step 6830: loss = 3.7385 (0.907 sec/step)\n","INFO:tensorflow:global step 6831: loss = 6.6121 (0.908 sec/step)\n","I1215 19:45:08.382339 140303514462080 learning.py:512] global step 6831: loss = 6.6121 (0.908 sec/step)\n","INFO:tensorflow:global step 6832: loss = 3.2126 (0.920 sec/step)\n","I1215 19:45:09.303844 140303514462080 learning.py:512] global step 6832: loss = 3.2126 (0.920 sec/step)\n","INFO:tensorflow:global step 6833: loss = 3.1866 (0.893 sec/step)\n","I1215 19:45:10.198642 140303514462080 learning.py:512] global step 6833: loss = 3.1866 (0.893 sec/step)\n","INFO:tensorflow:global step 6834: loss = 3.2859 (0.915 sec/step)\n","I1215 19:45:11.115015 140303514462080 learning.py:512] global step 6834: loss = 3.2859 (0.915 sec/step)\n","INFO:tensorflow:global step 6835: loss = 2.5817 (0.910 sec/step)\n","I1215 19:45:12.025997 140303514462080 learning.py:512] global step 6835: loss = 2.5817 (0.910 sec/step)\n","INFO:tensorflow:global step 6836: loss = 4.5023 (0.882 sec/step)\n","I1215 19:45:12.910047 140303514462080 learning.py:512] global step 6836: loss = 4.5023 (0.882 sec/step)\n","INFO:tensorflow:global step 6837: loss = 3.4556 (0.906 sec/step)\n","I1215 19:45:13.817922 140303514462080 learning.py:512] global step 6837: loss = 3.4556 (0.906 sec/step)\n","INFO:tensorflow:global step 6838: loss = 4.3148 (0.923 sec/step)\n","I1215 19:45:14.742868 140303514462080 learning.py:512] global step 6838: loss = 4.3148 (0.923 sec/step)\n","INFO:tensorflow:global step 6839: loss = 5.4675 (0.899 sec/step)\n","I1215 19:45:15.643528 140303514462080 learning.py:512] global step 6839: loss = 5.4675 (0.899 sec/step)\n","INFO:tensorflow:global step 6840: loss = 4.1257 (0.901 sec/step)\n","I1215 19:45:16.545641 140303514462080 learning.py:512] global step 6840: loss = 4.1257 (0.901 sec/step)\n","INFO:tensorflow:global step 6841: loss = 2.0853 (0.888 sec/step)\n","I1215 19:45:17.435261 140303514462080 learning.py:512] global step 6841: loss = 2.0853 (0.888 sec/step)\n","INFO:tensorflow:global step 6842: loss = 3.2359 (0.884 sec/step)\n","I1215 19:45:18.320883 140303514462080 learning.py:512] global step 6842: loss = 3.2359 (0.884 sec/step)\n","INFO:tensorflow:global step 6843: loss = 5.7215 (0.906 sec/step)\n","I1215 19:45:19.228842 140303514462080 learning.py:512] global step 6843: loss = 5.7215 (0.906 sec/step)\n","INFO:tensorflow:global step 6844: loss = 5.1399 (0.895 sec/step)\n","I1215 19:45:20.125337 140303514462080 learning.py:512] global step 6844: loss = 5.1399 (0.895 sec/step)\n","INFO:tensorflow:global step 6845: loss = 2.6938 (0.899 sec/step)\n","I1215 19:45:21.026428 140303514462080 learning.py:512] global step 6845: loss = 2.6938 (0.899 sec/step)\n","INFO:tensorflow:global step 6846: loss = 3.8154 (0.890 sec/step)\n","I1215 19:45:21.918095 140303514462080 learning.py:512] global step 6846: loss = 3.8154 (0.890 sec/step)\n","INFO:tensorflow:global step 6847: loss = 2.4989 (0.888 sec/step)\n","I1215 19:45:22.807210 140303514462080 learning.py:512] global step 6847: loss = 2.4989 (0.888 sec/step)\n","INFO:tensorflow:global step 6848: loss = 7.0972 (0.919 sec/step)\n","I1215 19:45:23.727765 140303514462080 learning.py:512] global step 6848: loss = 7.0972 (0.919 sec/step)\n","INFO:tensorflow:global step 6849: loss = 4.5546 (0.917 sec/step)\n","I1215 19:45:24.645927 140303514462080 learning.py:512] global step 6849: loss = 4.5546 (0.917 sec/step)\n","INFO:tensorflow:global step 6850: loss = 4.0651 (0.921 sec/step)\n","I1215 19:45:25.568136 140303514462080 learning.py:512] global step 6850: loss = 4.0651 (0.921 sec/step)\n","INFO:tensorflow:global step 6851: loss = 3.9308 (0.887 sec/step)\n","I1215 19:45:26.456748 140303514462080 learning.py:512] global step 6851: loss = 3.9308 (0.887 sec/step)\n","INFO:tensorflow:global step 6852: loss = 3.9988 (0.907 sec/step)\n","I1215 19:45:27.365885 140303514462080 learning.py:512] global step 6852: loss = 3.9988 (0.907 sec/step)\n","INFO:tensorflow:global step 6853: loss = 3.2060 (0.896 sec/step)\n","I1215 19:45:28.263637 140303514462080 learning.py:512] global step 6853: loss = 3.2060 (0.896 sec/step)\n","INFO:tensorflow:global step 6854: loss = 3.8504 (0.907 sec/step)\n","I1215 19:45:29.172459 140303514462080 learning.py:512] global step 6854: loss = 3.8504 (0.907 sec/step)\n","INFO:tensorflow:global step 6855: loss = 5.8357 (0.898 sec/step)\n","I1215 19:45:30.071788 140303514462080 learning.py:512] global step 6855: loss = 5.8357 (0.898 sec/step)\n","INFO:tensorflow:global step 6856: loss = 2.9530 (0.898 sec/step)\n","I1215 19:45:30.971331 140303514462080 learning.py:512] global step 6856: loss = 2.9530 (0.898 sec/step)\n","INFO:tensorflow:global step 6857: loss = 3.8347 (0.902 sec/step)\n","I1215 19:45:31.874596 140303514462080 learning.py:512] global step 6857: loss = 3.8347 (0.902 sec/step)\n","INFO:tensorflow:global step 6858: loss = 3.9905 (0.910 sec/step)\n","I1215 19:45:32.785687 140303514462080 learning.py:512] global step 6858: loss = 3.9905 (0.910 sec/step)\n","INFO:tensorflow:global step 6859: loss = 4.3291 (0.889 sec/step)\n","I1215 19:45:33.676143 140303514462080 learning.py:512] global step 6859: loss = 4.3291 (0.889 sec/step)\n","INFO:tensorflow:global step 6860: loss = 5.0243 (0.881 sec/step)\n","I1215 19:45:34.558301 140303514462080 learning.py:512] global step 6860: loss = 5.0243 (0.881 sec/step)\n","INFO:tensorflow:global step 6861: loss = 3.9174 (0.895 sec/step)\n","I1215 19:45:35.454899 140303514462080 learning.py:512] global step 6861: loss = 3.9174 (0.895 sec/step)\n","INFO:tensorflow:global step 6862: loss = 4.2674 (1.452 sec/step)\n","I1215 19:45:36.908917 140303514462080 learning.py:512] global step 6862: loss = 4.2674 (1.452 sec/step)\n","INFO:tensorflow:Recording summary at step 6862.\n","I1215 19:45:37.101732 140299899541248 supervisor.py:1050] Recording summary at step 6862.\n","INFO:tensorflow:global step 6863: loss = 3.0585 (0.950 sec/step)\n","I1215 19:45:37.860537 140303514462080 learning.py:512] global step 6863: loss = 3.0585 (0.950 sec/step)\n","INFO:tensorflow:global step 6864: loss = 4.4772 (0.878 sec/step)\n","I1215 19:45:38.739900 140303514462080 learning.py:512] global step 6864: loss = 4.4772 (0.878 sec/step)\n","INFO:tensorflow:global step 6865: loss = 4.3171 (0.909 sec/step)\n","I1215 19:45:39.650574 140303514462080 learning.py:512] global step 6865: loss = 4.3171 (0.909 sec/step)\n","INFO:tensorflow:global step 6866: loss = 3.3679 (0.907 sec/step)\n","I1215 19:45:40.559931 140303514462080 learning.py:512] global step 6866: loss = 3.3679 (0.907 sec/step)\n","INFO:tensorflow:global step 6867: loss = 6.0104 (0.918 sec/step)\n","I1215 19:45:41.479478 140303514462080 learning.py:512] global step 6867: loss = 6.0104 (0.918 sec/step)\n","INFO:tensorflow:global step 6868: loss = 3.8581 (0.920 sec/step)\n","I1215 19:45:42.401080 140303514462080 learning.py:512] global step 6868: loss = 3.8581 (0.920 sec/step)\n","INFO:tensorflow:global step 6869: loss = 3.5649 (0.921 sec/step)\n","I1215 19:45:43.323417 140303514462080 learning.py:512] global step 6869: loss = 3.5649 (0.921 sec/step)\n","INFO:tensorflow:global step 6870: loss = 3.8761 (0.913 sec/step)\n","I1215 19:45:44.237660 140303514462080 learning.py:512] global step 6870: loss = 3.8761 (0.913 sec/step)\n","INFO:tensorflow:global step 6871: loss = 3.7089 (0.918 sec/step)\n","I1215 19:45:45.156740 140303514462080 learning.py:512] global step 6871: loss = 3.7089 (0.918 sec/step)\n","INFO:tensorflow:global step 6872: loss = 3.6622 (0.908 sec/step)\n","I1215 19:45:46.066147 140303514462080 learning.py:512] global step 6872: loss = 3.6622 (0.908 sec/step)\n","INFO:tensorflow:global step 6873: loss = 4.8247 (0.937 sec/step)\n","I1215 19:45:47.004855 140303514462080 learning.py:512] global step 6873: loss = 4.8247 (0.937 sec/step)\n","INFO:tensorflow:global step 6874: loss = 6.0652 (0.887 sec/step)\n","I1215 19:45:47.893355 140303514462080 learning.py:512] global step 6874: loss = 6.0652 (0.887 sec/step)\n","INFO:tensorflow:global step 6875: loss = 3.6062 (0.892 sec/step)\n","I1215 19:45:48.787106 140303514462080 learning.py:512] global step 6875: loss = 3.6062 (0.892 sec/step)\n","INFO:tensorflow:global step 6876: loss = 3.9337 (0.908 sec/step)\n","I1215 19:45:49.696835 140303514462080 learning.py:512] global step 6876: loss = 3.9337 (0.908 sec/step)\n","INFO:tensorflow:global step 6877: loss = 5.3030 (0.899 sec/step)\n","I1215 19:45:50.597753 140303514462080 learning.py:512] global step 6877: loss = 5.3030 (0.899 sec/step)\n","INFO:tensorflow:global step 6878: loss = 3.7212 (0.909 sec/step)\n","I1215 19:45:51.507984 140303514462080 learning.py:512] global step 6878: loss = 3.7212 (0.909 sec/step)\n","INFO:tensorflow:global step 6879: loss = 4.5203 (0.920 sec/step)\n","I1215 19:45:52.429344 140303514462080 learning.py:512] global step 6879: loss = 4.5203 (0.920 sec/step)\n","INFO:tensorflow:global step 6880: loss = 5.1028 (0.908 sec/step)\n","I1215 19:45:53.338783 140303514462080 learning.py:512] global step 6880: loss = 5.1028 (0.908 sec/step)\n","INFO:tensorflow:global step 6881: loss = 4.3648 (0.910 sec/step)\n","I1215 19:45:54.250303 140303514462080 learning.py:512] global step 6881: loss = 4.3648 (0.910 sec/step)\n","INFO:tensorflow:global step 6882: loss = 3.7009 (0.911 sec/step)\n","I1215 19:45:55.162744 140303514462080 learning.py:512] global step 6882: loss = 3.7009 (0.911 sec/step)\n","INFO:tensorflow:global step 6883: loss = 3.3902 (0.892 sec/step)\n","I1215 19:45:56.056514 140303514462080 learning.py:512] global step 6883: loss = 3.3902 (0.892 sec/step)\n","INFO:tensorflow:global step 6884: loss = 4.7094 (0.912 sec/step)\n","I1215 19:45:56.969639 140303514462080 learning.py:512] global step 6884: loss = 4.7094 (0.912 sec/step)\n","INFO:tensorflow:global step 6885: loss = 4.4574 (0.910 sec/step)\n","I1215 19:45:57.881514 140303514462080 learning.py:512] global step 6885: loss = 4.4574 (0.910 sec/step)\n","INFO:tensorflow:global step 6886: loss = 4.9648 (0.914 sec/step)\n","I1215 19:45:58.797435 140303514462080 learning.py:512] global step 6886: loss = 4.9648 (0.914 sec/step)\n","INFO:tensorflow:global step 6887: loss = 3.2218 (0.915 sec/step)\n","I1215 19:45:59.713895 140303514462080 learning.py:512] global step 6887: loss = 3.2218 (0.915 sec/step)\n","INFO:tensorflow:global step 6888: loss = 5.8078 (0.928 sec/step)\n","I1215 19:46:00.643067 140303514462080 learning.py:512] global step 6888: loss = 5.8078 (0.928 sec/step)\n","INFO:tensorflow:global step 6889: loss = 2.9642 (0.898 sec/step)\n","I1215 19:46:01.542963 140303514462080 learning.py:512] global step 6889: loss = 2.9642 (0.898 sec/step)\n","INFO:tensorflow:global step 6890: loss = 2.8585 (0.897 sec/step)\n","I1215 19:46:02.441194 140303514462080 learning.py:512] global step 6890: loss = 2.8585 (0.897 sec/step)\n","INFO:tensorflow:global step 6891: loss = 3.3729 (0.915 sec/step)\n","I1215 19:46:03.357205 140303514462080 learning.py:512] global step 6891: loss = 3.3729 (0.915 sec/step)\n","INFO:tensorflow:global step 6892: loss = 2.7620 (0.895 sec/step)\n","I1215 19:46:04.253793 140303514462080 learning.py:512] global step 6892: loss = 2.7620 (0.895 sec/step)\n","INFO:tensorflow:global step 6893: loss = 5.6610 (0.890 sec/step)\n","I1215 19:46:05.145510 140303514462080 learning.py:512] global step 6893: loss = 5.6610 (0.890 sec/step)\n","INFO:tensorflow:global step 6894: loss = 3.3988 (0.892 sec/step)\n","I1215 19:46:06.038909 140303514462080 learning.py:512] global step 6894: loss = 3.3988 (0.892 sec/step)\n","INFO:tensorflow:global step 6895: loss = 5.3131 (0.915 sec/step)\n","I1215 19:46:06.955014 140303514462080 learning.py:512] global step 6895: loss = 5.3131 (0.915 sec/step)\n","INFO:tensorflow:global step 6896: loss = 2.7579 (0.895 sec/step)\n","I1215 19:46:07.851339 140303514462080 learning.py:512] global step 6896: loss = 2.7579 (0.895 sec/step)\n","INFO:tensorflow:global step 6897: loss = 3.7649 (0.899 sec/step)\n","I1215 19:46:08.752221 140303514462080 learning.py:512] global step 6897: loss = 3.7649 (0.899 sec/step)\n","INFO:tensorflow:global step 6898: loss = 4.5664 (0.911 sec/step)\n","I1215 19:46:09.664485 140303514462080 learning.py:512] global step 6898: loss = 4.5664 (0.911 sec/step)\n","INFO:tensorflow:global step 6899: loss = 4.8801 (0.890 sec/step)\n","I1215 19:46:10.556216 140303514462080 learning.py:512] global step 6899: loss = 4.8801 (0.890 sec/step)\n","INFO:tensorflow:global step 6900: loss = 3.9912 (0.915 sec/step)\n","I1215 19:46:11.472914 140303514462080 learning.py:512] global step 6900: loss = 3.9912 (0.915 sec/step)\n","INFO:tensorflow:global step 6901: loss = 4.5782 (0.928 sec/step)\n","I1215 19:46:12.402558 140303514462080 learning.py:512] global step 6901: loss = 4.5782 (0.928 sec/step)\n","INFO:tensorflow:global step 6902: loss = 4.2125 (0.892 sec/step)\n","I1215 19:46:13.296068 140303514462080 learning.py:512] global step 6902: loss = 4.2125 (0.892 sec/step)\n","INFO:tensorflow:global step 6903: loss = 3.1509 (0.891 sec/step)\n","I1215 19:46:14.188675 140303514462080 learning.py:512] global step 6903: loss = 3.1509 (0.891 sec/step)\n","INFO:tensorflow:global step 6904: loss = 3.0576 (0.908 sec/step)\n","I1215 19:46:15.097892 140303514462080 learning.py:512] global step 6904: loss = 3.0576 (0.908 sec/step)\n","INFO:tensorflow:global step 6905: loss = 7.6376 (0.898 sec/step)\n","I1215 19:46:15.997456 140303514462080 learning.py:512] global step 6905: loss = 7.6376 (0.898 sec/step)\n","INFO:tensorflow:global step 6906: loss = 5.1653 (0.898 sec/step)\n","I1215 19:46:16.896935 140303514462080 learning.py:512] global step 6906: loss = 5.1653 (0.898 sec/step)\n","INFO:tensorflow:global step 6907: loss = 5.9324 (0.915 sec/step)\n","I1215 19:46:17.813639 140303514462080 learning.py:512] global step 6907: loss = 5.9324 (0.915 sec/step)\n","INFO:tensorflow:global step 6908: loss = 3.6034 (0.899 sec/step)\n","I1215 19:46:18.714032 140303514462080 learning.py:512] global step 6908: loss = 3.6034 (0.899 sec/step)\n","INFO:tensorflow:global step 6909: loss = 5.0132 (0.887 sec/step)\n","I1215 19:46:19.602637 140303514462080 learning.py:512] global step 6909: loss = 5.0132 (0.887 sec/step)\n","INFO:tensorflow:global step 6910: loss = 3.3406 (0.882 sec/step)\n","I1215 19:46:20.485944 140303514462080 learning.py:512] global step 6910: loss = 3.3406 (0.882 sec/step)\n","INFO:tensorflow:global step 6911: loss = 5.7989 (0.926 sec/step)\n","I1215 19:46:21.413306 140303514462080 learning.py:512] global step 6911: loss = 5.7989 (0.926 sec/step)\n","INFO:tensorflow:global step 6912: loss = 4.9441 (0.879 sec/step)\n","I1215 19:46:22.294230 140303514462080 learning.py:512] global step 6912: loss = 4.9441 (0.879 sec/step)\n","INFO:tensorflow:global step 6913: loss = 2.9182 (0.908 sec/step)\n","I1215 19:46:23.203398 140303514462080 learning.py:512] global step 6913: loss = 2.9182 (0.908 sec/step)\n","INFO:tensorflow:global step 6914: loss = 5.0262 (0.887 sec/step)\n","I1215 19:46:24.092275 140303514462080 learning.py:512] global step 6914: loss = 5.0262 (0.887 sec/step)\n","INFO:tensorflow:global step 6915: loss = 5.4018 (0.891 sec/step)\n","I1215 19:46:24.985042 140303514462080 learning.py:512] global step 6915: loss = 5.4018 (0.891 sec/step)\n","INFO:tensorflow:global step 6916: loss = 3.4049 (0.892 sec/step)\n","I1215 19:46:25.878197 140303514462080 learning.py:512] global step 6916: loss = 3.4049 (0.892 sec/step)\n","INFO:tensorflow:global step 6917: loss = 5.3564 (0.902 sec/step)\n","I1215 19:46:26.782100 140303514462080 learning.py:512] global step 6917: loss = 5.3564 (0.902 sec/step)\n","INFO:tensorflow:global step 6918: loss = 3.1774 (0.890 sec/step)\n","I1215 19:46:27.673009 140303514462080 learning.py:512] global step 6918: loss = 3.1774 (0.890 sec/step)\n","INFO:tensorflow:global step 6919: loss = 3.4411 (0.886 sec/step)\n","I1215 19:46:28.560186 140303514462080 learning.py:512] global step 6919: loss = 3.4411 (0.886 sec/step)\n","INFO:tensorflow:global step 6920: loss = 4.7626 (0.874 sec/step)\n","I1215 19:46:29.435827 140303514462080 learning.py:512] global step 6920: loss = 4.7626 (0.874 sec/step)\n","INFO:tensorflow:global step 6921: loss = 3.7318 (0.896 sec/step)\n","I1215 19:46:30.334412 140303514462080 learning.py:512] global step 6921: loss = 3.7318 (0.896 sec/step)\n","INFO:tensorflow:global step 6922: loss = 3.8659 (0.906 sec/step)\n","I1215 19:46:31.242348 140303514462080 learning.py:512] global step 6922: loss = 3.8659 (0.906 sec/step)\n","INFO:tensorflow:global step 6923: loss = 5.0924 (0.916 sec/step)\n","I1215 19:46:32.159377 140303514462080 learning.py:512] global step 6923: loss = 5.0924 (0.916 sec/step)\n","INFO:tensorflow:global step 6924: loss = 4.1796 (0.889 sec/step)\n","I1215 19:46:33.050207 140303514462080 learning.py:512] global step 6924: loss = 4.1796 (0.889 sec/step)\n","INFO:tensorflow:global step 6925: loss = 4.7193 (0.901 sec/step)\n","I1215 19:46:33.953072 140303514462080 learning.py:512] global step 6925: loss = 4.7193 (0.901 sec/step)\n","INFO:tensorflow:global step 6926: loss = 5.1912 (0.886 sec/step)\n","I1215 19:46:34.840352 140303514462080 learning.py:512] global step 6926: loss = 5.1912 (0.886 sec/step)\n","INFO:tensorflow:global step 6927: loss = 4.7754 (0.895 sec/step)\n","I1215 19:46:35.736391 140303514462080 learning.py:512] global step 6927: loss = 4.7754 (0.895 sec/step)\n","INFO:tensorflow:global step 6928: loss = 3.0333 (0.861 sec/step)\n","I1215 19:46:36.599357 140303514462080 learning.py:512] global step 6928: loss = 3.0333 (0.861 sec/step)\n","INFO:tensorflow:global step 6929: loss = 3.0378 (0.886 sec/step)\n","I1215 19:46:37.487051 140303514462080 learning.py:512] global step 6929: loss = 3.0378 (0.886 sec/step)\n","INFO:tensorflow:global step 6930: loss = 4.3829 (0.890 sec/step)\n","I1215 19:46:38.378276 140303514462080 learning.py:512] global step 6930: loss = 4.3829 (0.890 sec/step)\n","INFO:tensorflow:global step 6931: loss = 5.0103 (0.894 sec/step)\n","I1215 19:46:39.273516 140303514462080 learning.py:512] global step 6931: loss = 5.0103 (0.894 sec/step)\n","INFO:tensorflow:global step 6932: loss = 4.9525 (0.876 sec/step)\n","I1215 19:46:40.151003 140303514462080 learning.py:512] global step 6932: loss = 4.9525 (0.876 sec/step)\n","INFO:tensorflow:global step 6933: loss = 4.8678 (0.890 sec/step)\n","I1215 19:46:41.042213 140303514462080 learning.py:512] global step 6933: loss = 4.8678 (0.890 sec/step)\n","INFO:tensorflow:global step 6934: loss = 3.8376 (0.883 sec/step)\n","I1215 19:46:41.926542 140303514462080 learning.py:512] global step 6934: loss = 3.8376 (0.883 sec/step)\n","INFO:tensorflow:global step 6935: loss = 2.7531 (0.925 sec/step)\n","I1215 19:46:42.853417 140303514462080 learning.py:512] global step 6935: loss = 2.7531 (0.925 sec/step)\n","INFO:tensorflow:global step 6936: loss = 4.8360 (0.888 sec/step)\n","I1215 19:46:43.742423 140303514462080 learning.py:512] global step 6936: loss = 4.8360 (0.888 sec/step)\n","INFO:tensorflow:global step 6937: loss = 2.8340 (0.884 sec/step)\n","I1215 19:46:44.627820 140303514462080 learning.py:512] global step 6937: loss = 2.8340 (0.884 sec/step)\n","INFO:tensorflow:global step 6938: loss = 3.6234 (0.904 sec/step)\n","I1215 19:46:45.533048 140303514462080 learning.py:512] global step 6938: loss = 3.6234 (0.904 sec/step)\n","INFO:tensorflow:global step 6939: loss = 4.6758 (0.905 sec/step)\n","I1215 19:46:46.439665 140303514462080 learning.py:512] global step 6939: loss = 4.6758 (0.905 sec/step)\n","INFO:tensorflow:global step 6940: loss = 4.8973 (0.910 sec/step)\n","I1215 19:46:47.350725 140303514462080 learning.py:512] global step 6940: loss = 4.8973 (0.910 sec/step)\n","INFO:tensorflow:global step 6941: loss = 3.5421 (0.900 sec/step)\n","I1215 19:46:48.252151 140303514462080 learning.py:512] global step 6941: loss = 3.5421 (0.900 sec/step)\n","INFO:tensorflow:global step 6942: loss = 3.3134 (0.921 sec/step)\n","I1215 19:46:49.174494 140303514462080 learning.py:512] global step 6942: loss = 3.3134 (0.921 sec/step)\n","INFO:tensorflow:global step 6943: loss = 4.5005 (0.898 sec/step)\n","I1215 19:46:50.074402 140303514462080 learning.py:512] global step 6943: loss = 4.5005 (0.898 sec/step)\n","INFO:tensorflow:global step 6944: loss = 4.3813 (0.915 sec/step)\n","I1215 19:46:50.990570 140303514462080 learning.py:512] global step 6944: loss = 4.3813 (0.915 sec/step)\n","INFO:tensorflow:global step 6945: loss = 2.8540 (0.901 sec/step)\n","I1215 19:46:51.892617 140303514462080 learning.py:512] global step 6945: loss = 2.8540 (0.901 sec/step)\n","INFO:tensorflow:global step 6946: loss = 4.1771 (0.896 sec/step)\n","I1215 19:46:52.790507 140303514462080 learning.py:512] global step 6946: loss = 4.1771 (0.896 sec/step)\n","INFO:tensorflow:global step 6947: loss = 4.4661 (0.889 sec/step)\n","I1215 19:46:53.680881 140303514462080 learning.py:512] global step 6947: loss = 4.4661 (0.889 sec/step)\n","INFO:tensorflow:global step 6948: loss = 3.4228 (0.898 sec/step)\n","I1215 19:46:54.580627 140303514462080 learning.py:512] global step 6948: loss = 3.4228 (0.898 sec/step)\n","INFO:tensorflow:global step 6949: loss = 5.1250 (0.889 sec/step)\n","I1215 19:46:55.470894 140303514462080 learning.py:512] global step 6949: loss = 5.1250 (0.889 sec/step)\n","INFO:tensorflow:global step 6950: loss = 2.9987 (0.891 sec/step)\n","I1215 19:46:56.363396 140303514462080 learning.py:512] global step 6950: loss = 2.9987 (0.891 sec/step)\n","INFO:tensorflow:global step 6951: loss = 5.7791 (0.921 sec/step)\n","I1215 19:46:57.285696 140303514462080 learning.py:512] global step 6951: loss = 5.7791 (0.921 sec/step)\n","INFO:tensorflow:global step 6952: loss = 3.8214 (0.889 sec/step)\n","I1215 19:46:58.176505 140303514462080 learning.py:512] global step 6952: loss = 3.8214 (0.889 sec/step)\n","INFO:tensorflow:global step 6953: loss = 6.1659 (0.900 sec/step)\n","I1215 19:46:59.078172 140303514462080 learning.py:512] global step 6953: loss = 6.1659 (0.900 sec/step)\n","INFO:tensorflow:global step 6954: loss = 5.5161 (0.899 sec/step)\n","I1215 19:46:59.978642 140303514462080 learning.py:512] global step 6954: loss = 5.5161 (0.899 sec/step)\n","INFO:tensorflow:global step 6955: loss = 4.6098 (0.905 sec/step)\n","I1215 19:47:00.884947 140303514462080 learning.py:512] global step 6955: loss = 4.6098 (0.905 sec/step)\n","INFO:tensorflow:global step 6956: loss = 3.9610 (0.884 sec/step)\n","I1215 19:47:01.770749 140303514462080 learning.py:512] global step 6956: loss = 3.9610 (0.884 sec/step)\n","INFO:tensorflow:global step 6957: loss = 3.7536 (0.890 sec/step)\n","I1215 19:47:02.662628 140303514462080 learning.py:512] global step 6957: loss = 3.7536 (0.890 sec/step)\n","INFO:tensorflow:global step 6958: loss = 5.3166 (0.922 sec/step)\n","I1215 19:47:03.586079 140303514462080 learning.py:512] global step 6958: loss = 5.3166 (0.922 sec/step)\n","INFO:tensorflow:global step 6959: loss = 4.4461 (0.895 sec/step)\n","I1215 19:47:04.482989 140303514462080 learning.py:512] global step 6959: loss = 4.4461 (0.895 sec/step)\n","INFO:tensorflow:global step 6960: loss = 4.9109 (0.896 sec/step)\n","I1215 19:47:05.380269 140303514462080 learning.py:512] global step 6960: loss = 4.9109 (0.896 sec/step)\n","INFO:tensorflow:global step 6961: loss = 4.7256 (0.900 sec/step)\n","I1215 19:47:06.281929 140303514462080 learning.py:512] global step 6961: loss = 4.7256 (0.900 sec/step)\n","INFO:tensorflow:global step 6962: loss = 3.2632 (0.890 sec/step)\n","I1215 19:47:07.173821 140303514462080 learning.py:512] global step 6962: loss = 3.2632 (0.890 sec/step)\n","INFO:tensorflow:global step 6963: loss = 4.8828 (0.899 sec/step)\n","I1215 19:47:08.074424 140303514462080 learning.py:512] global step 6963: loss = 4.8828 (0.899 sec/step)\n","INFO:tensorflow:global step 6964: loss = 3.3289 (0.890 sec/step)\n","I1215 19:47:08.966441 140303514462080 learning.py:512] global step 6964: loss = 3.3289 (0.890 sec/step)\n","INFO:tensorflow:global step 6965: loss = 4.1905 (0.906 sec/step)\n","I1215 19:47:09.874059 140303514462080 learning.py:512] global step 6965: loss = 4.1905 (0.906 sec/step)\n","INFO:tensorflow:global step 6966: loss = 3.9626 (0.910 sec/step)\n","I1215 19:47:10.785197 140303514462080 learning.py:512] global step 6966: loss = 3.9626 (0.910 sec/step)\n","INFO:tensorflow:global step 6967: loss = 3.1061 (0.906 sec/step)\n","I1215 19:47:11.692793 140303514462080 learning.py:512] global step 6967: loss = 3.1061 (0.906 sec/step)\n","INFO:tensorflow:global step 6968: loss = 3.9251 (0.929 sec/step)\n","I1215 19:47:12.623450 140303514462080 learning.py:512] global step 6968: loss = 3.9251 (0.929 sec/step)\n","INFO:tensorflow:global step 6969: loss = 3.1801 (0.903 sec/step)\n","I1215 19:47:13.527990 140303514462080 learning.py:512] global step 6969: loss = 3.1801 (0.903 sec/step)\n","INFO:tensorflow:global step 6970: loss = 3.0170 (0.912 sec/step)\n","I1215 19:47:14.441831 140303514462080 learning.py:512] global step 6970: loss = 3.0170 (0.912 sec/step)\n","INFO:tensorflow:global step 6971: loss = 3.1272 (0.903 sec/step)\n","I1215 19:47:15.346546 140303514462080 learning.py:512] global step 6971: loss = 3.1272 (0.903 sec/step)\n","INFO:tensorflow:global step 6972: loss = 4.3380 (0.903 sec/step)\n","I1215 19:47:16.250957 140303514462080 learning.py:512] global step 6972: loss = 4.3380 (0.903 sec/step)\n","INFO:tensorflow:global step 6973: loss = 3.0031 (0.900 sec/step)\n","I1215 19:47:17.152424 140303514462080 learning.py:512] global step 6973: loss = 3.0031 (0.900 sec/step)\n","INFO:tensorflow:global step 6974: loss = 3.1457 (0.903 sec/step)\n","I1215 19:47:18.057425 140303514462080 learning.py:512] global step 6974: loss = 3.1457 (0.903 sec/step)\n","INFO:tensorflow:global step 6975: loss = 4.8103 (0.902 sec/step)\n","I1215 19:47:18.960396 140303514462080 learning.py:512] global step 6975: loss = 4.8103 (0.902 sec/step)\n","INFO:tensorflow:global step 6976: loss = 5.2150 (0.902 sec/step)\n","I1215 19:47:19.864195 140303514462080 learning.py:512] global step 6976: loss = 5.2150 (0.902 sec/step)\n","INFO:tensorflow:global step 6977: loss = 2.7540 (0.890 sec/step)\n","I1215 19:47:20.755475 140303514462080 learning.py:512] global step 6977: loss = 2.7540 (0.890 sec/step)\n","INFO:tensorflow:global step 6978: loss = 3.2197 (0.882 sec/step)\n","I1215 19:47:21.639181 140303514462080 learning.py:512] global step 6978: loss = 3.2197 (0.882 sec/step)\n","INFO:tensorflow:global step 6979: loss = 3.5156 (0.892 sec/step)\n","I1215 19:47:22.532396 140303514462080 learning.py:512] global step 6979: loss = 3.5156 (0.892 sec/step)\n","INFO:tensorflow:global step 6980: loss = 4.1422 (0.909 sec/step)\n","I1215 19:47:23.442809 140303514462080 learning.py:512] global step 6980: loss = 4.1422 (0.909 sec/step)\n","INFO:tensorflow:global step 6981: loss = 4.7423 (0.925 sec/step)\n","I1215 19:47:24.369830 140303514462080 learning.py:512] global step 6981: loss = 4.7423 (0.925 sec/step)\n","INFO:tensorflow:global step 6982: loss = 5.1652 (0.901 sec/step)\n","I1215 19:47:25.272353 140303514462080 learning.py:512] global step 6982: loss = 5.1652 (0.901 sec/step)\n","INFO:tensorflow:global step 6983: loss = 5.4022 (0.886 sec/step)\n","I1215 19:47:26.160215 140303514462080 learning.py:512] global step 6983: loss = 5.4022 (0.886 sec/step)\n","INFO:tensorflow:global step 6984: loss = 4.8978 (0.908 sec/step)\n","I1215 19:47:27.069622 140303514462080 learning.py:512] global step 6984: loss = 4.8978 (0.908 sec/step)\n","INFO:tensorflow:global step 6985: loss = 5.4734 (0.889 sec/step)\n","I1215 19:47:27.959636 140303514462080 learning.py:512] global step 6985: loss = 5.4734 (0.889 sec/step)\n","INFO:tensorflow:global step 6986: loss = 4.4923 (0.881 sec/step)\n","I1215 19:47:28.842294 140303514462080 learning.py:512] global step 6986: loss = 4.4923 (0.881 sec/step)\n","INFO:tensorflow:global step 6987: loss = 5.5883 (0.900 sec/step)\n","I1215 19:47:29.744049 140303514462080 learning.py:512] global step 6987: loss = 5.5883 (0.900 sec/step)\n","INFO:tensorflow:global step 6988: loss = 3.6932 (0.900 sec/step)\n","I1215 19:47:30.646173 140303514462080 learning.py:512] global step 6988: loss = 3.6932 (0.900 sec/step)\n","INFO:tensorflow:global step 6989: loss = 5.5982 (0.898 sec/step)\n","I1215 19:47:31.545237 140303514462080 learning.py:512] global step 6989: loss = 5.5982 (0.898 sec/step)\n","INFO:tensorflow:global step 6990: loss = 4.7992 (0.892 sec/step)\n","I1215 19:47:32.438426 140303514462080 learning.py:512] global step 6990: loss = 4.7992 (0.892 sec/step)\n","INFO:tensorflow:global step 6991: loss = 5.4008 (0.892 sec/step)\n","I1215 19:47:33.331575 140303514462080 learning.py:512] global step 6991: loss = 5.4008 (0.892 sec/step)\n","INFO:tensorflow:global step 6992: loss = 4.0884 (0.889 sec/step)\n","I1215 19:47:34.222557 140303514462080 learning.py:512] global step 6992: loss = 4.0884 (0.889 sec/step)\n","INFO:tensorflow:global step 6993: loss = 3.7259 (0.907 sec/step)\n","I1215 19:47:35.131369 140303514462080 learning.py:512] global step 6993: loss = 3.7259 (0.907 sec/step)\n","INFO:tensorflow:global step 6994: loss = 4.7534 (1.198 sec/step)\n","I1215 19:47:36.334229 140303514462080 learning.py:512] global step 6994: loss = 4.7534 (1.198 sec/step)\n","INFO:tensorflow:Recording summary at step 6994.\n","I1215 19:47:37.222849 140299899541248 supervisor.py:1050] Recording summary at step 6994.\n","INFO:tensorflow:global step 6995: loss = 4.9656 (1.176 sec/step)\n","I1215 19:47:37.513028 140303514462080 learning.py:512] global step 6995: loss = 4.9656 (1.176 sec/step)\n","INFO:tensorflow:global step 6996: loss = 3.6838 (0.888 sec/step)\n","I1215 19:47:38.402219 140303514462080 learning.py:512] global step 6996: loss = 3.6838 (0.888 sec/step)\n","INFO:tensorflow:global step 6997: loss = 4.8536 (0.887 sec/step)\n","I1215 19:47:39.291148 140303514462080 learning.py:512] global step 6997: loss = 4.8536 (0.887 sec/step)\n","INFO:tensorflow:global step 6998: loss = 3.7937 (0.888 sec/step)\n","I1215 19:47:40.180464 140303514462080 learning.py:512] global step 6998: loss = 3.7937 (0.888 sec/step)\n","INFO:tensorflow:global step 6999: loss = 3.3378 (0.889 sec/step)\n","I1215 19:47:41.071056 140303514462080 learning.py:512] global step 6999: loss = 3.3378 (0.889 sec/step)\n","INFO:tensorflow:global step 7000: loss = 4.9681 (0.899 sec/step)\n","I1215 19:47:41.971696 140303514462080 learning.py:512] global step 7000: loss = 4.9681 (0.899 sec/step)\n","INFO:tensorflow:global step 7001: loss = 3.7796 (0.899 sec/step)\n","I1215 19:47:42.872281 140303514462080 learning.py:512] global step 7001: loss = 3.7796 (0.899 sec/step)\n","INFO:tensorflow:global step 7002: loss = 3.0892 (0.906 sec/step)\n","I1215 19:47:43.780346 140303514462080 learning.py:512] global step 7002: loss = 3.0892 (0.906 sec/step)\n","INFO:tensorflow:global step 7003: loss = 4.3300 (0.927 sec/step)\n","I1215 19:47:44.708884 140303514462080 learning.py:512] global step 7003: loss = 4.3300 (0.927 sec/step)\n","INFO:tensorflow:global step 7004: loss = 3.8778 (0.905 sec/step)\n","I1215 19:47:45.615183 140303514462080 learning.py:512] global step 7004: loss = 3.8778 (0.905 sec/step)\n","INFO:tensorflow:global step 7005: loss = 4.6267 (0.901 sec/step)\n","I1215 19:47:46.518141 140303514462080 learning.py:512] global step 7005: loss = 4.6267 (0.901 sec/step)\n","INFO:tensorflow:global step 7006: loss = 3.4465 (0.907 sec/step)\n","I1215 19:47:47.426972 140303514462080 learning.py:512] global step 7006: loss = 3.4465 (0.907 sec/step)\n","INFO:tensorflow:global step 7007: loss = 4.2028 (0.885 sec/step)\n","I1215 19:47:48.313281 140303514462080 learning.py:512] global step 7007: loss = 4.2028 (0.885 sec/step)\n","INFO:tensorflow:global step 7008: loss = 5.8749 (0.888 sec/step)\n","I1215 19:47:49.202381 140303514462080 learning.py:512] global step 7008: loss = 5.8749 (0.888 sec/step)\n","INFO:tensorflow:global step 7009: loss = 4.6686 (0.901 sec/step)\n","I1215 19:47:50.104607 140303514462080 learning.py:512] global step 7009: loss = 4.6686 (0.901 sec/step)\n","INFO:tensorflow:global step 7010: loss = 4.3031 (0.908 sec/step)\n","I1215 19:47:51.014504 140303514462080 learning.py:512] global step 7010: loss = 4.3031 (0.908 sec/step)\n","INFO:tensorflow:global step 7011: loss = 4.2026 (0.921 sec/step)\n","I1215 19:47:51.937157 140303514462080 learning.py:512] global step 7011: loss = 4.2026 (0.921 sec/step)\n","INFO:tensorflow:global step 7012: loss = 3.5727 (0.895 sec/step)\n","I1215 19:47:52.833281 140303514462080 learning.py:512] global step 7012: loss = 3.5727 (0.895 sec/step)\n","INFO:tensorflow:global step 7013: loss = 3.3209 (0.890 sec/step)\n","I1215 19:47:53.724641 140303514462080 learning.py:512] global step 7013: loss = 3.3209 (0.890 sec/step)\n","INFO:tensorflow:global step 7014: loss = 3.1623 (0.916 sec/step)\n","I1215 19:47:54.641995 140303514462080 learning.py:512] global step 7014: loss = 3.1623 (0.916 sec/step)\n","INFO:tensorflow:global step 7015: loss = 4.3599 (0.913 sec/step)\n","I1215 19:47:55.556583 140303514462080 learning.py:512] global step 7015: loss = 4.3599 (0.913 sec/step)\n","INFO:tensorflow:global step 7016: loss = 3.1788 (0.893 sec/step)\n","I1215 19:47:56.450949 140303514462080 learning.py:512] global step 7016: loss = 3.1788 (0.893 sec/step)\n","INFO:tensorflow:global step 7017: loss = 4.6744 (0.921 sec/step)\n","I1215 19:47:57.373179 140303514462080 learning.py:512] global step 7017: loss = 4.6744 (0.921 sec/step)\n","INFO:tensorflow:global step 7018: loss = 4.2533 (0.897 sec/step)\n","I1215 19:47:58.271485 140303514462080 learning.py:512] global step 7018: loss = 4.2533 (0.897 sec/step)\n","INFO:tensorflow:global step 7019: loss = 3.1995 (0.887 sec/step)\n","I1215 19:47:59.159498 140303514462080 learning.py:512] global step 7019: loss = 3.1995 (0.887 sec/step)\n","INFO:tensorflow:global step 7020: loss = 8.9906 (0.875 sec/step)\n","I1215 19:48:00.035869 140303514462080 learning.py:512] global step 7020: loss = 8.9906 (0.875 sec/step)\n","INFO:tensorflow:global step 7021: loss = 4.1138 (0.915 sec/step)\n","I1215 19:48:00.952361 140303514462080 learning.py:512] global step 7021: loss = 4.1138 (0.915 sec/step)\n","INFO:tensorflow:global step 7022: loss = 4.6748 (0.882 sec/step)\n","I1215 19:48:01.835674 140303514462080 learning.py:512] global step 7022: loss = 4.6748 (0.882 sec/step)\n","INFO:tensorflow:global step 7023: loss = 3.8822 (0.888 sec/step)\n","I1215 19:48:02.725441 140303514462080 learning.py:512] global step 7023: loss = 3.8822 (0.888 sec/step)\n","INFO:tensorflow:global step 7024: loss = 4.7518 (0.905 sec/step)\n","I1215 19:48:03.631456 140303514462080 learning.py:512] global step 7024: loss = 4.7518 (0.905 sec/step)\n","INFO:tensorflow:global step 7025: loss = 3.9535 (0.918 sec/step)\n","I1215 19:48:04.550702 140303514462080 learning.py:512] global step 7025: loss = 3.9535 (0.918 sec/step)\n","INFO:tensorflow:global step 7026: loss = 3.3133 (0.886 sec/step)\n","I1215 19:48:05.438293 140303514462080 learning.py:512] global step 7026: loss = 3.3133 (0.886 sec/step)\n","INFO:tensorflow:global step 7027: loss = 2.7568 (0.913 sec/step)\n","I1215 19:48:06.352782 140303514462080 learning.py:512] global step 7027: loss = 2.7568 (0.913 sec/step)\n","INFO:tensorflow:global step 7028: loss = 4.8594 (0.898 sec/step)\n","I1215 19:48:07.252632 140303514462080 learning.py:512] global step 7028: loss = 4.8594 (0.898 sec/step)\n","INFO:tensorflow:global step 7029: loss = 2.9941 (0.899 sec/step)\n","I1215 19:48:08.153321 140303514462080 learning.py:512] global step 7029: loss = 2.9941 (0.899 sec/step)\n","INFO:tensorflow:global step 7030: loss = 3.6431 (0.907 sec/step)\n","I1215 19:48:09.062041 140303514462080 learning.py:512] global step 7030: loss = 3.6431 (0.907 sec/step)\n","INFO:tensorflow:global step 7031: loss = 4.1317 (0.904 sec/step)\n","I1215 19:48:09.967701 140303514462080 learning.py:512] global step 7031: loss = 4.1317 (0.904 sec/step)\n","INFO:tensorflow:global step 7032: loss = 4.0321 (0.888 sec/step)\n","I1215 19:48:10.857453 140303514462080 learning.py:512] global step 7032: loss = 4.0321 (0.888 sec/step)\n","INFO:tensorflow:global step 7033: loss = 4.4842 (0.899 sec/step)\n","I1215 19:48:11.758473 140303514462080 learning.py:512] global step 7033: loss = 4.4842 (0.899 sec/step)\n","INFO:tensorflow:global step 7034: loss = 4.4382 (0.920 sec/step)\n","I1215 19:48:12.680102 140303514462080 learning.py:512] global step 7034: loss = 4.4382 (0.920 sec/step)\n","INFO:tensorflow:global step 7035: loss = 2.5804 (0.910 sec/step)\n","I1215 19:48:13.591921 140303514462080 learning.py:512] global step 7035: loss = 2.5804 (0.910 sec/step)\n","INFO:tensorflow:global step 7036: loss = 6.5024 (0.888 sec/step)\n","I1215 19:48:14.481594 140303514462080 learning.py:512] global step 7036: loss = 6.5024 (0.888 sec/step)\n","INFO:tensorflow:global step 7037: loss = 4.7587 (0.899 sec/step)\n","I1215 19:48:15.382194 140303514462080 learning.py:512] global step 7037: loss = 4.7587 (0.899 sec/step)\n","INFO:tensorflow:global step 7038: loss = 4.5233 (0.888 sec/step)\n","I1215 19:48:16.271638 140303514462080 learning.py:512] global step 7038: loss = 4.5233 (0.888 sec/step)\n","INFO:tensorflow:global step 7039: loss = 3.9536 (0.907 sec/step)\n","I1215 19:48:17.180656 140303514462080 learning.py:512] global step 7039: loss = 3.9536 (0.907 sec/step)\n","INFO:tensorflow:global step 7040: loss = 4.3118 (0.896 sec/step)\n","I1215 19:48:18.078492 140303514462080 learning.py:512] global step 7040: loss = 4.3118 (0.896 sec/step)\n","INFO:tensorflow:global step 7041: loss = 5.6409 (0.914 sec/step)\n","I1215 19:48:18.994255 140303514462080 learning.py:512] global step 7041: loss = 5.6409 (0.914 sec/step)\n","INFO:tensorflow:global step 7042: loss = 4.9377 (0.895 sec/step)\n","I1215 19:48:19.891256 140303514462080 learning.py:512] global step 7042: loss = 4.9377 (0.895 sec/step)\n","INFO:tensorflow:global step 7043: loss = 3.2578 (0.896 sec/step)\n","I1215 19:48:20.788883 140303514462080 learning.py:512] global step 7043: loss = 3.2578 (0.896 sec/step)\n","INFO:tensorflow:global step 7044: loss = 4.9225 (0.896 sec/step)\n","I1215 19:48:21.686111 140303514462080 learning.py:512] global step 7044: loss = 4.9225 (0.896 sec/step)\n","INFO:tensorflow:global step 7045: loss = 4.5571 (0.888 sec/step)\n","I1215 19:48:22.575203 140303514462080 learning.py:512] global step 7045: loss = 4.5571 (0.888 sec/step)\n","INFO:tensorflow:global step 7046: loss = 4.6111 (0.897 sec/step)\n","I1215 19:48:23.473858 140303514462080 learning.py:512] global step 7046: loss = 4.6111 (0.897 sec/step)\n","INFO:tensorflow:global step 7047: loss = 4.7708 (0.891 sec/step)\n","I1215 19:48:24.366588 140303514462080 learning.py:512] global step 7047: loss = 4.7708 (0.891 sec/step)\n","INFO:tensorflow:global step 7048: loss = 3.4563 (0.916 sec/step)\n","I1215 19:48:25.284841 140303514462080 learning.py:512] global step 7048: loss = 3.4563 (0.916 sec/step)\n","INFO:tensorflow:global step 7049: loss = 4.5039 (0.883 sec/step)\n","I1215 19:48:26.169515 140303514462080 learning.py:512] global step 7049: loss = 4.5039 (0.883 sec/step)\n","INFO:tensorflow:global step 7050: loss = 2.7471 (0.910 sec/step)\n","I1215 19:48:27.080773 140303514462080 learning.py:512] global step 7050: loss = 2.7471 (0.910 sec/step)\n","INFO:tensorflow:global step 7051: loss = 3.9516 (0.899 sec/step)\n","I1215 19:48:27.981713 140303514462080 learning.py:512] global step 7051: loss = 3.9516 (0.899 sec/step)\n","INFO:tensorflow:global step 7052: loss = 3.6819 (0.902 sec/step)\n","I1215 19:48:28.885392 140303514462080 learning.py:512] global step 7052: loss = 3.6819 (0.902 sec/step)\n","INFO:tensorflow:global step 7053: loss = 2.9838 (0.899 sec/step)\n","I1215 19:48:29.785912 140303514462080 learning.py:512] global step 7053: loss = 2.9838 (0.899 sec/step)\n","INFO:tensorflow:global step 7054: loss = 3.8269 (0.919 sec/step)\n","I1215 19:48:30.706743 140303514462080 learning.py:512] global step 7054: loss = 3.8269 (0.919 sec/step)\n","INFO:tensorflow:global step 7055: loss = 3.3134 (0.929 sec/step)\n","I1215 19:48:31.637338 140303514462080 learning.py:512] global step 7055: loss = 3.3134 (0.929 sec/step)\n","INFO:tensorflow:global step 7056: loss = 3.3927 (0.901 sec/step)\n","I1215 19:48:32.540283 140303514462080 learning.py:512] global step 7056: loss = 3.3927 (0.901 sec/step)\n","INFO:tensorflow:global step 7057: loss = 4.0040 (0.900 sec/step)\n","I1215 19:48:33.442113 140303514462080 learning.py:512] global step 7057: loss = 4.0040 (0.900 sec/step)\n","INFO:tensorflow:global step 7058: loss = 3.0868 (0.902 sec/step)\n","I1215 19:48:34.345831 140303514462080 learning.py:512] global step 7058: loss = 3.0868 (0.902 sec/step)\n","INFO:tensorflow:global step 7059: loss = 4.2052 (0.898 sec/step)\n","I1215 19:48:35.245044 140303514462080 learning.py:512] global step 7059: loss = 4.2052 (0.898 sec/step)\n","INFO:tensorflow:global step 7060: loss = 4.2841 (0.909 sec/step)\n","I1215 19:48:36.155905 140303514462080 learning.py:512] global step 7060: loss = 4.2841 (0.909 sec/step)\n","INFO:tensorflow:global step 7061: loss = 5.5175 (0.908 sec/step)\n","I1215 19:48:37.064822 140303514462080 learning.py:512] global step 7061: loss = 5.5175 (0.908 sec/step)\n","INFO:tensorflow:global step 7062: loss = 3.5423 (0.938 sec/step)\n","I1215 19:48:38.003932 140303514462080 learning.py:512] global step 7062: loss = 3.5423 (0.938 sec/step)\n","INFO:tensorflow:global step 7063: loss = 3.9808 (0.921 sec/step)\n","I1215 19:48:38.926041 140303514462080 learning.py:512] global step 7063: loss = 3.9808 (0.921 sec/step)\n","INFO:tensorflow:global step 7064: loss = 4.4973 (0.906 sec/step)\n","I1215 19:48:39.833229 140303514462080 learning.py:512] global step 7064: loss = 4.4973 (0.906 sec/step)\n","INFO:tensorflow:global step 7065: loss = 4.1064 (0.904 sec/step)\n","I1215 19:48:40.739040 140303514462080 learning.py:512] global step 7065: loss = 4.1064 (0.904 sec/step)\n","INFO:tensorflow:global step 7066: loss = 3.3148 (0.897 sec/step)\n","I1215 19:48:41.637617 140303514462080 learning.py:512] global step 7066: loss = 3.3148 (0.897 sec/step)\n","INFO:tensorflow:global step 7067: loss = 2.8659 (0.896 sec/step)\n","I1215 19:48:42.535335 140303514462080 learning.py:512] global step 7067: loss = 2.8659 (0.896 sec/step)\n","INFO:tensorflow:global step 7068: loss = 2.8884 (0.889 sec/step)\n","I1215 19:48:43.428117 140303514462080 learning.py:512] global step 7068: loss = 2.8884 (0.889 sec/step)\n","INFO:tensorflow:global step 7069: loss = 2.3052 (0.887 sec/step)\n","I1215 19:48:44.317250 140303514462080 learning.py:512] global step 7069: loss = 2.3052 (0.887 sec/step)\n","INFO:tensorflow:global step 7070: loss = 4.4671 (0.889 sec/step)\n","I1215 19:48:45.208041 140303514462080 learning.py:512] global step 7070: loss = 4.4671 (0.889 sec/step)\n","INFO:tensorflow:global step 7071: loss = 3.4622 (0.888 sec/step)\n","I1215 19:48:46.097707 140303514462080 learning.py:512] global step 7071: loss = 3.4622 (0.888 sec/step)\n","INFO:tensorflow:global step 7072: loss = 3.9203 (0.890 sec/step)\n","I1215 19:48:46.988833 140303514462080 learning.py:512] global step 7072: loss = 3.9203 (0.890 sec/step)\n","INFO:tensorflow:global step 7073: loss = 4.0167 (0.909 sec/step)\n","I1215 19:48:47.899867 140303514462080 learning.py:512] global step 7073: loss = 4.0167 (0.909 sec/step)\n","INFO:tensorflow:global step 7074: loss = 3.3844 (0.894 sec/step)\n","I1215 19:48:48.795063 140303514462080 learning.py:512] global step 7074: loss = 3.3844 (0.894 sec/step)\n","INFO:tensorflow:global step 7075: loss = 4.5526 (0.894 sec/step)\n","I1215 19:48:49.690670 140303514462080 learning.py:512] global step 7075: loss = 4.5526 (0.894 sec/step)\n","INFO:tensorflow:global step 7076: loss = 5.4870 (0.911 sec/step)\n","I1215 19:48:50.603179 140303514462080 learning.py:512] global step 7076: loss = 5.4870 (0.911 sec/step)\n","INFO:tensorflow:global step 7077: loss = 3.0968 (0.890 sec/step)\n","I1215 19:48:51.494467 140303514462080 learning.py:512] global step 7077: loss = 3.0968 (0.890 sec/step)\n","INFO:tensorflow:global step 7078: loss = 2.8760 (0.904 sec/step)\n","I1215 19:48:52.400052 140303514462080 learning.py:512] global step 7078: loss = 2.8760 (0.904 sec/step)\n","INFO:tensorflow:global step 7079: loss = 3.9655 (0.893 sec/step)\n","I1215 19:48:53.294567 140303514462080 learning.py:512] global step 7079: loss = 3.9655 (0.893 sec/step)\n","INFO:tensorflow:global step 7080: loss = 3.5270 (0.908 sec/step)\n","I1215 19:48:54.203625 140303514462080 learning.py:512] global step 7080: loss = 3.5270 (0.908 sec/step)\n","INFO:tensorflow:global step 7081: loss = 2.4658 (0.914 sec/step)\n","I1215 19:48:55.118697 140303514462080 learning.py:512] global step 7081: loss = 2.4658 (0.914 sec/step)\n","INFO:tensorflow:global step 7082: loss = 3.1182 (0.899 sec/step)\n","I1215 19:48:56.019415 140303514462080 learning.py:512] global step 7082: loss = 3.1182 (0.899 sec/step)\n","INFO:tensorflow:global step 7083: loss = 2.6942 (0.901 sec/step)\n","I1215 19:48:56.922237 140303514462080 learning.py:512] global step 7083: loss = 2.6942 (0.901 sec/step)\n","INFO:tensorflow:global step 7084: loss = 3.8808 (0.893 sec/step)\n","I1215 19:48:57.816490 140303514462080 learning.py:512] global step 7084: loss = 3.8808 (0.893 sec/step)\n","INFO:tensorflow:global step 7085: loss = 4.8879 (0.898 sec/step)\n","I1215 19:48:58.716515 140303514462080 learning.py:512] global step 7085: loss = 4.8879 (0.898 sec/step)\n","INFO:tensorflow:global step 7086: loss = 4.2921 (0.884 sec/step)\n","I1215 19:48:59.602341 140303514462080 learning.py:512] global step 7086: loss = 4.2921 (0.884 sec/step)\n","INFO:tensorflow:global step 7087: loss = 4.9524 (0.891 sec/step)\n","I1215 19:49:00.494832 140303514462080 learning.py:512] global step 7087: loss = 4.9524 (0.891 sec/step)\n","INFO:tensorflow:global step 7088: loss = 5.5831 (0.913 sec/step)\n","I1215 19:49:01.408924 140303514462080 learning.py:512] global step 7088: loss = 5.5831 (0.913 sec/step)\n","INFO:tensorflow:global step 7089: loss = 4.1225 (0.891 sec/step)\n","I1215 19:49:02.300841 140303514462080 learning.py:512] global step 7089: loss = 4.1225 (0.891 sec/step)\n","INFO:tensorflow:global step 7090: loss = 4.4548 (0.891 sec/step)\n","I1215 19:49:03.193440 140303514462080 learning.py:512] global step 7090: loss = 4.4548 (0.891 sec/step)\n","INFO:tensorflow:global step 7091: loss = 3.1060 (0.890 sec/step)\n","I1215 19:49:04.084546 140303514462080 learning.py:512] global step 7091: loss = 3.1060 (0.890 sec/step)\n","INFO:tensorflow:global step 7092: loss = 3.7002 (0.903 sec/step)\n","I1215 19:49:04.989015 140303514462080 learning.py:512] global step 7092: loss = 3.7002 (0.903 sec/step)\n","INFO:tensorflow:global step 7093: loss = 4.1946 (0.893 sec/step)\n","I1215 19:49:05.883569 140303514462080 learning.py:512] global step 7093: loss = 4.1946 (0.893 sec/step)\n","INFO:tensorflow:global step 7094: loss = 5.7200 (0.891 sec/step)\n","I1215 19:49:06.776017 140303514462080 learning.py:512] global step 7094: loss = 5.7200 (0.891 sec/step)\n","INFO:tensorflow:global step 7095: loss = 5.9513 (0.890 sec/step)\n","I1215 19:49:07.667677 140303514462080 learning.py:512] global step 7095: loss = 5.9513 (0.890 sec/step)\n","INFO:tensorflow:global step 7096: loss = 5.3484 (0.900 sec/step)\n","I1215 19:49:08.569091 140303514462080 learning.py:512] global step 7096: loss = 5.3484 (0.900 sec/step)\n","INFO:tensorflow:global step 7097: loss = 3.6061 (0.899 sec/step)\n","I1215 19:49:09.469439 140303514462080 learning.py:512] global step 7097: loss = 3.6061 (0.899 sec/step)\n","INFO:tensorflow:global step 7098: loss = 5.7287 (0.890 sec/step)\n","I1215 19:49:10.361365 140303514462080 learning.py:512] global step 7098: loss = 5.7287 (0.890 sec/step)\n","INFO:tensorflow:global step 7099: loss = 3.1945 (0.898 sec/step)\n","I1215 19:49:11.260833 140303514462080 learning.py:512] global step 7099: loss = 3.1945 (0.898 sec/step)\n","INFO:tensorflow:global step 7100: loss = 2.6598 (0.916 sec/step)\n","I1215 19:49:12.178117 140303514462080 learning.py:512] global step 7100: loss = 2.6598 (0.916 sec/step)\n","INFO:tensorflow:global step 7101: loss = 5.1412 (0.900 sec/step)\n","I1215 19:49:13.079420 140303514462080 learning.py:512] global step 7101: loss = 5.1412 (0.900 sec/step)\n","INFO:tensorflow:global step 7102: loss = 4.2961 (0.891 sec/step)\n","I1215 19:49:13.971683 140303514462080 learning.py:512] global step 7102: loss = 4.2961 (0.891 sec/step)\n","INFO:tensorflow:global step 7103: loss = 4.3053 (0.883 sec/step)\n","I1215 19:49:14.856466 140303514462080 learning.py:512] global step 7103: loss = 4.3053 (0.883 sec/step)\n","INFO:tensorflow:global step 7104: loss = 5.5207 (0.917 sec/step)\n","I1215 19:49:15.775014 140303514462080 learning.py:512] global step 7104: loss = 5.5207 (0.917 sec/step)\n","INFO:tensorflow:global step 7105: loss = 4.1517 (0.958 sec/step)\n","I1215 19:49:16.734094 140303514462080 learning.py:512] global step 7105: loss = 4.1517 (0.958 sec/step)\n","INFO:tensorflow:global step 7106: loss = 4.2231 (0.918 sec/step)\n","I1215 19:49:17.653936 140303514462080 learning.py:512] global step 7106: loss = 4.2231 (0.918 sec/step)\n","INFO:tensorflow:global step 7107: loss = 3.3444 (0.907 sec/step)\n","I1215 19:49:18.562402 140303514462080 learning.py:512] global step 7107: loss = 3.3444 (0.907 sec/step)\n","INFO:tensorflow:global step 7108: loss = 4.3242 (0.924 sec/step)\n","I1215 19:49:19.488101 140303514462080 learning.py:512] global step 7108: loss = 4.3242 (0.924 sec/step)\n","INFO:tensorflow:global step 7109: loss = 3.3331 (0.936 sec/step)\n","I1215 19:49:20.425978 140303514462080 learning.py:512] global step 7109: loss = 3.3331 (0.936 sec/step)\n","INFO:tensorflow:global step 7110: loss = 5.3127 (0.924 sec/step)\n","I1215 19:49:21.351501 140303514462080 learning.py:512] global step 7110: loss = 5.3127 (0.924 sec/step)\n","INFO:tensorflow:global step 7111: loss = 4.4666 (0.924 sec/step)\n","I1215 19:49:22.276928 140303514462080 learning.py:512] global step 7111: loss = 4.4666 (0.924 sec/step)\n","INFO:tensorflow:global step 7112: loss = 3.9792 (0.912 sec/step)\n","I1215 19:49:23.190667 140303514462080 learning.py:512] global step 7112: loss = 3.9792 (0.912 sec/step)\n","INFO:tensorflow:global step 7113: loss = 3.9323 (0.926 sec/step)\n","I1215 19:49:24.117605 140303514462080 learning.py:512] global step 7113: loss = 3.9323 (0.926 sec/step)\n","INFO:tensorflow:global step 7114: loss = 3.9053 (0.913 sec/step)\n","I1215 19:49:25.032888 140303514462080 learning.py:512] global step 7114: loss = 3.9053 (0.913 sec/step)\n","INFO:tensorflow:global step 7115: loss = 3.1040 (0.917 sec/step)\n","I1215 19:49:25.950995 140303514462080 learning.py:512] global step 7115: loss = 3.1040 (0.917 sec/step)\n","INFO:tensorflow:global step 7116: loss = 3.0937 (0.938 sec/step)\n","I1215 19:49:26.890463 140303514462080 learning.py:512] global step 7116: loss = 3.0937 (0.938 sec/step)\n","INFO:tensorflow:global step 7117: loss = 3.5345 (0.900 sec/step)\n","I1215 19:49:27.791471 140303514462080 learning.py:512] global step 7117: loss = 3.5345 (0.900 sec/step)\n","INFO:tensorflow:global step 7118: loss = 5.8064 (0.891 sec/step)\n","I1215 19:49:28.683607 140303514462080 learning.py:512] global step 7118: loss = 5.8064 (0.891 sec/step)\n","INFO:tensorflow:global step 7119: loss = 3.9401 (0.896 sec/step)\n","I1215 19:49:29.580850 140303514462080 learning.py:512] global step 7119: loss = 3.9401 (0.896 sec/step)\n","INFO:tensorflow:global step 7120: loss = 3.9923 (0.898 sec/step)\n","I1215 19:49:30.480734 140303514462080 learning.py:512] global step 7120: loss = 3.9923 (0.898 sec/step)\n","INFO:tensorflow:global step 7121: loss = 6.9705 (0.941 sec/step)\n","I1215 19:49:31.423254 140303514462080 learning.py:512] global step 7121: loss = 6.9705 (0.941 sec/step)\n","INFO:tensorflow:global step 7122: loss = 3.1079 (0.928 sec/step)\n","I1215 19:49:32.352795 140303514462080 learning.py:512] global step 7122: loss = 3.1079 (0.928 sec/step)\n","INFO:tensorflow:global step 7123: loss = 3.2674 (0.924 sec/step)\n","I1215 19:49:33.278124 140303514462080 learning.py:512] global step 7123: loss = 3.2674 (0.924 sec/step)\n","INFO:tensorflow:global step 7124: loss = 4.0916 (0.911 sec/step)\n","I1215 19:49:34.190838 140303514462080 learning.py:512] global step 7124: loss = 4.0916 (0.911 sec/step)\n","INFO:tensorflow:global step 7125: loss = 4.8914 (0.923 sec/step)\n","I1215 19:49:35.115321 140303514462080 learning.py:512] global step 7125: loss = 4.8914 (0.923 sec/step)\n","INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n","I1215 19:49:35.601168 140299865970432 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n","INFO:tensorflow:global step 7126: loss = 3.6098 (1.672 sec/step)\n","I1215 19:49:36.794224 140303514462080 learning.py:512] global step 7126: loss = 3.6098 (1.672 sec/step)\n","INFO:tensorflow:Recording summary at step 7126.\n","I1215 19:49:37.709889 140299899541248 supervisor.py:1050] Recording summary at step 7126.\n","INFO:tensorflow:global step 7127: loss = 4.7980 (1.490 sec/step)\n","I1215 19:49:38.291710 140303514462080 learning.py:512] global step 7127: loss = 4.7980 (1.490 sec/step)\n","INFO:tensorflow:global step 7128: loss = 4.0943 (1.619 sec/step)\n","I1215 19:49:39.922237 140303514462080 learning.py:512] global step 7128: loss = 4.0943 (1.619 sec/step)\n","INFO:tensorflow:global step 7129: loss = 3.0064 (1.152 sec/step)\n","I1215 19:49:41.076520 140303514462080 learning.py:512] global step 7129: loss = 3.0064 (1.152 sec/step)\n","INFO:tensorflow:global step 7130: loss = 3.2568 (0.911 sec/step)\n","I1215 19:49:41.989149 140303514462080 learning.py:512] global step 7130: loss = 3.2568 (0.911 sec/step)\n","INFO:tensorflow:global step 7131: loss = 3.5013 (0.934 sec/step)\n","I1215 19:49:42.924978 140303514462080 learning.py:512] global step 7131: loss = 3.5013 (0.934 sec/step)\n","INFO:tensorflow:global step 7132: loss = 3.5158 (0.949 sec/step)\n","I1215 19:49:43.876028 140303514462080 learning.py:512] global step 7132: loss = 3.5158 (0.949 sec/step)\n","INFO:tensorflow:global step 7133: loss = 5.0241 (0.910 sec/step)\n","I1215 19:49:44.787227 140303514462080 learning.py:512] global step 7133: loss = 5.0241 (0.910 sec/step)\n","INFO:tensorflow:global step 7134: loss = 2.9296 (0.919 sec/step)\n","I1215 19:49:45.707420 140303514462080 learning.py:512] global step 7134: loss = 2.9296 (0.919 sec/step)\n","INFO:tensorflow:global step 7135: loss = 3.8443 (0.911 sec/step)\n","I1215 19:49:46.620161 140303514462080 learning.py:512] global step 7135: loss = 3.8443 (0.911 sec/step)\n","INFO:tensorflow:global step 7136: loss = 2.8902 (0.897 sec/step)\n","I1215 19:49:47.518701 140303514462080 learning.py:512] global step 7136: loss = 2.8902 (0.897 sec/step)\n","INFO:tensorflow:global step 7137: loss = 4.5256 (0.903 sec/step)\n","I1215 19:49:48.423105 140303514462080 learning.py:512] global step 7137: loss = 4.5256 (0.903 sec/step)\n","INFO:tensorflow:global step 7138: loss = 3.4257 (0.934 sec/step)\n","I1215 19:49:49.358761 140303514462080 learning.py:512] global step 7138: loss = 3.4257 (0.934 sec/step)\n","INFO:tensorflow:global step 7139: loss = 3.7561 (0.936 sec/step)\n","I1215 19:49:50.296201 140303514462080 learning.py:512] global step 7139: loss = 3.7561 (0.936 sec/step)\n","INFO:tensorflow:global step 7140: loss = 3.6249 (0.937 sec/step)\n","I1215 19:49:51.234730 140303514462080 learning.py:512] global step 7140: loss = 3.6249 (0.937 sec/step)\n","INFO:tensorflow:global step 7141: loss = 4.2297 (0.922 sec/step)\n","I1215 19:49:52.157855 140303514462080 learning.py:512] global step 7141: loss = 4.2297 (0.922 sec/step)\n","INFO:tensorflow:global step 7142: loss = 4.8460 (0.939 sec/step)\n","I1215 19:49:53.098178 140303514462080 learning.py:512] global step 7142: loss = 4.8460 (0.939 sec/step)\n","INFO:tensorflow:global step 7143: loss = 3.0808 (0.905 sec/step)\n","I1215 19:49:54.004456 140303514462080 learning.py:512] global step 7143: loss = 3.0808 (0.905 sec/step)\n","INFO:tensorflow:global step 7144: loss = 5.3618 (0.924 sec/step)\n","I1215 19:49:54.929762 140303514462080 learning.py:512] global step 7144: loss = 5.3618 (0.924 sec/step)\n","INFO:tensorflow:global step 7145: loss = 2.5509 (0.922 sec/step)\n","I1215 19:49:55.853486 140303514462080 learning.py:512] global step 7145: loss = 2.5509 (0.922 sec/step)\n","INFO:tensorflow:global step 7146: loss = 3.6377 (0.936 sec/step)\n","I1215 19:49:56.790639 140303514462080 learning.py:512] global step 7146: loss = 3.6377 (0.936 sec/step)\n","INFO:tensorflow:global step 7147: loss = 4.0490 (0.902 sec/step)\n","I1215 19:49:57.693812 140303514462080 learning.py:512] global step 7147: loss = 4.0490 (0.902 sec/step)\n","INFO:tensorflow:global step 7148: loss = 4.2618 (0.898 sec/step)\n","I1215 19:49:58.593416 140303514462080 learning.py:512] global step 7148: loss = 4.2618 (0.898 sec/step)\n","INFO:tensorflow:global step 7149: loss = 3.4936 (0.923 sec/step)\n","I1215 19:49:59.518294 140303514462080 learning.py:512] global step 7149: loss = 3.4936 (0.923 sec/step)\n","INFO:tensorflow:global step 7150: loss = 6.7281 (0.918 sec/step)\n","I1215 19:50:00.437514 140303514462080 learning.py:512] global step 7150: loss = 6.7281 (0.918 sec/step)\n","INFO:tensorflow:global step 7151: loss = 4.7759 (0.932 sec/step)\n","I1215 19:50:01.370759 140303514462080 learning.py:512] global step 7151: loss = 4.7759 (0.932 sec/step)\n","INFO:tensorflow:global step 7152: loss = 6.7162 (0.901 sec/step)\n","I1215 19:50:02.272904 140303514462080 learning.py:512] global step 7152: loss = 6.7162 (0.901 sec/step)\n","INFO:tensorflow:global step 7153: loss = 3.8584 (0.903 sec/step)\n","I1215 19:50:03.177156 140303514462080 learning.py:512] global step 7153: loss = 3.8584 (0.903 sec/step)\n","INFO:tensorflow:global step 7154: loss = 5.4602 (0.911 sec/step)\n","I1215 19:50:04.089336 140303514462080 learning.py:512] global step 7154: loss = 5.4602 (0.911 sec/step)\n","INFO:tensorflow:global step 7155: loss = 4.3385 (0.942 sec/step)\n","I1215 19:50:05.032505 140303514462080 learning.py:512] global step 7155: loss = 4.3385 (0.942 sec/step)\n","INFO:tensorflow:global step 7156: loss = 3.3428 (0.888 sec/step)\n","I1215 19:50:05.922250 140303514462080 learning.py:512] global step 7156: loss = 3.3428 (0.888 sec/step)\n","INFO:tensorflow:global step 7157: loss = 4.6267 (0.901 sec/step)\n","I1215 19:50:06.824760 140303514462080 learning.py:512] global step 7157: loss = 4.6267 (0.901 sec/step)\n","INFO:tensorflow:global step 7158: loss = 3.2215 (0.899 sec/step)\n","I1215 19:50:07.725537 140303514462080 learning.py:512] global step 7158: loss = 3.2215 (0.899 sec/step)\n","INFO:tensorflow:global step 7159: loss = 4.7271 (0.894 sec/step)\n","I1215 19:50:08.621431 140303514462080 learning.py:512] global step 7159: loss = 4.7271 (0.894 sec/step)\n","INFO:tensorflow:global step 7160: loss = 3.1017 (0.904 sec/step)\n","I1215 19:50:09.526449 140303514462080 learning.py:512] global step 7160: loss = 3.1017 (0.904 sec/step)\n","INFO:tensorflow:global step 7161: loss = 5.0702 (0.907 sec/step)\n","I1215 19:50:10.434746 140303514462080 learning.py:512] global step 7161: loss = 5.0702 (0.907 sec/step)\n","INFO:tensorflow:global step 7162: loss = 3.7944 (0.901 sec/step)\n","I1215 19:50:11.337012 140303514462080 learning.py:512] global step 7162: loss = 3.7944 (0.901 sec/step)\n","INFO:tensorflow:global step 7163: loss = 3.3173 (0.928 sec/step)\n","I1215 19:50:12.266679 140303514462080 learning.py:512] global step 7163: loss = 3.3173 (0.928 sec/step)\n","INFO:tensorflow:global step 7164: loss = 4.0561 (0.892 sec/step)\n","I1215 19:50:13.160030 140303514462080 learning.py:512] global step 7164: loss = 4.0561 (0.892 sec/step)\n","INFO:tensorflow:global step 7165: loss = 2.8593 (0.914 sec/step)\n","I1215 19:50:14.075359 140303514462080 learning.py:512] global step 7165: loss = 2.8593 (0.914 sec/step)\n","INFO:tensorflow:global step 7166: loss = 4.4002 (0.902 sec/step)\n","I1215 19:50:14.978540 140303514462080 learning.py:512] global step 7166: loss = 4.4002 (0.902 sec/step)\n","INFO:tensorflow:global step 7167: loss = 3.4231 (0.894 sec/step)\n","I1215 19:50:15.874490 140303514462080 learning.py:512] global step 7167: loss = 3.4231 (0.894 sec/step)\n","INFO:tensorflow:global step 7168: loss = 4.5179 (0.895 sec/step)\n","I1215 19:50:16.770627 140303514462080 learning.py:512] global step 7168: loss = 4.5179 (0.895 sec/step)\n","INFO:tensorflow:global step 7169: loss = 3.7241 (0.895 sec/step)\n","I1215 19:50:17.667349 140303514462080 learning.py:512] global step 7169: loss = 3.7241 (0.895 sec/step)\n","INFO:tensorflow:global step 7170: loss = 3.7219 (0.907 sec/step)\n","I1215 19:50:18.576498 140303514462080 learning.py:512] global step 7170: loss = 3.7219 (0.907 sec/step)\n","INFO:tensorflow:global step 7171: loss = 4.7896 (0.909 sec/step)\n","I1215 19:50:19.486840 140303514462080 learning.py:512] global step 7171: loss = 4.7896 (0.909 sec/step)\n","INFO:tensorflow:global step 7172: loss = 5.7144 (0.906 sec/step)\n","I1215 19:50:20.394419 140303514462080 learning.py:512] global step 7172: loss = 5.7144 (0.906 sec/step)\n","INFO:tensorflow:global step 7173: loss = 3.5831 (0.922 sec/step)\n","I1215 19:50:21.317709 140303514462080 learning.py:512] global step 7173: loss = 3.5831 (0.922 sec/step)\n","INFO:tensorflow:global step 7174: loss = 6.0860 (0.932 sec/step)\n","I1215 19:50:22.250750 140303514462080 learning.py:512] global step 7174: loss = 6.0860 (0.932 sec/step)\n","INFO:tensorflow:global step 7175: loss = 5.2051 (0.912 sec/step)\n","I1215 19:50:23.165200 140303514462080 learning.py:512] global step 7175: loss = 5.2051 (0.912 sec/step)\n","INFO:tensorflow:global step 7176: loss = 4.5042 (0.898 sec/step)\n","I1215 19:50:24.064678 140303514462080 learning.py:512] global step 7176: loss = 4.5042 (0.898 sec/step)\n","INFO:tensorflow:global step 7177: loss = 4.9817 (0.896 sec/step)\n","I1215 19:50:24.961952 140303514462080 learning.py:512] global step 7177: loss = 4.9817 (0.896 sec/step)\n","INFO:tensorflow:global step 7178: loss = 4.6328 (0.900 sec/step)\n","I1215 19:50:25.863174 140303514462080 learning.py:512] global step 7178: loss = 4.6328 (0.900 sec/step)\n","INFO:tensorflow:global step 7179: loss = 6.2248 (0.893 sec/step)\n","I1215 19:50:26.757831 140303514462080 learning.py:512] global step 7179: loss = 6.2248 (0.893 sec/step)\n","INFO:tensorflow:global step 7180: loss = 3.8413 (0.916 sec/step)\n","I1215 19:50:27.674947 140303514462080 learning.py:512] global step 7180: loss = 3.8413 (0.916 sec/step)\n","INFO:tensorflow:global step 7181: loss = 4.2442 (0.911 sec/step)\n","I1215 19:50:28.586961 140303514462080 learning.py:512] global step 7181: loss = 4.2442 (0.911 sec/step)\n","INFO:tensorflow:global step 7182: loss = 5.5990 (0.911 sec/step)\n","I1215 19:50:29.499524 140303514462080 learning.py:512] global step 7182: loss = 5.5990 (0.911 sec/step)\n","INFO:tensorflow:global step 7183: loss = 6.1868 (0.899 sec/step)\n","I1215 19:50:30.400208 140303514462080 learning.py:512] global step 7183: loss = 6.1868 (0.899 sec/step)\n","INFO:tensorflow:global step 7184: loss = 5.7348 (0.908 sec/step)\n","I1215 19:50:31.309765 140303514462080 learning.py:512] global step 7184: loss = 5.7348 (0.908 sec/step)\n","INFO:tensorflow:global step 7185: loss = 5.0527 (0.907 sec/step)\n","I1215 19:50:32.218470 140303514462080 learning.py:512] global step 7185: loss = 5.0527 (0.907 sec/step)\n","INFO:tensorflow:global step 7186: loss = 8.4219 (0.898 sec/step)\n","I1215 19:50:33.119980 140303514462080 learning.py:512] global step 7186: loss = 8.4219 (0.898 sec/step)\n","INFO:tensorflow:global step 7187: loss = 4.8854 (0.891 sec/step)\n","I1215 19:50:34.012393 140303514462080 learning.py:512] global step 7187: loss = 4.8854 (0.891 sec/step)\n","INFO:tensorflow:global step 7188: loss = 4.9392 (0.895 sec/step)\n","I1215 19:50:34.908582 140303514462080 learning.py:512] global step 7188: loss = 4.9392 (0.895 sec/step)\n","INFO:tensorflow:global step 7189: loss = 4.0831 (0.921 sec/step)\n","I1215 19:50:35.831430 140303514462080 learning.py:512] global step 7189: loss = 4.0831 (0.921 sec/step)\n","INFO:tensorflow:global step 7190: loss = 3.2671 (0.901 sec/step)\n","I1215 19:50:36.734043 140303514462080 learning.py:512] global step 7190: loss = 3.2671 (0.901 sec/step)\n","INFO:tensorflow:global step 7191: loss = 7.1628 (0.925 sec/step)\n","I1215 19:50:37.660529 140303514462080 learning.py:512] global step 7191: loss = 7.1628 (0.925 sec/step)\n","INFO:tensorflow:global step 7192: loss = 6.0759 (0.918 sec/step)\n","I1215 19:50:38.580642 140303514462080 learning.py:512] global step 7192: loss = 6.0759 (0.918 sec/step)\n","INFO:tensorflow:global step 7193: loss = 4.1979 (0.914 sec/step)\n","I1215 19:50:39.496358 140303514462080 learning.py:512] global step 7193: loss = 4.1979 (0.914 sec/step)\n","INFO:tensorflow:global step 7194: loss = 4.7896 (0.922 sec/step)\n","I1215 19:50:40.419514 140303514462080 learning.py:512] global step 7194: loss = 4.7896 (0.922 sec/step)\n","INFO:tensorflow:global step 7195: loss = 3.8946 (0.923 sec/step)\n","I1215 19:50:41.344377 140303514462080 learning.py:512] global step 7195: loss = 3.8946 (0.923 sec/step)\n","INFO:tensorflow:global step 7196: loss = 3.8807 (0.912 sec/step)\n","I1215 19:50:42.257816 140303514462080 learning.py:512] global step 7196: loss = 3.8807 (0.912 sec/step)\n","INFO:tensorflow:global step 7197: loss = 5.5792 (0.908 sec/step)\n","I1215 19:50:43.167547 140303514462080 learning.py:512] global step 7197: loss = 5.5792 (0.908 sec/step)\n","INFO:tensorflow:global step 7198: loss = 5.8472 (0.925 sec/step)\n","I1215 19:50:44.094495 140303514462080 learning.py:512] global step 7198: loss = 5.8472 (0.925 sec/step)\n","INFO:tensorflow:global step 7199: loss = 4.3094 (0.901 sec/step)\n","I1215 19:50:44.997272 140303514462080 learning.py:512] global step 7199: loss = 4.3094 (0.901 sec/step)\n","INFO:tensorflow:global step 7200: loss = 6.0545 (0.917 sec/step)\n","I1215 19:50:45.916061 140303514462080 learning.py:512] global step 7200: loss = 6.0545 (0.917 sec/step)\n","INFO:tensorflow:global step 7201: loss = 7.0315 (0.903 sec/step)\n","I1215 19:50:46.821099 140303514462080 learning.py:512] global step 7201: loss = 7.0315 (0.903 sec/step)\n","INFO:tensorflow:global step 7202: loss = 3.3910 (0.940 sec/step)\n","I1215 19:50:47.763016 140303514462080 learning.py:512] global step 7202: loss = 3.3910 (0.940 sec/step)\n","INFO:tensorflow:global step 7203: loss = 4.7416 (0.946 sec/step)\n","I1215 19:50:48.711114 140303514462080 learning.py:512] global step 7203: loss = 4.7416 (0.946 sec/step)\n","INFO:tensorflow:global step 7204: loss = 3.6295 (0.935 sec/step)\n","I1215 19:50:49.648065 140303514462080 learning.py:512] global step 7204: loss = 3.6295 (0.935 sec/step)\n","INFO:tensorflow:global step 7205: loss = 4.0330 (0.930 sec/step)\n","I1215 19:50:50.579515 140303514462080 learning.py:512] global step 7205: loss = 4.0330 (0.930 sec/step)\n","INFO:tensorflow:global step 7206: loss = 2.6773 (0.925 sec/step)\n","I1215 19:50:51.505816 140303514462080 learning.py:512] global step 7206: loss = 2.6773 (0.925 sec/step)\n","INFO:tensorflow:global step 7207: loss = 3.8133 (0.919 sec/step)\n","I1215 19:50:52.426770 140303514462080 learning.py:512] global step 7207: loss = 3.8133 (0.919 sec/step)\n","INFO:tensorflow:global step 7208: loss = 3.4087 (0.905 sec/step)\n","I1215 19:50:53.333349 140303514462080 learning.py:512] global step 7208: loss = 3.4087 (0.905 sec/step)\n","INFO:tensorflow:global step 7209: loss = 4.7475 (0.916 sec/step)\n","I1215 19:50:54.250934 140303514462080 learning.py:512] global step 7209: loss = 4.7475 (0.916 sec/step)\n","INFO:tensorflow:global step 7210: loss = 5.3591 (0.958 sec/step)\n","I1215 19:50:55.210581 140303514462080 learning.py:512] global step 7210: loss = 5.3591 (0.958 sec/step)\n","INFO:tensorflow:global step 7211: loss = 5.8138 (0.930 sec/step)\n","I1215 19:50:56.142209 140303514462080 learning.py:512] global step 7211: loss = 5.8138 (0.930 sec/step)\n","INFO:tensorflow:global step 7212: loss = 2.9510 (0.905 sec/step)\n","I1215 19:50:57.048624 140303514462080 learning.py:512] global step 7212: loss = 2.9510 (0.905 sec/step)\n","INFO:tensorflow:global step 7213: loss = 4.7760 (0.899 sec/step)\n","I1215 19:50:57.949633 140303514462080 learning.py:512] global step 7213: loss = 4.7760 (0.899 sec/step)\n","INFO:tensorflow:global step 7214: loss = 3.3557 (0.897 sec/step)\n","I1215 19:50:58.847745 140303514462080 learning.py:512] global step 7214: loss = 3.3557 (0.897 sec/step)\n","INFO:tensorflow:global step 7215: loss = 3.4103 (0.917 sec/step)\n","I1215 19:50:59.766395 140303514462080 learning.py:512] global step 7215: loss = 3.4103 (0.917 sec/step)\n","INFO:tensorflow:global step 7216: loss = 3.6744 (0.907 sec/step)\n","I1215 19:51:00.674592 140303514462080 learning.py:512] global step 7216: loss = 3.6744 (0.907 sec/step)\n","INFO:tensorflow:global step 7217: loss = 3.1052 (0.926 sec/step)\n","I1215 19:51:01.602071 140303514462080 learning.py:512] global step 7217: loss = 3.1052 (0.926 sec/step)\n","INFO:tensorflow:global step 7218: loss = 4.1274 (0.884 sec/step)\n","I1215 19:51:02.487874 140303514462080 learning.py:512] global step 7218: loss = 4.1274 (0.884 sec/step)\n","INFO:tensorflow:global step 7219: loss = 5.6761 (0.895 sec/step)\n","I1215 19:51:03.384433 140303514462080 learning.py:512] global step 7219: loss = 5.6761 (0.895 sec/step)\n","INFO:tensorflow:global step 7220: loss = 3.9361 (0.918 sec/step)\n","I1215 19:51:04.303848 140303514462080 learning.py:512] global step 7220: loss = 3.9361 (0.918 sec/step)\n","INFO:tensorflow:global step 7221: loss = 4.6078 (0.916 sec/step)\n","I1215 19:51:05.221520 140303514462080 learning.py:512] global step 7221: loss = 4.6078 (0.916 sec/step)\n","INFO:tensorflow:global step 7222: loss = 4.2973 (0.898 sec/step)\n","I1215 19:51:06.121635 140303514462080 learning.py:512] global step 7222: loss = 4.2973 (0.898 sec/step)\n","INFO:tensorflow:global step 7223: loss = 4.6129 (0.906 sec/step)\n","I1215 19:51:07.028849 140303514462080 learning.py:512] global step 7223: loss = 4.6129 (0.906 sec/step)\n","INFO:tensorflow:global step 7224: loss = 3.7003 (0.918 sec/step)\n","I1215 19:51:07.948692 140303514462080 learning.py:512] global step 7224: loss = 3.7003 (0.918 sec/step)\n","INFO:tensorflow:global step 7225: loss = 3.5503 (0.897 sec/step)\n","I1215 19:51:08.847752 140303514462080 learning.py:512] global step 7225: loss = 3.5503 (0.897 sec/step)\n","INFO:tensorflow:global step 7226: loss = 4.2236 (0.906 sec/step)\n","I1215 19:51:09.755008 140303514462080 learning.py:512] global step 7226: loss = 4.2236 (0.906 sec/step)\n","INFO:tensorflow:global step 7227: loss = 4.0528 (0.890 sec/step)\n","I1215 19:51:10.646849 140303514462080 learning.py:512] global step 7227: loss = 4.0528 (0.890 sec/step)\n","INFO:tensorflow:global step 7228: loss = 5.0059 (0.914 sec/step)\n","I1215 19:51:11.562748 140303514462080 learning.py:512] global step 7228: loss = 5.0059 (0.914 sec/step)\n","INFO:tensorflow:global step 7229: loss = 5.6059 (0.924 sec/step)\n","I1215 19:51:12.488076 140303514462080 learning.py:512] global step 7229: loss = 5.6059 (0.924 sec/step)\n","INFO:tensorflow:global step 7230: loss = 4.7515 (0.911 sec/step)\n","I1215 19:51:13.400200 140303514462080 learning.py:512] global step 7230: loss = 4.7515 (0.911 sec/step)\n","INFO:tensorflow:global step 7231: loss = 4.2238 (0.934 sec/step)\n","I1215 19:51:14.336257 140303514462080 learning.py:512] global step 7231: loss = 4.2238 (0.934 sec/step)\n","INFO:tensorflow:global step 7232: loss = 4.4189 (0.908 sec/step)\n","I1215 19:51:15.246363 140303514462080 learning.py:512] global step 7232: loss = 4.4189 (0.908 sec/step)\n","INFO:tensorflow:global step 7233: loss = 4.7746 (0.925 sec/step)\n","I1215 19:51:16.172614 140303514462080 learning.py:512] global step 7233: loss = 4.7746 (0.925 sec/step)\n","INFO:tensorflow:global step 7234: loss = 3.9527 (0.899 sec/step)\n","I1215 19:51:17.072941 140303514462080 learning.py:512] global step 7234: loss = 3.9527 (0.899 sec/step)\n","INFO:tensorflow:global step 7235: loss = 4.0788 (0.923 sec/step)\n","I1215 19:51:17.997164 140303514462080 learning.py:512] global step 7235: loss = 4.0788 (0.923 sec/step)\n","INFO:tensorflow:global step 7236: loss = 4.6631 (0.923 sec/step)\n","I1215 19:51:18.921306 140303514462080 learning.py:512] global step 7236: loss = 4.6631 (0.923 sec/step)\n","INFO:tensorflow:global step 7237: loss = 3.2561 (0.903 sec/step)\n","I1215 19:51:19.825966 140303514462080 learning.py:512] global step 7237: loss = 3.2561 (0.903 sec/step)\n","INFO:tensorflow:global step 7238: loss = 2.4110 (0.916 sec/step)\n","I1215 19:51:20.743922 140303514462080 learning.py:512] global step 7238: loss = 2.4110 (0.916 sec/step)\n","INFO:tensorflow:global step 7239: loss = 5.3494 (0.905 sec/step)\n","I1215 19:51:21.650581 140303514462080 learning.py:512] global step 7239: loss = 5.3494 (0.905 sec/step)\n","INFO:tensorflow:global step 7240: loss = 4.9157 (0.899 sec/step)\n","I1215 19:51:22.550966 140303514462080 learning.py:512] global step 7240: loss = 4.9157 (0.899 sec/step)\n","INFO:tensorflow:global step 7241: loss = 2.7031 (0.927 sec/step)\n","I1215 19:51:23.479347 140303514462080 learning.py:512] global step 7241: loss = 2.7031 (0.927 sec/step)\n","INFO:tensorflow:global step 7242: loss = 4.0836 (0.905 sec/step)\n","I1215 19:51:24.385686 140303514462080 learning.py:512] global step 7242: loss = 4.0836 (0.905 sec/step)\n","INFO:tensorflow:global step 7243: loss = 3.0108 (0.931 sec/step)\n","I1215 19:51:25.318341 140303514462080 learning.py:512] global step 7243: loss = 3.0108 (0.931 sec/step)\n","INFO:tensorflow:global step 7244: loss = 5.8394 (0.928 sec/step)\n","I1215 19:51:26.247716 140303514462080 learning.py:512] global step 7244: loss = 5.8394 (0.928 sec/step)\n","INFO:tensorflow:global step 7245: loss = 4.7372 (0.929 sec/step)\n","I1215 19:51:27.178254 140303514462080 learning.py:512] global step 7245: loss = 4.7372 (0.929 sec/step)\n","INFO:tensorflow:global step 7246: loss = 3.3258 (0.906 sec/step)\n","I1215 19:51:28.086035 140303514462080 learning.py:512] global step 7246: loss = 3.3258 (0.906 sec/step)\n","INFO:tensorflow:global step 7247: loss = 3.3487 (0.908 sec/step)\n","I1215 19:51:28.996061 140303514462080 learning.py:512] global step 7247: loss = 3.3487 (0.908 sec/step)\n","INFO:tensorflow:global step 7248: loss = 7.2247 (0.910 sec/step)\n","I1215 19:51:29.907548 140303514462080 learning.py:512] global step 7248: loss = 7.2247 (0.910 sec/step)\n","INFO:tensorflow:global step 7249: loss = 2.9596 (0.932 sec/step)\n","I1215 19:51:30.840742 140303514462080 learning.py:512] global step 7249: loss = 2.9596 (0.932 sec/step)\n","INFO:tensorflow:global step 7250: loss = 4.4926 (0.921 sec/step)\n","I1215 19:51:31.763267 140303514462080 learning.py:512] global step 7250: loss = 4.4926 (0.921 sec/step)\n","INFO:tensorflow:global step 7251: loss = 5.0058 (0.929 sec/step)\n","I1215 19:51:32.693787 140303514462080 learning.py:512] global step 7251: loss = 5.0058 (0.929 sec/step)\n","INFO:tensorflow:global step 7252: loss = 4.5407 (0.901 sec/step)\n","I1215 19:51:33.596167 140303514462080 learning.py:512] global step 7252: loss = 4.5407 (0.901 sec/step)\n","INFO:tensorflow:global step 7253: loss = 3.4782 (0.902 sec/step)\n","I1215 19:51:34.499704 140303514462080 learning.py:512] global step 7253: loss = 3.4782 (0.902 sec/step)\n","INFO:tensorflow:global step 7254: loss = 3.8663 (0.907 sec/step)\n","I1215 19:51:35.408265 140303514462080 learning.py:512] global step 7254: loss = 3.8663 (0.907 sec/step)\n","INFO:tensorflow:global step 7255: loss = 2.8430 (1.491 sec/step)\n","I1215 19:51:36.901823 140303514462080 learning.py:512] global step 7255: loss = 2.8430 (1.491 sec/step)\n","INFO:tensorflow:Recording summary at step 7255.\n","I1215 19:51:36.978913 140299899541248 supervisor.py:1050] Recording summary at step 7255.\n","INFO:tensorflow:global step 7256: loss = 4.1484 (0.902 sec/step)\n","I1215 19:51:37.808333 140303514462080 learning.py:512] global step 7256: loss = 4.1484 (0.902 sec/step)\n","INFO:tensorflow:global step 7257: loss = 4.7132 (0.904 sec/step)\n","I1215 19:51:38.713415 140303514462080 learning.py:512] global step 7257: loss = 4.7132 (0.904 sec/step)\n","INFO:tensorflow:global step 7258: loss = 5.1841 (0.895 sec/step)\n","I1215 19:51:39.610393 140303514462080 learning.py:512] global step 7258: loss = 5.1841 (0.895 sec/step)\n","INFO:tensorflow:global step 7259: loss = 5.7635 (0.892 sec/step)\n","I1215 19:51:40.503768 140303514462080 learning.py:512] global step 7259: loss = 5.7635 (0.892 sec/step)\n","INFO:tensorflow:global step 7260: loss = 3.1174 (0.891 sec/step)\n","I1215 19:51:41.396257 140303514462080 learning.py:512] global step 7260: loss = 3.1174 (0.891 sec/step)\n","INFO:tensorflow:global step 7261: loss = 4.3207 (0.894 sec/step)\n","I1215 19:51:42.292094 140303514462080 learning.py:512] global step 7261: loss = 4.3207 (0.894 sec/step)\n","INFO:tensorflow:global step 7262: loss = 3.4472 (0.902 sec/step)\n","I1215 19:51:43.195470 140303514462080 learning.py:512] global step 7262: loss = 3.4472 (0.902 sec/step)\n","INFO:tensorflow:global step 7263: loss = 3.3182 (0.886 sec/step)\n","I1215 19:51:44.083198 140303514462080 learning.py:512] global step 7263: loss = 3.3182 (0.886 sec/step)\n","INFO:tensorflow:global step 7264: loss = 5.1155 (0.895 sec/step)\n","I1215 19:51:44.979599 140303514462080 learning.py:512] global step 7264: loss = 5.1155 (0.895 sec/step)\n","INFO:tensorflow:global step 7265: loss = 3.3126 (0.897 sec/step)\n","I1215 19:51:45.878111 140303514462080 learning.py:512] global step 7265: loss = 3.3126 (0.897 sec/step)\n","INFO:tensorflow:global step 7266: loss = 4.6191 (0.903 sec/step)\n","I1215 19:51:46.782869 140303514462080 learning.py:512] global step 7266: loss = 4.6191 (0.903 sec/step)\n","INFO:tensorflow:global step 7267: loss = 5.0138 (0.904 sec/step)\n","I1215 19:51:47.688460 140303514462080 learning.py:512] global step 7267: loss = 5.0138 (0.904 sec/step)\n","INFO:tensorflow:global step 7268: loss = 3.7826 (0.897 sec/step)\n","I1215 19:51:48.587511 140303514462080 learning.py:512] global step 7268: loss = 3.7826 (0.897 sec/step)\n","INFO:tensorflow:global step 7269: loss = 3.9864 (0.907 sec/step)\n","I1215 19:51:49.496138 140303514462080 learning.py:512] global step 7269: loss = 3.9864 (0.907 sec/step)\n","INFO:tensorflow:global step 7270: loss = 5.9969 (0.886 sec/step)\n","I1215 19:51:50.383778 140303514462080 learning.py:512] global step 7270: loss = 5.9969 (0.886 sec/step)\n","INFO:tensorflow:global step 7271: loss = 4.4353 (0.892 sec/step)\n","I1215 19:51:51.277044 140303514462080 learning.py:512] global step 7271: loss = 4.4353 (0.892 sec/step)\n","INFO:tensorflow:global step 7272: loss = 3.2362 (0.881 sec/step)\n","I1215 19:51:52.159438 140303514462080 learning.py:512] global step 7272: loss = 3.2362 (0.881 sec/step)\n","INFO:tensorflow:global step 7273: loss = 3.2546 (0.894 sec/step)\n","I1215 19:51:53.055405 140303514462080 learning.py:512] global step 7273: loss = 3.2546 (0.894 sec/step)\n","INFO:tensorflow:global step 7274: loss = 5.6633 (0.883 sec/step)\n","I1215 19:51:53.940619 140303514462080 learning.py:512] global step 7274: loss = 5.6633 (0.883 sec/step)\n","INFO:tensorflow:global step 7275: loss = 4.3245 (0.895 sec/step)\n","I1215 19:51:54.837503 140303514462080 learning.py:512] global step 7275: loss = 4.3245 (0.895 sec/step)\n","INFO:tensorflow:global step 7276: loss = 4.3540 (0.896 sec/step)\n","I1215 19:51:55.735284 140303514462080 learning.py:512] global step 7276: loss = 4.3540 (0.896 sec/step)\n","INFO:tensorflow:global step 7277: loss = 3.9669 (0.923 sec/step)\n","I1215 19:51:56.659461 140303514462080 learning.py:512] global step 7277: loss = 3.9669 (0.923 sec/step)\n","INFO:tensorflow:global step 7278: loss = 3.1182 (0.935 sec/step)\n","I1215 19:51:57.596108 140303514462080 learning.py:512] global step 7278: loss = 3.1182 (0.935 sec/step)\n","INFO:tensorflow:global step 7279: loss = 3.2525 (0.925 sec/step)\n","I1215 19:51:58.522805 140303514462080 learning.py:512] global step 7279: loss = 3.2525 (0.925 sec/step)\n","INFO:tensorflow:global step 7280: loss = 3.0906 (0.904 sec/step)\n","I1215 19:51:59.428394 140303514462080 learning.py:512] global step 7280: loss = 3.0906 (0.904 sec/step)\n","INFO:tensorflow:global step 7281: loss = 2.4855 (0.896 sec/step)\n","I1215 19:52:00.326485 140303514462080 learning.py:512] global step 7281: loss = 2.4855 (0.896 sec/step)\n","INFO:tensorflow:global step 7282: loss = 5.9409 (0.912 sec/step)\n","I1215 19:52:01.239691 140303514462080 learning.py:512] global step 7282: loss = 5.9409 (0.912 sec/step)\n","INFO:tensorflow:global step 7283: loss = 5.3621 (0.900 sec/step)\n","I1215 19:52:02.141313 140303514462080 learning.py:512] global step 7283: loss = 5.3621 (0.900 sec/step)\n","INFO:tensorflow:global step 7284: loss = 5.1627 (0.904 sec/step)\n","I1215 19:52:03.046591 140303514462080 learning.py:512] global step 7284: loss = 5.1627 (0.904 sec/step)\n","INFO:tensorflow:global step 7285: loss = 3.4877 (0.908 sec/step)\n","I1215 19:52:03.956710 140303514462080 learning.py:512] global step 7285: loss = 3.4877 (0.908 sec/step)\n","INFO:tensorflow:global step 7286: loss = 4.0582 (0.923 sec/step)\n","I1215 19:52:04.881504 140303514462080 learning.py:512] global step 7286: loss = 4.0582 (0.923 sec/step)\n","INFO:tensorflow:global step 7287: loss = 3.1003 (0.897 sec/step)\n","I1215 19:52:05.779978 140303514462080 learning.py:512] global step 7287: loss = 3.1003 (0.897 sec/step)\n","INFO:tensorflow:global step 7288: loss = 3.2657 (0.904 sec/step)\n","I1215 19:52:06.685002 140303514462080 learning.py:512] global step 7288: loss = 3.2657 (0.904 sec/step)\n","INFO:tensorflow:global step 7289: loss = 3.9416 (0.912 sec/step)\n","I1215 19:52:07.598252 140303514462080 learning.py:512] global step 7289: loss = 3.9416 (0.912 sec/step)\n","INFO:tensorflow:global step 7290: loss = 2.5832 (0.889 sec/step)\n","I1215 19:52:08.489099 140303514462080 learning.py:512] global step 7290: loss = 2.5832 (0.889 sec/step)\n","INFO:tensorflow:global step 7291: loss = 4.0794 (0.919 sec/step)\n","I1215 19:52:09.410001 140303514462080 learning.py:512] global step 7291: loss = 4.0794 (0.919 sec/step)\n","INFO:tensorflow:global step 7292: loss = 3.9131 (0.905 sec/step)\n","I1215 19:52:10.316395 140303514462080 learning.py:512] global step 7292: loss = 3.9131 (0.905 sec/step)\n","INFO:tensorflow:global step 7293: loss = 3.5124 (0.905 sec/step)\n","I1215 19:52:11.222853 140303514462080 learning.py:512] global step 7293: loss = 3.5124 (0.905 sec/step)\n","INFO:tensorflow:global step 7294: loss = 3.5132 (0.917 sec/step)\n","I1215 19:52:12.140870 140303514462080 learning.py:512] global step 7294: loss = 3.5132 (0.917 sec/step)\n","INFO:tensorflow:global step 7295: loss = 4.3048 (0.908 sec/step)\n","I1215 19:52:13.050363 140303514462080 learning.py:512] global step 7295: loss = 4.3048 (0.908 sec/step)\n","INFO:tensorflow:global step 7296: loss = 2.5129 (0.899 sec/step)\n","I1215 19:52:13.950534 140303514462080 learning.py:512] global step 7296: loss = 2.5129 (0.899 sec/step)\n","INFO:tensorflow:global step 7297: loss = 5.1593 (0.909 sec/step)\n","I1215 19:52:14.860924 140303514462080 learning.py:512] global step 7297: loss = 5.1593 (0.909 sec/step)\n","INFO:tensorflow:global step 7298: loss = 3.4839 (0.905 sec/step)\n","I1215 19:52:15.767482 140303514462080 learning.py:512] global step 7298: loss = 3.4839 (0.905 sec/step)\n","INFO:tensorflow:global step 7299: loss = 3.0303 (0.899 sec/step)\n","I1215 19:52:16.668409 140303514462080 learning.py:512] global step 7299: loss = 3.0303 (0.899 sec/step)\n","INFO:tensorflow:global step 7300: loss = 3.7883 (0.904 sec/step)\n","I1215 19:52:17.574295 140303514462080 learning.py:512] global step 7300: loss = 3.7883 (0.904 sec/step)\n","INFO:tensorflow:global step 7301: loss = 4.7655 (0.905 sec/step)\n","I1215 19:52:18.480677 140303514462080 learning.py:512] global step 7301: loss = 4.7655 (0.905 sec/step)\n","INFO:tensorflow:global step 7302: loss = 3.4845 (0.911 sec/step)\n","I1215 19:52:19.393637 140303514462080 learning.py:512] global step 7302: loss = 3.4845 (0.911 sec/step)\n","INFO:tensorflow:global step 7303: loss = 4.8668 (0.901 sec/step)\n","I1215 19:52:20.296420 140303514462080 learning.py:512] global step 7303: loss = 4.8668 (0.901 sec/step)\n","INFO:tensorflow:global step 7304: loss = 4.0207 (0.891 sec/step)\n","I1215 19:52:21.189378 140303514462080 learning.py:512] global step 7304: loss = 4.0207 (0.891 sec/step)\n","INFO:tensorflow:global step 7305: loss = 3.8565 (0.915 sec/step)\n","I1215 19:52:22.105857 140303514462080 learning.py:512] global step 7305: loss = 3.8565 (0.915 sec/step)\n","INFO:tensorflow:global step 7306: loss = 6.1105 (0.908 sec/step)\n","I1215 19:52:23.015325 140303514462080 learning.py:512] global step 7306: loss = 6.1105 (0.908 sec/step)\n","INFO:tensorflow:global step 7307: loss = 2.1983 (0.899 sec/step)\n","I1215 19:52:23.915797 140303514462080 learning.py:512] global step 7307: loss = 2.1983 (0.899 sec/step)\n","INFO:tensorflow:global step 7308: loss = 4.1960 (0.907 sec/step)\n","I1215 19:52:24.824563 140303514462080 learning.py:512] global step 7308: loss = 4.1960 (0.907 sec/step)\n","INFO:tensorflow:global step 7309: loss = 3.8015 (0.887 sec/step)\n","I1215 19:52:25.713083 140303514462080 learning.py:512] global step 7309: loss = 3.8015 (0.887 sec/step)\n","INFO:tensorflow:global step 7310: loss = 3.3823 (0.894 sec/step)\n","I1215 19:52:26.610441 140303514462080 learning.py:512] global step 7310: loss = 3.3823 (0.894 sec/step)\n","INFO:tensorflow:global step 7311: loss = 6.5541 (0.914 sec/step)\n","I1215 19:52:27.526244 140303514462080 learning.py:512] global step 7311: loss = 6.5541 (0.914 sec/step)\n","INFO:tensorflow:global step 7312: loss = 3.8309 (0.899 sec/step)\n","I1215 19:52:28.426929 140303514462080 learning.py:512] global step 7312: loss = 3.8309 (0.899 sec/step)\n","INFO:tensorflow:global step 7313: loss = 5.7449 (0.890 sec/step)\n","I1215 19:52:29.318044 140303514462080 learning.py:512] global step 7313: loss = 5.7449 (0.890 sec/step)\n","INFO:tensorflow:global step 7314: loss = 3.3109 (0.911 sec/step)\n","I1215 19:52:30.230119 140303514462080 learning.py:512] global step 7314: loss = 3.3109 (0.911 sec/step)\n","INFO:tensorflow:global step 7315: loss = 3.8335 (0.934 sec/step)\n","I1215 19:52:31.165912 140303514462080 learning.py:512] global step 7315: loss = 3.8335 (0.934 sec/step)\n","INFO:tensorflow:global step 7316: loss = 5.7537 (0.926 sec/step)\n","I1215 19:52:32.093610 140303514462080 learning.py:512] global step 7316: loss = 5.7537 (0.926 sec/step)\n","INFO:tensorflow:global step 7317: loss = 5.5375 (0.921 sec/step)\n","I1215 19:52:33.016747 140303514462080 learning.py:512] global step 7317: loss = 5.5375 (0.921 sec/step)\n","INFO:tensorflow:global step 7318: loss = 4.1784 (0.892 sec/step)\n","I1215 19:52:33.910551 140303514462080 learning.py:512] global step 7318: loss = 4.1784 (0.892 sec/step)\n","INFO:tensorflow:global step 7319: loss = 3.8162 (0.884 sec/step)\n","I1215 19:52:34.796227 140303514462080 learning.py:512] global step 7319: loss = 3.8162 (0.884 sec/step)\n","INFO:tensorflow:global step 7320: loss = 4.8277 (0.881 sec/step)\n","I1215 19:52:35.678918 140303514462080 learning.py:512] global step 7320: loss = 4.8277 (0.881 sec/step)\n","INFO:tensorflow:global step 7321: loss = 4.8587 (0.908 sec/step)\n","I1215 19:52:36.588437 140303514462080 learning.py:512] global step 7321: loss = 4.8587 (0.908 sec/step)\n","INFO:tensorflow:global step 7322: loss = 4.1755 (0.886 sec/step)\n","I1215 19:52:37.475929 140303514462080 learning.py:512] global step 7322: loss = 4.1755 (0.886 sec/step)\n","INFO:tensorflow:global step 7323: loss = 4.3390 (0.898 sec/step)\n","I1215 19:52:38.375679 140303514462080 learning.py:512] global step 7323: loss = 4.3390 (0.898 sec/step)\n","INFO:tensorflow:global step 7324: loss = 2.4794 (0.906 sec/step)\n","I1215 19:52:39.282866 140303514462080 learning.py:512] global step 7324: loss = 2.4794 (0.906 sec/step)\n","INFO:tensorflow:global step 7325: loss = 2.8006 (0.902 sec/step)\n","I1215 19:52:40.186573 140303514462080 learning.py:512] global step 7325: loss = 2.8006 (0.902 sec/step)\n","INFO:tensorflow:global step 7326: loss = 3.9983 (0.892 sec/step)\n","I1215 19:52:41.079737 140303514462080 learning.py:512] global step 7326: loss = 3.9983 (0.892 sec/step)\n","INFO:tensorflow:global step 7327: loss = 3.5631 (0.887 sec/step)\n","I1215 19:52:41.968229 140303514462080 learning.py:512] global step 7327: loss = 3.5631 (0.887 sec/step)\n","INFO:tensorflow:global step 7328: loss = 3.3028 (0.886 sec/step)\n","I1215 19:52:42.856031 140303514462080 learning.py:512] global step 7328: loss = 3.3028 (0.886 sec/step)\n","INFO:tensorflow:global step 7329: loss = 3.7972 (0.884 sec/step)\n","I1215 19:52:43.741749 140303514462080 learning.py:512] global step 7329: loss = 3.7972 (0.884 sec/step)\n","INFO:tensorflow:global step 7330: loss = 3.2351 (0.909 sec/step)\n","I1215 19:52:44.651803 140303514462080 learning.py:512] global step 7330: loss = 3.2351 (0.909 sec/step)\n","INFO:tensorflow:global step 7331: loss = 2.8132 (0.889 sec/step)\n","I1215 19:52:45.542229 140303514462080 learning.py:512] global step 7331: loss = 2.8132 (0.889 sec/step)\n","INFO:tensorflow:global step 7332: loss = 4.2326 (0.893 sec/step)\n","I1215 19:52:46.436417 140303514462080 learning.py:512] global step 7332: loss = 4.2326 (0.893 sec/step)\n","INFO:tensorflow:global step 7333: loss = 4.9877 (0.897 sec/step)\n","I1215 19:52:47.334451 140303514462080 learning.py:512] global step 7333: loss = 4.9877 (0.897 sec/step)\n","INFO:tensorflow:global step 7334: loss = 3.0230 (0.905 sec/step)\n","I1215 19:52:48.240583 140303514462080 learning.py:512] global step 7334: loss = 3.0230 (0.905 sec/step)\n","INFO:tensorflow:global step 7335: loss = 4.7809 (0.919 sec/step)\n","I1215 19:52:49.161376 140303514462080 learning.py:512] global step 7335: loss = 4.7809 (0.919 sec/step)\n","INFO:tensorflow:global step 7336: loss = 4.7126 (0.888 sec/step)\n","I1215 19:52:50.051056 140303514462080 learning.py:512] global step 7336: loss = 4.7126 (0.888 sec/step)\n","INFO:tensorflow:global step 7337: loss = 3.9690 (0.893 sec/step)\n","I1215 19:52:50.945319 140303514462080 learning.py:512] global step 7337: loss = 3.9690 (0.893 sec/step)\n","INFO:tensorflow:global step 7338: loss = 4.8105 (0.891 sec/step)\n","I1215 19:52:51.838170 140303514462080 learning.py:512] global step 7338: loss = 4.8105 (0.891 sec/step)\n","INFO:tensorflow:global step 7339: loss = 5.3732 (0.890 sec/step)\n","I1215 19:52:52.729989 140303514462080 learning.py:512] global step 7339: loss = 5.3732 (0.890 sec/step)\n","INFO:tensorflow:global step 7340: loss = 4.0113 (0.887 sec/step)\n","I1215 19:52:53.618003 140303514462080 learning.py:512] global step 7340: loss = 4.0113 (0.887 sec/step)\n","INFO:tensorflow:global step 7341: loss = 4.7600 (0.896 sec/step)\n","I1215 19:52:54.516020 140303514462080 learning.py:512] global step 7341: loss = 4.7600 (0.896 sec/step)\n","INFO:tensorflow:global step 7342: loss = 5.6659 (0.892 sec/step)\n","I1215 19:52:55.409102 140303514462080 learning.py:512] global step 7342: loss = 5.6659 (0.892 sec/step)\n","INFO:tensorflow:global step 7343: loss = 4.6505 (0.906 sec/step)\n","I1215 19:52:56.316622 140303514462080 learning.py:512] global step 7343: loss = 4.6505 (0.906 sec/step)\n","INFO:tensorflow:global step 7344: loss = 4.4799 (0.883 sec/step)\n","I1215 19:52:57.201305 140303514462080 learning.py:512] global step 7344: loss = 4.4799 (0.883 sec/step)\n","INFO:tensorflow:global step 7345: loss = 5.1385 (0.894 sec/step)\n","I1215 19:52:58.097099 140303514462080 learning.py:512] global step 7345: loss = 5.1385 (0.894 sec/step)\n","INFO:tensorflow:global step 7346: loss = 4.0280 (0.891 sec/step)\n","I1215 19:52:58.989151 140303514462080 learning.py:512] global step 7346: loss = 4.0280 (0.891 sec/step)\n","INFO:tensorflow:global step 7347: loss = 4.3136 (0.900 sec/step)\n","I1215 19:52:59.890877 140303514462080 learning.py:512] global step 7347: loss = 4.3136 (0.900 sec/step)\n","INFO:tensorflow:global step 7348: loss = 2.9033 (0.889 sec/step)\n","I1215 19:53:00.781677 140303514462080 learning.py:512] global step 7348: loss = 2.9033 (0.889 sec/step)\n","INFO:tensorflow:global step 7349: loss = 4.1969 (0.922 sec/step)\n","I1215 19:53:01.704929 140303514462080 learning.py:512] global step 7349: loss = 4.1969 (0.922 sec/step)\n","INFO:tensorflow:global step 7350: loss = 4.7771 (0.906 sec/step)\n","I1215 19:53:02.612046 140303514462080 learning.py:512] global step 7350: loss = 4.7771 (0.906 sec/step)\n","INFO:tensorflow:global step 7351: loss = 4.5630 (0.899 sec/step)\n","I1215 19:53:03.512300 140303514462080 learning.py:512] global step 7351: loss = 4.5630 (0.899 sec/step)\n","INFO:tensorflow:global step 7352: loss = 4.0262 (0.882 sec/step)\n","I1215 19:53:04.395591 140303514462080 learning.py:512] global step 7352: loss = 4.0262 (0.882 sec/step)\n","INFO:tensorflow:global step 7353: loss = 5.0261 (0.893 sec/step)\n","I1215 19:53:05.289746 140303514462080 learning.py:512] global step 7353: loss = 5.0261 (0.893 sec/step)\n","INFO:tensorflow:global step 7354: loss = 3.2266 (0.880 sec/step)\n","I1215 19:53:06.173311 140303514462080 learning.py:512] global step 7354: loss = 3.2266 (0.880 sec/step)\n","INFO:tensorflow:global step 7355: loss = 3.9594 (0.901 sec/step)\n","I1215 19:53:07.077584 140303514462080 learning.py:512] global step 7355: loss = 3.9594 (0.901 sec/step)\n","INFO:tensorflow:global step 7356: loss = 3.5353 (0.903 sec/step)\n","I1215 19:53:07.981996 140303514462080 learning.py:512] global step 7356: loss = 3.5353 (0.903 sec/step)\n","INFO:tensorflow:global step 7357: loss = 3.4744 (0.895 sec/step)\n","I1215 19:53:08.878304 140303514462080 learning.py:512] global step 7357: loss = 3.4744 (0.895 sec/step)\n","INFO:tensorflow:global step 7358: loss = 3.4845 (0.898 sec/step)\n","I1215 19:53:09.778440 140303514462080 learning.py:512] global step 7358: loss = 3.4845 (0.898 sec/step)\n","INFO:tensorflow:global step 7359: loss = 4.2107 (0.880 sec/step)\n","I1215 19:53:10.660060 140303514462080 learning.py:512] global step 7359: loss = 4.2107 (0.880 sec/step)\n","INFO:tensorflow:global step 7360: loss = 3.8556 (0.903 sec/step)\n","I1215 19:53:11.565155 140303514462080 learning.py:512] global step 7360: loss = 3.8556 (0.903 sec/step)\n","INFO:tensorflow:global step 7361: loss = 4.1397 (0.911 sec/step)\n","I1215 19:53:12.477950 140303514462080 learning.py:512] global step 7361: loss = 4.1397 (0.911 sec/step)\n","INFO:tensorflow:global step 7362: loss = 3.8536 (0.880 sec/step)\n","I1215 19:53:13.359896 140303514462080 learning.py:512] global step 7362: loss = 3.8536 (0.880 sec/step)\n","INFO:tensorflow:global step 7363: loss = 2.9084 (0.890 sec/step)\n","I1215 19:53:14.250947 140303514462080 learning.py:512] global step 7363: loss = 2.9084 (0.890 sec/step)\n","INFO:tensorflow:global step 7364: loss = 3.2370 (0.894 sec/step)\n","I1215 19:53:15.146381 140303514462080 learning.py:512] global step 7364: loss = 3.2370 (0.894 sec/step)\n","INFO:tensorflow:global step 7365: loss = 4.9431 (0.891 sec/step)\n","I1215 19:53:16.039020 140303514462080 learning.py:512] global step 7365: loss = 4.9431 (0.891 sec/step)\n","INFO:tensorflow:global step 7366: loss = 2.8282 (0.892 sec/step)\n","I1215 19:53:16.932332 140303514462080 learning.py:512] global step 7366: loss = 2.8282 (0.892 sec/step)\n","INFO:tensorflow:global step 7367: loss = 5.4293 (0.897 sec/step)\n","I1215 19:53:17.831032 140303514462080 learning.py:512] global step 7367: loss = 5.4293 (0.897 sec/step)\n","INFO:tensorflow:global step 7368: loss = 4.6256 (0.901 sec/step)\n","I1215 19:53:18.733090 140303514462080 learning.py:512] global step 7368: loss = 4.6256 (0.901 sec/step)\n","INFO:tensorflow:global step 7369: loss = 3.3674 (0.885 sec/step)\n","I1215 19:53:19.619226 140303514462080 learning.py:512] global step 7369: loss = 3.3674 (0.885 sec/step)\n","INFO:tensorflow:global step 7370: loss = 3.6573 (0.905 sec/step)\n","I1215 19:53:20.525576 140303514462080 learning.py:512] global step 7370: loss = 3.6573 (0.905 sec/step)\n","INFO:tensorflow:global step 7371: loss = 3.6892 (0.873 sec/step)\n","I1215 19:53:21.400420 140303514462080 learning.py:512] global step 7371: loss = 3.6892 (0.873 sec/step)\n","INFO:tensorflow:global step 7372: loss = 5.9524 (0.893 sec/step)\n","I1215 19:53:22.295216 140303514462080 learning.py:512] global step 7372: loss = 5.9524 (0.893 sec/step)\n","INFO:tensorflow:global step 7373: loss = 2.3641 (0.885 sec/step)\n","I1215 19:53:23.182053 140303514462080 learning.py:512] global step 7373: loss = 2.3641 (0.885 sec/step)\n","INFO:tensorflow:global step 7374: loss = 4.6388 (0.893 sec/step)\n","I1215 19:53:24.076508 140303514462080 learning.py:512] global step 7374: loss = 4.6388 (0.893 sec/step)\n","INFO:tensorflow:global step 7375: loss = 5.2917 (0.878 sec/step)\n","I1215 19:53:24.955848 140303514462080 learning.py:512] global step 7375: loss = 5.2917 (0.878 sec/step)\n","INFO:tensorflow:global step 7376: loss = 5.7611 (0.909 sec/step)\n","I1215 19:53:25.866724 140303514462080 learning.py:512] global step 7376: loss = 5.7611 (0.909 sec/step)\n","INFO:tensorflow:global step 7377: loss = 2.7419 (0.901 sec/step)\n","I1215 19:53:26.769511 140303514462080 learning.py:512] global step 7377: loss = 2.7419 (0.901 sec/step)\n","INFO:tensorflow:global step 7378: loss = 3.3664 (0.894 sec/step)\n","I1215 19:53:27.665477 140303514462080 learning.py:512] global step 7378: loss = 3.3664 (0.894 sec/step)\n","INFO:tensorflow:global step 7379: loss = 3.5263 (0.889 sec/step)\n","I1215 19:53:28.556091 140303514462080 learning.py:512] global step 7379: loss = 3.5263 (0.889 sec/step)\n","INFO:tensorflow:global step 7380: loss = 3.6976 (0.901 sec/step)\n","I1215 19:53:29.458997 140303514462080 learning.py:512] global step 7380: loss = 3.6976 (0.901 sec/step)\n","INFO:tensorflow:global step 7381: loss = 3.9098 (0.871 sec/step)\n","I1215 19:53:30.331964 140303514462080 learning.py:512] global step 7381: loss = 3.9098 (0.871 sec/step)\n","INFO:tensorflow:global step 7382: loss = 4.4531 (0.901 sec/step)\n","I1215 19:53:31.234679 140303514462080 learning.py:512] global step 7382: loss = 4.4531 (0.901 sec/step)\n","INFO:tensorflow:global step 7383: loss = 3.9820 (0.902 sec/step)\n","I1215 19:53:32.137898 140303514462080 learning.py:512] global step 7383: loss = 3.9820 (0.902 sec/step)\n","INFO:tensorflow:global step 7384: loss = 4.0834 (0.883 sec/step)\n","I1215 19:53:33.022372 140303514462080 learning.py:512] global step 7384: loss = 4.0834 (0.883 sec/step)\n","INFO:tensorflow:global step 7385: loss = 3.9566 (0.904 sec/step)\n","I1215 19:53:33.928198 140303514462080 learning.py:512] global step 7385: loss = 3.9566 (0.904 sec/step)\n","INFO:tensorflow:global step 7386: loss = 5.0326 (0.891 sec/step)\n","I1215 19:53:34.820327 140303514462080 learning.py:512] global step 7386: loss = 5.0326 (0.891 sec/step)\n","INFO:tensorflow:global step 7387: loss = 3.9495 (0.910 sec/step)\n","I1215 19:53:35.732162 140303514462080 learning.py:512] global step 7387: loss = 3.9495 (0.910 sec/step)\n","INFO:tensorflow:Recording summary at step 7387.\n","I1215 19:53:37.041309 140299899541248 supervisor.py:1050] Recording summary at step 7387.\n","INFO:tensorflow:global step 7388: loss = 3.9004 (1.467 sec/step)\n","I1215 19:53:37.200619 140303514462080 learning.py:512] global step 7388: loss = 3.9004 (1.467 sec/step)\n","INFO:tensorflow:global step 7389: loss = 3.8912 (0.884 sec/step)\n","I1215 19:53:38.086612 140303514462080 learning.py:512] global step 7389: loss = 3.8912 (0.884 sec/step)\n","INFO:tensorflow:global step 7390: loss = 3.2278 (0.905 sec/step)\n","I1215 19:53:38.992940 140303514462080 learning.py:512] global step 7390: loss = 3.2278 (0.905 sec/step)\n","INFO:tensorflow:global step 7391: loss = 2.5997 (0.894 sec/step)\n","I1215 19:53:39.888032 140303514462080 learning.py:512] global step 7391: loss = 2.5997 (0.894 sec/step)\n","INFO:tensorflow:global step 7392: loss = 2.7113 (0.880 sec/step)\n","I1215 19:53:40.769081 140303514462080 learning.py:512] global step 7392: loss = 2.7113 (0.880 sec/step)\n","INFO:tensorflow:global step 7393: loss = 4.4610 (0.901 sec/step)\n","I1215 19:53:41.671108 140303514462080 learning.py:512] global step 7393: loss = 4.4610 (0.901 sec/step)\n","INFO:tensorflow:global step 7394: loss = 3.7578 (0.891 sec/step)\n","I1215 19:53:42.563637 140303514462080 learning.py:512] global step 7394: loss = 3.7578 (0.891 sec/step)\n","INFO:tensorflow:global step 7395: loss = 2.9490 (0.893 sec/step)\n","I1215 19:53:43.458572 140303514462080 learning.py:512] global step 7395: loss = 2.9490 (0.893 sec/step)\n","INFO:tensorflow:global step 7396: loss = 3.4788 (0.895 sec/step)\n","I1215 19:53:44.355305 140303514462080 learning.py:512] global step 7396: loss = 3.4788 (0.895 sec/step)\n","INFO:tensorflow:global step 7397: loss = 3.8666 (0.887 sec/step)\n","I1215 19:53:45.244255 140303514462080 learning.py:512] global step 7397: loss = 3.8666 (0.887 sec/step)\n","INFO:tensorflow:global step 7398: loss = 5.4632 (0.905 sec/step)\n","I1215 19:53:46.150890 140303514462080 learning.py:512] global step 7398: loss = 5.4632 (0.905 sec/step)\n","INFO:tensorflow:global step 7399: loss = 4.6236 (0.881 sec/step)\n","I1215 19:53:47.033784 140303514462080 learning.py:512] global step 7399: loss = 4.6236 (0.881 sec/step)\n","INFO:tensorflow:global step 7400: loss = 3.2971 (0.865 sec/step)\n","I1215 19:53:47.900190 140303514462080 learning.py:512] global step 7400: loss = 3.2971 (0.865 sec/step)\n","INFO:tensorflow:global step 7401: loss = 4.1818 (0.883 sec/step)\n","I1215 19:53:48.784773 140303514462080 learning.py:512] global step 7401: loss = 4.1818 (0.883 sec/step)\n","INFO:tensorflow:global step 7402: loss = 3.3773 (0.883 sec/step)\n","I1215 19:53:49.668847 140303514462080 learning.py:512] global step 7402: loss = 3.3773 (0.883 sec/step)\n","INFO:tensorflow:global step 7403: loss = 2.8470 (0.881 sec/step)\n","I1215 19:53:50.551138 140303514462080 learning.py:512] global step 7403: loss = 2.8470 (0.881 sec/step)\n","INFO:tensorflow:global step 7404: loss = 2.5243 (0.881 sec/step)\n","I1215 19:53:51.433752 140303514462080 learning.py:512] global step 7404: loss = 2.5243 (0.881 sec/step)\n","INFO:tensorflow:global step 7405: loss = 3.5129 (0.895 sec/step)\n","I1215 19:53:52.330818 140303514462080 learning.py:512] global step 7405: loss = 3.5129 (0.895 sec/step)\n","INFO:tensorflow:global step 7406: loss = 3.0886 (0.900 sec/step)\n","I1215 19:53:53.232547 140303514462080 learning.py:512] global step 7406: loss = 3.0886 (0.900 sec/step)\n","INFO:tensorflow:global step 7407: loss = 4.6448 (0.901 sec/step)\n","I1215 19:53:54.134945 140303514462080 learning.py:512] global step 7407: loss = 4.6448 (0.901 sec/step)\n","INFO:tensorflow:global step 7408: loss = 3.3477 (0.891 sec/step)\n","I1215 19:53:55.027956 140303514462080 learning.py:512] global step 7408: loss = 3.3477 (0.891 sec/step)\n","INFO:tensorflow:global step 7409: loss = 2.6552 (0.890 sec/step)\n","I1215 19:53:55.919883 140303514462080 learning.py:512] global step 7409: loss = 2.6552 (0.890 sec/step)\n","INFO:tensorflow:global step 7410: loss = 3.3922 (0.913 sec/step)\n","I1215 19:53:56.834544 140303514462080 learning.py:512] global step 7410: loss = 3.3922 (0.913 sec/step)\n","INFO:tensorflow:global step 7411: loss = 6.0330 (0.929 sec/step)\n","I1215 19:53:57.765381 140303514462080 learning.py:512] global step 7411: loss = 6.0330 (0.929 sec/step)\n","INFO:tensorflow:global step 7412: loss = 4.0500 (0.905 sec/step)\n","I1215 19:53:58.671360 140303514462080 learning.py:512] global step 7412: loss = 4.0500 (0.905 sec/step)\n","INFO:tensorflow:global step 7413: loss = 3.9219 (0.901 sec/step)\n","I1215 19:53:59.574148 140303514462080 learning.py:512] global step 7413: loss = 3.9219 (0.901 sec/step)\n","INFO:tensorflow:global step 7414: loss = 4.6213 (0.903 sec/step)\n","I1215 19:54:00.478455 140303514462080 learning.py:512] global step 7414: loss = 4.6213 (0.903 sec/step)\n","INFO:tensorflow:global step 7415: loss = 4.1392 (0.930 sec/step)\n","I1215 19:54:01.410404 140303514462080 learning.py:512] global step 7415: loss = 4.1392 (0.930 sec/step)\n","INFO:tensorflow:global step 7416: loss = 3.5272 (0.912 sec/step)\n","I1215 19:54:02.324098 140303514462080 learning.py:512] global step 7416: loss = 3.5272 (0.912 sec/step)\n","INFO:tensorflow:global step 7417: loss = 3.7955 (0.875 sec/step)\n","I1215 19:54:03.200677 140303514462080 learning.py:512] global step 7417: loss = 3.7955 (0.875 sec/step)\n","INFO:tensorflow:global step 7418: loss = 2.6128 (0.869 sec/step)\n","I1215 19:54:04.071607 140303514462080 learning.py:512] global step 7418: loss = 2.6128 (0.869 sec/step)\n","INFO:tensorflow:global step 7419: loss = 5.2820 (0.906 sec/step)\n","I1215 19:54:04.979539 140303514462080 learning.py:512] global step 7419: loss = 5.2820 (0.906 sec/step)\n","INFO:tensorflow:global step 7420: loss = 4.4893 (0.909 sec/step)\n","I1215 19:54:05.890821 140303514462080 learning.py:512] global step 7420: loss = 4.4893 (0.909 sec/step)\n","INFO:tensorflow:global step 7421: loss = 4.0742 (0.901 sec/step)\n","I1215 19:54:06.793378 140303514462080 learning.py:512] global step 7421: loss = 4.0742 (0.901 sec/step)\n","INFO:tensorflow:global step 7422: loss = 6.4672 (0.894 sec/step)\n","I1215 19:54:07.688742 140303514462080 learning.py:512] global step 7422: loss = 6.4672 (0.894 sec/step)\n","INFO:tensorflow:global step 7423: loss = 3.2971 (0.885 sec/step)\n","I1215 19:54:08.574961 140303514462080 learning.py:512] global step 7423: loss = 3.2971 (0.885 sec/step)\n","INFO:tensorflow:global step 7424: loss = 4.8086 (0.903 sec/step)\n","I1215 19:54:09.479924 140303514462080 learning.py:512] global step 7424: loss = 4.8086 (0.903 sec/step)\n","INFO:tensorflow:global step 7425: loss = 3.7439 (0.895 sec/step)\n","I1215 19:54:10.376013 140303514462080 learning.py:512] global step 7425: loss = 3.7439 (0.895 sec/step)\n","INFO:tensorflow:global step 7426: loss = 3.7640 (0.905 sec/step)\n","I1215 19:54:11.283053 140303514462080 learning.py:512] global step 7426: loss = 3.7640 (0.905 sec/step)\n","INFO:tensorflow:global step 7427: loss = 2.8836 (0.911 sec/step)\n","I1215 19:54:12.196328 140303514462080 learning.py:512] global step 7427: loss = 2.8836 (0.911 sec/step)\n","INFO:tensorflow:global step 7428: loss = 3.8498 (0.892 sec/step)\n","I1215 19:54:13.089676 140303514462080 learning.py:512] global step 7428: loss = 3.8498 (0.892 sec/step)\n","INFO:tensorflow:global step 7429: loss = 3.1814 (0.885 sec/step)\n","I1215 19:54:13.975951 140303514462080 learning.py:512] global step 7429: loss = 3.1814 (0.885 sec/step)\n","INFO:tensorflow:global step 7430: loss = 2.7606 (0.892 sec/step)\n","I1215 19:54:14.869617 140303514462080 learning.py:512] global step 7430: loss = 2.7606 (0.892 sec/step)\n","INFO:tensorflow:global step 7431: loss = 4.3901 (0.889 sec/step)\n","I1215 19:54:15.760254 140303514462080 learning.py:512] global step 7431: loss = 4.3901 (0.889 sec/step)\n","INFO:tensorflow:global step 7432: loss = 3.5878 (0.888 sec/step)\n","I1215 19:54:16.649807 140303514462080 learning.py:512] global step 7432: loss = 3.5878 (0.888 sec/step)\n","INFO:tensorflow:global step 7433: loss = 3.6378 (0.887 sec/step)\n","I1215 19:54:17.538579 140303514462080 learning.py:512] global step 7433: loss = 3.6378 (0.887 sec/step)\n","INFO:tensorflow:global step 7434: loss = 2.8160 (0.874 sec/step)\n","I1215 19:54:18.414417 140303514462080 learning.py:512] global step 7434: loss = 2.8160 (0.874 sec/step)\n","INFO:tensorflow:global step 7435: loss = 3.1964 (0.891 sec/step)\n","I1215 19:54:19.306535 140303514462080 learning.py:512] global step 7435: loss = 3.1964 (0.891 sec/step)\n","INFO:tensorflow:global step 7436: loss = 4.6419 (0.883 sec/step)\n","I1215 19:54:20.190747 140303514462080 learning.py:512] global step 7436: loss = 4.6419 (0.883 sec/step)\n","INFO:tensorflow:global step 7437: loss = 4.0918 (0.885 sec/step)\n","I1215 19:54:21.077429 140303514462080 learning.py:512] global step 7437: loss = 4.0918 (0.885 sec/step)\n","INFO:tensorflow:global step 7438: loss = 2.7444 (0.901 sec/step)\n","I1215 19:54:21.979572 140303514462080 learning.py:512] global step 7438: loss = 2.7444 (0.901 sec/step)\n","INFO:tensorflow:global step 7439: loss = 5.5789 (0.888 sec/step)\n","I1215 19:54:22.869908 140303514462080 learning.py:512] global step 7439: loss = 5.5789 (0.888 sec/step)\n","INFO:tensorflow:global step 7440: loss = 6.5708 (0.891 sec/step)\n","I1215 19:54:23.762318 140303514462080 learning.py:512] global step 7440: loss = 6.5708 (0.891 sec/step)\n","INFO:tensorflow:global step 7441: loss = 3.8927 (0.897 sec/step)\n","I1215 19:54:24.661092 140303514462080 learning.py:512] global step 7441: loss = 3.8927 (0.897 sec/step)\n","INFO:tensorflow:global step 7442: loss = 4.6486 (0.868 sec/step)\n","I1215 19:54:25.530491 140303514462080 learning.py:512] global step 7442: loss = 4.6486 (0.868 sec/step)\n","INFO:tensorflow:global step 7443: loss = 3.3014 (0.894 sec/step)\n","I1215 19:54:26.426098 140303514462080 learning.py:512] global step 7443: loss = 3.3014 (0.894 sec/step)\n","INFO:tensorflow:global step 7444: loss = 2.3974 (0.947 sec/step)\n","I1215 19:54:27.374104 140303514462080 learning.py:512] global step 7444: loss = 2.3974 (0.947 sec/step)\n","INFO:tensorflow:global step 7445: loss = 8.0484 (0.909 sec/step)\n","I1215 19:54:28.284460 140303514462080 learning.py:512] global step 7445: loss = 8.0484 (0.909 sec/step)\n","INFO:tensorflow:global step 7446: loss = 2.6689 (0.915 sec/step)\n","I1215 19:54:29.201431 140303514462080 learning.py:512] global step 7446: loss = 2.6689 (0.915 sec/step)\n","INFO:tensorflow:global step 7447: loss = 3.4614 (0.911 sec/step)\n","I1215 19:54:30.113582 140303514462080 learning.py:512] global step 7447: loss = 3.4614 (0.911 sec/step)\n","INFO:tensorflow:global step 7448: loss = 3.4550 (0.924 sec/step)\n","I1215 19:54:31.038795 140303514462080 learning.py:512] global step 7448: loss = 3.4550 (0.924 sec/step)\n","INFO:tensorflow:global step 7449: loss = 4.5579 (0.924 sec/step)\n","I1215 19:54:31.964317 140303514462080 learning.py:512] global step 7449: loss = 4.5579 (0.924 sec/step)\n","INFO:tensorflow:global step 7450: loss = 3.3863 (0.914 sec/step)\n","I1215 19:54:32.879956 140303514462080 learning.py:512] global step 7450: loss = 3.3863 (0.914 sec/step)\n","INFO:tensorflow:global step 7451: loss = 2.7041 (0.909 sec/step)\n","I1215 19:54:33.790309 140303514462080 learning.py:512] global step 7451: loss = 2.7041 (0.909 sec/step)\n","INFO:tensorflow:global step 7452: loss = 3.4069 (0.910 sec/step)\n","I1215 19:54:34.702565 140303514462080 learning.py:512] global step 7452: loss = 3.4069 (0.910 sec/step)\n","INFO:tensorflow:global step 7453: loss = 3.4392 (0.900 sec/step)\n","I1215 19:54:35.603731 140303514462080 learning.py:512] global step 7453: loss = 3.4392 (0.900 sec/step)\n","INFO:tensorflow:global step 7454: loss = 3.4355 (0.926 sec/step)\n","I1215 19:54:36.531442 140303514462080 learning.py:512] global step 7454: loss = 3.4355 (0.926 sec/step)\n","INFO:tensorflow:global step 7455: loss = 3.7365 (0.928 sec/step)\n","I1215 19:54:37.461391 140303514462080 learning.py:512] global step 7455: loss = 3.7365 (0.928 sec/step)\n","INFO:tensorflow:global step 7456: loss = 2.9568 (0.921 sec/step)\n","I1215 19:54:38.384105 140303514462080 learning.py:512] global step 7456: loss = 2.9568 (0.921 sec/step)\n","INFO:tensorflow:global step 7457: loss = 2.7849 (0.886 sec/step)\n","I1215 19:54:39.271265 140303514462080 learning.py:512] global step 7457: loss = 2.7849 (0.886 sec/step)\n","INFO:tensorflow:global step 7458: loss = 2.8825 (0.882 sec/step)\n","I1215 19:54:40.154522 140303514462080 learning.py:512] global step 7458: loss = 2.8825 (0.882 sec/step)\n","INFO:tensorflow:global step 7459: loss = 3.0247 (0.891 sec/step)\n","I1215 19:54:41.046729 140303514462080 learning.py:512] global step 7459: loss = 3.0247 (0.891 sec/step)\n","INFO:tensorflow:global step 7460: loss = 3.9331 (0.881 sec/step)\n","I1215 19:54:41.929812 140303514462080 learning.py:512] global step 7460: loss = 3.9331 (0.881 sec/step)\n","INFO:tensorflow:global step 7461: loss = 3.9987 (0.899 sec/step)\n","I1215 19:54:42.830514 140303514462080 learning.py:512] global step 7461: loss = 3.9987 (0.899 sec/step)\n","INFO:tensorflow:global step 7462: loss = 5.0161 (0.889 sec/step)\n","I1215 19:54:43.720744 140303514462080 learning.py:512] global step 7462: loss = 5.0161 (0.889 sec/step)\n","INFO:tensorflow:global step 7463: loss = 4.2599 (0.886 sec/step)\n","I1215 19:54:44.608097 140303514462080 learning.py:512] global step 7463: loss = 4.2599 (0.886 sec/step)\n","INFO:tensorflow:global step 7464: loss = 3.6140 (0.882 sec/step)\n","I1215 19:54:45.491663 140303514462080 learning.py:512] global step 7464: loss = 3.6140 (0.882 sec/step)\n","INFO:tensorflow:global step 7465: loss = 4.1324 (0.890 sec/step)\n","I1215 19:54:46.382994 140303514462080 learning.py:512] global step 7465: loss = 4.1324 (0.890 sec/step)\n","INFO:tensorflow:global step 7466: loss = 4.1980 (0.897 sec/step)\n","I1215 19:54:47.281461 140303514462080 learning.py:512] global step 7466: loss = 4.1980 (0.897 sec/step)\n","INFO:tensorflow:global step 7467: loss = 7.7243 (0.903 sec/step)\n","I1215 19:54:48.186318 140303514462080 learning.py:512] global step 7467: loss = 7.7243 (0.903 sec/step)\n","INFO:tensorflow:global step 7468: loss = 4.2442 (0.887 sec/step)\n","I1215 19:54:49.074957 140303514462080 learning.py:512] global step 7468: loss = 4.2442 (0.887 sec/step)\n","INFO:tensorflow:global step 7469: loss = 5.7881 (0.891 sec/step)\n","I1215 19:54:49.967523 140303514462080 learning.py:512] global step 7469: loss = 5.7881 (0.891 sec/step)\n","INFO:tensorflow:global step 7470: loss = 3.6944 (0.877 sec/step)\n","I1215 19:54:50.845856 140303514462080 learning.py:512] global step 7470: loss = 3.6944 (0.877 sec/step)\n","INFO:tensorflow:global step 7471: loss = 4.1665 (0.884 sec/step)\n","I1215 19:54:51.731586 140303514462080 learning.py:512] global step 7471: loss = 4.1665 (0.884 sec/step)\n","INFO:tensorflow:global step 7472: loss = 3.1539 (0.887 sec/step)\n","I1215 19:54:52.620218 140303514462080 learning.py:512] global step 7472: loss = 3.1539 (0.887 sec/step)\n","INFO:tensorflow:global step 7473: loss = 3.1957 (0.886 sec/step)\n","I1215 19:54:53.507938 140303514462080 learning.py:512] global step 7473: loss = 3.1957 (0.886 sec/step)\n","INFO:tensorflow:global step 7474: loss = 4.7712 (0.900 sec/step)\n","I1215 19:54:54.409054 140303514462080 learning.py:512] global step 7474: loss = 4.7712 (0.900 sec/step)\n","INFO:tensorflow:global step 7475: loss = 3.4852 (0.891 sec/step)\n","I1215 19:54:55.301258 140303514462080 learning.py:512] global step 7475: loss = 3.4852 (0.891 sec/step)\n","INFO:tensorflow:global step 7476: loss = 4.3903 (0.892 sec/step)\n","I1215 19:54:56.195080 140303514462080 learning.py:512] global step 7476: loss = 4.3903 (0.892 sec/step)\n","INFO:tensorflow:global step 7477: loss = 3.3180 (0.921 sec/step)\n","I1215 19:54:57.117504 140303514462080 learning.py:512] global step 7477: loss = 3.3180 (0.921 sec/step)\n","INFO:tensorflow:global step 7478: loss = 6.2851 (0.888 sec/step)\n","I1215 19:54:58.007218 140303514462080 learning.py:512] global step 7478: loss = 6.2851 (0.888 sec/step)\n","INFO:tensorflow:global step 7479: loss = 6.4202 (0.883 sec/step)\n","I1215 19:54:58.891565 140303514462080 learning.py:512] global step 7479: loss = 6.4202 (0.883 sec/step)\n","INFO:tensorflow:global step 7480: loss = 5.9404 (0.889 sec/step)\n","I1215 19:54:59.781918 140303514462080 learning.py:512] global step 7480: loss = 5.9404 (0.889 sec/step)\n","INFO:tensorflow:global step 7481: loss = 3.5512 (0.896 sec/step)\n","I1215 19:55:00.679701 140303514462080 learning.py:512] global step 7481: loss = 3.5512 (0.896 sec/step)\n","INFO:tensorflow:global step 7482: loss = 7.6531 (0.906 sec/step)\n","I1215 19:55:01.586982 140303514462080 learning.py:512] global step 7482: loss = 7.6531 (0.906 sec/step)\n","INFO:tensorflow:global step 7483: loss = 3.2373 (0.879 sec/step)\n","I1215 19:55:02.466883 140303514462080 learning.py:512] global step 7483: loss = 3.2373 (0.879 sec/step)\n","INFO:tensorflow:global step 7484: loss = 3.4061 (0.896 sec/step)\n","I1215 19:55:03.364480 140303514462080 learning.py:512] global step 7484: loss = 3.4061 (0.896 sec/step)\n","INFO:tensorflow:global step 7485: loss = 3.1132 (0.883 sec/step)\n","I1215 19:55:04.249556 140303514462080 learning.py:512] global step 7485: loss = 3.1132 (0.883 sec/step)\n","INFO:tensorflow:global step 7486: loss = 3.2909 (0.888 sec/step)\n","I1215 19:55:05.138899 140303514462080 learning.py:512] global step 7486: loss = 3.2909 (0.888 sec/step)\n","INFO:tensorflow:global step 7487: loss = 3.0512 (0.881 sec/step)\n","I1215 19:55:06.021273 140303514462080 learning.py:512] global step 7487: loss = 3.0512 (0.881 sec/step)\n","INFO:tensorflow:global step 7488: loss = 3.9526 (0.883 sec/step)\n","I1215 19:55:06.906433 140303514462080 learning.py:512] global step 7488: loss = 3.9526 (0.883 sec/step)\n","INFO:tensorflow:global step 7489: loss = 3.4945 (0.893 sec/step)\n","I1215 19:55:07.800521 140303514462080 learning.py:512] global step 7489: loss = 3.4945 (0.893 sec/step)\n","INFO:tensorflow:global step 7490: loss = 4.1338 (0.917 sec/step)\n","I1215 19:55:08.718890 140303514462080 learning.py:512] global step 7490: loss = 4.1338 (0.917 sec/step)\n","INFO:tensorflow:global step 7491: loss = 4.8729 (0.919 sec/step)\n","I1215 19:55:09.639469 140303514462080 learning.py:512] global step 7491: loss = 4.8729 (0.919 sec/step)\n","INFO:tensorflow:global step 7492: loss = 3.2331 (0.909 sec/step)\n","I1215 19:55:10.550370 140303514462080 learning.py:512] global step 7492: loss = 3.2331 (0.909 sec/step)\n","INFO:tensorflow:global step 7493: loss = 4.5711 (0.880 sec/step)\n","I1215 19:55:11.432488 140303514462080 learning.py:512] global step 7493: loss = 4.5711 (0.880 sec/step)\n","INFO:tensorflow:global step 7494: loss = 3.4568 (0.908 sec/step)\n","I1215 19:55:12.342439 140303514462080 learning.py:512] global step 7494: loss = 3.4568 (0.908 sec/step)\n","INFO:tensorflow:global step 7495: loss = 4.3769 (0.905 sec/step)\n","I1215 19:55:13.249162 140303514462080 learning.py:512] global step 7495: loss = 4.3769 (0.905 sec/step)\n","INFO:tensorflow:global step 7496: loss = 4.8477 (0.923 sec/step)\n","I1215 19:55:14.173530 140303514462080 learning.py:512] global step 7496: loss = 4.8477 (0.923 sec/step)\n","INFO:tensorflow:global step 7497: loss = 3.5726 (0.902 sec/step)\n","I1215 19:55:15.076748 140303514462080 learning.py:512] global step 7497: loss = 3.5726 (0.902 sec/step)\n","INFO:tensorflow:global step 7498: loss = 2.9441 (0.889 sec/step)\n","I1215 19:55:15.967467 140303514462080 learning.py:512] global step 7498: loss = 2.9441 (0.889 sec/step)\n","INFO:tensorflow:global step 7499: loss = 5.3401 (0.903 sec/step)\n","I1215 19:55:16.872150 140303514462080 learning.py:512] global step 7499: loss = 5.3401 (0.903 sec/step)\n","INFO:tensorflow:global step 7500: loss = 4.5850 (0.900 sec/step)\n","I1215 19:55:17.774089 140303514462080 learning.py:512] global step 7500: loss = 4.5850 (0.900 sec/step)\n","INFO:tensorflow:global step 7501: loss = 2.6157 (0.927 sec/step)\n","I1215 19:55:18.702629 140303514462080 learning.py:512] global step 7501: loss = 2.6157 (0.927 sec/step)\n","INFO:tensorflow:global step 7502: loss = 4.4170 (0.900 sec/step)\n","I1215 19:55:19.604088 140303514462080 learning.py:512] global step 7502: loss = 4.4170 (0.900 sec/step)\n","INFO:tensorflow:global step 7503: loss = 4.9964 (0.904 sec/step)\n","I1215 19:55:20.509308 140303514462080 learning.py:512] global step 7503: loss = 4.9964 (0.904 sec/step)\n","INFO:tensorflow:global step 7504: loss = 4.1000 (0.901 sec/step)\n","I1215 19:55:21.411993 140303514462080 learning.py:512] global step 7504: loss = 4.1000 (0.901 sec/step)\n","INFO:tensorflow:global step 7505: loss = 4.0672 (0.911 sec/step)\n","I1215 19:55:22.324732 140303514462080 learning.py:512] global step 7505: loss = 4.0672 (0.911 sec/step)\n","INFO:tensorflow:global step 7506: loss = 4.0427 (0.895 sec/step)\n","I1215 19:55:23.221734 140303514462080 learning.py:512] global step 7506: loss = 4.0427 (0.895 sec/step)\n","INFO:tensorflow:global step 7507: loss = 4.8382 (0.891 sec/step)\n","I1215 19:55:24.114617 140303514462080 learning.py:512] global step 7507: loss = 4.8382 (0.891 sec/step)\n","INFO:tensorflow:global step 7508: loss = 4.0867 (0.891 sec/step)\n","I1215 19:55:25.007154 140303514462080 learning.py:512] global step 7508: loss = 4.0867 (0.891 sec/step)\n","INFO:tensorflow:global step 7509: loss = 3.5275 (0.897 sec/step)\n","I1215 19:55:25.905364 140303514462080 learning.py:512] global step 7509: loss = 3.5275 (0.897 sec/step)\n","INFO:tensorflow:global step 7510: loss = 3.2989 (0.908 sec/step)\n","I1215 19:55:26.815052 140303514462080 learning.py:512] global step 7510: loss = 3.2989 (0.908 sec/step)\n","INFO:tensorflow:global step 7511: loss = 3.6068 (0.901 sec/step)\n","I1215 19:55:27.717940 140303514462080 learning.py:512] global step 7511: loss = 3.6068 (0.901 sec/step)\n","INFO:tensorflow:global step 7512: loss = 3.8877 (0.887 sec/step)\n","I1215 19:55:28.606232 140303514462080 learning.py:512] global step 7512: loss = 3.8877 (0.887 sec/step)\n","INFO:tensorflow:global step 7513: loss = 3.4245 (0.907 sec/step)\n","I1215 19:55:29.515116 140303514462080 learning.py:512] global step 7513: loss = 3.4245 (0.907 sec/step)\n","INFO:tensorflow:global step 7514: loss = 3.3842 (0.900 sec/step)\n","I1215 19:55:30.417000 140303514462080 learning.py:512] global step 7514: loss = 3.3842 (0.900 sec/step)\n","INFO:tensorflow:global step 7515: loss = 4.3042 (0.890 sec/step)\n","I1215 19:55:31.308290 140303514462080 learning.py:512] global step 7515: loss = 4.3042 (0.890 sec/step)\n","INFO:tensorflow:global step 7516: loss = 4.8746 (0.906 sec/step)\n","I1215 19:55:32.215818 140303514462080 learning.py:512] global step 7516: loss = 4.8746 (0.906 sec/step)\n","INFO:tensorflow:global step 7517: loss = 4.3048 (0.914 sec/step)\n","I1215 19:55:33.131009 140303514462080 learning.py:512] global step 7517: loss = 4.3048 (0.914 sec/step)\n","INFO:tensorflow:global step 7518: loss = 4.3859 (0.902 sec/step)\n","I1215 19:55:34.033951 140303514462080 learning.py:512] global step 7518: loss = 4.3859 (0.902 sec/step)\n","INFO:tensorflow:global step 7519: loss = 4.6453 (0.888 sec/step)\n","I1215 19:55:34.923824 140303514462080 learning.py:512] global step 7519: loss = 4.6453 (0.888 sec/step)\n","INFO:tensorflow:global step 7520: loss = 4.2268 (0.960 sec/step)\n","I1215 19:55:35.885688 140303514462080 learning.py:512] global step 7520: loss = 4.2268 (0.960 sec/step)\n","INFO:tensorflow:Recording summary at step 7520.\n","I1215 19:55:37.075248 140299899541248 supervisor.py:1050] Recording summary at step 7520.\n","INFO:tensorflow:global step 7521: loss = 3.3313 (1.374 sec/step)\n","I1215 19:55:37.260972 140303514462080 learning.py:512] global step 7521: loss = 3.3313 (1.374 sec/step)\n","INFO:tensorflow:global step 7522: loss = 4.7042 (0.880 sec/step)\n","I1215 19:55:38.142510 140303514462080 learning.py:512] global step 7522: loss = 4.7042 (0.880 sec/step)\n","INFO:tensorflow:global step 7523: loss = 6.0928 (0.922 sec/step)\n","I1215 19:55:39.066004 140303514462080 learning.py:512] global step 7523: loss = 6.0928 (0.922 sec/step)\n","INFO:tensorflow:global step 7524: loss = 6.0070 (0.909 sec/step)\n","I1215 19:55:39.976612 140303514462080 learning.py:512] global step 7524: loss = 6.0070 (0.909 sec/step)\n","INFO:tensorflow:global step 7525: loss = 2.8330 (0.889 sec/step)\n","I1215 19:55:40.867603 140303514462080 learning.py:512] global step 7525: loss = 2.8330 (0.889 sec/step)\n","INFO:tensorflow:global step 7526: loss = 2.5564 (0.896 sec/step)\n","I1215 19:55:41.765276 140303514462080 learning.py:512] global step 7526: loss = 2.5564 (0.896 sec/step)\n","INFO:tensorflow:global step 7527: loss = 3.8622 (0.888 sec/step)\n","I1215 19:55:42.655084 140303514462080 learning.py:512] global step 7527: loss = 3.8622 (0.888 sec/step)\n","INFO:tensorflow:global step 7528: loss = 5.8447 (0.898 sec/step)\n","I1215 19:55:43.554239 140303514462080 learning.py:512] global step 7528: loss = 5.8447 (0.898 sec/step)\n","INFO:tensorflow:global step 7529: loss = 2.8590 (0.875 sec/step)\n","I1215 19:55:44.431060 140303514462080 learning.py:512] global step 7529: loss = 2.8590 (0.875 sec/step)\n","INFO:tensorflow:global step 7530: loss = 4.7542 (0.895 sec/step)\n","I1215 19:55:45.327892 140303514462080 learning.py:512] global step 7530: loss = 4.7542 (0.895 sec/step)\n","INFO:tensorflow:global step 7531: loss = 4.0724 (0.884 sec/step)\n","I1215 19:55:46.213443 140303514462080 learning.py:512] global step 7531: loss = 4.0724 (0.884 sec/step)\n","INFO:tensorflow:global step 7532: loss = 2.5492 (0.889 sec/step)\n","I1215 19:55:47.104020 140303514462080 learning.py:512] global step 7532: loss = 2.5492 (0.889 sec/step)\n","INFO:tensorflow:global step 7533: loss = 3.5027 (0.897 sec/step)\n","I1215 19:55:48.003051 140303514462080 learning.py:512] global step 7533: loss = 3.5027 (0.897 sec/step)\n","INFO:tensorflow:global step 7534: loss = 3.9476 (0.892 sec/step)\n","I1215 19:55:48.896531 140303514462080 learning.py:512] global step 7534: loss = 3.9476 (0.892 sec/step)\n","INFO:tensorflow:global step 7535: loss = 2.7585 (0.903 sec/step)\n","I1215 19:55:49.800791 140303514462080 learning.py:512] global step 7535: loss = 2.7585 (0.903 sec/step)\n","INFO:tensorflow:global step 7536: loss = 4.2514 (0.887 sec/step)\n","I1215 19:55:50.689604 140303514462080 learning.py:512] global step 7536: loss = 4.2514 (0.887 sec/step)\n","INFO:tensorflow:global step 7537: loss = 5.6510 (0.880 sec/step)\n","I1215 19:55:51.570615 140303514462080 learning.py:512] global step 7537: loss = 5.6510 (0.880 sec/step)\n","INFO:tensorflow:global step 7538: loss = 3.5407 (0.886 sec/step)\n","I1215 19:55:52.458050 140303514462080 learning.py:512] global step 7538: loss = 3.5407 (0.886 sec/step)\n","INFO:tensorflow:global step 7539: loss = 3.5550 (0.904 sec/step)\n","I1215 19:55:53.363246 140303514462080 learning.py:512] global step 7539: loss = 3.5550 (0.904 sec/step)\n","INFO:tensorflow:global step 7540: loss = 5.5863 (0.919 sec/step)\n","I1215 19:55:54.283714 140303514462080 learning.py:512] global step 7540: loss = 5.5863 (0.919 sec/step)\n","INFO:tensorflow:global step 7541: loss = 2.6253 (0.922 sec/step)\n","I1215 19:55:55.206768 140303514462080 learning.py:512] global step 7541: loss = 2.6253 (0.922 sec/step)\n","INFO:tensorflow:global step 7542: loss = 2.8363 (0.911 sec/step)\n","I1215 19:55:56.119625 140303514462080 learning.py:512] global step 7542: loss = 2.8363 (0.911 sec/step)\n","INFO:tensorflow:global step 7543: loss = 4.4379 (0.903 sec/step)\n","I1215 19:55:57.024312 140303514462080 learning.py:512] global step 7543: loss = 4.4379 (0.903 sec/step)\n","INFO:tensorflow:global step 7544: loss = 6.0361 (0.924 sec/step)\n","I1215 19:55:57.949443 140303514462080 learning.py:512] global step 7544: loss = 6.0361 (0.924 sec/step)\n","Traceback (most recent call last):\n","  File \"train.py\", line 185, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n","    return func(*args, **kwargs)\n","  File \"train.py\", line 181, in main\n","    graph_hook_fn=graph_rewriter_fn)\n","  File \"/content/models-master/research/object_detection/legacy/trainer.py\", line 415, in train\n","    saver=saver)\n","  File \"/usr/local/lib/python3.6/dist-packages/tf_slim/learning.py\", line 767, in train\n","    train_step_kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tf_slim/learning.py\", line 495, in train_step\n","    run_metadata=run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ACYAoAWuEzC2"},"source":["Pause your training. Change your model.ckpt- XXXXX to the correct numbers."]},{"cell_type":"code","metadata":{"id":"aKYmR4NPScOm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608065270130,"user_tz":-330,"elapsed":17752,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"7de23d75-20c8-40d7-f451-eadc1292d9bf"},"source":["!python export_inference_graph.py --input_type image_tensor --pipeline_config_path ssd_mobilenet_v2_quantized_300x300_coco.config --trained_checkpoint_prefix training/model.ckpt-7125 --output_directory new_graph"],"execution_count":34,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W1215 20:47:37.387584 140123344643968 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:47:39.503582 140123344643968 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:47:39.542547 140123344643968 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:47:39.579399 140123344643968 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:47:39.615704 140123344643968 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:47:39.651603 140123344643968 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:47:39.687864 140123344643968 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models-master/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W1215 20:47:39.936785 140123344643968 deprecation.py:323] From /content/models-master/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models-master/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W1215 20:47:40.331422 140123344643968 deprecation.py:323] From /content/models-master/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I1215 20:47:41.883250 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I1215 20:47:41.883603 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I1215 20:47:41.883900 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I1215 20:47:41.884112 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I1215 20:47:41.884376 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I1215 20:47:41.884563 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I1215 20:47:41.884823 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I1215 20:47:41.885003 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I1215 20:47:41.885250 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I1215 20:47:41.885446 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I1215 20:47:41.885743 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I1215 20:47:41.885931 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I1215 20:47:41.886193 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I1215 20:47:41.886388 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I1215 20:47:41.886655 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I1215 20:47:41.886833 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I1215 20:47:41.887111 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I1215 20:47:41.887299 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I1215 20:47:41.887552 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I1215 20:47:41.887737 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I1215 20:47:41.887987 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I1215 20:47:41.888159 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I1215 20:47:41.888407 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I1215 20:47:41.888585 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I1215 20:47:41.888841 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I1215 20:47:41.889015 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I1215 20:47:41.889256 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I1215 20:47:41.889432 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I1215 20:47:41.889695 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I1215 20:47:41.889872 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I1215 20:47:41.890119 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I1215 20:47:41.890292 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I1215 20:47:41.890542 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I1215 20:47:41.890730 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I1215 20:47:41.890979 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I1215 20:47:41.891145 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I1215 20:47:41.891311 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I1215 20:47:41.891479 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I1215 20:47:41.891670 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I1215 20:47:41.891847 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I1215 20:47:41.892018 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I1215 20:47:41.892190 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I1215 20:47:41.892363 140123344643968 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /content/models-master/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W1215 20:47:41.894751 140123344643968 deprecation.py:323] From /content/models-master/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W1215 20:47:41.895237 140123344643968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","257 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/4.61m params)\n","  BoxPredictor_0 (--/13.85k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/ClassPredictor (--/6.92k params)\n","      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","  BoxPredictor_1 (--/61.49k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/ClassPredictor (--/30.74k params)\n","      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","  BoxPredictor_2 (--/24.62k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/ClassPredictor (--/12.31k params)\n","      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","  BoxPredictor_3 (--/12.34k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/ClassPredictor (--/6.17k params)\n","      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","  BoxPredictor_4 (--/12.34k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/ClassPredictor (--/6.17k params)\n","      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","  BoxPredictor_5 (--/6.19k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/ClassPredictor (--/3.10k params)\n","      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","  FeatureExtractor (--/4.48m params)\n","    FeatureExtractor/MobilenetV2 (--/4.48m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n","\n","======================End of Report==========================\n","257 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/4.49m flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n","  FeatureExtractor/MobilenetV2/Conv_1/mul_fold (409.60k/409.60k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/mul_fold (327.68k/327.68k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/project/mul_fold (307.20k/307.20k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/project/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/project/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/expand/mul_fold (153.60k/153.60k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/project/mul_fold (92.16k/92.16k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/project/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/project/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/expand/mul_fold (55.30k/55.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/project/mul_fold (36.86k/36.86k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/project/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/expand/mul_fold (24.58k/24.58k flops)\n","  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/project/mul_fold (12.29k/12.29k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/mul_fold (8.64k/8.64k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/project/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/project/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/expand/mul_fold (6.14k/6.14k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/mul_fold (5.18k/5.18k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/project/mul_fold (4.61k/4.61k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/expand/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/project/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/expand/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/mul_fold (3.46k/3.46k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/project/mul_fold (2.30k/2.30k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/mul_fold (1.73k/1.73k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/expand/mul_fold (1.54k/1.54k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/mul_fold (1.30k/1.30k flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/mul_fold (1.30k/1.30k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  FeatureExtractor/MobilenetV2/Conv/mul_fold (864/864 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/mul_fold (864/864 flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv/project/mul_fold (512/512 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  FeatureExtractor/MobilenetV2/expanded_conv/depthwise/mul_fold (288/288 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","\n","======================End of Report==========================\n","2020-12-15 20:47:44.651077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-12-15 20:47:44.686457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.687256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 20:47:44.687596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:47:44.689205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 20:47:44.691253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 20:47:44.691606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 20:47:44.693516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 20:47:44.694745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 20:47:44.698761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 20:47:44.698876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.699527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.700064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 20:47:44.705141: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-12-15 20:47:44.705321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c08bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-12-15 20:47:44.705348: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-12-15 20:47:44.815340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.816047: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c09b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-12-15 20:47:44.816078: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-12-15 20:47:44.816257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.816830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 20:47:44.816896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:47:44.816924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 20:47:44.816945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 20:47:44.816972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 20:47:44.816993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 20:47:44.817019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 20:47:44.817038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 20:47:44.817113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.817736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.818288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 20:47:44.818351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:47:44.819577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-15 20:47:44.819605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-15 20:47:44.819616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-15 20:47:44.819763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.820374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:44.820916: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-12-15 20:47:44.820963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-7125\n","I1215 20:47:44.822878 140123344643968 saver.py:1284] Restoring parameters from training/model.ckpt-7125\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W1215 20:47:47.222149 140123344643968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-12-15 20:47:48.112631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:48.113298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 20:47:48.113410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:47:48.113451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 20:47:48.113480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 20:47:48.113513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 20:47:48.113539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 20:47:48.113565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 20:47:48.113604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 20:47:48.113721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:48.114342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:48.114930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 20:47:48.114976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-15 20:47:48.114992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-15 20:47:48.115002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-15 20:47:48.115233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:48.115875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:48.116442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-7125\n","I1215 20:47:48.117601 140123344643968 saver.py:1284] Restoring parameters from training/model.ckpt-7125\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W1215 20:47:49.214137 140123344643968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W1215 20:47:49.214397 140123344643968 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 632 variables.\n","I1215 20:47:49.812093 140123344643968 graph_util_impl.py:334] Froze 632 variables.\n","INFO:tensorflow:Converted 632 variables to const ops.\n","I1215 20:47:49.913678 140123344643968 graph_util_impl.py:394] Converted 632 variables to const ops.\n","2020-12-15 20:47:50.098755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:50.099373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 20:47:50.099465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:47:50.099500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 20:47:50.099529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 20:47:50.099553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 20:47:50.099575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 20:47:50.099598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 20:47:50.099623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 20:47:50.099730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:50.100295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:50.100835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 20:47:50.100885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-15 20:47:50.100899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-15 20:47:50.100909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-15 20:47:50.101005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:50.101564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:47:50.102165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Traceback (most recent call last):\n","  File \"export_inference_graph.py\", line 206, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"export_inference_graph.py\", line 202, in main\n","    side_input_types=side_input_types)\n","  File \"/content/models-master/research/object_detection/exporter.py\", line 625, in export_inference_graph\n","    side_input_types=side_input_types)\n","  File \"/content/models-master/research/object_detection/exporter.py\", line 566, in _export_inference_graph\n","    placeholder_tensor_dict, outputs)\n","  File \"/content/models-master/research/object_detection/exporter.py\", line 379, in write_saved_model\n","    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/builder_impl.py\", line 436, in __init__\n","    super(SavedModelBuilder, self).__init__(export_dir=export_dir)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/builder_impl.py\", line 103, in __init__\n","    \"specified directory: %s\" % export_dir)\n","AssertionError: Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: new_graph/saved_model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"22wf5JXJT0ZH"},"source":["Zip file in Google Drive"]},{"cell_type":"code","metadata":{"id":"cWS0XX3xlXZQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608065135857,"user_tz":-330,"elapsed":12358,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"bd0f81b8-7eaa-43c5-df6e-b33b567f344f"},"source":["%cd /content/models-master/research/object_detection\n","!python export_tflite_ssd_graph.py --input_type image_tensor --pipeline_config_path ssd_mobilenet_v2_quantized_300x300_coco.config --trained_checkpoint_prefix training/model.ckpt-7125 --output_directory new_graph"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/content/models-master/research/object_detection\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W1215 20:45:28.330695 140662541301632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:45:30.466739 140662541301632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:45:30.496382 140662541301632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:45:30.526718 140662541301632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:45:30.555397 140662541301632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:45:30.584939 140662541301632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I1215 20:45:30.613903 140662541301632 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n","2020-12-15 20:45:30.654994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-12-15 20:45:30.688365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.688998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 20:45:30.689296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:45:30.691236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 20:45:30.692917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 20:45:30.693255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 20:45:30.695126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 20:45:30.696300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 20:45:30.699900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 20:45:30.700034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.700621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.701145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 20:45:30.706473: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-12-15 20:45:30.706675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28f4a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-12-15 20:45:30.706703: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-12-15 20:45:30.816558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.817359: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28f4840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-12-15 20:45:30.817388: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-12-15 20:45:30.817555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.818145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 20:45:30.818214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:45:30.818239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 20:45:30.818267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 20:45:30.818289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 20:45:30.818322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 20:45:30.818369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 20:45:30.818399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 20:45:30.818476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.819074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.819631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 20:45:30.819702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:45:30.820949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-15 20:45:30.820975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-15 20:45:30.820990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-15 20:45:30.821100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.821690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:30.822245: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-12-15 20:45:30.822283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","I1215 20:45:32.406122 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","I1215 20:45:32.406433 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","I1215 20:45:32.406710 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","I1215 20:45:32.406892 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","I1215 20:45:32.407150 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","I1215 20:45:32.407315 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","I1215 20:45:32.407549 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","I1215 20:45:32.407743 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","I1215 20:45:32.407991 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","I1215 20:45:32.408159 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","I1215 20:45:32.408399 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","I1215 20:45:32.408589 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","I1215 20:45:32.408856 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","I1215 20:45:32.409024 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","I1215 20:45:32.409256 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","I1215 20:45:32.409433 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","I1215 20:45:32.409687 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","I1215 20:45:32.409858 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","I1215 20:45:32.410092 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","I1215 20:45:32.410259 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","I1215 20:45:32.410509 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","I1215 20:45:32.410679 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","I1215 20:45:32.410901 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","I1215 20:45:32.411087 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","I1215 20:45:32.411366 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","I1215 20:45:32.411536 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","I1215 20:45:32.411784 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","I1215 20:45:32.411961 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","I1215 20:45:32.412189 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","I1215 20:45:32.412367 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","I1215 20:45:32.412612 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","I1215 20:45:32.412783 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","I1215 20:45:32.413026 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","I1215 20:45:32.413212 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","I1215 20:45:32.413545 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","I1215 20:45:32.413761 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","I1215 20:45:32.413956 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","I1215 20:45:32.414124 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","I1215 20:45:32.414299 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","I1215 20:45:32.414480 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","I1215 20:45:32.414659 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","I1215 20:45:32.414832 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n","INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","I1215 20:45:32.415006 140662541301632 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W1215 20:45:32.894434 140662541301632 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-12-15 20:45:33.478980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:33.479585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 20:45:33.479699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 20:45:33.479733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 20:45:33.479756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 20:45:33.479777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 20:45:33.479798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 20:45:33.479817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 20:45:33.479838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 20:45:33.479973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:33.480696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:33.481285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 20:45:33.481326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-15 20:45:33.481345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-15 20:45:33.481356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-15 20:45:33.481467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:33.482043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 20:45:33.482687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/model.ckpt-7125\n","I1215 20:45:33.483913 140662541301632 saver.py:1284] Restoring parameters from training/model.ckpt-7125\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W1215 20:45:35.053607 140662541301632 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W1215 20:45:35.053912 140662541301632 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 632 variables.\n","I1215 20:45:35.690623 140662541301632 graph_util_impl.py:334] Froze 632 variables.\n","INFO:tensorflow:Converted 632 variables to const ops.\n","I1215 20:45:35.779359 140662541301632 graph_util_impl.py:394] Converted 632 variables to const ops.\n","2020-12-15 20:45:35.917232: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4rLVa25GSwOj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608066211590,"user_tz":-330,"elapsed":2951,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"1346d104-0944-4785-85b9-86bcf9fc8b70"},"source":["%cd /content/models-master/research/object_detection\n","!tflite_convert \\--graph_def_file=new_graph/tflite_graph.pb \\ --output_file tflite/detect.tflite \\ --output_format=TFLITE \\--input_shapes=1,300,300,3 \\--input_arrays=normalized_input_image_tensor \\--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\--inference_type=QUANTIZED_UINT8 \\--mean_values=128 \\--std_dev_values=127 \\--change_concat_input_ranges=false \\--allow_custom_ops"],"execution_count":35,"outputs":[{"output_type":"stream","text":["/content/models-master/research/object_detection\n","usage: tflite_convert [-h] --output_file OUTPUT_FILE\n","                      (--graph_def_file GRAPH_DEF_FILE | --saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE)\n","                      [--output_format {TFLITE,GRAPHVIZ_DOT}]\n","                      [--inference_type {FLOAT,QUANTIZED_UINT8}]\n","                      [--inference_input_type {FLOAT,QUANTIZED_UINT8}]\n","                      [--input_arrays INPUT_ARRAYS]\n","                      [--input_shapes INPUT_SHAPES]\n","                      [--output_arrays OUTPUT_ARRAYS]\n","                      [--saved_model_tag_set SAVED_MODEL_TAG_SET]\n","                      [--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY]\n","                      [--std_dev_values STD_DEV_VALUES]\n","                      [--mean_values MEAN_VALUES]\n","                      [--default_ranges_min DEFAULT_RANGES_MIN]\n","                      [--default_ranges_max DEFAULT_RANGES_MAX]\n","                      [--post_training_quantize] [--quantize_to_float16]\n","                      [--drop_control_dependency]\n","                      [--reorder_across_fake_quant]\n","                      [--change_concat_input_ranges {TRUE,FALSE}]\n","                      [--allow_custom_ops] [--target_ops TARGET_OPS]\n","                      [--dump_graphviz_dir DUMP_GRAPHVIZ_DIR]\n","                      [--dump_graphviz_video]\n","tflite_convert: error: the following arguments are required: --output_file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fCnK26CicKiG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608062849494,"user_tz":-330,"elapsed":15574,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"67710bea-3ade-4514-a812-0fc54dd40ada"},"source":["%cd /content/models-master/research/object_detection\n","\n","!zip -r model_graph.zip new_graph"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/content/models-master/research/object_detection\n","  adding: new_graph/ (stored 0%)\n","  adding: new_graph/tflite_graph.pbtxt (deflated 56%)\n","  adding: new_graph/model.ckpt.data-00000-of-00001 (deflated 7%)\n","  adding: new_graph/saved_model/ (stored 0%)\n","  adding: new_graph/saved_model/saved_model.pb (deflated 11%)\n","  adding: new_graph/saved_model/variables/ (stored 0%)\n","  adding: new_graph/pipeline.config (deflated 68%)\n","  adding: new_graph/model.ckpt.meta (deflated 93%)\n","  adding: new_graph/frozen_inference_graph.pb (deflated 11%)\n","  adding: new_graph/checkpoint (deflated 42%)\n","  adding: new_graph/model.ckpt.index (deflated 67%)\n","  adding: new_graph/tflite_graph.pb (deflated 9%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bzBSemPYI35X","executionInfo":{"status":"ok","timestamp":1608062869075,"user_tz":-330,"elapsed":1083,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}}},"source":["!cp -r /content/models-master/research/object_detection/model_graph.zip /content/drive/'My Drive'"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lx0CfyoLElGv"},"source":["Recommend to run this once you have finish running the entire training."]},{"cell_type":"code","metadata":{"id":"GwdGZegqQPcS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608063074551,"user_tz":-330,"elapsed":72498,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"08e0a80e-5cc5-4f5c-87f6-1066d601643e"},"source":["%cd /content\n","\n","!zip -r models-master.zip /content/models-master\n","!cp -a /content/models-master.zip /content/drive/'My Drive'"],"execution_count":27,"outputs":[{"output_type":"stream","text":["/content\n","  adding: content/models-master/ (stored 0%)\n","  adding: content/models-master/ISSUES.md (deflated 49%)\n","  adding: content/models-master/official/ (stored 0%)\n","  adding: content/models-master/official/recommendation/ (stored 0%)\n","  adding: content/models-master/official/recommendation/run.sh (deflated 53%)\n","  adding: content/models-master/official/recommendation/stat_utils.py (deflated 54%)\n","  adding: content/models-master/official/recommendation/data_pipeline.py (deflated 74%)\n","  adding: content/models-master/official/recommendation/README.md (deflated 58%)\n","  adding: content/models-master/official/recommendation/ncf_keras_main.py (deflated 70%)\n","  adding: content/models-master/official/recommendation/create_ncf_data.py (deflated 63%)\n","  adding: content/models-master/official/recommendation/movielens.py (deflated 64%)\n","  adding: content/models-master/official/recommendation/ncf_input_pipeline.py (deflated 68%)\n","  adding: content/models-master/official/recommendation/ncf_test.py (deflated 71%)\n","  adding: content/models-master/official/recommendation/ncf_common.py (deflated 68%)\n","  adding: content/models-master/official/recommendation/data_preprocessing.py (deflated 67%)\n","  adding: content/models-master/official/recommendation/__init__.py (stored 0%)\n","  adding: content/models-master/official/recommendation/constants.py (deflated 55%)\n","  adding: content/models-master/official/recommendation/data_test.py (deflated 67%)\n","  adding: content/models-master/official/recommendation/popen_helper.py (deflated 60%)\n","  adding: content/models-master/official/recommendation/neumf_model.py (deflated 67%)\n","  adding: content/models-master/official/core/ (stored 0%)\n","  adding: content/models-master/official/core/input_reader.py (deflated 73%)\n","  adding: content/models-master/official/core/task_factory.py (deflated 56%)\n","  adding: content/models-master/official/core/registry_test.py (deflated 66%)\n","  adding: content/models-master/official/core/base_trainer_test.py (deflated 75%)\n","  adding: content/models-master/official/core/registry.py (deflated 69%)\n","  adding: content/models-master/official/core/train_utils.py (deflated 68%)\n","  adding: content/models-master/official/core/config_definitions.py (deflated 64%)\n","  adding: content/models-master/official/core/exp_factory.py (deflated 52%)\n","  adding: content/models-master/official/core/train_lib_test.py (deflated 67%)\n","  adding: content/models-master/official/core/train_lib.py (deflated 67%)\n","  adding: content/models-master/official/core/base_task.py (deflated 70%)\n","  adding: content/models-master/official/core/base_trainer.py (deflated 72%)\n","  adding: content/models-master/official/core/__init__.py (stored 0%)\n","  adding: content/models-master/official/requirements.txt (deflated 37%)\n","  adding: content/models-master/official/vision/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/augment_test.py (deflated 66%)\n","  adding: content/models-master/official/vision/image_classification/preprocessing.py (deflated 75%)\n","  adding: content/models-master/official/vision/image_classification/mnist_test.py (deflated 57%)\n","  adding: content/models-master/official/vision/image_classification/augment.py (deflated 73%)\n","  adding: content/models-master/official/vision/image_classification/README.md (deflated 64%)\n","  adding: content/models-master/official/vision/image_classification/optimizer_factory.py (deflated 70%)\n","  adding: content/models-master/official/vision/image_classification/callbacks.py (deflated 69%)\n","  adding: content/models-master/official/vision/image_classification/classifier_trainer.py (deflated 71%)\n","  adding: content/models-master/official/vision/image_classification/learning_rate_test.py (deflated 54%)\n","  adding: content/models-master/official/vision/image_classification/classifier_trainer_util_test.py (deflated 66%)\n","  adding: content/models-master/official/vision/image_classification/configs/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/configs/configs.py (deflated 73%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/efficientnet/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b0-tpu.yaml (deflated 54%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b1-tpu.yaml (deflated 55%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b1-gpu.yaml (deflated 55%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/efficientnet/imagenet/efficientnet-b0-gpu.yaml (deflated 54%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/resnet/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/resnet/imagenet/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/resnet/imagenet/tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/image_classification/configs/examples/resnet/imagenet/gpu.yaml (deflated 55%)\n","  adding: content/models-master/official/vision/image_classification/configs/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/image_classification/configs/base_configs.py (deflated 71%)\n","  adding: content/models-master/official/vision/image_classification/dataset_factory.py (deflated 72%)\n","  adding: content/models-master/official/vision/image_classification/classifier_trainer_test.py (deflated 74%)\n","  adding: content/models-master/official/vision/image_classification/efficientnet/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/efficientnet/common_modules.py (deflated 63%)\n","  adding: content/models-master/official/vision/image_classification/efficientnet/efficientnet_model.py (deflated 70%)\n","  adding: content/models-master/official/vision/image_classification/efficientnet/tfhub_export.py (deflated 55%)\n","  adding: content/models-master/official/vision/image_classification/efficientnet/efficientnet_config.py (deflated 58%)\n","  adding: content/models-master/official/vision/image_classification/efficientnet/__init__.py (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/optimizer_factory_test.py (deflated 66%)\n","  adding: content/models-master/official/vision/image_classification/learning_rate.py (deflated 67%)\n","  adding: content/models-master/official/vision/image_classification/__init__.py (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/test_utils.py (deflated 51%)\n","  adding: content/models-master/official/vision/image_classification/mnist_main.py (deflated 63%)\n","  adding: content/models-master/official/vision/image_classification/resnet/ (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/resnet/README.md (deflated 57%)\n","  adding: content/models-master/official/vision/image_classification/resnet/resnet_ctl_imagenet_main.py (deflated 66%)\n","  adding: content/models-master/official/vision/image_classification/resnet/tfhub_export.py (deflated 55%)\n","  adding: content/models-master/official/vision/image_classification/resnet/resnet_config.py (deflated 54%)\n","  adding: content/models-master/official/vision/image_classification/resnet/resnet_runnable.py (deflated 69%)\n","  adding: content/models-master/official/vision/image_classification/resnet/resnet_model.py (deflated 78%)\n","  adding: content/models-master/official/vision/image_classification/resnet/imagenet_preprocessing.py (deflated 69%)\n","  adding: content/models-master/official/vision/image_classification/resnet/__init__.py (stored 0%)\n","  adding: content/models-master/official/vision/image_classification/resnet/common.py (deflated 68%)\n","  adding: content/models-master/official/vision/detection/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/executor/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/executor/distributed_executor.py (deflated 76%)\n","  adding: content/models-master/official/vision/detection/executor/detection_executor.py (deflated 67%)\n","  adding: content/models-master/official/vision/detection/executor/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/main.py (deflated 71%)\n","  adding: content/models-master/official/vision/detection/README.md (deflated 83%)\n","  adding: content/models-master/official/vision/detection/dataloader/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/dataloader/olnmask_parser.py (deflated 72%)\n","  adding: content/models-master/official/vision/detection/dataloader/mode_keys.py (deflated 48%)\n","  adding: content/models-master/official/vision/detection/dataloader/input_reader.py (deflated 63%)\n","  adding: content/models-master/official/vision/detection/dataloader/shapemask_parser.py (deflated 75%)\n","  adding: content/models-master/official/vision/detection/dataloader/factory.py (deflated 81%)\n","  adding: content/models-master/official/vision/detection/dataloader/retinanet_parser.py (deflated 77%)\n","  adding: content/models-master/official/vision/detection/dataloader/maskrcnn_parser.py (deflated 74%)\n","  adding: content/models-master/official/vision/detection/dataloader/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/dataloader/tf_example_decoder.py (deflated 72%)\n","  adding: content/models-master/official/vision/detection/dataloader/anchor.py (deflated 79%)\n","  adding: content/models-master/official/vision/detection/evaluation/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/evaluation/coco_evaluator.py (deflated 82%)\n","  adding: content/models-master/official/vision/detection/evaluation/factory.py (deflated 66%)\n","  adding: content/models-master/official/vision/detection/evaluation/coco_utils.py (deflated 72%)\n","  adding: content/models-master/official/vision/detection/evaluation/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/ops/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/ops/nms.py (deflated 69%)\n","  adding: content/models-master/official/vision/detection/ops/spatial_transform_ops.py (deflated 77%)\n","  adding: content/models-master/official/vision/detection/ops/target_ops.py (deflated 84%)\n","  adding: content/models-master/official/vision/detection/ops/postprocess_ops.py (deflated 81%)\n","  adding: content/models-master/official/vision/detection/ops/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/ops/roi_ops.py (deflated 84%)\n","  adding: content/models-master/official/vision/detection/configs/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/configs/olnmask_config.py (deflated 66%)\n","  adding: content/models-master/official/vision/detection/configs/factory.py (deflated 60%)\n","  adding: content/models-master/official/vision/detection/configs/retinanet_config.py (deflated 52%)\n","  adding: content/models-master/official/vision/detection/configs/shapemask_config.py (deflated 60%)\n","  adding: content/models-master/official/vision/detection/configs/maskrcnn_config.py (deflated 64%)\n","  adding: content/models-master/official/vision/detection/configs/base_config.py (deflated 57%)\n","  adding: content/models-master/official/vision/detection/configs/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/utils/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/utils/input_utils.py (deflated 77%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/faster_rcnn_box_coder.py (deflated 62%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/matcher.py (deflated 72%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/region_similarity_calculator.py (deflated 67%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/box_coder.py (deflated 64%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/minibatch_sampler.py (deflated 58%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/argmax_matcher.py (deflated 71%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/box_list.py (deflated 66%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/visualization_utils.py (deflated 75%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/ops.py (deflated 58%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/shape_utils.py (deflated 62%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/balanced_positive_negative_sampler.py (deflated 73%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/box_list_ops.py (deflated 77%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/preprocessor.py (deflated 75%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/utils/object_detection/target_assigner.py (deflated 83%)\n","  adding: content/models-master/official/vision/detection/utils/mask_utils.py (deflated 67%)\n","  adding: content/models-master/official/vision/detection/utils/box_utils.py (deflated 80%)\n","  adding: content/models-master/official/vision/detection/utils/dataloader_utils.py (deflated 53%)\n","  adding: content/models-master/official/vision/detection/utils/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/utils/class_utils.py (deflated 48%)\n","  adding: content/models-master/official/vision/detection/modeling/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/ (stored 0%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/factory.py (deflated 82%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/heads.py (deflated 86%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/keras_utils.py (deflated 50%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/nn_blocks.py (deflated 83%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/spinenet.py (deflated 77%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/nn_ops.py (deflated 62%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/resnet.py (deflated 74%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/fpn.py (deflated 67%)\n","  adding: content/models-master/official/vision/detection/modeling/architecture/identity.py (deflated 49%)\n","  adding: content/models-master/official/vision/detection/modeling/checkpoint_utils.py (deflated 63%)\n","  adding: content/models-master/official/vision/detection/modeling/factory.py (deflated 57%)\n","  adding: content/models-master/official/vision/detection/modeling/base_model.py (deflated 66%)\n","  adding: content/models-master/official/vision/detection/modeling/losses.py (deflated 80%)\n","  adding: content/models-master/official/vision/detection/modeling/optimizers.py (deflated 58%)\n","  adding: content/models-master/official/vision/detection/modeling/shapemask_model.py (deflated 76%)\n","  adding: content/models-master/official/vision/detection/modeling/retinanet_model.py (deflated 68%)\n","  adding: content/models-master/official/vision/detection/modeling/learning_rates.py (deflated 70%)\n","  adding: content/models-master/official/vision/detection/modeling/__init__.py (deflated 43%)\n","  adding: content/models-master/official/vision/detection/modeling/maskrcnn_model.py (deflated 76%)\n","  adding: content/models-master/official/vision/detection/modeling/olnmask_model.py (deflated 78%)\n","  adding: content/models-master/official/vision/detection/__init__.py (stored 0%)\n","  adding: content/models-master/official/vision/keras_cv/ (stored 0%)\n","  adding: content/models-master/official/vision/keras_cv/requirements.txt (stored 0%)\n","  adding: content/models-master/official/vision/keras_cv/README.md (deflated 30%)\n","  adding: content/models-master/official/vision/keras_cv/metrics/ (stored 0%)\n","  adding: content/models-master/official/vision/keras_cv/metrics/iou.py (deflated 61%)\n","  adding: content/models-master/official/vision/keras_cv/metrics/iou_test.py (deflated 71%)\n","  adding: content/models-master/official/vision/keras_cv/metrics/__init__.py (deflated 42%)\n","  adding: content/models-master/official/vision/keras_cv/losses/ (stored 0%)\n","  adding: content/models-master/official/vision/keras_cv/losses/focal_loss.py (deflated 56%)\n","  adding: content/models-master/official/vision/keras_cv/losses/loss_utils.py (deflated 54%)\n","  adding: content/models-master/official/vision/keras_cv/losses/__init__.py (deflated 45%)\n","  adding: content/models-master/official/vision/keras_cv/ops/ (stored 0%)\n","  adding: content/models-master/official/vision/keras_cv/ops/target_gather.py (deflated 68%)\n","  adding: content/models-master/official/vision/keras_cv/ops/box_matcher.py (deflated 69%)\n","  adding: content/models-master/official/vision/keras_cv/ops/anchor_generator.py (deflated 71%)\n","  adding: content/models-master/official/vision/keras_cv/ops/iou_similarity.py (deflated 69%)\n","  adding: content/models-master/official/vision/keras_cv/ops/target_gather_test.py (deflated 67%)\n","  adding: content/models-master/official/vision/keras_cv/ops/iou_similarity_test.py (deflated 64%)\n","  adding: content/models-master/official/vision/keras_cv/ops/box_matcher_test.py (deflated 67%)\n","  adding: content/models-master/official/vision/keras_cv/ops/__init__.py (deflated 49%)\n","  adding: content/models-master/official/vision/keras_cv/ops/anchor_generator_test.py (deflated 77%)\n","  adding: content/models-master/official/vision/keras_cv/contributing.md (deflated 50%)\n","  adding: content/models-master/official/vision/keras_cv/layers/ (stored 0%)\n","  adding: content/models-master/official/vision/keras_cv/layers/deeplab.py (deflated 72%)\n","  adding: content/models-master/official/vision/keras_cv/layers/__init__.py (deflated 42%)\n","  adding: content/models-master/official/vision/keras_cv/layers/deeplab_test.py (deflated 57%)\n","  adding: content/models-master/official/vision/keras_cv/setup.py (deflated 54%)\n","  adding: content/models-master/official/vision/keras_cv/LICENSE (deflated 65%)\n","  adding: content/models-master/official/vision/keras_cv/__init__.py (deflated 49%)\n","  adding: content/models-master/official/vision/beta/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/tasks/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/tasks/maskrcnn.py (deflated 71%)\n","  adding: content/models-master/official/vision/beta/tasks/image_classification.py (deflated 69%)\n","  adding: content/models-master/official/vision/beta/tasks/semantic_segmentation.py (deflated 69%)\n","  adding: content/models-master/official/vision/beta/tasks/video_classification.py (deflated 71%)\n","  adding: content/models-master/official/vision/beta/tasks/retinanet.py (deflated 71%)\n","  adding: content/models-master/official/vision/beta/tasks/__init__.py (deflated 51%)\n","  adding: content/models-master/official/vision/beta/dataloaders/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/dataloaders/parser.py (deflated 61%)\n","  adding: content/models-master/official/vision/beta/dataloaders/segmentation_input.py (deflated 71%)\n","  adding: content/models-master/official/vision/beta/dataloaders/decoder.py (deflated 48%)\n","  adding: content/models-master/official/vision/beta/dataloaders/maskrcnn_input.py (deflated 74%)\n","  adding: content/models-master/official/vision/beta/dataloaders/tf_example_decoder_test.py (deflated 87%)\n","  adding: content/models-master/official/vision/beta/dataloaders/retinanet_input.py (deflated 74%)\n","  adding: content/models-master/official/vision/beta/dataloaders/classification_input.py (deflated 66%)\n","  adding: content/models-master/official/vision/beta/dataloaders/tf_example_label_map_decoder_test.py (deflated 82%)\n","  adding: content/models-master/official/vision/beta/dataloaders/video_input_test.py (deflated 70%)\n","  adding: content/models-master/official/vision/beta/dataloaders/tf_example_label_map_decoder.py (deflated 56%)\n","  adding: content/models-master/official/vision/beta/dataloaders/tf_example_decoder.py (deflated 72%)\n","  adding: content/models-master/official/vision/beta/dataloaders/video_input.py (deflated 73%)\n","  adding: content/models-master/official/vision/beta/dataloaders/utils.py (deflated 57%)\n","  adding: content/models-master/official/vision/beta/data/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/data/create_coco_tf_record.py (deflated 73%)\n","  adding: content/models-master/official/vision/beta/data/tfrecord_lib.py (deflated 64%)\n","  adding: content/models-master/official/vision/beta/data/tfrecord_lib_test.py (deflated 61%)\n","  adding: content/models-master/official/vision/beta/README.md (deflated 11%)\n","  adding: content/models-master/official/vision/beta/losses/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/losses/segmentation_losses.py (deflated 62%)\n","  adding: content/models-master/official/vision/beta/losses/maskrcnn_losses.py (deflated 76%)\n","  adding: content/models-master/official/vision/beta/losses/retinanet_losses.py (deflated 70%)\n","  adding: content/models-master/official/vision/beta/evaluation/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/evaluation/coco_evaluator.py (deflated 74%)\n","  adding: content/models-master/official/vision/beta/evaluation/segmentation_metrics.py (deflated 67%)\n","  adding: content/models-master/official/vision/beta/evaluation/coco_utils.py (deflated 72%)\n","  adding: content/models-master/official/vision/beta/train.py (deflated 57%)\n","  adding: content/models-master/official/vision/beta/ops/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/ops/augment_test.py (deflated 71%)\n","  adding: content/models-master/official/vision/beta/ops/nms.py (deflated 69%)\n","  adding: content/models-master/official/vision/beta/ops/box_ops.py (deflated 79%)\n","  adding: content/models-master/official/vision/beta/ops/augment.py (deflated 75%)\n","  adding: content/models-master/official/vision/beta/ops/spatial_transform_ops.py (deflated 77%)\n","  adding: content/models-master/official/vision/beta/ops/anchor_test.py (deflated 72%)\n","  adding: content/models-master/official/vision/beta/ops/preprocess_ops.py (deflated 78%)\n","  adding: content/models-master/official/vision/beta/ops/preprocess_ops_3d_test.py (deflated 70%)\n","  adding: content/models-master/official/vision/beta/ops/sampling_ops.py (deflated 72%)\n","  adding: content/models-master/official/vision/beta/ops/preprocess_ops_test.py (deflated 79%)\n","  adding: content/models-master/official/vision/beta/ops/preprocess_ops_3d.py (deflated 69%)\n","  adding: content/models-master/official/vision/beta/ops/mask_ops.py (deflated 68%)\n","  adding: content/models-master/official/vision/beta/ops/anchor.py (deflated 75%)\n","  adding: content/models-master/official/vision/beta/ops/mask_ops_test.py (deflated 57%)\n","  adding: content/models-master/official/vision/beta/configs/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/configs/maskrcnn.py (deflated 79%)\n","  adding: content/models-master/official/vision/beta/configs/image_classification.py (deflated 81%)\n","  adding: content/models-master/official/vision/beta/configs/semantic_segmentation.py (deflated 84%)\n","  adding: content/models-master/official/vision/beta/configs/semantic_segmentation_test.py (deflated 55%)\n","  adding: content/models-master/official/vision/beta/configs/backbones.py (deflated 65%)\n","  adding: content/models-master/official/vision/beta/configs/image_classification_test.py (deflated 57%)\n","  adding: content/models-master/official/vision/beta/configs/backbones_3d.py (deflated 65%)\n","  adding: content/models-master/official/vision/beta/configs/video_classification.py (deflated 74%)\n","  adding: content/models-master/official/vision/beta/configs/retinanet.py (deflated 76%)\n","  adding: content/models-master/official/vision/beta/configs/__init__.py (deflated 52%)\n","  adding: content/models-master/official/vision/beta/configs/decoders.py (deflated 55%)\n","  adding: content/models-master/official/vision/beta/configs/common.py (deflated 44%)\n","  adding: content/models-master/official/vision/beta/configs/video_classification_test.py (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet300_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_deeplab_tpu.yaml (deflated 58%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_mobilenetv2_gpu.yaml (deflated 55%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet50_gpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet200_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet101_deeplab_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet152_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet350_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_mobilenetv2_tpu.yaml (deflated 54%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/image_classification/imagenet_resnet101_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/video_classification/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/video_classification/k400_slowonly8x8_tpu.yaml (deflated 69%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/video_classification/k400_3d-resnet50_tpu.yaml (deflated 69%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/maskrcnn/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/maskrcnn/r50fpn_640_coco_scratch_tpu4x4.yaml (deflated 47%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/retinanet/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/retinanet/coco_spinenet96_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/retinanet/coco_spinenet49_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/retinanet/coco_spinenet190_tpu.yaml (deflated 57%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/retinanet/resnet50fpn_coco_tpu4x4_benchmark.yaml (deflated 31%)\n","  adding: content/models-master/official/vision/beta/configs/experiments/retinanet/coco_spinenet143_tpu.yaml (deflated 56%)\n","  adding: content/models-master/official/vision/beta/modeling/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/modeling/classification_model_test.py (deflated 73%)\n","  adding: content/models-master/official/vision/beta/modeling/maskrcnn_model_test.py (deflated 79%)\n","  adding: content/models-master/official/vision/beta/modeling/factory_3d.py (deflated 64%)\n","  adding: content/models-master/official/vision/beta/modeling/heads/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/modeling/heads/dense_prediction_heads_test.py (deflated 75%)\n","  adding: content/models-master/official/vision/beta/modeling/heads/segmentation_heads.py (deflated 69%)\n","  adding: content/models-master/official/vision/beta/modeling/heads/dense_prediction_heads.py (deflated 85%)\n","  adding: content/models-master/official/vision/beta/modeling/heads/segmentation_heads_test.py (deflated 57%)\n","  adding: content/models-master/official/vision/beta/modeling/heads/instance_heads.py (deflated 82%)\n","  adding: content/models-master/official/vision/beta/modeling/heads/instance_heads_test.py (deflated 73%)\n","  adding: content/models-master/official/vision/beta/modeling/segmentation_model_test.py (deflated 61%)\n","  adding: content/models-master/official/vision/beta/modeling/factory.py (deflated 83%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/resnet_deeplab.py (deflated 73%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/efficientnet_test.py (deflated 63%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/mobilenet.py (deflated 79%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/spinenet_test.py (deflated 62%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/mobilenet_test.py (deflated 70%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/factory.py (deflated 59%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/resnet_3d_test.py (deflated 62%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/spinenet.py (deflated 76%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/revnet.py (deflated 66%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/revnet_test.py (deflated 61%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/resnet_test.py (deflated 67%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/factory_test.py (deflated 80%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/resnet.py (deflated 74%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/resnet_3d.py (deflated 72%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/resnet_deeplab_test.py (deflated 67%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/__init__.py (deflated 58%)\n","  adding: content/models-master/official/vision/beta/modeling/backbones/efficientnet.py (deflated 71%)\n","  adding: content/models-master/official/vision/beta/modeling/video_classification_model.py (deflated 63%)\n","  adding: content/models-master/official/vision/beta/modeling/retinanet_model_test.py (deflated 75%)\n","  adding: content/models-master/official/vision/beta/modeling/classification_model.py (deflated 64%)\n","  adding: content/models-master/official/vision/beta/modeling/factory_test.py (deflated 76%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/roi_aligner.py (deflated 54%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/detection_generator.py (deflated 83%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/nn_blocks_3d_test.py (deflated 56%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/nn_blocks.py (deflated 85%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/nn_layers.py (deflated 68%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/nn_blocks_test.py (deflated 80%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/roi_aligner_test.py (deflated 50%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/roi_generator.py (deflated 76%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/box_sampler.py (deflated 62%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/roi_sampler.py (deflated 70%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/detection_generator_test.py (deflated 78%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/nn_blocks_3d.py (deflated 74%)\n","  adding: content/models-master/official/vision/beta/modeling/layers/mask_sampler.py (deflated 76%)\n","  adding: content/models-master/official/vision/beta/modeling/retinanet_model.py (deflated 67%)\n","  adding: content/models-master/official/vision/beta/modeling/segmentation_model.py (deflated 57%)\n","  adding: content/models-master/official/vision/beta/modeling/maskrcnn_model.py (deflated 70%)\n","  adding: content/models-master/official/vision/beta/modeling/video_classification_model_test.py (deflated 63%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/fpn_test.py (deflated 56%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/factory.py (deflated 69%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/aspp.py (deflated 63%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/nasfpn_test.py (deflated 52%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/nasfpn.py (deflated 70%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/aspp_test.py (deflated 56%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/__init__.py (deflated 48%)\n","  adding: content/models-master/official/vision/beta/modeling/decoders/fpn.py (deflated 67%)\n","  adding: content/models-master/official/vision/beta/train_spatial_partitioning.py (deflated 67%)\n","  adding: content/models-master/official/vision/beta/__init__.py (deflated 45%)\n","  adding: content/models-master/official/vision/beta/projects/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/README.md (deflated 34%)\n","  adding: content/models-master/official/vision/beta/projects/keypoint/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/keypoint/README.md (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/tasks/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/tasks/image_classification.py (deflated 62%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/dataloaders/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/dataloaders/classification_tfds_decoder.py (deflated 48%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/README.md (deflated 57%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/train.py (deflated 57%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/common/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/common/registry_imports.py (deflated 49%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/configs/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/configs/darknet_classification.py (deflated 58%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/configs/backbones.py (deflated 48%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/configs/experiments/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/configs/experiments/darknet53.yaml (deflated 58%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/configs/experiments/csp_darknet53.yaml (deflated 58%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/configs/experiments/darknet53_tfds.yaml (deflated 62%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/configs/experiments/csp_darknet53_tfds.yaml (deflated 62%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/modeling/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/modeling/backbones/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/modeling/backbones/darknet_test.py (deflated 63%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/modeling/backbones/darknet.py (deflated 75%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/modeling/layers/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/modeling/layers/nn_blocks.py (deflated 84%)\n","  adding: content/models-master/official/vision/beta/projects/yolo/modeling/layers/nn_blocks_test.py (deflated 82%)\n","  adding: content/models-master/official/vision/beta/MODEL_GARDEN.md (deflated 71%)\n","  adding: content/models-master/official/vision/beta/serving/ (stored 0%)\n","  adding: content/models-master/official/vision/beta/serving/export_saved_model.py (deflated 66%)\n","  adding: content/models-master/official/vision/beta/serving/image_classification.py (deflated 57%)\n","  adding: content/models-master/official/vision/beta/serving/export_base.py (deflated 64%)\n","  adding: content/models-master/official/vision/beta/serving/image_classification_test.py (deflated 66%)\n","  adding: content/models-master/official/vision/beta/serving/detection_test.py (deflated 68%)\n","  adding: content/models-master/official/vision/beta/serving/detection.py (deflated 66%)\n","  adding: content/models-master/official/vision/__init__.py (stored 0%)\n","  adding: content/models-master/official/README-TPU.md (deflated 63%)\n","  adding: content/models-master/official/README.md (deflated 61%)\n","  adding: content/models-master/official/nlp/ (stored 0%)\n","  adding: content/models-master/official/nlp/nhnet/ (stored 0%)\n","  adding: content/models-master/official/nlp/nhnet/raw_data_processor.py (deflated 70%)\n","  adding: content/models-master/official/nlp/nhnet/configs.py (deflated 60%)\n","  adding: content/models-master/official/nlp/nhnet/models.py (deflated 79%)\n","  adding: content/models-master/official/nlp/nhnet/decoder.py (deflated 76%)\n","  adding: content/models-master/official/nlp/nhnet/evaluation.py (deflated 66%)\n","  adding: content/models-master/official/nlp/nhnet/README.md (deflated 56%)\n","  adding: content/models-master/official/nlp/nhnet/raw_data_process.py (deflated 63%)\n","  adding: content/models-master/official/nlp/nhnet/trainer_test.py (deflated 58%)\n","  adding: content/models-master/official/nlp/nhnet/decoder_test.py (deflated 77%)\n","  adding: content/models-master/official/nlp/nhnet/configs_test.py (deflated 67%)\n","  adding: content/models-master/official/nlp/nhnet/optimizer.py (deflated 63%)\n","  adding: content/models-master/official/nlp/nhnet/input_pipeline.py (deflated 73%)\n","  adding: content/models-master/official/nlp/nhnet/models_test.py (deflated 78%)\n","  adding: content/models-master/official/nlp/nhnet/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/nhnet/trainer.py (deflated 65%)\n","  adding: content/models-master/official/nlp/nhnet/utils.py (deflated 60%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/ (stored 0%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/vocab.txt (deflated 10%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/stories.json (deflated 81%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/crawled_articles/ (stored 0%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/crawled_articles/domain_1.com/ (stored 0%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/crawled_articles/domain_1.com/url_001.html (deflated 9%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/crawled_articles/domain_1.com/url_001.json (deflated 27%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/crawled_articles/domain_0.com/ (stored 0%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/crawled_articles/domain_0.com/url_000.json (deflated 24%)\n","  adding: content/models-master/official/nlp/nhnet/testdata/crawled_articles/domain_0.com/url_000.html (deflated 9%)\n","  adding: content/models-master/official/nlp/tasks/ (stored 0%)\n","  adding: content/models-master/official/nlp/tasks/masked_lm.py (deflated 68%)\n","  adding: content/models-master/official/nlp/tasks/tagging_test.py (deflated 70%)\n","  adding: content/models-master/official/nlp/tasks/tagging.py (deflated 67%)\n","  adding: content/models-master/official/nlp/tasks/electra_task_test.py (deflated 60%)\n","  adding: content/models-master/official/nlp/tasks/masked_lm_test.py (deflated 55%)\n","  adding: content/models-master/official/nlp/tasks/question_answering_test.py (deflated 78%)\n","  adding: content/models-master/official/nlp/tasks/electra_task.py (deflated 71%)\n","  adding: content/models-master/official/nlp/tasks/question_answering.py (deflated 76%)\n","  adding: content/models-master/official/nlp/tasks/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/tasks/sentence_prediction_test.py (deflated 74%)\n","  adding: content/models-master/official/nlp/tasks/sentence_prediction.py (deflated 70%)\n","  adding: content/models-master/official/nlp/tasks/utils.py (deflated 57%)\n","  adding: content/models-master/official/nlp/bert/ (stored 0%)\n","  adding: content/models-master/official/nlp/bert/tokenization.py (deflated 70%)\n","  adding: content/models-master/official/nlp/bert/model_training_utils.py (deflated 71%)\n","  adding: content/models-master/official/nlp/bert/bert_models_test.py (deflated 71%)\n","  adding: content/models-master/official/nlp/bert/squad_evaluate_v1_1.py (deflated 60%)\n","  adding: content/models-master/official/nlp/bert/configs.py (deflated 62%)\n","  adding: content/models-master/official/nlp/bert/tf2_encoder_checkpoint_converter.py (deflated 66%)\n","  adding: content/models-master/official/nlp/bert/model_saving_utils.py (deflated 59%)\n","  adding: content/models-master/official/nlp/bert/serving.py (deflated 64%)\n","  adding: content/models-master/official/nlp/bert/README.md (deflated 73%)\n","  adding: content/models-master/official/nlp/bert/model_training_utils_test.py (deflated 73%)\n","  adding: content/models-master/official/nlp/bert/run_pretraining.py (deflated 70%)\n","  adding: content/models-master/official/nlp/bert/squad_evaluate_v2_0.py (deflated 69%)\n","  adding: content/models-master/official/nlp/bert/export_tfhub.py (deflated 69%)\n","  adding: content/models-master/official/nlp/bert/tokenization_test.py (deflated 73%)\n","  adding: content/models-master/official/nlp/bert/bert_cloud_tpu.md (deflated 54%)\n","  adding: content/models-master/official/nlp/bert/export_tfhub_test.py (deflated 63%)\n","  adding: content/models-master/official/nlp/bert/run_squad.py (deflated 66%)\n","  adding: content/models-master/official/nlp/bert/tf1_checkpoint_converter_lib.py (deflated 69%)\n","  adding: content/models-master/official/nlp/bert/input_pipeline.py (deflated 78%)\n","  adding: content/models-master/official/nlp/bert/common_flags.py (deflated 62%)\n","  adding: content/models-master/official/nlp/bert/bert_models.py (deflated 77%)\n","  adding: content/models-master/official/nlp/bert/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/bert/run_classifier.py (deflated 72%)\n","  adding: content/models-master/official/nlp/bert/run_squad_helper.py (deflated 72%)\n","  adding: content/models-master/official/nlp/data/ (stored 0%)\n","  adding: content/models-master/official/nlp/data/question_answering_dataloader_test.py (deflated 61%)\n","  adding: content/models-master/official/nlp/data/train_sentencepiece.py (deflated 59%)\n","  adding: content/models-master/official/nlp/data/sentence_prediction_dataloader.py (deflated 61%)\n","  adding: content/models-master/official/nlp/data/create_pretraining_data.py (deflated 69%)\n","  adding: content/models-master/official/nlp/data/squad_lib.py (deflated 75%)\n","  adding: content/models-master/official/nlp/data/tagging_dataloader.py (deflated 62%)\n","  adding: content/models-master/official/nlp/data/create_xlnet_pretraining_data.py (deflated 71%)\n","  adding: content/models-master/official/nlp/data/question_answering_dataloader.py (deflated 63%)\n","  adding: content/models-master/official/nlp/data/tagging_data_lib_test.py (deflated 63%)\n","  adding: content/models-master/official/nlp/data/squad_lib_sp.py (deflated 75%)\n","  adding: content/models-master/official/nlp/data/data_loader_factory_test.py (deflated 51%)\n","  adding: content/models-master/official/nlp/data/tagging_dataloader_test.py (deflated 63%)\n","  adding: content/models-master/official/nlp/data/classifier_data_lib.py (deflated 84%)\n","  adding: content/models-master/official/nlp/data/sentence_prediction_dataloader_test.py (deflated 62%)\n","  adding: content/models-master/official/nlp/data/pretrain_dataloader.py (deflated 77%)\n","  adding: content/models-master/official/nlp/data/sentence_retrieval_lib.py (deflated 71%)\n","  adding: content/models-master/official/nlp/data/create_finetuning_data.py (deflated 78%)\n","  adding: content/models-master/official/nlp/data/data_loader_factory.py (deflated 55%)\n","  adding: content/models-master/official/nlp/data/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/data/create_xlnet_pretraining_data_test.py (deflated 73%)\n","  adding: content/models-master/official/nlp/data/pretrain_dataloader_test.py (deflated 79%)\n","  adding: content/models-master/official/nlp/data/data_loader.py (deflated 51%)\n","  adding: content/models-master/official/nlp/data/tagging_data_lib.py (deflated 73%)\n","  adding: content/models-master/official/nlp/data/create_pretraining_data_test.py (deflated 71%)\n","  adding: content/models-master/official/nlp/README.md (deflated 51%)\n","  adding: content/models-master/official/nlp/optimization.py (deflated 70%)\n","  adding: content/models-master/official/nlp/train.md (deflated 58%)\n","  adding: content/models-master/official/nlp/keras_nlp/ (stored 0%)\n","  adding: content/models-master/official/nlp/keras_nlp/requirements.txt (stored 0%)\n","  adding: content/models-master/official/nlp/keras_nlp/README.md (deflated 55%)\n","  adding: content/models-master/official/nlp/keras_nlp/contributing.md (deflated 50%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/ (stored 0%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/position_embedding.py (deflated 58%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/masked_lm.py (deflated 62%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/transformer_encoder_block_test.py (deflated 83%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/self_attention_mask.py (deflated 54%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/on_device_embedding_test.py (deflated 85%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/__init__.py (deflated 52%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/on_device_embedding.py (deflated 61%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/transformer_encoder_block.py (deflated 75%)\n","  adding: content/models-master/official/nlp/keras_nlp/layers/position_embedding_test.py (deflated 69%)\n","  adding: content/models-master/official/nlp/keras_nlp/setup.py (deflated 54%)\n","  adding: content/models-master/official/nlp/keras_nlp/__init__.py (deflated 45%)\n","  adding: content/models-master/official/nlp/keras_nlp/encoders/ (stored 0%)\n","  adding: content/models-master/official/nlp/keras_nlp/encoders/bert_encoder.py (deflated 67%)\n","  adding: content/models-master/official/nlp/keras_nlp/encoders/bert_encoder_test.py (deflated 78%)\n","  adding: content/models-master/official/nlp/keras_nlp/encoders/__init__.py (deflated 43%)\n","  adding: content/models-master/official/nlp/train_ctl_continuous_finetune_test.py (deflated 62%)\n","  adding: content/models-master/official/nlp/train_ctl_continuous_finetune.py (deflated 62%)\n","  adding: content/models-master/official/nlp/train.py (deflated 57%)\n","  adding: content/models-master/official/nlp/albert/ (stored 0%)\n","  adding: content/models-master/official/nlp/albert/configs.py (deflated 52%)\n","  adding: content/models-master/official/nlp/albert/README.md (deflated 71%)\n","  adding: content/models-master/official/nlp/albert/export_albert_tfhub_test.py (deflated 62%)\n","  adding: content/models-master/official/nlp/albert/export_albert_tfhub.py (deflated 61%)\n","  adding: content/models-master/official/nlp/albert/run_squad.py (deflated 65%)\n","  adding: content/models-master/official/nlp/albert/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/albert/run_classifier.py (deflated 64%)\n","  adding: content/models-master/official/nlp/albert/tf2_albert_encoder_checkpoint_converter.py (deflated 68%)\n","  adding: content/models-master/official/nlp/configs/ (stored 0%)\n","  adding: content/models-master/official/nlp/configs/finetuning_experiments.py (deflated 73%)\n","  adding: content/models-master/official/nlp/configs/bert.py (deflated 50%)\n","  adding: content/models-master/official/nlp/configs/electra.py (deflated 50%)\n","  adding: content/models-master/official/nlp/configs/encoders.py (deflated 78%)\n","  adding: content/models-master/official/nlp/configs/models/ (stored 0%)\n","  adding: content/models-master/official/nlp/configs/models/bert_en_uncased_base.yaml (deflated 52%)\n","  adding: content/models-master/official/nlp/configs/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/configs/experiment_configs.py (deflated 43%)\n","  adding: content/models-master/official/nlp/configs/experiments/ (stored 0%)\n","  adding: content/models-master/official/nlp/configs/experiments/glue_mnli_matched.yaml (deflated 59%)\n","  adding: content/models-master/official/nlp/transformer/ (stored 0%)\n","  adding: content/models-master/official/nlp/transformer/compute_bleu.py (deflated 60%)\n","  adding: content/models-master/official/nlp/transformer/model_utils.py (deflated 61%)\n","  adding: content/models-master/official/nlp/transformer/data_pipeline.py (deflated 67%)\n","  adding: content/models-master/official/nlp/transformer/ffn_layer.py (deflated 60%)\n","  adding: content/models-master/official/nlp/transformer/README.md (deflated 63%)\n","  adding: content/models-master/official/nlp/transformer/misc.py (deflated 68%)\n","  adding: content/models-master/official/nlp/transformer/attention_layer.py (deflated 67%)\n","  adding: content/models-master/official/nlp/transformer/beam_search_v1.py (deflated 61%)\n","  adding: content/models-master/official/nlp/transformer/transformer_main.py (deflated 72%)\n","  adding: content/models-master/official/nlp/transformer/optimizer.py (deflated 62%)\n","  adding: content/models-master/official/nlp/transformer/compute_bleu_test.py (deflated 67%)\n","  adding: content/models-master/official/nlp/transformer/embedding_layer.py (deflated 62%)\n","  adding: content/models-master/official/nlp/transformer/transformer_layers_test.py (deflated 68%)\n","  adding: content/models-master/official/nlp/transformer/translate.py (deflated 64%)\n","  adding: content/models-master/official/nlp/transformer/model_params.py (deflated 58%)\n","  adding: content/models-master/official/nlp/transformer/utils/ (stored 0%)\n","  adding: content/models-master/official/nlp/transformer/utils/tokenizer_test.py (deflated 72%)\n","  adding: content/models-master/official/nlp/transformer/utils/tokenizer.py (deflated 71%)\n","  adding: content/models-master/official/nlp/transformer/utils/metrics.py (deflated 71%)\n","  adding: content/models-master/official/nlp/transformer/utils/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/transformer/model_utils_test.py (deflated 59%)\n","  adding: content/models-master/official/nlp/transformer/data_download.py (deflated 69%)\n","  adding: content/models-master/official/nlp/transformer/metrics.py (deflated 70%)\n","  adding: content/models-master/official/nlp/transformer/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/transformer/transformer_forward_test.py (deflated 70%)\n","  adding: content/models-master/official/nlp/transformer/transformer_test.py (deflated 66%)\n","  adding: content/models-master/official/nlp/transformer/transformer_main_test.py (deflated 71%)\n","  adding: content/models-master/official/nlp/transformer/transformer.py (deflated 76%)\n","  adding: content/models-master/official/nlp/modeling/ (stored 0%)\n","  adding: content/models-master/official/nlp/modeling/README.md (deflated 56%)\n","  adding: content/models-master/official/nlp/modeling/losses/ (stored 0%)\n","  adding: content/models-master/official/nlp/modeling/losses/README.md (deflated 31%)\n","  adding: content/models-master/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy_test.py (deflated 72%)\n","  adding: content/models-master/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy.py (deflated 58%)\n","  adding: content/models-master/official/nlp/modeling/losses/__init__.py (deflated 45%)\n","  adding: content/models-master/official/nlp/modeling/models/ (stored 0%)\n","  adding: content/models-master/official/nlp/modeling/models/seq2seq_transformer.py (deflated 78%)\n","  adding: content/models-master/official/nlp/modeling/models/dual_encoder_test.py (deflated 69%)\n","  adding: content/models-master/official/nlp/modeling/models/electra_pretrainer.py (deflated 70%)\n","  adding: content/models-master/official/nlp/modeling/models/README.md (deflated 56%)\n","  adding: content/models-master/official/nlp/modeling/models/electra_pretrainer_test.py (deflated 73%)\n","  adding: content/models-master/official/nlp/modeling/models/bert_span_labeler_test.py (deflated 66%)\n","  adding: content/models-master/official/nlp/modeling/models/dual_encoder.py (deflated 66%)\n","  adding: content/models-master/official/nlp/modeling/models/seq2seq_transformer_test.py (deflated 65%)\n","  adding: content/models-master/official/nlp/modeling/models/bert_classifier.py (deflated 60%)\n","  adding: content/models-master/official/nlp/modeling/models/bert_pretrainer_test.py (deflated 78%)\n","  adding: content/models-master/official/nlp/modeling/models/xlnet.py (deflated 74%)\n","  adding: content/models-master/official/nlp/modeling/models/bert_pretrainer.py (deflated 69%)\n","  adding: content/models-master/official/nlp/modeling/models/xlnet_test.py (deflated 83%)\n","  adding: content/models-master/official/nlp/modeling/models/bert_classifier_test.py (deflated 65%)\n","  adding: content/models-master/official/nlp/modeling/models/bert_token_classifier_test.py (deflated 66%)\n","  adding: content/models-master/official/nlp/modeling/models/bert_token_classifier.py (deflated 58%)\n","  adding: content/models-master/official/nlp/modeling/models/__init__.py (deflated 60%)\n","  adding: content/models-master/official/nlp/modeling/models/bert_span_labeler.py (deflated 58%)\n","  adding: content/models-master/official/nlp/modeling/ops/ (stored 0%)\n","  adding: content/models-master/official/nlp/modeling/ops/decoding_module_test.py (deflated 61%)\n","  adding: content/models-master/official/nlp/modeling/ops/segment_extractor.py (deflated 71%)\n","  adding: content/models-master/official/nlp/modeling/ops/decoding_module.py (deflated 69%)\n","  adding: content/models-master/official/nlp/modeling/ops/beam_search_test.py (deflated 62%)\n","  adding: content/models-master/official/nlp/modeling/ops/sampling_module.py (deflated 76%)\n","  adding: content/models-master/official/nlp/modeling/ops/segment_extractor_test.py (deflated 78%)\n","  adding: content/models-master/official/nlp/modeling/ops/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/modeling/ops/beam_search.py (deflated 74%)\n","  adding: content/models-master/official/nlp/modeling/layers/ (stored 0%)\n","  adding: content/models-master/official/nlp/modeling/layers/transformer_scaffold_test.py (deflated 87%)\n","  adding: content/models-master/official/nlp/modeling/layers/mat_mul_with_margin_test.py (deflated 56%)\n","  adding: content/models-master/official/nlp/modeling/layers/masked_softmax_test.py (deflated 74%)\n","  adding: content/models-master/official/nlp/modeling/layers/attention.py (deflated 60%)\n","  adding: content/models-master/official/nlp/modeling/layers/position_embedding.py (deflated 59%)\n","  adding: content/models-master/official/nlp/modeling/layers/masked_lm.py (deflated 43%)\n","  adding: content/models-master/official/nlp/modeling/layers/dense_einsum.py (deflated 71%)\n","  adding: content/models-master/official/nlp/modeling/layers/self_attention_mask.py (deflated 50%)\n","  adding: content/models-master/official/nlp/modeling/layers/tn_transformer_test.py (deflated 81%)\n","  adding: content/models-master/official/nlp/modeling/layers/README.md (deflated 63%)\n","  adding: content/models-master/official/nlp/modeling/layers/relative_attention_test.py (deflated 74%)\n","  adding: content/models-master/official/nlp/modeling/layers/mobile_bert_layers_test.py (deflated 77%)\n","  adding: content/models-master/official/nlp/modeling/layers/attention_test.py (deflated 67%)\n","  adding: content/models-master/official/nlp/modeling/layers/masked_lm_test.py (deflated 72%)\n","  adding: content/models-master/official/nlp/modeling/layers/gated_feedforward.py (deflated 72%)\n","  adding: content/models-master/official/nlp/modeling/layers/tn_expand_condense_test.py (deflated 71%)\n","  adding: content/models-master/official/nlp/modeling/layers/rezero_transformer.py (deflated 73%)\n","  adding: content/models-master/official/nlp/modeling/layers/tn_transformer_expand_condense.py (deflated 75%)\n","  adding: content/models-master/official/nlp/modeling/layers/tn_expand_condense.py (deflated 65%)\n","  adding: content/models-master/official/nlp/modeling/layers/talking_heads_attention_test.py (deflated 74%)\n","  adding: content/models-master/official/nlp/modeling/layers/cls_head_test.py (deflated 64%)\n","  adding: content/models-master/official/nlp/modeling/layers/gated_feedforward_test.py (deflated 70%)\n","  adding: content/models-master/official/nlp/modeling/layers/transformer_scaffold.py (deflated 75%)\n","  adding: content/models-master/official/nlp/modeling/layers/dense_einsum_test.py (deflated 74%)\n","  adding: content/models-master/official/nlp/modeling/layers/relative_attention.py (deflated 80%)\n","  adding: content/models-master/official/nlp/modeling/layers/talking_heads_attention.py (deflated 67%)\n","  adding: content/models-master/official/nlp/modeling/layers/multi_channel_attention.py (deflated 67%)\n","  adding: content/models-master/official/nlp/modeling/layers/mobile_bert_layers.py (deflated 77%)\n","  adding: content/models-master/official/nlp/modeling/layers/__init__.py (deflated 68%)\n","  adding: content/models-master/official/nlp/modeling/layers/on_device_embedding.py (deflated 44%)\n","  adding: content/models-master/official/nlp/modeling/layers/mat_mul_with_margin.py (deflated 55%)\n","  adding: content/models-master/official/nlp/modeling/layers/transformer_xl.py (deflated 79%)\n","  adding: content/models-master/official/nlp/modeling/layers/transformer_test.py (deflated 70%)\n","  adding: content/models-master/official/nlp/modeling/layers/transformer_xl_test.py (deflated 76%)\n","  adding: content/models-master/official/nlp/modeling/layers/masked_softmax.py (deflated 57%)\n","  adding: content/models-master/official/nlp/modeling/layers/util.py (deflated 52%)\n","  adding: content/models-master/official/nlp/modeling/layers/multi_channel_attention_test.py (deflated 57%)\n","  adding: content/models-master/official/nlp/modeling/layers/rezero_transformer_test.py (deflated 70%)\n","  adding: content/models-master/official/nlp/modeling/layers/transformer.py (deflated 80%)\n","  adding: content/models-master/official/nlp/modeling/layers/cls_head.py (deflated 74%)\n","  adding: content/models-master/official/nlp/modeling/layers/position_embedding_test.py (deflated 59%)\n","  adding: content/models-master/official/nlp/modeling/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/modeling/networks/ (stored 0%)\n","  adding: content/models-master/official/nlp/modeling/networks/xlnet_base_test.py (deflated 80%)\n","  adding: content/models-master/official/nlp/modeling/networks/albert_encoder_test.py (deflated 71%)\n","  adding: content/models-master/official/nlp/modeling/networks/packed_sequence_embedding.py (deflated 71%)\n","  adding: content/models-master/official/nlp/modeling/networks/encoder_scaffold.py (deflated 71%)\n","  adding: content/models-master/official/nlp/modeling/networks/encoder_scaffold_test.py (deflated 86%)\n","  adding: content/models-master/official/nlp/modeling/networks/packed_sequence_embedding_test.py (deflated 68%)\n","  adding: content/models-master/official/nlp/modeling/networks/bert_encoder.py (deflated 65%)\n","  adding: content/models-master/official/nlp/modeling/networks/README.md (deflated 54%)\n","  adding: content/models-master/official/nlp/modeling/networks/mobile_bert_encoder.py (deflated 69%)\n","  adding: content/models-master/official/nlp/modeling/networks/classification.py (deflated 57%)\n","  adding: content/models-master/official/nlp/modeling/networks/classification_test.py (deflated 77%)\n","  adding: content/models-master/official/nlp/modeling/networks/span_labeling_test.py (deflated 81%)\n","  adding: content/models-master/official/nlp/modeling/networks/mobile_bert_encoder_test.py (deflated 77%)\n","  adding: content/models-master/official/nlp/modeling/networks/span_labeling.py (deflated 72%)\n","  adding: content/models-master/official/nlp/modeling/networks/albert_encoder.py (deflated 66%)\n","  adding: content/models-master/official/nlp/modeling/networks/bert_encoder_test.py (deflated 78%)\n","  adding: content/models-master/official/nlp/modeling/networks/xlnet_base.py (deflated 75%)\n","  adding: content/models-master/official/nlp/modeling/networks/__init__.py (deflated 58%)\n","  adding: content/models-master/official/nlp/xlnet/ (stored 0%)\n","  adding: content/models-master/official/nlp/xlnet/classifier_utils.py (deflated 64%)\n","  adding: content/models-master/official/nlp/xlnet/xlnet_modeling.py (deflated 80%)\n","  adding: content/models-master/official/nlp/xlnet/README.md (deflated 60%)\n","  adding: content/models-master/official/nlp/xlnet/optimization.py (deflated 65%)\n","  adding: content/models-master/official/nlp/xlnet/xlnet_config.py (deflated 64%)\n","  adding: content/models-master/official/nlp/xlnet/preprocess_utils.py (deflated 62%)\n","  adding: content/models-master/official/nlp/xlnet/run_squad.py (deflated 71%)\n","  adding: content/models-master/official/nlp/xlnet/squad_utils.py (deflated 73%)\n","  adding: content/models-master/official/nlp/xlnet/common_flags.py (deflated 67%)\n","  adding: content/models-master/official/nlp/xlnet/preprocess_squad_data.py (deflated 64%)\n","  adding: content/models-master/official/nlp/xlnet/training_utils.py (deflated 68%)\n","  adding: content/models-master/official/nlp/xlnet/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/xlnet/run_classifier.py (deflated 66%)\n","  adding: content/models-master/official/nlp/xlnet/preprocess_pretrain_data.py (deflated 73%)\n","  adding: content/models-master/official/nlp/xlnet/run_pretrain.py (deflated 67%)\n","  adding: content/models-master/official/nlp/xlnet/data_utils.py (deflated 76%)\n","  adding: content/models-master/official/nlp/xlnet/preprocess_classification_data.py (deflated 74%)\n","  adding: content/models-master/official/nlp/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/projects/ (stored 0%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/ (stored 0%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/sentencepiece_pb2.py (deflated 83%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/predict.py (deflated 65%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/preprocess.py (deflated 73%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/prediction.py (deflated 56%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/evaluation.py (deflated 69%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/evaluate.py (deflated 47%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/train.py (deflated 69%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/modeling.py (deflated 67%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/dataset.py (deflated 74%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/inputs.py (deflated 75%)\n","  adding: content/models-master/official/nlp/projects/triviaqa/download_and_prepare.py (deflated 53%)\n","  adding: content/models-master/official/nlp/projects/bigbird/ (stored 0%)\n","  adding: content/models-master/official/nlp/projects/bigbird/encoder.py (deflated 69%)\n","  adding: content/models-master/official/nlp/projects/bigbird/attention.py (deflated 79%)\n","  adding: content/models-master/official/nlp/projects/bigbird/attention_test.py (deflated 59%)\n","  adding: content/models-master/official/nlp/projects/bigbird/__init__.py (stored 0%)\n","  adding: content/models-master/official/nlp/projects/bigbird/encoder_test.py (deflated 63%)\n","  adding: content/models-master/official/nlp/projects/__init__.py (stored 0%)\n","  adding: content/models-master/official/common/ (stored 0%)\n","  adding: content/models-master/official/common/flags.py (deflated 61%)\n","  adding: content/models-master/official/common/registry_imports.py (deflated 46%)\n","  adding: content/models-master/official/common/__init__.py (stored 0%)\n","  adding: content/models-master/official/common/distribute_utils_test.py (deflated 61%)\n","  adding: content/models-master/official/common/distribute_utils.py (deflated 69%)\n","  adding: content/models-master/official/colab/ (stored 0%)\n","  adding: content/models-master/official/colab/nlp/ (stored 0%)\n","  adding: content/models-master/official/colab/nlp/customize_encoder.ipynb (deflated 80%)\n","  adding: content/models-master/official/colab/nlp/nlp_modeling_library_intro.ipynb (deflated 81%)\n","  adding: content/models-master/official/colab/fine_tuning_bert.ipynb (deflated 81%)\n","  adding: content/models-master/official/utils/ (stored 0%)\n","  adding: content/models-master/official/utils/misc/ (stored 0%)\n","  adding: content/models-master/official/utils/misc/model_helpers_test.py (deflated 71%)\n","  adding: content/models-master/official/utils/misc/keras_utils.py (deflated 68%)\n","  adding: content/models-master/official/utils/misc/callstack_sampler.py (deflated 61%)\n","  adding: content/models-master/official/utils/misc/distribution_utils.py (deflated 44%)\n","  adding: content/models-master/official/utils/misc/model_helpers.py (deflated 61%)\n","  adding: content/models-master/official/utils/misc/__init__.py (stored 0%)\n","  adding: content/models-master/official/utils/testing/ (stored 0%)\n","  adding: content/models-master/official/utils/testing/scripts/ (stored 0%)\n","  adding: content/models-master/official/utils/testing/scripts/builds_common.sh (deflated 49%)\n","  adding: content/models-master/official/utils/testing/scripts/presubmit.sh (deflated 51%)\n","  adding: content/models-master/official/utils/testing/scripts/ci_sanity.sh (deflated 57%)\n","  adding: content/models-master/official/utils/testing/__init__.py (stored 0%)\n","  adding: content/models-master/official/utils/testing/integration.py (deflated 56%)\n","  adding: content/models-master/official/utils/testing/pylint.rcfile (deflated 60%)\n","  adding: content/models-master/official/utils/testing/mock_task.py (deflated 58%)\n","  adding: content/models-master/official/utils/flags/ (stored 0%)\n","  adding: content/models-master/official/utils/flags/_base.py (deflated 68%)\n","  adding: content/models-master/official/utils/flags/_conventions.py (deflated 48%)\n","  adding: content/models-master/official/utils/flags/_benchmark.py (deflated 67%)\n","  adding: content/models-master/official/utils/flags/README.md (deflated 57%)\n","  adding: content/models-master/official/utils/flags/flags_test.py (deflated 72%)\n","  adding: content/models-master/official/utils/flags/_device.py (deflated 57%)\n","  adding: content/models-master/official/utils/flags/__init__.py (stored 0%)\n","  adding: content/models-master/official/utils/flags/_performance.py (deflated 71%)\n","  adding: content/models-master/official/utils/flags/guidelines.md (deflated 55%)\n","  adding: content/models-master/official/utils/flags/_misc.py (deflated 50%)\n","  adding: content/models-master/official/utils/flags/_distribution.py (deflated 54%)\n","  adding: content/models-master/official/utils/flags/core.py (deflated 62%)\n","  adding: content/models-master/official/utils/__init__.py (stored 0%)\n","  adding: content/models-master/official/utils/hyperparams_flags.py (deflated 65%)\n","  adding: content/models-master/official/modeling/ (stored 0%)\n","  adding: content/models-master/official/modeling/hyperparams/ (stored 0%)\n","  adding: content/models-master/official/modeling/hyperparams/base_config_test.py (deflated 75%)\n","  adding: content/models-master/official/modeling/hyperparams/params_dict_test.py (deflated 82%)\n","  adding: content/models-master/official/modeling/hyperparams/oneof.py (deflated 56%)\n","  adding: content/models-master/official/modeling/hyperparams/config_definitions.py (deflated 59%)\n","  adding: content/models-master/official/modeling/hyperparams/params_dict.py (deflated 71%)\n","  adding: content/models-master/official/modeling/hyperparams/base_config.py (deflated 68%)\n","  adding: content/models-master/official/modeling/hyperparams/__init__.py (deflated 47%)\n","  adding: content/models-master/official/modeling/hyperparams/oneof_test.py (deflated 58%)\n","  adding: content/models-master/official/modeling/activations/ (stored 0%)\n","  adding: content/models-master/official/modeling/activations/relu.py (deflated 45%)\n","  adding: content/models-master/official/modeling/activations/swish_test.py (deflated 54%)\n","  adding: content/models-master/official/modeling/activations/gelu.py (deflated 44%)\n","  adding: content/models-master/official/modeling/activations/gelu_test.py (deflated 44%)\n","  adding: content/models-master/official/modeling/activations/sigmoid_test.py (deflated 48%)\n","  adding: content/models-master/official/modeling/activations/relu_test.py (deflated 47%)\n","  adding: content/models-master/official/modeling/activations/sigmoid.py (deflated 45%)\n","  adding: content/models-master/official/modeling/activations/__init__.py (deflated 54%)\n","  adding: content/models-master/official/modeling/activations/swish.py (deflated 60%)\n","  adding: content/models-master/official/modeling/performance.py (deflated 66%)\n","  adding: content/models-master/official/modeling/__init__.py (stored 0%)\n","  adding: content/models-master/official/modeling/optimization/ (stored 0%)\n","  adding: content/models-master/official/modeling/optimization/lr_schedule.py (deflated 79%)\n","  adding: content/models-master/official/modeling/optimization/optimizer_factory.py (deflated 67%)\n","  adding: content/models-master/official/modeling/optimization/configs/ (stored 0%)\n","  adding: content/models-master/official/modeling/optimization/configs/learning_rate_config.py (deflated 76%)\n","  adding: content/models-master/official/modeling/optimization/configs/optimizer_config.py (deflated 73%)\n","  adding: content/models-master/official/modeling/optimization/configs/__init__.py (stored 0%)\n","  adding: content/models-master/official/modeling/optimization/configs/optimization_config.py (deflated 69%)\n","  adding: content/models-master/official/modeling/optimization/configs/optimization_config_test.py (deflated 62%)\n","  adding: content/models-master/official/modeling/optimization/optimizer_factory_test.py (deflated 84%)\n","  adding: content/models-master/official/modeling/optimization/__init__.py (deflated 62%)\n","  adding: content/models-master/official/modeling/optimization/ema_optimizer.py (deflated 68%)\n","  adding: content/models-master/official/modeling/tf_utils.py (deflated 64%)\n","  adding: content/models-master/official/LICENSE (deflated 65%)\n","  adding: content/models-master/official/__init__.py (stored 0%)\n","  adding: content/models-master/official/staging/ (stored 0%)\n","  adding: content/models-master/official/staging/training/ (stored 0%)\n","  adding: content/models-master/official/staging/training/__init__.py (deflated 43%)\n","  adding: content/models-master/official/staging/training/grad_utils.py (deflated 70%)\n","  adding: content/models-master/official/staging/__init__.py (stored 0%)\n","  adding: content/models-master/official/pip_package/ (stored 0%)\n","  adding: content/models-master/official/pip_package/setup.py (deflated 57%)\n","  adding: content/models-master/.github/ (stored 0%)\n","  adding: content/models-master/.github/PULL_REQUEST_TEMPLATE.md (deflated 55%)\n","  adding: content/models-master/.github/bot_config.yml (deflated 43%)\n","  adding: content/models-master/.github/stale.yml (deflated 51%)\n","  adding: content/models-master/.github/README_TEMPLATE.md (deflated 60%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/ (stored 0%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/40-research-documentation-issue.md (deflated 38%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/config.yml (stored 0%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/00-official-bug-report-issue.md (deflated 50%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/20-official-feature-request-issue.md (deflated 40%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/30-research-bug-report-issue.md (deflated 50%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/60-questions-help-issue.md (deflated 38%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/50-research-feature-request-issue.md (deflated 40%)\n","  adding: content/models-master/.github/ISSUE_TEMPLATE/10-official-documentation-issue.md (deflated 37%)\n","  adding: content/models-master/README.md (deflated 59%)\n","  adding: content/models-master/CODEOWNERS (deflated 52%)\n","  adding: content/models-master/community/ (stored 0%)\n","  adding: content/models-master/community/README.md (deflated 77%)\n","  adding: content/models-master/research/ (stored 0%)\n","  adding: content/models-master/research/cvt_text/ (stored 0%)\n","  adding: content/models-master/research/cvt_text/cvt.py (deflated 57%)\n","  adding: content/models-master/research/cvt_text/training/ (stored 0%)\n","  adding: content/models-master/research/cvt_text/training/training_progress.py (deflated 61%)\n","  adding: content/models-master/research/cvt_text/training/__init__.py (stored 0%)\n","  adding: content/models-master/research/cvt_text/training/trainer.py (deflated 66%)\n","  adding: content/models-master/research/cvt_text/preprocessing.py (deflated 60%)\n","  adding: content/models-master/research/cvt_text/README.md (deflated 50%)\n","  adding: content/models-master/research/cvt_text/base/ (stored 0%)\n","  adding: content/models-master/research/cvt_text/base/configure.py (deflated 63%)\n","  adding: content/models-master/research/cvt_text/base/embeddings.py (deflated 60%)\n","  adding: content/models-master/research/cvt_text/base/__init__.py (stored 0%)\n","  adding: content/models-master/research/cvt_text/base/utils.py (deflated 52%)\n","  adding: content/models-master/research/cvt_text/model/ (stored 0%)\n","  adding: content/models-master/research/cvt_text/model/shared_inputs.py (deflated 59%)\n","  adding: content/models-master/research/cvt_text/model/encoder.py (deflated 72%)\n","  adding: content/models-master/research/cvt_text/model/multitask_model.py (deflated 68%)\n","  adding: content/models-master/research/cvt_text/model/task_module.py (deflated 53%)\n","  adding: content/models-master/research/cvt_text/model/model_helpers.py (deflated 56%)\n","  adding: content/models-master/research/cvt_text/model/__init__.py (stored 0%)\n","  adding: content/models-master/research/cvt_text/task_specific/ (stored 0%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/ (stored 0%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/tagging_scorers.py (deflated 64%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/word_level_scorer.py (deflated 55%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/word_level_data.py (deflated 66%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/tagging_utils.py (deflated 56%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/depparse_module.py (deflated 67%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/tagging_module.py (deflated 61%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/depparse_scorer.py (deflated 55%)\n","  adding: content/models-master/research/cvt_text/task_specific/word_level/__init__.py (stored 0%)\n","  adding: content/models-master/research/cvt_text/task_specific/task_definitions.py (deflated 64%)\n","  adding: content/models-master/research/cvt_text/task_specific/__init__.py (stored 0%)\n","  adding: content/models-master/research/cvt_text/corpus_processing/ (stored 0%)\n","  adding: content/models-master/research/cvt_text/corpus_processing/minibatching.py (deflated 63%)\n","  adding: content/models-master/research/cvt_text/corpus_processing/scorer.py (deflated 54%)\n","  adding: content/models-master/research/cvt_text/corpus_processing/__init__.py (stored 0%)\n","  adding: content/models-master/research/cvt_text/corpus_processing/example.py (deflated 56%)\n","  adding: content/models-master/research/cvt_text/corpus_processing/unlabeled_data.py (deflated 59%)\n","  adding: content/models-master/research/cvt_text/__init__.py (stored 0%)\n","  adding: content/models-master/research/cvt_text/fetch_data.sh (deflated 55%)\n","  adding: content/models-master/research/autoaugment/ (stored 0%)\n","  adding: content/models-master/research/autoaugment/shake_shake.py (deflated 64%)\n","  adding: content/models-master/research/autoaugment/README.md (deflated 57%)\n","  adding: content/models-master/research/autoaugment/train_cifar.py (deflated 70%)\n","  adding: content/models-master/research/autoaugment/wrn.py (deflated 66%)\n","  adding: content/models-master/research/autoaugment/shake_drop.py (deflated 68%)\n","  adding: content/models-master/research/autoaugment/custom_ops.py (deflated 66%)\n","  adding: content/models-master/research/autoaugment/policies.py (deflated 77%)\n","  adding: content/models-master/research/autoaugment/augmentation_transforms.py (deflated 71%)\n","  adding: content/models-master/research/autoaugment/data_utils.py (deflated 68%)\n","  adding: content/models-master/research/autoaugment/helper_utils.py (deflated 65%)\n","  adding: content/models-master/research/object_detection.egg-info/ (stored 0%)\n","  adding: content/models-master/research/object_detection.egg-info/top_level.txt (stored 0%)\n","  adding: content/models-master/research/object_detection.egg-info/dependency_links.txt (stored 0%)\n","  adding: content/models-master/research/object_detection.egg-info/requires.txt (stored 0%)\n","  adding: content/models-master/research/object_detection.egg-info/SOURCES.txt (deflated 89%)\n","  adding: content/models-master/research/object_detection.egg-info/PKG-INFO (deflated 34%)\n","  adding: content/models-master/research/marco/ (stored 0%)\n","  adding: content/models-master/research/marco/jpeg2json.py (deflated 41%)\n","  adding: content/models-master/research/marco/README.md (deflated 55%)\n","  adding: content/models-master/research/marco/Automated_Marco.py (deflated 55%)\n","  adding: content/models-master/research/marco/request.json (deflated 25%)\n","  adding: content/models-master/research/rebar/ (stored 0%)\n","  adding: content/models-master/research/rebar/rebar_train.py (deflated 65%)\n","  adding: content/models-master/research/rebar/rebar.py (deflated 81%)\n","  adding: content/models-master/research/rebar/README.md (deflated 57%)\n","  adding: content/models-master/research/rebar/download_data.py (deflated 60%)\n","  adding: content/models-master/research/rebar/config.py (deflated 45%)\n","  adding: content/models-master/research/rebar/logger.py (deflated 47%)\n","  adding: content/models-master/research/rebar/datasets.py (deflated 60%)\n","  adding: content/models-master/research/rebar/utils.py (deflated 57%)\n","  adding: content/models-master/research/README.md (deflated 63%)\n","  adding: content/models-master/research/attention_ocr/ (stored 0%)\n","  adding: content/models-master/research/attention_ocr/README.md (deflated 63%)\n","  adding: content/models-master/research/attention_ocr/python/ (stored 0%)\n","  adding: content/models-master/research/attention_ocr/python/data_provider_test.py (deflated 60%)\n","  adding: content/models-master/research/attention_ocr/python/demo_inference.py (deflated 60%)\n","  adding: content/models-master/research/attention_ocr/python/all_jobs.screenrc (deflated 55%)\n","  adding: content/models-master/research/attention_ocr/python/sequence_layers.py (deflated 72%)\n","  adding: content/models-master/research/attention_ocr/python/model_export_lib.py (deflated 61%)\n","  adding: content/models-master/research/attention_ocr/python/metrics_test.py (deflated 66%)\n","  adding: content/models-master/research/attention_ocr/python/train.py (deflated 66%)\n","  adding: content/models-master/research/attention_ocr/python/model_export.py (deflated 63%)\n","  adding: content/models-master/research/attention_ocr/python/model_export_test.py (deflated 64%)\n","  adding: content/models-master/research/attention_ocr/python/common_flags.py (deflated 64%)\n","  adding: content/models-master/research/attention_ocr/python/model.py (deflated 71%)\n","  adding: content/models-master/research/attention_ocr/python/demo_inference_test.py (deflated 74%)\n","  adding: content/models-master/research/attention_ocr/python/metrics.py (deflated 69%)\n","  adding: content/models-master/research/attention_ocr/python/inception_preprocessing.py (deflated 72%)\n","  adding: content/models-master/research/attention_ocr/python/eval.py (deflated 56%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/ (stored 0%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/unittest_utils_test.py (deflated 55%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/fsns_test.py (deflated 59%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/unittest_utils.py (deflated 52%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/__init__.py (deflated 44%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/testdata/ (stored 0%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/testdata/fsns/ (stored 0%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/testdata/fsns/download_data.py (deflated 46%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/testdata/fsns/links.txt (deflated 15%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/testdata/fsns/fsns-00000-of-00001 (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/testdata/fsns/charset_size=134.txt (deflated 33%)\n","  adding: content/models-master/research/attention_ocr/python/datasets/fsns.py (deflated 63%)\n","  adding: content/models-master/research/attention_ocr/python/data_provider.py (deflated 65%)\n","  adding: content/models-master/research/attention_ocr/python/sequence_layers_test.py (deflated 71%)\n","  adding: content/models-master/research/attention_ocr/python/model_test.py (deflated 75%)\n","  adding: content/models-master/research/attention_ocr/python/utils.py (deflated 56%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/ (stored 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_25.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_19.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_08.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_13.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_06.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_04.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_20.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_30.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_24.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_26.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_11.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_03.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_02.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_14.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_27.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_21.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_07.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_22.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_28.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_15.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_29.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_01.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_17.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_18.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_16.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_10.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_00.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_31.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_12.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_05.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_09.png (deflated 0%)\n","  adding: content/models-master/research/attention_ocr/python/testdata/fsns_train_23.png (deflated 0%)\n","  adding: content/models-master/research/pcl_rl/ (stored 0%)\n","  adding: content/models-master/research/pcl_rl/objective.py (deflated 81%)\n","  adding: content/models-master/research/pcl_rl/policy.py (deflated 78%)\n","  adding: content/models-master/research/pcl_rl/expert_paths.py (deflated 71%)\n","  adding: content/models-master/research/pcl_rl/README.md (deflated 64%)\n","  adding: content/models-master/research/pcl_rl/baseline.py (deflated 73%)\n","  adding: content/models-master/research/pcl_rl/env_spec.py (deflated 71%)\n","  adding: content/models-master/research/pcl_rl/gym_wrapper.py (deflated 62%)\n","  adding: content/models-master/research/pcl_rl/optimizers.py (deflated 72%)\n","  adding: content/models-master/research/pcl_rl/full_episode_objective.py (deflated 61%)\n","  adding: content/models-master/research/pcl_rl/model.py (deflated 78%)\n","  adding: content/models-master/research/pcl_rl/trust_region.py (deflated 65%)\n","  adding: content/models-master/research/pcl_rl/controller.py (deflated 74%)\n","  adding: content/models-master/research/pcl_rl/trainer.py (deflated 73%)\n","  adding: content/models-master/research/pcl_rl/replay_buffer.py (deflated 70%)\n","  adding: content/models-master/research/slim/ (stored 0%)\n","  adding: content/models-master/research/slim/export_inference_graph_test.py (deflated 49%)\n","  adding: content/models-master/research/slim/WORKSPACE (stored 0%)\n","  adding: content/models-master/research/slim/download_and_convert_data.py (deflated 64%)\n","  adding: content/models-master/research/slim/scripts/ (stored 0%)\n","  adding: content/models-master/research/slim/scripts/finetune_inception_resnet_v2_on_flowers.sh (deflated 68%)\n","  adding: content/models-master/research/slim/scripts/train_lenet_on_mnist.sh (deflated 54%)\n","  adding: content/models-master/research/slim/scripts/train_cifarnet_on_cifar10.sh (deflated 55%)\n","  adding: content/models-master/research/slim/scripts/finetune_resnet_v1_50_on_flowers.sh (deflated 67%)\n","  adding: content/models-master/research/slim/scripts/finetune_inception_v1_on_flowers.sh (deflated 67%)\n","  adding: content/models-master/research/slim/scripts/finetune_inception_v3_on_flowers.sh (deflated 67%)\n","  adding: content/models-master/research/slim/scripts/export_mobilenet.sh (deflated 63%)\n","  adding: content/models-master/research/slim/README.md (deflated 70%)\n","  adding: content/models-master/research/slim/slim_walkthrough.ipynb (deflated 78%)\n","  adding: content/models-master/research/slim/nets/ (stored 0%)\n","  adding: content/models-master/research/slim/nets/i3d_test.py (deflated 74%)\n","  adding: content/models-master/research/slim/nets/nasnet/ (stored 0%)\n","  adding: content/models-master/research/slim/nets/nasnet/pnasnet_test.py (deflated 83%)\n","  adding: content/models-master/research/slim/nets/nasnet/nasnet_test.py (deflated 87%)\n","  adding: content/models-master/research/slim/nets/nasnet/README.md (deflated 61%)\n","  adding: content/models-master/research/slim/nets/nasnet/nasnet.py (deflated 81%)\n","  adding: content/models-master/research/slim/nets/nasnet/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/slim/nets/nasnet/__pycache__/nasnet_utils.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/slim/nets/nasnet/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n","  adding: content/models-master/research/slim/nets/nasnet/__pycache__/pnasnet.cpython-36.pyc (deflated 50%)\n","  adding: content/models-master/research/slim/nets/nasnet/__pycache__/nasnet.cpython-36.pyc (deflated 59%)\n","  adding: content/models-master/research/slim/nets/nasnet/pnasnet.py (deflated 75%)\n","  adding: content/models-master/research/slim/nets/nasnet/nasnet_utils_test.py (deflated 61%)\n","  adding: content/models-master/research/slim/nets/nasnet/__init__.py (stored 0%)\n","  adding: content/models-master/research/slim/nets/nasnet/nasnet_utils.py (deflated 74%)\n","  adding: content/models-master/research/slim/nets/mobilenet_v1_test.py (deflated 88%)\n","  adding: content/models-master/research/slim/nets/mobilenet_v1.png (deflated 2%)\n","  adding: content/models-master/research/slim/nets/mobilenet_v1.py (deflated 74%)\n","  adding: content/models-master/research/slim/nets/inception.py (deflated 65%)\n","  adding: content/models-master/research/slim/nets/post_training_quantization.py (deflated 63%)\n","  adding: content/models-master/research/slim/nets/inception_utils.py (deflated 59%)\n","  adding: content/models-master/research/slim/nets/alexnet.py (deflated 63%)\n","  adding: content/models-master/research/slim/nets/mobilenet_v1_train.py (deflated 65%)\n","  adding: content/models-master/research/slim/nets/dcgan.py (deflated 70%)\n","  adding: content/models-master/research/slim/nets/vgg_test.py (deflated 91%)\n","  adding: content/models-master/research/slim/nets/s3dg_test.py (deflated 74%)\n","  adding: content/models-master/research/slim/nets/mobilenet_v1.md (deflated 74%)\n","  adding: content/models-master/research/slim/nets/inception_v1_test.py (deflated 80%)\n","  adding: content/models-master/research/slim/nets/mobilenet_v1_eval.py (deflated 62%)\n","  adding: content/models-master/research/slim/nets/resnet_v2.py (deflated 73%)\n","  adding: content/models-master/research/slim/nets/overfeat_test.py (deflated 80%)\n","  adding: content/models-master/research/slim/nets/inception_v3.py (deflated 84%)\n","  adding: content/models-master/research/slim/nets/s3dg.py (deflated 80%)\n","  adding: content/models-master/research/slim/nets/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/slim/nets/__pycache__/inception_v3.cpython-36.pyc (deflated 67%)\n","  adding: content/models-master/research/slim/nets/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n","  adding: content/models-master/research/slim/nets/__pycache__/inception_v2.cpython-36.pyc (deflated 66%)\n","  adding: content/models-master/research/slim/nets/__pycache__/inception_utils.cpython-36.pyc (deflated 45%)\n","  adding: content/models-master/research/slim/nets/__pycache__/resnet_v1.cpython-36.pyc (deflated 60%)\n","  adding: content/models-master/research/slim/nets/__pycache__/resnet_utils.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/slim/nets/__pycache__/mobilenet_v1.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/slim/nets/__pycache__/inception_resnet_v2.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/slim/nets/inception_v2.py (deflated 83%)\n","  adding: content/models-master/research/slim/nets/i3d_utils.py (deflated 72%)\n","  adding: content/models-master/research/slim/nets/cifarnet.py (deflated 61%)\n","  adding: content/models-master/research/slim/nets/i3d.py (deflated 62%)\n","  adding: content/models-master/research/slim/nets/inception_resnet_v2.py (deflated 77%)\n","  adding: content/models-master/research/slim/nets/alexnet_test.py (deflated 80%)\n","  adding: content/models-master/research/slim/nets/pix2pix_test.py (deflated 76%)\n","  adding: content/models-master/research/slim/nets/pix2pix.py (deflated 66%)\n","  adding: content/models-master/research/slim/nets/inception_v2_test.py (deflated 82%)\n","  adding: content/models-master/research/slim/nets/inception_v1.py (deflated 83%)\n","  adding: content/models-master/research/slim/nets/overfeat.py (deflated 65%)\n","  adding: content/models-master/research/slim/nets/inception_resnet_v2_test.py (deflated 84%)\n","  adding: content/models-master/research/slim/nets/nets_factory_test.py (deflated 72%)\n","  adding: content/models-master/research/slim/nets/vgg.py (deflated 82%)\n","  adding: content/models-master/research/slim/nets/inception_v4_test.py (deflated 82%)\n","  adding: content/models-master/research/slim/nets/resnet_utils.py (deflated 65%)\n","  adding: content/models-master/research/slim/nets/cyclegan_test.py (deflated 71%)\n","  adding: content/models-master/research/slim/nets/inception_v4.py (deflated 81%)\n","  adding: content/models-master/research/slim/nets/dcgan_test.py (deflated 67%)\n","  adding: content/models-master/research/slim/nets/lenet.py (deflated 58%)\n","  adding: content/models-master/research/slim/nets/cyclegan.py (deflated 68%)\n","  adding: content/models-master/research/slim/nets/resnet_v1.py (deflated 74%)\n","  adding: content/models-master/research/slim/nets/__init__.py (stored 0%)\n","  adding: content/models-master/research/slim/nets/nets_factory.py (deflated 72%)\n","  adding: content/models-master/research/slim/nets/resnet_v1_test.py (deflated 83%)\n","  adding: content/models-master/research/slim/nets/inception_v3_test.py (deflated 82%)\n","  adding: content/models-master/research/slim/nets/resnet_v2_test.py (deflated 81%)\n","  adding: content/models-master/research/slim/nets/mobilenet/ (stored 0%)\n","  adding: content/models-master/research/slim/nets/mobilenet/mobilenet.py (deflated 66%)\n","  adding: content/models-master/research/slim/nets/mobilenet/mobilenet_example.ipynb (deflated 28%)\n","  adding: content/models-master/research/slim/nets/mobilenet/README.md (deflated 76%)\n","  adding: content/models-master/research/slim/nets/mobilenet/mnet_v1_vs_v2_pixel1_latency.png (deflated 10%)\n","  adding: content/models-master/research/slim/nets/mobilenet/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/slim/nets/mobilenet/__pycache__/conv_blocks.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/slim/nets/mobilenet/__pycache__/__init__.cpython-36.pyc (deflated 21%)\n","  adding: content/models-master/research/slim/nets/mobilenet/__pycache__/mobilenet.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/slim/nets/mobilenet/__pycache__/mobilenet_v2.cpython-36.pyc (deflated 49%)\n","  adding: content/models-master/research/slim/nets/mobilenet/__pycache__/mobilenet_v3.cpython-36.pyc (deflated 86%)\n","  adding: content/models-master/research/slim/nets/mobilenet/mobilenet_v3.py (deflated 88%)\n","  adding: content/models-master/research/slim/nets/mobilenet/conv_blocks.py (deflated 71%)\n","  adding: content/models-master/research/slim/nets/mobilenet/mobilenet_v2_test.py (deflated 72%)\n","  adding: content/models-master/research/slim/nets/mobilenet/mobilenet_v2.py (deflated 68%)\n","  adding: content/models-master/research/slim/nets/mobilenet/g3doc/ (stored 0%)\n","  adding: content/models-master/research/slim/nets/mobilenet/g3doc/madds_top1_accuracy.png (deflated 2%)\n","  adding: content/models-master/research/slim/nets/mobilenet/g3doc/latency_pixel1.png (deflated 1%)\n","  adding: content/models-master/research/slim/nets/mobilenet/g3doc/edgetpu_latency.png (deflated 8%)\n","  adding: content/models-master/research/slim/nets/mobilenet/__init__.py (stored 0%)\n","  adding: content/models-master/research/slim/nets/mobilenet/mobilenet_v3_test.py (deflated 76%)\n","  adding: content/models-master/research/slim/BUILD (deflated 91%)\n","  adding: content/models-master/research/slim/eval_image_classifier.py (deflated 66%)\n","  adding: content/models-master/research/slim/deployment/ (stored 0%)\n","  adding: content/models-master/research/slim/deployment/model_deploy.py (deflated 74%)\n","  adding: content/models-master/research/slim/deployment/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/slim/deployment/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n","  adding: content/models-master/research/slim/deployment/__pycache__/model_deploy.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/slim/deployment/__init__.py (stored 0%)\n","  adding: content/models-master/research/slim/deployment/model_deploy_test.py (deflated 88%)\n","  adding: content/models-master/research/slim/preprocessing/ (stored 0%)\n","  adding: content/models-master/research/slim/preprocessing/lenet_preprocessing.py (deflated 55%)\n","  adding: content/models-master/research/slim/preprocessing/preprocessing_factory.py (deflated 70%)\n","  adding: content/models-master/research/slim/preprocessing/vgg_preprocessing.py (deflated 73%)\n","  adding: content/models-master/research/slim/preprocessing/cifarnet_preprocessing.py (deflated 73%)\n","  adding: content/models-master/research/slim/preprocessing/inception_preprocessing.py (deflated 74%)\n","  adding: content/models-master/research/slim/preprocessing/__init__.py (stored 0%)\n","  adding: content/models-master/research/slim/train_image_classifier.py (deflated 73%)\n","  adding: content/models-master/research/slim/setup.py (deflated 47%)\n","  adding: content/models-master/research/slim/__init__.py (stored 0%)\n","  adding: content/models-master/research/slim/datasets/ (stored 0%)\n","  adding: content/models-master/research/slim/datasets/download_and_convert_cifar10.py (deflated 63%)\n","  adding: content/models-master/research/slim/datasets/download_and_convert_visualwakewords_lib.py (deflated 72%)\n","  adding: content/models-master/research/slim/datasets/dataset_utils.py (deflated 68%)\n","  adding: content/models-master/research/slim/datasets/download_and_convert_flowers.py (deflated 64%)\n","  adding: content/models-master/research/slim/datasets/imagenet_lsvrc_2015_synsets.txt (deflated 62%)\n","  adding: content/models-master/research/slim/datasets/download_imagenet.sh (deflated 59%)\n","  adding: content/models-master/research/slim/datasets/preprocess_imagenet_validation_data.py (deflated 56%)\n","  adding: content/models-master/research/slim/datasets/mnist.py (deflated 56%)\n","  adding: content/models-master/research/slim/datasets/visualwakewords.py (deflated 60%)\n","  adding: content/models-master/research/slim/datasets/imagenet_metadata.txt (deflated 60%)\n","  adding: content/models-master/research/slim/datasets/imagenet_2012_validation_synset_labels.txt (deflated 76%)\n","  adding: content/models-master/research/slim/datasets/process_bounding_boxes.py (deflated 63%)\n","  adding: content/models-master/research/slim/datasets/flowers.py (deflated 56%)\n","  adding: content/models-master/research/slim/datasets/download_and_convert_mnist.py (deflated 67%)\n","  adding: content/models-master/research/slim/datasets/download_and_convert_imagenet.sh (deflated 60%)\n","  adding: content/models-master/research/slim/datasets/dataset_factory.py (deflated 54%)\n","  adding: content/models-master/research/slim/datasets/build_imagenet_data.py (deflated 73%)\n","  adding: content/models-master/research/slim/datasets/__init__.py (stored 0%)\n","  adding: content/models-master/research/slim/datasets/cifar10.py (deflated 56%)\n","  adding: content/models-master/research/slim/datasets/download_and_convert_visualwakewords.py (deflated 67%)\n","  adding: content/models-master/research/slim/datasets/imagenet.py (deflated 61%)\n","  adding: content/models-master/research/slim/export_inference_graph.py (deflated 63%)\n","  adding: content/models-master/research/vid2depth/ (stored 0%)\n","  adding: content/models-master/research/vid2depth/inference.py (deflated 64%)\n","  adding: content/models-master/research/vid2depth/WORKSPACE (deflated 64%)\n","  adding: content/models-master/research/vid2depth/project.py (deflated 68%)\n","  adding: content/models-master/research/vid2depth/README.md (deflated 64%)\n","  adding: content/models-master/research/vid2depth/BUILD (deflated 11%)\n","  adding: content/models-master/research/vid2depth/train.py (deflated 65%)\n","  adding: content/models-master/research/vid2depth/dataset/ (stored 0%)\n","  adding: content/models-master/research/vid2depth/dataset/gen_data.py (deflated 67%)\n","  adding: content/models-master/research/vid2depth/dataset/__init__.py (deflated 43%)\n","  adding: content/models-master/research/vid2depth/dataset/kitti/ (stored 0%)\n","  adding: content/models-master/research/vid2depth/dataset/kitti/static_frames.txt (deflated 94%)\n","  adding: content/models-master/research/vid2depth/dataset/kitti/test_files_stereo.txt (deflated 92%)\n","  adding: content/models-master/research/vid2depth/dataset/kitti/test_scenes_stereo.txt (deflated 83%)\n","  adding: content/models-master/research/vid2depth/dataset/kitti/test_files_eigen.txt (deflated 94%)\n","  adding: content/models-master/research/vid2depth/dataset/kitti/test_scenes_eigen.txt (deflated 81%)\n","  adding: content/models-master/research/vid2depth/dataset/dataset_loader.py (deflated 78%)\n","  adding: content/models-master/research/vid2depth/ops/ (stored 0%)\n","  adding: content/models-master/research/vid2depth/ops/icp_op.py (deflated 46%)\n","  adding: content/models-master/research/vid2depth/ops/icp_test.py (deflated 80%)\n","  adding: content/models-master/research/vid2depth/ops/icp_grad_test.py (deflated 72%)\n","  adding: content/models-master/research/vid2depth/ops/icp_train_demo.py (deflated 64%)\n","  adding: content/models-master/research/vid2depth/ops/BUILD (deflated 78%)\n","  adding: content/models-master/research/vid2depth/ops/icp_util.py (deflated 71%)\n","  adding: content/models-master/research/vid2depth/ops/pcl_demo.cc (deflated 70%)\n","  adding: content/models-master/research/vid2depth/ops/icp_op_kernel.cc (deflated 72%)\n","  adding: content/models-master/research/vid2depth/ops/icp_grad.py (deflated 53%)\n","  adding: content/models-master/research/vid2depth/ops/__init__.py (deflated 43%)\n","  adding: content/models-master/research/vid2depth/ops/testdata/ (stored 0%)\n","  adding: content/models-master/research/vid2depth/ops/testdata/pointcloud.npy (deflated 23%)\n","  adding: content/models-master/research/vid2depth/nets.py (deflated 72%)\n","  adding: content/models-master/research/vid2depth/repo.bzl (deflated 57%)\n","  adding: content/models-master/research/vid2depth/model.py (deflated 74%)\n","  adding: content/models-master/research/vid2depth/third_party/ (stored 0%)\n","  adding: content/models-master/research/vid2depth/third_party/hdf5.BUILD (deflated 66%)\n","  adding: content/models-master/research/vid2depth/third_party/BUILD (stored 0%)\n","  adding: content/models-master/research/vid2depth/third_party/eigen.BUILD (deflated 43%)\n","  adding: content/models-master/research/vid2depth/third_party/pcl.BUILD (deflated 80%)\n","  adding: content/models-master/research/vid2depth/third_party/flann.BUILD (deflated 70%)\n","  adding: content/models-master/research/vid2depth/.bazelrc (deflated 31%)\n","  adding: content/models-master/research/vid2depth/util.py (deflated 58%)\n","  adding: content/models-master/research/vid2depth/reader.py (deflated 70%)\n","  adding: content/models-master/research/audioset/ (stored 0%)\n","  adding: content/models-master/research/audioset/vggish/ (stored 0%)\n","  adding: content/models-master/research/audioset/vggish/vggish_params.py (deflated 49%)\n","  adding: content/models-master/research/audioset/vggish/vggish_export_tfhub.py (deflated 60%)\n","  adding: content/models-master/research/audioset/vggish/README.md (deflated 59%)\n","  adding: content/models-master/research/audioset/vggish/vggish_slim.py (deflated 60%)\n","  adding: content/models-master/research/audioset/vggish/vggish_postprocess.py (deflated 60%)\n","  adding: content/models-master/research/audioset/vggish/vggish_inference_demo.py (deflated 62%)\n","  adding: content/models-master/research/audioset/vggish/mel_features.py (deflated 64%)\n","  adding: content/models-master/research/audioset/vggish/vggish_train_demo.py (deflated 60%)\n","  adding: content/models-master/research/audioset/vggish/vggish_input.py (deflated 58%)\n","  adding: content/models-master/research/audioset/vggish/vggish_smoke_test.py (deflated 56%)\n","  adding: content/models-master/research/audioset/README.md (deflated 55%)\n","  adding: content/models-master/research/audioset/yamnet/ (stored 0%)\n","  adding: content/models-master/research/audioset/yamnet/inference.py (deflated 51%)\n","  adding: content/models-master/research/audioset/yamnet/README.md (deflated 53%)\n","  adding: content/models-master/research/audioset/yamnet/yamnet.py (deflated 69%)\n","  adding: content/models-master/research/audioset/yamnet/yamnet_class_map.csv (deflated 51%)\n","  adding: content/models-master/research/audioset/yamnet/yamnet_visualization.ipynb (deflated 28%)\n","  adding: content/models-master/research/audioset/yamnet/params.py (deflated 50%)\n","  adding: content/models-master/research/audioset/yamnet/yamnet_test.py (deflated 59%)\n","  adding: content/models-master/research/audioset/yamnet/export.py (deflated 69%)\n","  adding: content/models-master/research/audioset/yamnet/features.py (deflated 67%)\n","  adding: content/models-master/research/seq_flow_lite/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/tf_custom_ops.cc (deflated 73%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/BUILD (deflated 82%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/projection_normalizer_util.cc (deflated 67%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/sequence_string_projection_test.cc (deflated 89%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/projection_tokenizer_util.h (deflated 56%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/sequence_string_projection_op_v2.cc (deflated 69%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/repo.bzl (deflated 80%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/text_distorter.cc (deflated 56%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/build_def.bzl (deflated 58%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/sequence_string_projection.cc (deflated 71%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/projection_normalizer_util.h (deflated 58%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/projection_tokenizer_util.cc (deflated 60%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/sequence_string_projection_op_v2_test.cc (deflated 81%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/projection_util.cc (deflated 71%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/text_distorter.h (deflated 51%)\n","  adding: content/models-master/research/seq_flow_lite/tf_ops/projection_util.h (deflated 65%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/expected_value.cc (deflated 65%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/quantization_util.h (deflated 55%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/BUILD (deflated 80%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/sequence_string_projection_test.cc (deflated 90%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/layer_norm_test.cc (deflated 76%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/expected_value.h (deflated 50%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/layer_norm.h (deflated 50%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/sequence_string_projection.cc (deflated 74%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/sequence_string_projection.h (deflated 55%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/tf_tflite_diff_test_util.cc (deflated 78%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/layer_norm.cc (deflated 75%)\n","  adding: content/models-master/research/seq_flow_lite/tflite_ops/tf_tflite_diff_test_util.h (deflated 66%)\n","  adding: content/models-master/research/seq_flow_lite/WORKSPACE (deflated 68%)\n","  adding: content/models-master/research/seq_flow_lite/README.md (deflated 56%)\n","  adding: content/models-master/research/seq_flow_lite/BUILD (deflated 71%)\n","  adding: content/models-master/research/seq_flow_lite/export_to_tflite.py (deflated 56%)\n","  adding: content/models-master/research/seq_flow_lite/models/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/sgnn_projection_test.cc (deflated 60%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/sgnn_test.py (deflated 60%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/sgnn_projection_op_resolver.cc (deflated 50%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/BUILD (deflated 76%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/train.py (deflated 56%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/sgnn.py (deflated 65%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/sgnn_projection.h (deflated 51%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/run_tflite.py (deflated 51%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/sgnn_projection.cc (deflated 63%)\n","  adding: content/models-master/research/seq_flow_lite/models/sgnn/sgnn_projection_op_resolver.h (deflated 51%)\n","  adding: content/models-master/research/seq_flow_lite/models/prado.py (deflated 72%)\n","  adding: content/models-master/research/seq_flow_lite/models/BUILD (deflated 63%)\n","  adding: content/models-master/research/seq_flow_lite/configs/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/configs/civil_comments_prado.txt (deflated 52%)\n","  adding: content/models-master/research/seq_flow_lite/configs/go_emotion_prado.txt (deflated 53%)\n","  adding: content/models-master/research/seq_flow_lite/colab/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/colab/move_ops.sh (deflated 47%)\n","  adding: content/models-master/research/seq_flow_lite/colab/setup_workspace.sh (deflated 42%)\n","  adding: content/models-master/research/seq_flow_lite/colab/BUILD (deflated 25%)\n","  adding: content/models-master/research/seq_flow_lite/colab/setup.py (deflated 50%)\n","  adding: content/models-master/research/seq_flow_lite/demo/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/demo/prado/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/demo/prado/data/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/demo/prado/data/tflite.fb (deflated 88%)\n","  adding: content/models-master/research/seq_flow_lite/demo/prado/BUILD (deflated 53%)\n","  adding: content/models-master/research/seq_flow_lite/demo/prado/prado_tflite_example.cc (deflated 63%)\n","  adding: content/models-master/research/seq_flow_lite/demo/colab/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/demo/colab/move_ops.sh (deflated 61%)\n","  adding: content/models-master/research/seq_flow_lite/demo/colab/setup_workspace.sh (deflated 42%)\n","  adding: content/models-master/research/seq_flow_lite/demo/colab/BUILD (deflated 47%)\n","  adding: content/models-master/research/seq_flow_lite/demo/colab/setup.py (deflated 49%)\n","  adding: content/models-master/research/seq_flow_lite/utils/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/utils/misc_utils.py (deflated 56%)\n","  adding: content/models-master/research/seq_flow_lite/utils/BUILD (deflated 55%)\n","  adding: content/models-master/research/seq_flow_lite/utils/tflite_utils.py (deflated 61%)\n","  adding: content/models-master/research/seq_flow_lite/layers/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/layers/conv_layers.py (deflated 67%)\n","  adding: content/models-master/research/seq_flow_lite/layers/dense_layers.py (deflated 68%)\n","  adding: content/models-master/research/seq_flow_lite/layers/BUILD (deflated 82%)\n","  adding: content/models-master/research/seq_flow_lite/layers/projection_layers.py (deflated 72%)\n","  adding: content/models-master/research/seq_flow_lite/layers/base_layers.py (deflated 63%)\n","  adding: content/models-master/research/seq_flow_lite/layers/quantization_layers.py (deflated 71%)\n","  adding: content/models-master/research/seq_flow_lite/layers/normalization_layers.py (deflated 70%)\n","  adding: content/models-master/research/seq_flow_lite/metric_functions.py (deflated 58%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/flatbuffers/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/flatbuffers/BUILD.bazel (deflated 76%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/flatbuffers/BUILD (deflated 5%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/flatbuffers/build_defs.bzl (deflated 77%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/flatbuffers/workspace.bzl (deflated 52%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/farmhash.BUILD (deflated 39%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/python_runtime/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/python_runtime/BUILD (deflated 25%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/icu.BUILD (deflated 53%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/BUILD (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/py/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/py/BUILD (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/py/BUILD.tpl (deflated 57%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/py/python_configure.bzl (deflated 60%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/protobuf.BUILD (deflated 60%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/repo.bzl (deflated 62%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/pybind11.BUILD (deflated 55%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/utf.BUILD (deflated 76%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/android/ (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/android/android_configure.BUILD.tpl (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/android/android.bzl.tpl (deflated 35%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/android/BUILD (stored 0%)\n","  adding: content/models-master/research/seq_flow_lite/third_party/android/android_configure.bzl (deflated 71%)\n","  adding: content/models-master/research/seq_flow_lite/.bazelrc (deflated 53%)\n","  adding: content/models-master/research/seq_flow_lite/input_fn_reader.py (deflated 59%)\n","  adding: content/models-master/research/seq_flow_lite/CONTRIBUTING.md (deflated 47%)\n","  adding: content/models-master/research/seq_flow_lite/trainer.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/ (stored 0%)\n","  adding: content/models-master/research/object_detection/Object_detection_video.py (deflated 58%)\n","  adding: content/models-master/research/object_detection/test_images/ (stored 0%)\n","  adding: content/models-master/research/object_detection/test_images/snapshot_serengeti/ (stored 0%)\n","  adding: content/models-master/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0040.jpeg (deflated 44%)\n","  adding: content/models-master/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0038.jpeg (deflated 44%)\n","  adding: content/models-master/research/object_detection/test_images/snapshot_serengeti/README.md (deflated 39%)\n","  adding: content/models-master/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0039.jpeg (deflated 44%)\n","  adding: content/models-master/research/object_detection/test_images/snapshot_serengeti/context_rcnn_demo_metadata.json (deflated 71%)\n","  adding: content/models-master/research/object_detection/test_images/snapshot_serengeti/S1_E03_R3_PICT0041.jpeg (deflated 43%)\n","  adding: content/models-master/research/object_detection/test_images/image_info.txt (deflated 26%)\n","  adding: content/models-master/research/object_detection/test_images/image2.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/ (stored 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/train/ (stored 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/train/robertducky5.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/train/robertducky2.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/train/robertducky4.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/train/robertducky1.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/train/robertducky3.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/ (stored 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out7.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out47.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out14.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out45.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out5.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out26.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out25.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out16.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out13.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out34.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out21.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out42.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out12.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out37.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out11.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out33.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out32.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out22.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out43.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out20.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out2.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out46.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out44.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out39.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out31.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out30.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out15.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out38.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out9.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out1.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out24.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out8.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out4.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out23.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out28.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out36.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out48.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out6.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out17.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out49.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out3.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out29.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out27.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out18.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out19.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out41.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out10.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out35.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_images/ducky/test/out40.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/test_images/image1.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/export_tflite_ssd_graph_lib.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/export_tflite_graph_lib_tf2.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/training/ (stored 0%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-7125.index (deflated 73%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-7125.data-00000-of-00001 (deflated 7%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-6466.meta (deflated 93%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-7125.meta (deflated 93%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-4490.index (deflated 73%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-5149.meta (deflated 93%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-4490.meta (deflated 93%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-5809.data-00000-of-00001 (deflated 7%)\n","  adding: content/models-master/research/object_detection/training/graph.pbtxt (deflated 97%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-6466.index (deflated 73%)\n","  adding: content/models-master/research/object_detection/training/pipeline.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-5149.index (deflated 73%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-5809.meta (deflated 93%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-5809.index (deflated 73%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-6466.data-00000-of-00001 (deflated 7%)\n","  adding: content/models-master/research/object_detection/training/events.out.tfevents.1608055174.bea29351cc85 (deflated 90%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-5149.data-00000-of-00001 (deflated 7%)\n","  adding: content/models-master/research/object_detection/training/checkpoint (deflated 72%)\n","  adding: content/models-master/research/object_detection/training/model.ckpt-4490.data-00000-of-00001 (deflated 7%)\n","  adding: content/models-master/research/object_detection/eval_util.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/export_tflite_graph_tf2.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/test_data/ (stored 0%)\n","  adding: content/models-master/research/object_detection/test_data/context_rcnn_camera_trap.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/test_data/snapshot_serengeti_sequence_examples.record (deflated 14%)\n","  adding: content/models-master/research/object_detection/test_data/pets_examples.record (deflated 1%)\n","  adding: content/models-master/research/object_detection/test_data/ssd_mobilenet_v1_fpp.config (deflated 74%)\n","  adding: content/models-master/research/object_detection/model_lib.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/images/ (stored 0%)\n","  adding: content/models-master/research/object_detection/images/train/ (stored 0%)\n","  adding: content/models-master/research/object_detection/images/train/0278.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0235.JPEG (deflated 2%)\n","  adding: content/models-master/research/object_detection/images/train/0282.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0281.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0182.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0165.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0175.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0163.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0100.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0104.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0001.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0065.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0294.xml (deflated 64%)\n","  adding: content/models-master/research/object_detection/images/train/0011.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0015.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0299.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0145.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0071.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0237.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0032.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0204.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0214.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0281.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0217.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0210.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0176.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0276.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0025.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0019.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0271.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0105.xml (deflated 74%)\n","  adding: content/models-master/research/object_detection/images/train/0201.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0257.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0234.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0001.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0218.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0272.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0137.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0080.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0241.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0151.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0021.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0189.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0133.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0206.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0008.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0124.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0211.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0163.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0192.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0296.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0253.xml (deflated 69%)\n","  adding: content/models-master/research/object_detection/images/train/0202.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0135.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0277.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0241.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0180.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0219.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0285.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0048.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0064.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0170.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0013.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0084.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0110.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0166.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0262.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0220.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0067.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0006.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0040.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0133.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0024.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0069.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0161.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0025.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0124.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0083.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0099.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0048.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0228.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0220.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0259.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0178.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0071.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0040.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0147.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0177.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0052.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0075.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0233.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0248.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0020.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0046.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0228.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0184.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0226.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0202.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0185.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0043.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0034.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0258.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0233.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0198.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0118.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0255.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0269.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0108.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0197.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0186.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0191.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0195.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0184.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0279.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0120.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0207.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0239.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0093.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0159.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0145.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0259.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0223.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0136.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0157.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0052.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0268.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0161.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0190.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0221.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0129.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0073.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0194.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0199.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0130.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0253.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0195.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0114.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0024.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0301.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0012.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0076.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0027.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0106.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0279.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0146.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0117.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0090.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0085.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0016.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/train/0154.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0055.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0138.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0138.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0051.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0141.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0171.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0151.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0263.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0231.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0053.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0051.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0298.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0174.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0109.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0045.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0069.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0146.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0168.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0054.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0049.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0020.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/images/train/0193.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0286.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0252.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0095.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0198.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0190.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0131.xml (deflated 70%)\n","  adding: content/models-master/research/object_detection/images/train/0095.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0017.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/train/0257.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0093.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0200.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0173.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0132.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0266.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0075.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0256.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0009.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0283.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0200.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0168.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0285.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0239.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0267.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0112.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0222.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0258.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0240.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0144.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0293.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0126.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/train/0092.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0046.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0193.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0050.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0067.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0260.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0062.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0289.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0004.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0127.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0182.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0211.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0261.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0244.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0136.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0081.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0072.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0021.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0197.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0264.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0194.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0116.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0276.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0003.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0013.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0266.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0178.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0242.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0082.JPEG (deflated 4%)\n","  adding: content/models-master/research/object_detection/images/train/0120.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0172.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0141.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0043.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0251.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/images/train/0246.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0140.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0243.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0035.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0068.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0074.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0262.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0044.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0129.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0272.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0292.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0292.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0015.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0143.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0061.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0229.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0268.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0066.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0033.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0174.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0111.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0107.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0031.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0099.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0019.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0298.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0028.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0156.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0031.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0109.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0041.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0189.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0086.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0008.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0210.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0045.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0110.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0050.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0022.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/images/train/0273.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0250.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0208.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0014.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0209.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0005.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0227.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0246.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0054.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0287.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0230.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0207.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0208.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0009.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0123.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0139.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0088.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0077.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0271.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0062.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0097.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0274.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0152.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0284.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0123.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0089.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0205.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0238.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0002.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0196.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0038.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/images/train/0294.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0018.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0295.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0149.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0167.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0103.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0121.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0086.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0295.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0187.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0072.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0212.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0096.xml (deflated 70%)\n","  adding: content/models-master/research/object_detection/images/train/0277.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0173.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0255.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0192.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0256.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0128.jpeg (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0058.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0217.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0280.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0106.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0096.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0179.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0300.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/train/0148.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0245.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0169.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0170.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0131.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0111.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0183.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0070.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0085.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0235.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0006.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0057.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0056.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0291.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0125.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0232.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0299.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0252.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0297.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0055.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0236.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0142.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0143.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0084.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0150.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0098.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0164.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0249.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/train/0260.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0206.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0216.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0209.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0160.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0215.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0218.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0128.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0203.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0222.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0134.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0291.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0223.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0205.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0065.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0162.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0044.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0149.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0227.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0297.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0037.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0005.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0061.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0301.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0122.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0126.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0118.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0064.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0079.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0003.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0104.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0127.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0154.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0254.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0155.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0289.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0107.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0169.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0066.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0116.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0274.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0122.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0070.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0288.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0059.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0155.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0060.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0004.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0092.xml (deflated 67%)\n","  adding: content/models-master/research/object_detection/images/train/0164.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0224.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0079.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0056.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0119.JPEG (deflated 2%)\n","  adding: content/models-master/research/object_detection/images/train/0275.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0057.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0293.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0027.JPEG (deflated 3%)\n","  adding: content/models-master/research/object_detection/images/train/0023.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0248.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0265.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0152.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0153.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0213.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0113.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0011.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0267.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0014.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0036.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0187.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0282.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0162.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0219.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0097.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0203.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0254.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0103.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0033.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0022.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0074.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0221.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0275.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0026.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0082.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/images/train/0251.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0088.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0076.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0159.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0134.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0264.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0226.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0035.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0144.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0047.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0105.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0290.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0172.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0244.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0080.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0201.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0199.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0167.xml (deflated 64%)\n","  adding: content/models-master/research/object_detection/images/train/0030.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0115.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0142.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0181.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0073.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0029.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0204.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/train/0042.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0286.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0153.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0247.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0098.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0032.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0290.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0270.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0238.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0117.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0101.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0269.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0102.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0216.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0176.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0245.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0150.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0108.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0284.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0273.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0039.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0039.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0300.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0007.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0188.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0224.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0112.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0077.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0029.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0249.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0158.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0094.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0283.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0023.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0261.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0078.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0017.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0083.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0230.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0049.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0212.xml (deflated 77%)\n","  adding: content/models-master/research/object_detection/images/train/0148.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0240.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0191.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0091.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0158.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0147.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0137.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0114.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0250.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0165.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0018.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/images/train/0265.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0229.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0237.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0225.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0012.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0036.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0002.JPEG (stored 0%)\n","  adding: content/models-master/research/object_detection/images/train/0215.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0132.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0058.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0101.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0236.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0130.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0247.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0047.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0068.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0135.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/train/0278.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0139.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0042.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0121.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0213.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0243.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0177.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0087.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/images/train/0196.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0181.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0214.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0090.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0059.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/train/0185.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0087.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0063.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0231.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0091.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0078.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0166.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0016.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0028.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0094.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0119.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0030.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0179.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0175.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0089.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0288.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0115.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0034.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0125.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0183.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0037.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0026.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0010.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0113.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0053.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0041.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0232.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0296.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0180.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0081.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/train/0280.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0186.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0007.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0156.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0242.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0060.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/images/train/0188.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/train/0010.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/train/0157.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0171.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0038.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0063.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train/0140.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/train/0263.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0160.xml (deflated 64%)\n","  adding: content/models-master/research/object_detection/images/train/0100.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0287.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0225.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/train/0270.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/train/0234.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/train/0102.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/train_labels.csv (deflated 71%)\n","  adding: content/models-master/research/object_detection/images/test_labels.csv (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/test/ (stored 0%)\n","  adding: content/models-master/research/object_detection/images/test/0001.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0011.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0015.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0019.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/test/0001.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/test/0021.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/test/0008.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/images/test/0013.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/test/0006.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0024.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0025.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/test/0020.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0024.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/test/0012.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0027.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/images/test/0016.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/images/test/0020.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/test/0017.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0027.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0009.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0004.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/test/0021.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/test/0003.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0013.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0015.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0019.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0028.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/test/0008.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/test/0022.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/test/0014.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/test/0005.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0009.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0002.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/images/test/0018.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0006.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/test/0005.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0003.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0004.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0023.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0011.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0014.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0022.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0026.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0030.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0029.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/images/test/0007.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/test/0029.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0023.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/test/0017.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0018.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0012.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/images/test/0002.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0016.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/test/0028.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/test/0030.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/images/test/0025.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0026.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0010.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/images/test/0007.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/images/test/0010.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/data_decoders/ (stored 0%)\n","  adding: content/models-master/research/object_detection/data_decoders/tf_example_decoder_test.py (deflated 92%)\n","  adding: content/models-master/research/object_detection/data_decoders/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/data_decoders/__pycache__/tf_example_decoder.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/object_detection/data_decoders/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n","  adding: content/models-master/research/object_detection/data_decoders/__pycache__/tf_sequence_example_decoder.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/data_decoders/tf_sequence_example_decoder_test.py (deflated 84%)\n","  adding: content/models-master/research/object_detection/data_decoders/tf_sequence_example_decoder.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/data_decoders/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/data_decoders/tf_example_decoder.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/export_tflite_graph_lib_tf2_test.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/new_graph/ (stored 0%)\n","  adding: content/models-master/research/object_detection/new_graph/tflite_graph.pbtxt (deflated 56%)\n","  adding: content/models-master/research/object_detection/new_graph/model.ckpt.data-00000-of-00001 (deflated 7%)\n","  adding: content/models-master/research/object_detection/new_graph/saved_model/ (stored 0%)\n","  adding: content/models-master/research/object_detection/new_graph/saved_model/saved_model.pb (deflated 11%)\n","  adding: content/models-master/research/object_detection/new_graph/saved_model/variables/ (stored 0%)\n","  adding: content/models-master/research/object_detection/new_graph/pipeline.config (deflated 68%)\n","  adding: content/models-master/research/object_detection/new_graph/model.ckpt.meta (deflated 93%)\n","  adding: content/models-master/research/object_detection/new_graph/frozen_inference_graph.pb (deflated 11%)\n","  adding: content/models-master/research/object_detection/new_graph/checkpoint (deflated 42%)\n","  adding: content/models-master/research/object_detection/new_graph/model.ckpt.index (deflated 67%)\n","  adding: content/models-master/research/object_detection/new_graph/tflite_graph.pb (deflated 9%)\n","  adding: content/models-master/research/object_detection/core/ (stored 0%)\n","  adding: content/models-master/research/object_detection/core/batch_multiclass_nms_test.py (deflated 91%)\n","  adding: content/models-master/research/object_detection/core/post_processing.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/core/class_agnostic_nms_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/core/freezable_batch_norm.py (deflated 54%)\n","  adding: content/models-master/research/object_detection/core/batcher.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/core/keypoint_ops.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/core/matcher.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/core/keypoint_ops_test.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/core/data_parser.py (deflated 52%)\n","  adding: content/models-master/research/object_detection/core/prefetcher.py (deflated 58%)\n","  adding: content/models-master/research/object_detection/core/box_predictor.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/core/prefetcher_tf1_test.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/core/region_similarity_calculator.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/core/box_list_test.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/core/box_coder.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/core/box_coder_test.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/core/anchor_generator.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/core/data_decoder.py (deflated 50%)\n","  adding: content/models-master/research/object_detection/core/minibatch_sampler.py (deflated 59%)\n","  adding: content/models-master/research/object_detection/core/losses.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/core/balanced_positive_negative_sampler_test.py (deflated 84%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/box_list.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/target_assigner.cpython-36.pyc (deflated 70%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/preprocessor_cache.cpython-36.pyc (deflated 51%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/box_coder.cpython-36.pyc (deflated 57%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/freezable_batch_norm.cpython-36.pyc (deflated 48%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/anchor_generator.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/data_decoder.cpython-36.pyc (deflated 42%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/box_list_ops.cpython-36.pyc (deflated 66%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/matcher.cpython-36.pyc (deflated 65%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/region_similarity_calculator.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/post_processing.cpython-36.pyc (deflated 68%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/losses.cpython-36.pyc (deflated 69%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/standard_fields.cpython-36.pyc (deflated 71%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/keypoint_ops.cpython-36.pyc (deflated 69%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/prefetcher.cpython-36.pyc (deflated 48%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/balanced_positive_negative_sampler.cpython-36.pyc (deflated 59%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/minibatch_sampler.cpython-36.pyc (deflated 51%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/batcher.cpython-36.pyc (deflated 52%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/model.cpython-36.pyc (deflated 69%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/box_predictor.cpython-36.pyc (deflated 73%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/densepose_ops.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/object_detection/core/__pycache__/preprocessor.cpython-36.pyc (deflated 76%)\n","  adding: content/models-master/research/object_detection/core/box_list.py (deflated 66%)\n","  adding: content/models-master/research/object_detection/core/batcher_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/core/region_similarity_calculator_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/core/box_list_ops_test.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/core/losses_test.py (deflated 92%)\n","  adding: content/models-master/research/object_detection/core/densepose_ops_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/core/matcher_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/core/minibatch_sampler_test.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/core/balanced_positive_negative_sampler.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/core/target_assigner_test.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/core/box_list_ops.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/core/preprocessor_cache.py (deflated 62%)\n","  adding: content/models-master/research/object_detection/core/model.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/core/densepose_ops.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/core/freezable_batch_norm_tf2_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/core/preprocessor.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/core/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/core/multiclass_nms_test.py (deflated 89%)\n","  adding: content/models-master/research/object_detection/core/standard_fields.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/core/model_test.py (deflated 60%)\n","  adding: content/models-master/research/object_detection/core/target_assigner.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/core/preprocessor_test.py (deflated 91%)\n","  adding: content/models-master/research/object_detection/export_tflite_ssd_graph.py (deflated 64%)\n","  adding: content/models-master/research/object_detection/anchor_generators/ (stored 0%)\n","  adding: content/models-master/research/object_detection/anchor_generators/grid_anchor_generator_test.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/anchor_generators/multiple_grid_anchor_generator.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/anchor_generators/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/anchor_generators/__pycache__/__init__.cpython-36.pyc (deflated 18%)\n","  adding: content/models-master/research/object_detection/anchor_generators/__pycache__/multiple_grid_anchor_generator.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/object_detection/anchor_generators/__pycache__/grid_anchor_generator.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/anchor_generators/__pycache__/flexible_grid_anchor_generator.cpython-36.pyc (deflated 59%)\n","  adding: content/models-master/research/object_detection/anchor_generators/__pycache__/multiscale_grid_anchor_generator.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/object_detection/anchor_generators/grid_anchor_generator.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/anchor_generators/flexible_grid_anchor_generator.py (deflated 66%)\n","  adding: content/models-master/research/object_detection/anchor_generators/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/ (stored 0%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/utils_test.py (deflated 58%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/export_saved_model_tpu_lib.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/faster_rcnn.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/export_saved_model_tpu.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/ssd.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/utils.py (deflated 54%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/testdata/ (stored 0%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/testdata/faster_rcnn/ (stored 0%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/testdata/ssd/ (stored 0%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config (deflated 68%)\n","  adding: content/models-master/research/object_detection/tpu_exporters/testdata/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/model_lib_tf1_test.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/data/ (stored 0%)\n","  adding: content/models-master/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt (deflated 79%)\n","  adding: content/models-master/research/object_detection/data/face_label_map.pbtxt (deflated 21%)\n","  adding: content/models-master/research/object_detection/data/snapshot_serengeti_label_map.pbtxt (deflated 74%)\n","  adding: content/models-master/research/object_detection/data/kitti_label_map.pbtxt (deflated 29%)\n","  adding: content/models-master/research/object_detection/data/oid_v4_label_map.pbtxt (deflated 79%)\n","  adding: content/models-master/research/object_detection/data/pet_label_map.pbtxt (deflated 71%)\n","  adding: content/models-master/research/object_detection/data/face_person_with_keypoints_label_map.pbtxt (deflated 77%)\n","  adding: content/models-master/research/object_detection/data/mscoco_label_map.pbtxt (deflated 78%)\n","  adding: content/models-master/research/object_detection/data/ava_label_map_v2.1.pbtxt (deflated 74%)\n","  adding: content/models-master/research/object_detection/data/pascal_label_map.pbtxt (deflated 73%)\n","  adding: content/models-master/research/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt (deflated 79%)\n","  adding: content/models-master/research/object_detection/data/fgvc_2854_classes_label_map.pbtxt (deflated 77%)\n","  adding: content/models-master/research/object_detection/data/mscoco_minival_ids.txt (deflated 52%)\n","  adding: content/models-master/research/object_detection/data/mscoco_complete_label_map.pbtxt (deflated 79%)\n","  adding: content/models-master/research/object_detection/labelmap.pbtxt (deflated 42%)\n","  adding: content/models-master/research/object_detection/dockerfiles/ (stored 0%)\n","  adding: content/models-master/research/object_detection/dockerfiles/tf1/ (stored 0%)\n","  adding: content/models-master/research/object_detection/dockerfiles/tf1/README.md (deflated 30%)\n","  adding: content/models-master/research/object_detection/dockerfiles/tf1/Dockerfile (deflated 50%)\n","  adding: content/models-master/research/object_detection/dockerfiles/tf2/ (stored 0%)\n","  adding: content/models-master/research/object_detection/dockerfiles/tf2/README.md (deflated 30%)\n","  adding: content/models-master/research/object_detection/dockerfiles/tf2/Dockerfile (deflated 50%)\n","  adding: content/models-master/research/object_detection/dockerfiles/android/ (stored 0%)\n","  adding: content/models-master/research/object_detection/dockerfiles/android/README.md (deflated 55%)\n","  adding: content/models-master/research/object_detection/dockerfiles/android/Dockerfile (deflated 61%)\n","  adding: content/models-master/research/object_detection/README.md (deflated 56%)\n","  adding: content/models-master/research/object_detection/box_coders/ (stored 0%)\n","  adding: content/models-master/research/object_detection/box_coders/faster_rcnn_box_coder.py (deflated 61%)\n","  adding: content/models-master/research/object_detection/box_coders/faster_rcnn_box_coder_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/box_coders/keypoint_box_coder.py (deflated 68%)\n","  adding: content/models-master/research/object_detection/box_coders/mean_stddev_box_coder.py (deflated 62%)\n","  adding: content/models-master/research/object_detection/box_coders/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/box_coders/__pycache__/faster_rcnn_box_coder.cpython-36.pyc (deflated 49%)\n","  adding: content/models-master/research/object_detection/box_coders/__pycache__/__init__.cpython-36.pyc (deflated 19%)\n","  adding: content/models-master/research/object_detection/box_coders/__pycache__/keypoint_box_coder.cpython-36.pyc (deflated 52%)\n","  adding: content/models-master/research/object_detection/box_coders/__pycache__/square_box_coder.cpython-36.pyc (deflated 49%)\n","  adding: content/models-master/research/object_detection/box_coders/__pycache__/mean_stddev_box_coder.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/object_detection/box_coders/square_box_coder.py (deflated 61%)\n","  adding: content/models-master/research/object_detection/box_coders/keypoint_box_coder_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/box_coders/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/box_coders/square_box_coder_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/box_coders/mean_stddev_box_coder_test.py (deflated 64%)\n","  adding: content/models-master/research/object_detection/model_hparams.py (deflated 52%)\n","  adding: content/models-master/research/object_detection/export_tflite_ssd_graph_lib_tf1_test.py (deflated 84%)\n","  adding: content/models-master/research/object_detection/model_lib_v2.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/metrics/ (stored 0%)\n","  adding: content/models-master/research/object_detection/metrics/oid_vrd_challenge_evaluation.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/metrics/coco_tools_test.py (deflated 84%)\n","  adding: content/models-master/research/object_detection/metrics/lvis_evaluation.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/metrics/oid_challenge_evaluation.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/metrics/oid_challenge_evaluation_utils.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/metrics/coco_evaluation_test.py (deflated 93%)\n","  adding: content/models-master/research/object_detection/metrics/coco_tools.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/metrics/calibration_metrics_tf1_test.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/metrics/tf_example_parser.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/metrics/coco_evaluation.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/metrics/io_utils.py (deflated 47%)\n","  adding: content/models-master/research/object_detection/metrics/lvis_evaluation_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/metrics/lvis_tools_test.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/metrics/offline_eval_map_corloc.py (deflated 64%)\n","  adding: content/models-master/research/object_detection/metrics/calibration_evaluation.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/metrics/calibration_metrics.py (deflated 61%)\n","  adding: content/models-master/research/object_detection/metrics/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/metrics/calibration_evaluation_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/metrics/lvis_tools.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/metrics/offline_eval_map_corloc_test.py (deflated 66%)\n","  adding: content/models-master/research/object_detection/metrics/oid_challenge_evaluation_utils_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/metrics/tf_example_parser_test.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/__pycache__/__init__.cpython-36.pyc (deflated 20%)\n","  adding: content/models-master/research/object_detection/__pycache__/export_tflite_ssd_graph_lib.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/object_detection/__pycache__/exporter.cpython-36.pyc (deflated 57%)\n","  adding: content/models-master/research/object_detection/packages/ (stored 0%)\n","  adding: content/models-master/research/object_detection/packages/tf1/ (stored 0%)\n","  adding: content/models-master/research/object_detection/packages/tf1/setup.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/packages/tf2/ (stored 0%)\n","  adding: content/models-master/research/object_detection/packages/tf2/setup.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/matchers/ (stored 0%)\n","  adding: content/models-master/research/object_detection/matchers/argmax_matcher_test.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/matchers/hungarian_matcher_tf2_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/matchers/argmax_matcher.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/matchers/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/matchers/__pycache__/__init__.cpython-36.pyc (deflated 19%)\n","  adding: content/models-master/research/object_detection/matchers/__pycache__/bipartite_matcher.cpython-36.pyc (deflated 46%)\n","  adding: content/models-master/research/object_detection/matchers/__pycache__/argmax_matcher.cpython-36.pyc (deflated 57%)\n","  adding: content/models-master/research/object_detection/matchers/__pycache__/hungarian_matcher.cpython-36.pyc (deflated 47%)\n","  adding: content/models-master/research/object_detection/matchers/bipartite_matcher_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/matchers/hungarian_matcher.py (deflated 55%)\n","  adding: content/models-master/research/object_detection/matchers/bipartite_matcher.py (deflated 58%)\n","  adding: content/models-master/research/object_detection/matchers/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/train.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/Preparation.zip (stored 0%)\n","  adding: content/models-master/research/object_detection/models/ (stored 0%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/models/center_net_mobilenet_v2_feature_extractor.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/models/center_net_hourglass_feature_extractor.py (deflated 60%)\n","  adding: content/models-master/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py (deflated 62%)\n","  adding: content/models-master/research/object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py (deflated 52%)\n","  adding: content/models-master/research/object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/models/ssd_pnasnet_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/models/ssd_feature_extractor_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v3_feature_extractor.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/models/ssd_inception_v3_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/models/center_net_resnet_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobiledet_feature_extractor.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_nas_feature_extractor.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_pnas_feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/embedded_ssd_mobilenet_v1_feature_extractor.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/faster_rcnn_inception_v2_feature_extractor.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobiledet_feature_extractor.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/__init__.cpython-36.pyc (deflated 23%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/faster_rcnn_inception_resnet_v2_feature_extractor.cpython-36.pyc (deflated 57%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobilenet_v1_fpn_feature_extractor.cpython-36.pyc (deflated 54%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobilenet_v1_ppn_feature_extractor.cpython-36.pyc (deflated 51%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobilenet_edgetpu_feature_extractor.cpython-36.pyc (deflated 43%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobilenet_v2_mnasfpn_feature_extractor.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobilenet_v1_feature_extractor.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/faster_rcnn_pnas_feature_extractor.cpython-36.pyc (deflated 54%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/feature_map_generators.cpython-36.pyc (deflated 66%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_pnasnet_feature_extractor.cpython-36.pyc (deflated 54%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/faster_rcnn_nas_feature_extractor.cpython-36.pyc (deflated 54%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/faster_rcnn_resnet_v1_feature_extractor.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_resnet_v1_fpn_feature_extractor.cpython-36.pyc (deflated 71%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_inception_v3_feature_extractor.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_inception_v2_feature_extractor.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobilenet_v3_feature_extractor.cpython-36.pyc (deflated 59%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc (deflated 54%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_mobilenet_v2_feature_extractor.cpython-36.pyc (deflated 54%)\n","  adding: content/models-master/research/object_detection/models/__pycache__/ssd_resnet_v1_ppn_feature_extractor.cpython-36.pyc (deflated 70%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py (deflated 52%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py (deflated 53%)\n","  adding: content/models-master/research/object_detection/models/ssd_inception_v2_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/object_detection/models/feature_map_generators_test.py (deflated 88%)\n","  adding: content/models-master/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/models/keras_models/ (stored 0%)\n","  adding: content/models-master/research/object_detection/models/keras_models/mobilenet_v1.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/models/keras_models/model_utils.py (deflated 52%)\n","  adding: content/models-master/research/object_detection/models/keras_models/resnet_v1_tf2_test.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/models/keras_models/base_models/ (stored 0%)\n","  adding: content/models-master/research/object_detection/models/keras_models/base_models/original_mobilenet_v2.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/models/keras_models/convert_keras_models.py (deflated 57%)\n","  adding: content/models-master/research/object_detection/models/keras_models/mobilenet_v1_tf2_test.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/models/keras_models/inception_resnet_v2.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/models/keras_models/mobilenet_v2.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/models/keras_models/mobilenet_v2_tf2_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/models/keras_models/hourglass_network_tf2_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/models/keras_models/resnet_v1.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/models/keras_models/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/models/keras_models/hourglass_network.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/models/keras_models/test_utils.py (deflated 86%)\n","  adding: content/models-master/research/object_detection/models/keras_models/inception_resnet_v2_tf2_test.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/models/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/models/bidirectional_feature_pyramid_generators.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/models/feature_map_generators.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py (deflated 59%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/models/center_net_resnet_feature_extractor_tf2_test.py (deflated 59%)\n","  adding: content/models-master/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py (deflated 61%)\n","  adding: content/models-master/research/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py (deflated 52%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py (deflated 91%)\n","  adding: content/models-master/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/eval_util_test.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/inference/ (stored 0%)\n","  adding: content/models-master/research/object_detection/inference/infer_detections.py (deflated 61%)\n","  adding: content/models-master/research/object_detection/inference/detection_inference.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/inference/detection_inference_tf1_test.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/inference/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/configs/ (stored 0%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ (stored 0%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_800x1333_coco17_gpu-8.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/centernet_resnet50_v2_512x512_kpts_coco17_tpu-8.config (deflated 78%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/centernet_hourglass104_512x512_coco17_tpu-8.config (deflated 62%)\n","  adding: content/models-master/research/object_detection/configs/tf2/centernet_hourglass104_1024x1024_kpts_coco17_tpu-32.config (deflated 78%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_efficientdet_d2_768x768_coco17_tpu-8.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_efficientdet_d6_1408x1408_coco17_tpu-32.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_efficientdet_d7_1536x1536_coco17_tpu-32.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_1024x1024_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/centernet_resnet50_v1_fpn_512x512_kpts_coco17_tpu-8.config (deflated 78%)\n","  adding: content/models-master/research/object_detection/configs/tf2/centernet_resnet101_v1_fpn_512x512_coco17_tpu-8.config (deflated 63%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_800x1333_coco17_gpu-8.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/centernet_hourglass104_512x512_kpts_coco17_tpu-32.config (deflated 78%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_efficientdet_d1_640x640_coco17_tpu-8.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_efficientdet_d3_896x896_coco17_tpu-32.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_efficientdet_d5_1280x1280_coco17_tpu-32.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/configs/tf2/centernet_hourglass104_1024x1024_coco17_tpu-32.config (deflated 61%)\n","  adding: content/models-master/research/object_detection/configs/tf2/ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/builders/ (stored 0%)\n","  adding: content/models-master/research/object_detection/builders/input_reader_builder_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/builders/model_builder_tf1_test.py (deflated 57%)\n","  adding: content/models-master/research/object_detection/builders/optimizer_builder_tf2_test.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/builders/model_builder_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/builders/hyperparams_builder.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/builders/box_predictor_builder.py (deflated 88%)\n","  adding: content/models-master/research/object_detection/builders/graph_rewriter_builder_tf1_test.py (deflated 66%)\n","  adding: content/models-master/research/object_detection/builders/post_processing_builder_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/builders/hyperparams_builder_test.py (deflated 92%)\n","  adding: content/models-master/research/object_detection/builders/region_similarity_calculator_builder_test.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/builders/calibration_builder_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/builders/model_builder.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/builders/losses_builder.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/builders/target_assigner_builder_test.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/builders/optimizer_builder.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/builders/box_predictor_builder_test.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/builders/model_builder_tf2_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/builders/matcher_builder_test.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/builders/decoder_builder_test.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/builders/input_reader_builder.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/hyperparams_builder.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/image_resizer_builder.cpython-36.pyc (deflated 54%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/optimizer_builder.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/__init__.cpython-36.pyc (deflated 19%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/model_builder.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/dataset_builder.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/calibration_builder.cpython-36.pyc (deflated 61%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/anchor_generator_builder.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/box_coder_builder.cpython-36.pyc (deflated 47%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/box_predictor_builder.cpython-36.pyc (deflated 76%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/decoder_builder.cpython-36.pyc (deflated 45%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/preprocessor_builder.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/graph_rewriter_builder.cpython-36.pyc (deflated 41%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/losses_builder.cpython-36.pyc (deflated 62%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/post_processing_builder.cpython-36.pyc (deflated 59%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/matcher_builder.cpython-36.pyc (deflated 43%)\n","  adding: content/models-master/research/object_detection/builders/__pycache__/region_similarity_calculator_builder.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/object_detection/builders/optimizer_builder_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/builders/dataset_builder.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/builders/dataset_builder_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/builders/anchor_generator_builder.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/builders/graph_rewriter_builder.py (deflated 55%)\n","  adding: content/models-master/research/object_detection/builders/preprocessor_builder.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/builders/calibration_builder.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/builders/image_resizer_builder.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/builders/region_similarity_calculator_builder.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/builders/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/builders/box_coder_builder_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/builders/post_processing_builder.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/builders/matcher_builder.py (deflated 61%)\n","  adding: content/models-master/research/object_detection/builders/anchor_generator_builder_test.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/builders/box_coder_builder.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/builders/losses_builder_test.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/builders/preprocessor_builder_test.py (deflated 89%)\n","  adding: content/models-master/research/object_detection/builders/image_resizer_builder_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/builders/target_assigner_builder.py (deflated 60%)\n","  adding: content/models-master/research/object_detection/builders/decoder_builder.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/model_main_tf2.py (deflated 62%)\n","  adding: content/models-master/research/object_detection/Object_detection_webcam.py (deflated 58%)\n","  adding: content/models-master/research/object_detection/utils/ (stored 0%)\n","  adding: content/models-master/research/object_detection/utils/np_box_mask_list_test.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/utils/static_shape.py (deflated 66%)\n","  adding: content/models-master/research/object_detection/utils/per_image_vrd_evaluation.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/utils/per_image_evaluation_test.py (deflated 92%)\n","  adding: content/models-master/research/object_detection/utils/dataset_util.py (deflated 58%)\n","  adding: content/models-master/research/object_detection/utils/patch_ops_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/utils/label_map_util.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/utils/label_map_util_test.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/utils/vrd_evaluation.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/utils/np_mask_ops.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/utils/json_utils.py (deflated 60%)\n","  adding: content/models-master/research/object_detection/utils/np_box_list_ops.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/utils/np_box_list.py (deflated 64%)\n","  adding: content/models-master/research/object_detection/utils/category_util.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/utils/spatial_transform_ops.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/utils/variables_helper.py (deflated 68%)\n","  adding: content/models-master/research/object_detection/utils/model_util_tf2_test.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/utils/target_assigner_utils.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/utils/colab_utils.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/utils/np_box_list_ops_test.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/utils/test_case.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/utils/np_box_mask_list_ops.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/utils/model_util.py (deflated 64%)\n","  adding: content/models-master/research/object_detection/utils/category_util_test.py (deflated 59%)\n","  adding: content/models-master/research/object_detection/utils/variables_helper_tf1_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/utils/metrics_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/dataset_util.cpython-36.pyc (deflated 50%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/variables_helper.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/__init__.cpython-36.pyc (deflated 19%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/visualization_utils.cpython-36.pyc (deflated 65%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/static_shape.cpython-36.pyc (deflated 61%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/target_assigner_utils.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/shape_utils.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/learning_schedules.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/spatial_transform_ops.cpython-36.pyc (deflated 66%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/context_manager.cpython-36.pyc (deflated 41%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/label_map_util.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/config_util.cpython-36.pyc (deflated 67%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/patch_ops.cpython-36.pyc (deflated 49%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/ops.cpython-36.pyc (deflated 62%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/autoaugment_utils.cpython-36.pyc (deflated 67%)\n","  adding: content/models-master/research/object_detection/utils/__pycache__/tf_version.cpython-36.pyc (deflated 41%)\n","  adding: content/models-master/research/object_detection/utils/context_manager.py (deflated 48%)\n","  adding: content/models-master/research/object_detection/utils/np_box_mask_list.py (deflated 57%)\n","  adding: content/models-master/research/object_detection/utils/config_util.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/utils/visualization_utils.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/utils/ops_test.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/utils/ops.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/utils/np_box_mask_list_ops_test.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/utils/vrd_evaluation_test.py (deflated 86%)\n","  adding: content/models-master/research/object_detection/utils/learning_schedules.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/utils/json_utils_test.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/utils/shape_utils.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/utils/static_shape_test.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/utils/learning_schedules_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/utils/target_assigner_utils_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/utils/spatial_transform_ops_test.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/utils/patch_ops.py (deflated 60%)\n","  adding: content/models-master/research/object_detection/utils/context_manager_test.py (deflated 49%)\n","  adding: content/models-master/research/object_detection/utils/visualization_utils_test.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/utils/np_box_ops_test.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/utils/test_case_test.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/utils/shape_utils_test.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/utils/bifpn_utils.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/utils/test_utils_test.py (deflated 66%)\n","  adding: content/models-master/research/object_detection/utils/config_util_test.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/utils/metrics.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/utils/object_detection_evaluation_test.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/utils/per_image_evaluation.py (deflated 84%)\n","  adding: content/models-master/research/object_detection/utils/np_box_ops.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/utils/tf_version.py (deflated 48%)\n","  adding: content/models-master/research/object_detection/utils/dataset_util_test.py (deflated 50%)\n","  adding: content/models-master/research/object_detection/utils/object_detection_evaluation.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/utils/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/utils/test_utils.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/utils/per_image_vrd_evaluation_test.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/utils/np_mask_ops_test.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/utils/np_box_list_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/utils/autoaugment_utils.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/meta_architectures/ (stored 0%)\n","  adding: content/models-master/research/object_detection/meta_architectures/rfcn_meta_arch.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/meta_architectures/ssd_meta_arch_test.py (deflated 86%)\n","  adding: content/models-master/research/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py (deflated 86%)\n","  adding: content/models-master/research/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/meta_architectures/context_rcnn_lib_tf1_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/context_rcnn_meta_arch.cpython-36.pyc (deflated 70%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/context_rcnn_lib_tf2.cpython-36.pyc (deflated 57%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/__init__.cpython-36.pyc (deflated 21%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/rfcn_meta_arch.cpython-36.pyc (deflated 65%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/faster_rcnn_meta_arch.cpython-36.pyc (deflated 72%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/center_net_meta_arch.cpython-36.pyc (deflated 70%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/ssd_meta_arch.cpython-36.pyc (deflated 67%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__pycache__/context_rcnn_lib.cpython-36.pyc (deflated 60%)\n","  adding: content/models-master/research/object_detection/meta_architectures/context_rcnn_meta_arch.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/meta_architectures/center_net_meta_arch.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/meta_architectures/context_rcnn_meta_arch_test.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/meta_architectures/context_rcnn_lib_tf2_test.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/meta_architectures/rfcn_meta_arch_test.py (deflated 61%)\n","  adding: content/models-master/research/object_detection/meta_architectures/ssd_meta_arch.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/meta_architectures/context_rcnn_lib_tf2.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/meta_architectures/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/meta_architectures/context_rcnn_lib.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/meta_architectures/ssd_meta_arch_test_lib.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/exporter_lib_v2.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/Object_detection_image.py (deflated 58%)\n","  adding: content/models-master/research/object_detection/inputs_test.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz (deflated 0%)\n","  adding: content/models-master/research/object_detection/model_tpu_main.py (deflated 64%)\n","  adding: content/models-master/research/object_detection/model_main.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/g3doc/ (stored 0%)\n","  adding: content/models-master/research/object_detection/g3doc/challenge_evaluation.md (deflated 76%)\n","  adding: content/models-master/research/object_detection/g3doc/img/ (stored 0%)\n","  adding: content/models-master/research/object_detection/g3doc/img/nongroupof_case_eval.png (deflated 0%)\n","  adding: content/models-master/research/object_detection/g3doc/img/tensorboard2.png (deflated 4%)\n","  adding: content/models-master/research/object_detection/g3doc/img/oxford_pet.png (deflated 0%)\n","  adding: content/models-master/research/object_detection/g3doc/img/dogs_detections_output.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/g3doc/img/kites_with_segment_overlay.png (deflated 0%)\n","  adding: content/models-master/research/object_detection/g3doc/img/groupof_case_eval.png (deflated 0%)\n","  adding: content/models-master/research/object_detection/g3doc/img/tf-od-api-logo.png (deflated 17%)\n","  adding: content/models-master/research/object_detection/g3doc/img/tensorboard.png (deflated 9%)\n","  adding: content/models-master/research/object_detection/g3doc/img/kites_detections_output.jpg (deflated 0%)\n","  adding: content/models-master/research/object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg (deflated 1%)\n","  adding: content/models-master/research/object_detection/g3doc/img/example_cat.jpg (deflated 2%)\n","  adding: content/models-master/research/object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg (deflated 3%)\n","  adding: content/models-master/research/object_detection/g3doc/tf1.md (deflated 61%)\n","  adding: content/models-master/research/object_detection/g3doc/tf1_detection_zoo.md (deflated 80%)\n","  adding: content/models-master/research/object_detection/g3doc/evaluation_protocols.md (deflated 68%)\n","  adding: content/models-master/research/object_detection/g3doc/exporting_models.md (deflated 53%)\n","  adding: content/models-master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md (deflated 64%)\n","  adding: content/models-master/research/object_detection/g3doc/tf2.md (deflated 58%)\n","  adding: content/models-master/research/object_detection/g3doc/tpu_exporters.md (deflated 46%)\n","  adding: content/models-master/research/object_detection/g3doc/tf2_classification_zoo.md (deflated 79%)\n","  adding: content/models-master/research/object_detection/g3doc/configuring_jobs.md (deflated 61%)\n","  adding: content/models-master/research/object_detection/g3doc/tf2_detection_zoo.md (deflated 83%)\n","  adding: content/models-master/research/object_detection/g3doc/oid_inference_and_evaluation.md (deflated 64%)\n","  adding: content/models-master/research/object_detection/g3doc/running_on_mobile_tf2.md (deflated 60%)\n","  adding: content/models-master/research/object_detection/g3doc/instance_segmentation.md (deflated 59%)\n","  adding: content/models-master/research/object_detection/g3doc/context_rcnn.md (deflated 65%)\n","  adding: content/models-master/research/object_detection/g3doc/running_pets.md (deflated 66%)\n","  adding: content/models-master/research/object_detection/g3doc/tf2_training_and_evaluation.md (deflated 74%)\n","  adding: content/models-master/research/object_detection/g3doc/preparing_inputs.md (deflated 69%)\n","  adding: content/models-master/research/object_detection/g3doc/running_notebook.md (deflated 53%)\n","  adding: content/models-master/research/object_detection/g3doc/defining_your_own_model.md (deflated 60%)\n","  adding: content/models-master/research/object_detection/g3doc/tpu_compatibility.md (deflated 65%)\n","  adding: content/models-master/research/object_detection/g3doc/tf1_training_and_evaluation.md (deflated 66%)\n","  adding: content/models-master/research/object_detection/g3doc/release_notes.md (deflated 63%)\n","  adding: content/models-master/research/object_detection/g3doc/using_your_own_dataset.md (deflated 67%)\n","  adding: content/models-master/research/object_detection/g3doc/faq.md (deflated 49%)\n","  adding: content/models-master/research/object_detection/model_lib_tf2_test.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/exporter_lib_tf2_test.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/CONTRIBUTING.md (deflated 48%)\n","  adding: content/models-master/research/object_detection/train.record (deflated 5%)\n","  adding: content/models-master/research/object_detection/protos/ (stored 0%)\n","  adding: content/models-master/research/object_detection/protos/string_int_label_map_pb2.py (deflated 83%)\n","  adding: content/models-master/research/object_detection/protos/keypoint_box_coder.proto (deflated 56%)\n","  adding: content/models-master/research/object_detection/protos/anchor_generator_pb2.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/protos/center_net_pb2.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/protos/box_predictor_pb2.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/protos/eval.proto (deflated 65%)\n","  adding: content/models-master/research/object_detection/protos/optimizer_pb2.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/protos/preprocessor_pb2.py (deflated 92%)\n","  adding: content/models-master/research/object_detection/protos/faster_rcnn_box_coder.proto (deflated 55%)\n","  adding: content/models-master/research/object_detection/protos/multiscale_anchor_generator_pb2.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/protos/matcher.proto (deflated 49%)\n","  adding: content/models-master/research/object_detection/protos/input_reader_pb2.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/protos/region_similarity_calculator.proto (deflated 63%)\n","  adding: content/models-master/research/object_detection/protos/center_net.proto (deflated 71%)\n","  adding: content/models-master/research/object_detection/protos/post_processing.proto (deflated 61%)\n","  adding: content/models-master/research/object_detection/protos/flexible_grid_anchor_generator_pb2.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/protos/box_predictor.proto (deflated 74%)\n","  adding: content/models-master/research/object_detection/protos/square_box_coder.proto (deflated 49%)\n","  adding: content/models-master/research/object_detection/protos/square_box_coder_pb2.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/protos/post_processing_pb2.py (deflated 84%)\n","  adding: content/models-master/research/object_detection/protos/train.proto (deflated 63%)\n","  adding: content/models-master/research/object_detection/protos/ssd_anchor_generator_pb2.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/protos/ssd.proto (deflated 67%)\n","  adding: content/models-master/research/object_detection/protos/mean_stddev_box_coder_pb2.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/protos/anchor_generator.proto (deflated 65%)\n","  adding: content/models-master/research/object_detection/protos/argmax_matcher.proto (deflated 59%)\n","  adding: content/models-master/research/object_detection/protos/model_pb2.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/preprocessor_pb2.cpython-36.pyc (deflated 79%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/box_predictor_pb2.cpython-36.pyc (deflated 74%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/ssd_anchor_generator_pb2.cpython-36.pyc (deflated 61%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/__init__.cpython-36.pyc (deflated 19%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/ssd_pb2.cpython-36.pyc (deflated 69%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/faster_rcnn_pb2.cpython-36.pyc (deflated 71%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/calibration_pb2.cpython-36.pyc (deflated 69%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/region_similarity_calculator_pb2.cpython-36.pyc (deflated 62%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/optimizer_pb2.cpython-36.pyc (deflated 72%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/input_reader_pb2.cpython-36.pyc (deflated 67%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/string_int_label_map_pb2.cpython-36.pyc (deflated 60%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/grid_anchor_generator_pb2.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/pipeline_pb2.cpython-36.pyc (deflated 59%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/matcher_pb2.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/image_resizer_pb2.cpython-36.pyc (deflated 68%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/square_box_coder_pb2.cpython-36.pyc (deflated 50%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/mean_stddev_box_coder_pb2.cpython-36.pyc (deflated 47%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/model_pb2.cpython-36.pyc (deflated 57%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/train_pb2.cpython-36.pyc (deflated 66%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/hyperparams_pb2.cpython-36.pyc (deflated 69%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/bipartite_matcher_pb2.cpython-36.pyc (deflated 47%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/fpn_pb2.cpython-36.pyc (deflated 59%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/center_net_pb2.cpython-36.pyc (deflated 74%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/faster_rcnn_box_coder_pb2.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/multiscale_anchor_generator_pb2.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/flexible_grid_anchor_generator_pb2.cpython-36.pyc (deflated 58%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/box_coder_pb2.cpython-36.pyc (deflated 59%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/eval_pb2.cpython-36.pyc (deflated 69%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/keypoint_box_coder_pb2.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/graph_rewriter_pb2.cpython-36.pyc (deflated 52%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/argmax_matcher_pb2.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/post_processing_pb2.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/anchor_generator_pb2.cpython-36.pyc (deflated 62%)\n","  adding: content/models-master/research/object_detection/protos/__pycache__/losses_pb2.cpython-36.pyc (deflated 73%)\n","  adding: content/models-master/research/object_detection/protos/fpn_pb2.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/protos/image_resizer.proto (deflated 69%)\n","  adding: content/models-master/research/object_detection/protos/string_int_label_map.proto (deflated 53%)\n","  adding: content/models-master/research/object_detection/protos/target_assigner_pb2.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/protos/input_reader.proto (deflated 65%)\n","  adding: content/models-master/research/object_detection/protos/faster_rcnn_pb2.py (deflated 88%)\n","  adding: content/models-master/research/object_detection/protos/faster_rcnn_box_coder_pb2.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/protos/box_coder_pb2.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/protos/optimizer.proto (deflated 73%)\n","  adding: content/models-master/research/object_detection/protos/fpn.proto (deflated 67%)\n","  adding: content/models-master/research/object_detection/protos/matcher_pb2.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/protos/calibration_pb2.py (deflated 88%)\n","  adding: content/models-master/research/object_detection/protos/mean_stddev_box_coder.proto (deflated 32%)\n","  adding: content/models-master/research/object_detection/protos/multiscale_anchor_generator.proto (deflated 50%)\n","  adding: content/models-master/research/object_detection/protos/graph_rewriter.proto (deflated 56%)\n","  adding: content/models-master/research/object_detection/protos/hyperparams_pb2.py (deflated 88%)\n","  adding: content/models-master/research/object_detection/protos/losses.proto (deflated 70%)\n","  adding: content/models-master/research/object_detection/protos/eval_pb2.py (deflated 88%)\n","  adding: content/models-master/research/object_detection/protos/train_pb2.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/protos/ssd_anchor_generator.proto (deflated 66%)\n","  adding: content/models-master/research/object_detection/protos/ssd_pb2.py (deflated 88%)\n","  adding: content/models-master/research/object_detection/protos/flexible_grid_anchor_generator.proto (deflated 60%)\n","  adding: content/models-master/research/object_detection/protos/grid_anchor_generator_pb2.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/protos/preprocessor.proto (deflated 78%)\n","  adding: content/models-master/research/object_detection/protos/model.proto (deflated 49%)\n","  adding: content/models-master/research/object_detection/protos/bipartite_matcher.proto (deflated 37%)\n","  adding: content/models-master/research/object_detection/protos/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/protos/bipartite_matcher_pb2.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/protos/losses_pb2.py (deflated 90%)\n","  adding: content/models-master/research/object_detection/protos/graph_rewriter_pb2.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/protos/target_assigner.proto (deflated 52%)\n","  adding: content/models-master/research/object_detection/protos/hyperparams.proto (deflated 69%)\n","  adding: content/models-master/research/object_detection/protos/pipeline.proto (deflated 57%)\n","  adding: content/models-master/research/object_detection/protos/pipeline_pb2.py (deflated 79%)\n","  adding: content/models-master/research/object_detection/protos/calibration.proto (deflated 67%)\n","  adding: content/models-master/research/object_detection/protos/grid_anchor_generator.proto (deflated 63%)\n","  adding: content/models-master/research/object_detection/protos/argmax_matcher_pb2.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/protos/keypoint_box_coder_pb2.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/protos/box_coder.proto (deflated 60%)\n","  adding: content/models-master/research/object_detection/protos/image_resizer_pb2.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/protos/faster_rcnn.proto (deflated 69%)\n","  adding: content/models-master/research/object_detection/protos/region_similarity_calculator_pb2.py (deflated 85%)\n","  adding: content/models-master/research/object_detection/export_inference_graph.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/Preparation/ (stored 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/ (stored 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/ (stored 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0278.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0235.JPEG (deflated 2%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0282.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0281.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0182.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0165.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0175.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0163.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0100.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0104.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0001.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0065.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0294.xml (deflated 64%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0011.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0015.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0299.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0145.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0071.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0237.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0032.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0204.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0214.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0281.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0217.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0210.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0176.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0276.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0025.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0019.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0271.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0105.xml (deflated 74%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0201.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0257.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0234.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0001.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0218.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0272.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0137.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0080.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0241.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0151.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0021.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0189.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0133.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0206.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0008.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0124.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0211.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0163.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0192.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0296.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0253.xml (deflated 69%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0202.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0135.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0277.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0241.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0180.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0219.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0285.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0048.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0064.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0170.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0013.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0084.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0110.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0166.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0262.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0220.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0067.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0006.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0040.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0133.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0024.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0069.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0161.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0025.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0124.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0083.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0099.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0048.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0228.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0220.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0259.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0178.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0071.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0040.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0147.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0177.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0052.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0075.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0233.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0248.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0020.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0046.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0228.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0184.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0226.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0202.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0185.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0043.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0034.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0258.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0233.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0198.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0118.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0255.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0269.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0108.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0197.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0186.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0191.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0195.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0184.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0279.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0120.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0207.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0239.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0093.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0159.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0145.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0259.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0223.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0136.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0157.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0052.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0268.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0161.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0190.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0221.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0129.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0073.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0194.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0199.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0130.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0253.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0195.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0114.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0024.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0301.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0012.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0076.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0027.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0106.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0279.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0146.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0117.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0090.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0085.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0016.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0154.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0055.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0138.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0138.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0051.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0141.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0171.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0151.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0263.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0231.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0053.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0051.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0298.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0174.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0109.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0045.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0069.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0146.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0168.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0054.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0049.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0020.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0193.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0286.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0252.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0095.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0198.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0190.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0131.xml (deflated 70%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0095.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0017.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0257.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0093.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0200.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0173.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0132.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0266.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0075.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0256.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0009.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0283.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0200.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0168.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0285.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0239.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0267.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0112.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0222.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0258.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0240.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0144.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0293.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0126.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0092.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0046.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0193.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0050.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0067.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0260.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0062.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0289.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0004.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0127.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0182.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0211.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0261.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0244.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0136.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0081.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0072.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0021.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0197.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0264.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0194.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0116.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0276.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0003.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0013.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0266.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0178.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0242.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0082.JPEG (deflated 4%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0120.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0172.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0141.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0043.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0251.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0246.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0140.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0243.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0035.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0068.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0074.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0262.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0044.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0129.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0272.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0292.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0292.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0015.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0143.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0061.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0229.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0268.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0066.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0033.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0174.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0111.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0107.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0031.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0099.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0019.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0298.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0028.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0156.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0031.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0109.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0041.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0189.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0086.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0008.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0210.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0045.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0110.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0050.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0022.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0273.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0250.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0208.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0014.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0209.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0005.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0227.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0246.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0054.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0287.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0230.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0207.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0208.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0009.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0123.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0139.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0088.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0077.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0271.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0062.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0097.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0274.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0152.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0284.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0123.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0089.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0205.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0238.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0002.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0196.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0038.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0294.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0018.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0295.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0149.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0167.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0103.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0121.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0086.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0295.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0187.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0072.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0212.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0096.xml (deflated 70%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0277.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0173.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0255.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0192.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0256.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0128.jpeg (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0058.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0217.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0280.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0106.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0096.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0179.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0300.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0148.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0245.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0169.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0170.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0131.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0111.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0183.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0070.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0085.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0235.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0006.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0057.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0056.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0291.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0125.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0232.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0299.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0252.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0297.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0055.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0236.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0142.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0143.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0084.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0150.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0098.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0164.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0249.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0260.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0206.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0216.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0209.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0160.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0215.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0218.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0128.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0203.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0222.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0134.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0291.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0223.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0205.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0065.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0162.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0044.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0149.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0227.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0297.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0037.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0005.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0061.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0301.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0122.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0126.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0118.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0064.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0079.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0003.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0104.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0127.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0154.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0254.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0155.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0289.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0107.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0169.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0066.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0116.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0274.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0122.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0070.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0288.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0059.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0155.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0060.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0004.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0092.xml (deflated 67%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0164.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0224.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0079.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0056.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0119.JPEG (deflated 2%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0275.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0057.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0293.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0027.JPEG (deflated 3%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0023.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0248.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0265.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0152.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0153.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0213.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0113.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0011.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0267.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0014.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0036.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0187.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0282.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0162.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0219.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0097.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0203.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0254.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0103.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0033.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0022.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0074.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0221.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0275.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0026.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0082.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0251.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0088.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0076.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0159.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0134.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0264.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0226.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0035.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0144.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0047.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0105.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0290.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0172.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0244.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0080.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0201.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0199.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0167.xml (deflated 64%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0030.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0115.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0142.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0181.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0073.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0029.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0204.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0042.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0286.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0153.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0247.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0098.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0032.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0290.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0270.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0238.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0117.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0101.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0269.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0102.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0216.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0176.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0245.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0150.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0108.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0284.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0273.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0039.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0039.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0300.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0007.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0188.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0224.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0112.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0077.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0029.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0249.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0158.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0094.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0283.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0023.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0261.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0078.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0017.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0083.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0230.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0049.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0212.xml (deflated 77%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0148.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0240.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0191.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0091.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0158.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0147.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0137.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0114.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0250.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0165.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0018.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0265.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0229.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0237.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0225.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0012.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0036.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0002.JPEG (stored 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0215.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0132.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0058.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0101.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0236.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0130.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0247.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0047.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0068.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0135.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0278.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0139.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0042.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0121.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0213.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0243.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0177.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0087.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0196.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0181.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0214.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0090.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0059.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0185.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0087.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0063.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0231.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0091.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0078.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0166.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0016.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0028.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0094.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0119.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0030.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0179.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0175.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0089.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0288.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0115.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0034.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0125.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0183.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0037.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0026.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0010.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0113.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0053.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0041.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0232.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0296.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0180.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0081.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0280.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0186.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0007.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0156.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0242.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0060.xml (deflated 57%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0188.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0010.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0157.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0171.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0038.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0063.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0140.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0263.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0160.xml (deflated 64%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0100.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0287.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0225.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0270.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0234.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train/0102.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/train_labels.csv (deflated 71%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test_labels.csv (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/ (stored 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0001.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0011.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0015.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0019.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0001.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0021.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0008.xml (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0013.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0006.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0024.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0025.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0020.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0024.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0012.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0027.xml (deflated 47%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0016.xml (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0020.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0017.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0027.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0009.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0004.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0021.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0003.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0013.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0015.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0019.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0028.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0008.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0022.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0014.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0005.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0009.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0002.xml (deflated 58%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0018.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0006.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0005.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0003.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0004.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0023.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0011.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0014.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0022.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0026.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0030.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0029.xml (deflated 59%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0007.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0029.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0023.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0017.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0018.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0012.xml (deflated 45%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0002.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0016.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0028.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0030.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0025.jpeg (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0026.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0010.JPEG (deflated 0%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0007.JPEG (deflated 1%)\n","  adding: content/models-master/research/object_detection/Preparation/images/test/0010.xml (deflated 46%)\n","  adding: content/models-master/research/object_detection/Preparation/labelmap.pbtxt (deflated 42%)\n","  adding: content/models-master/research/object_detection/Preparation/xml_to_csv.py (deflated 60%)\n","  adding: content/models-master/research/object_detection/Preparation/generate_tfrecord.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/Preparation/ssd_mobilenet_v2_quantized_300x300_coco.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/Preparation/train.py (deflated 67%)\n","  adding: content/models-master/research/object_detection/Preparation/train.record (deflated 5%)\n","  adding: content/models-master/research/object_detection/Preparation/test.record (deflated 4%)\n","  adding: content/models-master/research/object_detection/inputs.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/dataset_tools/ (stored 0%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_coco_tf_record.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/dataset_tools/oid_tfrecord_creation.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_kitti_tf_record_test.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_oid_tf_record.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_coco_tf_record_test.py (deflated 84%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_pascal_tf_record.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/ (stored 0%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/generate_detection_data.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/dataset_tools/tf_record_creation_util_test.py (deflated 52%)\n","  adding: content/models-master/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/dataset_tools/download_and_preprocess_ava.sh (deflated 51%)\n","  adding: content/models-master/research/object_detection/dataset_tools/seq_example_util_test.py (deflated 87%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_pascal_tf_record_test.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_pet_tf_record.py (deflated 69%)\n","  adding: content/models-master/research/object_detection/dataset_tools/download_and_preprocess_mscoco.sh (deflated 61%)\n","  adding: content/models-master/research/object_detection/dataset_tools/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/dataset_tools/densepose/ (stored 0%)\n","  adding: content/models-master/research/object_detection/dataset_tools/densepose/UV_symmetry_transforms.mat (deflated 96%)\n","  adding: content/models-master/research/object_detection/dataset_tools/seq_example_util.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_kitti_tf_record.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/dataset_tools/tf_record_creation_util.py (deflated 50%)\n","  adding: content/models-master/research/object_detection/dataset_tools/oid_tfrecord_creation_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_ava_actions_tf_record.py (deflated 74%)\n","  adding: content/models-master/research/object_detection/dataset_tools/create_pycocotools_package.sh (deflated 54%)\n","  adding: content/models-master/research/object_detection/legacy/ (stored 0%)\n","  adding: content/models-master/research/object_detection/legacy/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/legacy/__pycache__/__init__.cpython-36.pyc (deflated 19%)\n","  adding: content/models-master/research/object_detection/legacy/__pycache__/trainer.cpython-36.pyc (deflated 52%)\n","  adding: content/models-master/research/object_detection/legacy/train.py (deflated 66%)\n","  adding: content/models-master/research/object_detection/legacy/evaluator.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/legacy/trainer_tf1_test.py (deflated 71%)\n","  adding: content/models-master/research/object_detection/legacy/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/legacy/eval.py (deflated 66%)\n","  adding: content/models-master/research/object_detection/legacy/trainer.py (deflated 72%)\n","  adding: content/models-master/research/object_detection/exporter.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/model_graph.zip (stored 0%)\n","  adding: content/models-master/research/object_detection/samples/ (stored 0%)\n","  adding: content/models-master/research/object_detection/samples/configs/ (stored 0%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_inception_v2_coco.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobilenet_v3_small_320x320_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/samples/configs/rfcn_resnet101_coco.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/rfcn_resnet101_pets.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet50_coco.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet50_pets.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco_quant.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_inception_v3_pets.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config (deflated 69%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_coco.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_pets.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_pets.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobiledet_cpu_320x320_coco_sync_4x4.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet152_coco.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_nas_coco.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config (deflated 68%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet152_pets.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config (deflated 64%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobiledet_edgetpu_320x320_coco_sync_4x4.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_inception_v2_pets.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobiledet_gpu_320x320_coco_sync_4x4.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/mask_rcnn_resnet101_pets.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_kitti.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssdlite_mobiledet_dsp_320x320_coco_sync_4x4.config (deflated 66%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti_sync.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config (deflated 68%)\n","  adding: content/models-master/research/object_detection/samples/configs/faster_rcnn_resnet101_voc07.config (deflated 65%)\n","  adding: content/models-master/research/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config (deflated 68%)\n","  adding: content/models-master/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config (deflated 67%)\n","  adding: content/models-master/research/object_detection/samples/cloud/ (stored 0%)\n","  adding: content/models-master/research/object_detection/samples/cloud/cloud.yml (deflated 36%)\n","  adding: content/models-master/research/object_detection/test.record (deflated 4%)\n","  adding: content/models-master/research/object_detection/colab_tutorials/ (stored 0%)\n","  adding: content/models-master/research/object_detection/colab_tutorials/context_rcnn_tutorial.ipynb (deflated 30%)\n","  adding: content/models-master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tflite.ipynb (deflated 74%)\n","  adding: content/models-master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb (deflated 74%)\n","  adding: content/models-master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb (deflated 78%)\n","  adding: content/models-master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb (deflated 74%)\n","  adding: content/models-master/research/object_detection/colab_tutorials/inference_from_saved_model_tf2_colab.ipynb (deflated 74%)\n","  adding: content/models-master/research/object_detection/predictors/ (stored 0%)\n","  adding: content/models-master/research/object_detection/predictors/convolutional_box_predictor_tf1_test.py (deflated 91%)\n","  adding: content/models-master/research/object_detection/predictors/mask_rcnn_box_predictor.py (deflated 65%)\n","  adding: content/models-master/research/object_detection/predictors/heads/ (stored 0%)\n","  adding: content/models-master/research/object_detection/predictors/heads/keras_class_head_tf2_test.py (deflated 82%)\n","  adding: content/models-master/research/object_detection/predictors/heads/keras_mask_head_tf2_test.py (deflated 84%)\n","  adding: content/models-master/research/object_detection/predictors/heads/keypoint_head_tf1_test.py (deflated 56%)\n","  adding: content/models-master/research/object_detection/predictors/heads/keras_mask_head.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/predictors/heads/mask_head.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/predictors/heads/keypoint_head.py (deflated 64%)\n","  adding: content/models-master/research/object_detection/predictors/heads/keras_class_head.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/keras_class_head.cpython-36.pyc (deflated 66%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/class_head.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/__init__.cpython-36.pyc (deflated 18%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/box_head.cpython-36.pyc (deflated 61%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/mask_head.cpython-36.pyc (deflated 63%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/keras_mask_head.cpython-36.pyc (deflated 65%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/keras_box_head.cpython-36.pyc (deflated 64%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__pycache__/head.cpython-36.pyc (deflated 56%)\n","  adding: content/models-master/research/object_detection/predictors/heads/class_head.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/predictors/heads/class_head_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/predictors/heads/keras_box_head.py (deflated 78%)\n","  adding: content/models-master/research/object_detection/predictors/heads/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/predictors/heads/box_head.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/predictors/heads/mask_head_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/object_detection/predictors/heads/box_head_tf1_test.py (deflated 73%)\n","  adding: content/models-master/research/object_detection/predictors/heads/head.py (deflated 57%)\n","  adding: content/models-master/research/object_detection/predictors/heads/keras_box_head_tf2_test.py (deflated 81%)\n","  adding: content/models-master/research/object_detection/predictors/mask_rcnn_keras_box_predictor.py (deflated 63%)\n","  adding: content/models-master/research/object_detection/predictors/__pycache__/ (stored 0%)\n","  adding: content/models-master/research/object_detection/predictors/__pycache__/convolutional_box_predictor.cpython-36.pyc (deflated 62%)\n","  adding: content/models-master/research/object_detection/predictors/__pycache__/__init__.cpython-36.pyc (deflated 19%)\n","  adding: content/models-master/research/object_detection/predictors/__pycache__/rfcn_keras_box_predictor.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/object_detection/predictors/__pycache__/mask_rcnn_keras_box_predictor.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/object_detection/predictors/__pycache__/convolutional_keras_box_predictor.cpython-36.pyc (deflated 61%)\n","  adding: content/models-master/research/object_detection/predictors/__pycache__/mask_rcnn_box_predictor.cpython-36.pyc (deflated 55%)\n","  adding: content/models-master/research/object_detection/predictors/__pycache__/rfcn_box_predictor.cpython-36.pyc (deflated 53%)\n","  adding: content/models-master/research/object_detection/predictors/rfcn_keras_box_predictor.py (deflated 70%)\n","  adding: content/models-master/research/object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py (deflated 75%)\n","  adding: content/models-master/research/object_detection/predictors/rfcn_box_predictor_tf1_test.py (deflated 60%)\n","  adding: content/models-master/research/object_detection/predictors/rfcn_box_predictor.py (deflated 68%)\n","  adding: content/models-master/research/object_detection/predictors/convolutional_box_predictor.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py (deflated 92%)\n","  adding: content/models-master/research/object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py (deflated 76%)\n","  adding: content/models-master/research/object_detection/predictors/__init__.py (stored 0%)\n","  adding: content/models-master/research/object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py (deflated 60%)\n","  adding: content/models-master/research/object_detection/predictors/convolutional_keras_box_predictor.py (deflated 77%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/ (stored 0%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/tflite_graph.pbtxt (deflated 57%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt.data-00000-of-00001 (deflated 7%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/pipeline.config (deflated 68%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt.meta (deflated 94%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt.index (deflated 73%)\n","  adding: content/models-master/research/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/tflite_graph.pb (deflated 9%)\n","  adding: content/models-master/research/object_detection/exporter_main_v2.py (deflated 68%)\n","  adding: content/models-master/research/object_detection/exporter_tf1_test.py (deflated 90%)\n","  adding: content/models-master/research/adversarial_text/ (stored 0%)\n","  adding: content/models-master/research/adversarial_text/gen_vocab.py (deflated 58%)\n","  adding: content/models-master/research/adversarial_text/data/ (stored 0%)\n","  adding: content/models-master/research/adversarial_text/data/document_generators.py (deflated 74%)\n","  adding: content/models-master/research/adversarial_text/data/data_utils_test.py (deflated 75%)\n","  adding: content/models-master/research/adversarial_text/data/__init__.py (stored 0%)\n","  adding: content/models-master/research/adversarial_text/data/data_utils.py (deflated 70%)\n","  adding: content/models-master/research/adversarial_text/README.md (deflated 66%)\n","  adding: content/models-master/research/adversarial_text/evaluate.py (deflated 61%)\n","  adding: content/models-master/research/adversarial_text/graphs_test.py (deflated 67%)\n","  adding: content/models-master/research/adversarial_text/train_utils.py (deflated 63%)\n","  adding: content/models-master/research/adversarial_text/train_classifier.py (deflated 53%)\n","  adding: content/models-master/research/adversarial_text/adversarial_losses.py (deflated 69%)\n","  adding: content/models-master/research/adversarial_text/pretrain.py (deflated 46%)\n","  adding: content/models-master/research/adversarial_text/layers.py (deflated 69%)\n","  adding: content/models-master/research/adversarial_text/graphs.py (deflated 78%)\n","  adding: content/models-master/research/adversarial_text/gen_data.py (deflated 71%)\n","  adding: content/models-master/research/adversarial_text/__init__.py (stored 0%)\n","  adding: content/models-master/research/adversarial_text/inputs.py (deflated 72%)\n","  adding: content/models-master/research/nst_blogpost/ (stored 0%)\n","  adding: content/models-master/research/nst_blogpost/The_Great_Wave_off_Kanagawa.jpg (deflated 0%)\n","  adding: content/models-master/research/nst_blogpost/wave_turtle.png (deflated 0%)\n","  adding: content/models-master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb (deflated 77%)\n","  adding: content/models-master/research/nst_blogpost/Green_Sea_Turtle_grazing_seagrass.jpg (deflated 1%)\n","  adding: content/models-master/research/efficient-hrl/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/run_train.py (deflated 49%)\n","  adding: content/models-master/research/efficient-hrl/run_env.py (deflated 62%)\n","  adding: content/models-master/research/efficient-hrl/scripts/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/scripts/local_train.py (deflated 58%)\n","  adding: content/models-master/research/efficient-hrl/scripts/local_eval.py (deflated 59%)\n","  adding: content/models-master/research/efficient-hrl/agent.py (deflated 78%)\n","  adding: content/models-master/research/efficient-hrl/README.md (deflated 54%)\n","  adding: content/models-master/research/efficient-hrl/run_eval.py (deflated 51%)\n","  adding: content/models-master/research/efficient-hrl/context/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/context/context.py (deflated 73%)\n","  adding: content/models-master/research/efficient-hrl/context/rewards_functions.py (deflated 86%)\n","  adding: content/models-master/research/efficient-hrl/context/gin_utils.py (deflated 50%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_maze_img.gin (deflated 71%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/hiro_orig.gin (deflated 46%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_fall_single.gin (deflated 68%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/default.gin (deflated 29%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_block_maze.gin (deflated 69%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/point_maze.gin (deflated 69%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_block.gin (deflated 69%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/hiro_xy.gin (deflated 32%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/hiro_repr.gin (deflated 43%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_push_single.gin (deflated 68%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_maze.gin (deflated 69%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_push_multi.gin (deflated 68%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_fall_multi_img.gin (deflated 70%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_fall_multi.gin (deflated 68%)\n","  adding: content/models-master/research/efficient-hrl/context/configs/ant_push_multi_img.gin (deflated 70%)\n","  adding: content/models-master/research/efficient-hrl/context/samplers.py (deflated 78%)\n","  adding: content/models-master/research/efficient-hrl/context/gin_imports.py (deflated 50%)\n","  adding: content/models-master/research/efficient-hrl/context/context_transition_functions.py (deflated 66%)\n","  adding: content/models-master/research/efficient-hrl/context/__init__.py (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/train_utils.py (deflated 68%)\n","  adding: content/models-master/research/efficient-hrl/train.py (deflated 77%)\n","  adding: content/models-master/research/efficient-hrl/environments/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/environments/create_maze_env.py (deflated 61%)\n","  adding: content/models-master/research/efficient-hrl/environments/ant_maze_env.py (deflated 44%)\n","  adding: content/models-master/research/efficient-hrl/environments/point.py (deflated 57%)\n","  adding: content/models-master/research/efficient-hrl/environments/assets/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/environments/assets/ant.xml (deflated 78%)\n","  adding: content/models-master/research/efficient-hrl/environments/point_maze_env.py (deflated 44%)\n","  adding: content/models-master/research/efficient-hrl/environments/ant.py (deflated 62%)\n","  adding: content/models-master/research/efficient-hrl/environments/maze_env_utils.py (deflated 62%)\n","  adding: content/models-master/research/efficient-hrl/environments/maze_env.py (deflated 76%)\n","  adding: content/models-master/research/efficient-hrl/environments/__init__.py (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/agents/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/agents/circular_buffer.py (deflated 72%)\n","  adding: content/models-master/research/efficient-hrl/agents/ddpg_agent.py (deflated 83%)\n","  adding: content/models-master/research/efficient-hrl/agents/__init__.py (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/agents/ddpg_networks.py (deflated 71%)\n","  adding: content/models-master/research/efficient-hrl/cond_fn.py (deflated 79%)\n","  adding: content/models-master/research/efficient-hrl/configs/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/configs/train_uvf.gin (deflated 70%)\n","  adding: content/models-master/research/efficient-hrl/configs/eval_uvf.gin (deflated 48%)\n","  adding: content/models-master/research/efficient-hrl/configs/base_uvf.gin (deflated 71%)\n","  adding: content/models-master/research/efficient-hrl/utils/ (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/utils/eval_utils.py (deflated 68%)\n","  adding: content/models-master/research/efficient-hrl/utils/__init__.py (stored 0%)\n","  adding: content/models-master/research/efficient-hrl/utils/utils.py (deflated 66%)\n","  adding: content/models-master/research/efficient-hrl/eval.py (deflated 72%)\n","  adding: content/models-master/research/build/ (stored 0%)\n","  adding: content/models-master/research/build/bdist.linux-x86_64/ (stored 0%)\n","  adding: content/models-master/research/build/lib/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/export_tflite_ssd_graph_lib.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/export_tflite_graph_lib_tf2.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/eval_util.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/export_tflite_graph_tf2.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/model_lib.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/data_decoders/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/data_decoders/tf_example_decoder_test.py (deflated 92%)\n","  adding: content/models-master/research/build/lib/object_detection/data_decoders/tf_sequence_example_decoder_test.py (deflated 84%)\n","  adding: content/models-master/research/build/lib/object_detection/data_decoders/tf_sequence_example_decoder.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/data_decoders/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/data_decoders/tf_example_decoder.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/export_tflite_graph_lib_tf2_test.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/core/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/core/batch_multiclass_nms_test.py (deflated 91%)\n","  adding: content/models-master/research/build/lib/object_detection/core/post_processing.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/core/class_agnostic_nms_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/core/freezable_batch_norm.py (deflated 54%)\n","  adding: content/models-master/research/build/lib/object_detection/core/batcher.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/core/keypoint_ops.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/core/matcher.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/core/keypoint_ops_test.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/core/data_parser.py (deflated 52%)\n","  adding: content/models-master/research/build/lib/object_detection/core/prefetcher.py (deflated 58%)\n","  adding: content/models-master/research/build/lib/object_detection/core/box_predictor.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/core/prefetcher_tf1_test.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/core/region_similarity_calculator.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/core/box_list_test.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/core/box_coder.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/core/box_coder_test.py (deflated 56%)\n","  adding: content/models-master/research/build/lib/object_detection/core/anchor_generator.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/core/data_decoder.py (deflated 50%)\n","  adding: content/models-master/research/build/lib/object_detection/core/minibatch_sampler.py (deflated 59%)\n","  adding: content/models-master/research/build/lib/object_detection/core/losses.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/core/balanced_positive_negative_sampler_test.py (deflated 84%)\n","  adding: content/models-master/research/build/lib/object_detection/core/box_list.py (deflated 66%)\n","  adding: content/models-master/research/build/lib/object_detection/core/batcher_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/core/region_similarity_calculator_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/core/box_list_ops_test.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/core/losses_test.py (deflated 92%)\n","  adding: content/models-master/research/build/lib/object_detection/core/densepose_ops_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/core/matcher_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/core/minibatch_sampler_test.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/core/balanced_positive_negative_sampler.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/core/target_assigner_test.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/core/box_list_ops.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/core/preprocessor_cache.py (deflated 62%)\n","  adding: content/models-master/research/build/lib/object_detection/core/model.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/core/densepose_ops.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/core/freezable_batch_norm_tf2_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/core/preprocessor.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/core/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/core/multiclass_nms_test.py (deflated 89%)\n","  adding: content/models-master/research/build/lib/object_detection/core/standard_fields.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/core/model_test.py (deflated 60%)\n","  adding: content/models-master/research/build/lib/object_detection/core/target_assigner.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/core/preprocessor_test.py (deflated 91%)\n","  adding: content/models-master/research/build/lib/object_detection/export_tflite_ssd_graph.py (deflated 64%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/grid_anchor_generator_test.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/grid_anchor_generator.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator.py (deflated 66%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/utils_test.py (deflated 58%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/faster_rcnn.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib_tf1_test.py (deflated 56%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/export_saved_model_tpu.py (deflated 56%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/ssd.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/utils.py (deflated 54%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/testdata/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/tpu_exporters/testdata/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/model_lib_tf1_test.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/faster_rcnn_box_coder.py (deflated 61%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/faster_rcnn_box_coder_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/keypoint_box_coder.py (deflated 68%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/mean_stddev_box_coder.py (deflated 62%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/square_box_coder.py (deflated 61%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/keypoint_box_coder_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/square_box_coder_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/box_coders/mean_stddev_box_coder_test.py (deflated 64%)\n","  adding: content/models-master/research/build/lib/object_detection/model_hparams.py (deflated 52%)\n","  adding: content/models-master/research/build/lib/object_detection/export_tflite_ssd_graph_lib_tf1_test.py (deflated 84%)\n","  adding: content/models-master/research/build/lib/object_detection/model_lib_v2.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/oid_vrd_challenge_evaluation.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/coco_tools_test.py (deflated 84%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/lvis_evaluation.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/oid_challenge_evaluation.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/oid_challenge_evaluation_utils.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/coco_evaluation_test.py (deflated 93%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/coco_tools.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/calibration_metrics_tf1_test.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/tf_example_parser.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/coco_evaluation.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/io_utils.py (deflated 47%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/lvis_evaluation_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/lvis_tools_test.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/offline_eval_map_corloc.py (deflated 64%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/calibration_evaluation.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/calibration_metrics.py (deflated 61%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/calibration_evaluation_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/lvis_tools.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/offline_eval_map_corloc_test.py (deflated 66%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/oid_challenge_evaluation_utils_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/metrics/tf_example_parser_test.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/matchers/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/matchers/argmax_matcher_test.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/matchers/hungarian_matcher_tf2_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/matchers/argmax_matcher.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/matchers/bipartite_matcher_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/matchers/hungarian_matcher.py (deflated 55%)\n","  adding: content/models-master/research/build/lib/object_detection/matchers/bipartite_matcher.py (deflated 58%)\n","  adding: content/models-master/research/build/lib/object_detection/matchers/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_resnet_keras_feature_extractor.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_mobilenet_v2_feature_extractor.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_hourglass_feature_extractor.py (deflated 60%)\n","  adding: content/models-master/research/build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_tf1_test.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf1_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py (deflated 62%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_mobilenet_v2_feature_extractor_tf2_test.py (deflated 52%)\n","  adding: content/models-master/research/build/lib/object_detection/models/bidirectional_feature_pyramid_generators_tf2_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_pnasnet_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_tf1_test.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_feature_extractor_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_inception_v2_feature_extractor_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor_tf1_test.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf2_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_efficientnet_bifpn_feature_extractor_tf2_test.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_resnet_v1_fpn_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_resnet_keras_feature_extractor_tf2_test.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_pnasnet_feature_extractor_tf1_test.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor_tf1_test.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf2_test.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_tf2_test.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_nas_feature_extractor_tf1_test.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_inception_v3_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_inception_v3_feature_extractor_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_resnet_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobiledet_feature_extractor.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor_tf1_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_nas_feature_extractor.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_tf1_test.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor_tf2_test.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_tf1_test.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_mobilenet_v2_fpn_feature_extractor_tf2_test.py (deflated 52%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_tf1_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_resnet_v1_fpn_feature_extractor_tf2_test.py (deflated 53%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_inception_v2_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/build/lib/object_detection/models/feature_map_generators_test.py (deflated 88%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/mobilenet_v1.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/model_utils.py (deflated 52%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/resnet_v1_tf2_test.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/convert_keras_models.py (deflated 57%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/mobilenet_v1_tf2_test.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/inception_resnet_v2.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/mobilenet_v2.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/mobilenet_v2_tf2_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/hourglass_network_tf2_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/resnet_v1.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/hourglass_network.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/test_utils.py (deflated 86%)\n","  adding: content/models-master/research/build/lib/object_detection/models/keras_models/inception_resnet_v2_tf2_test.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/models/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/models/bidirectional_feature_pyramid_generators.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_tf2_test.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/models/feature_map_generators.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_tf1_test.py (deflated 59%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_tf2_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_resnet_feature_extractor_tf2_test.py (deflated 59%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v2_mnasfpn_feature_extractor.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_tf1_test.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_resnet_v1_fpn_keras_feature_extractor.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py (deflated 61%)\n","  adding: content/models-master/research/build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/models/center_net_hourglass_feature_extractor_tf2_test.py (deflated 52%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobiledet_feature_extractor_tf1_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_efficientnet_bifpn_feature_extractor.py (deflated 91%)\n","  adding: content/models-master/research/build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_tf2_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/eval_util_test.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/inference/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/inference/infer_detections.py (deflated 61%)\n","  adding: content/models-master/research/build/lib/object_detection/inference/detection_inference.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/inference/detection_inference_tf1_test.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/inference/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/input_reader_builder_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/model_builder_tf1_test.py (deflated 57%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/optimizer_builder_tf2_test.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/model_builder_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/hyperparams_builder.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/box_predictor_builder.py (deflated 88%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/graph_rewriter_builder_tf1_test.py (deflated 66%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/post_processing_builder_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/hyperparams_builder_test.py (deflated 92%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/region_similarity_calculator_builder_test.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/calibration_builder_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/model_builder.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/losses_builder.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/target_assigner_builder_test.py (deflated 56%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/optimizer_builder.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/box_predictor_builder_test.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/model_builder_tf2_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/matcher_builder_test.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/decoder_builder_test.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/input_reader_builder.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/optimizer_builder_tf1_test.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/dataset_builder.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/dataset_builder_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/anchor_generator_builder.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/graph_rewriter_builder.py (deflated 55%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/preprocessor_builder.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/calibration_builder.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/image_resizer_builder.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/region_similarity_calculator_builder.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/box_coder_builder_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/post_processing_builder.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/matcher_builder.py (deflated 61%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/anchor_generator_builder_test.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/box_coder_builder.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/losses_builder_test.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/preprocessor_builder_test.py (deflated 89%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/image_resizer_builder_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/target_assigner_builder.py (deflated 60%)\n","  adding: content/models-master/research/build/lib/object_detection/builders/decoder_builder.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/model_main_tf2.py (deflated 62%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_mask_list_test.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/static_shape.py (deflated 66%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/per_image_vrd_evaluation.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/per_image_evaluation_test.py (deflated 92%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/dataset_util.py (deflated 58%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/patch_ops_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/label_map_util.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/label_map_util_test.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/vrd_evaluation.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_mask_ops.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/json_utils.py (deflated 60%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_list_ops.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_list.py (deflated 64%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/category_util.py (deflated 56%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/spatial_transform_ops.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/variables_helper.py (deflated 68%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/model_util_tf2_test.py (deflated 56%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/target_assigner_utils.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/colab_utils.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_list_ops_test.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/test_case.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_mask_list_ops.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/model_util.py (deflated 64%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/category_util_test.py (deflated 59%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/variables_helper_tf1_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/metrics_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/context_manager.py (deflated 48%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_mask_list.py (deflated 57%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/config_util.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/visualization_utils.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/ops_test.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/ops.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_mask_list_ops_test.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/vrd_evaluation_test.py (deflated 86%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/learning_schedules.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/json_utils_test.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/shape_utils.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/static_shape_test.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/learning_schedules_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/target_assigner_utils_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/spatial_transform_ops_test.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/patch_ops.py (deflated 60%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/context_manager_test.py (deflated 49%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/visualization_utils_test.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_ops_test.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/test_case_test.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/shape_utils_test.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/bifpn_utils.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/test_utils_test.py (deflated 66%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/config_util_test.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/metrics.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/object_detection_evaluation_test.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/per_image_evaluation.py (deflated 84%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_ops.py (deflated 67%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/tf_version.py (deflated 48%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/dataset_util_test.py (deflated 50%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/object_detection_evaluation.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/test_utils.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/per_image_vrd_evaluation_test.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_mask_ops_test.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/np_box_list_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/utils/autoaugment_utils.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/rfcn_meta_arch.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/ssd_meta_arch_test.py (deflated 86%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py (deflated 86%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/center_net_meta_arch_tf2_test.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/context_rcnn_lib_tf1_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/context_rcnn_meta_arch.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/center_net_meta_arch.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/context_rcnn_meta_arch_test.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/context_rcnn_lib_tf2_test.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/rfcn_meta_arch_test.py (deflated 61%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/ssd_meta_arch.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/context_rcnn_lib_tf2.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/context_rcnn_lib.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/meta_architectures/ssd_meta_arch_test_lib.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/exporter_lib_v2.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/inputs_test.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/model_tpu_main.py (deflated 64%)\n","  adding: content/models-master/research/build/lib/object_detection/model_main.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/model_lib_tf2_test.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/exporter_lib_tf2_test.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/string_int_label_map_pb2.py (deflated 83%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/anchor_generator_pb2.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/center_net_pb2.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/box_predictor_pb2.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/optimizer_pb2.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/preprocessor_pb2.py (deflated 92%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/multiscale_anchor_generator_pb2.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/input_reader_pb2.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/flexible_grid_anchor_generator_pb2.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/square_box_coder_pb2.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/post_processing_pb2.py (deflated 84%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/ssd_anchor_generator_pb2.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/mean_stddev_box_coder_pb2.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/model_pb2.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/fpn_pb2.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/target_assigner_pb2.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/faster_rcnn_pb2.py (deflated 88%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/faster_rcnn_box_coder_pb2.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/box_coder_pb2.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/matcher_pb2.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/calibration_pb2.py (deflated 88%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/hyperparams_pb2.py (deflated 88%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/eval_pb2.py (deflated 88%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/train_pb2.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/ssd_pb2.py (deflated 88%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/grid_anchor_generator_pb2.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/bipartite_matcher_pb2.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/losses_pb2.py (deflated 90%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/graph_rewriter_pb2.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/pipeline_pb2.py (deflated 79%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/argmax_matcher_pb2.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/keypoint_box_coder_pb2.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/image_resizer_pb2.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/protos/region_similarity_calculator_pb2.py (deflated 85%)\n","  adding: content/models-master/research/build/lib/object_detection/export_inference_graph.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/inputs.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_coco_tf_record.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/oid_tfrecord_creation.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_kitti_tf_record_test.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_oid_tf_record.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_coco_tf_record_test.py (deflated 84%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_pascal_tf_record.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/generate_detection_data.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/add_context_to_examples_tf2_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/generate_embedding_data_tf2_test.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_tf2_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/context_rcnn/generate_detection_data_tf2_test.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/tf_record_creation_util_test.py (deflated 52%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/seq_example_util_test.py (deflated 87%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_pascal_tf_record_test.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_pet_tf_record.py (deflated 69%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/seq_example_util.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_kitti_tf_record.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/tf_record_creation_util.py (deflated 50%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/oid_tfrecord_creation_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/dataset_tools/create_ava_actions_tf_record.py (deflated 74%)\n","  adding: content/models-master/research/build/lib/object_detection/legacy/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/legacy/train.py (deflated 66%)\n","  adding: content/models-master/research/build/lib/object_detection/legacy/evaluator.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/legacy/trainer_tf1_test.py (deflated 71%)\n","  adding: content/models-master/research/build/lib/object_detection/legacy/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/legacy/eval.py (deflated 66%)\n","  adding: content/models-master/research/build/lib/object_detection/legacy/trainer.py (deflated 72%)\n","  adding: content/models-master/research/build/lib/object_detection/exporter.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/convolutional_box_predictor_tf1_test.py (deflated 91%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/mask_rcnn_box_predictor.py (deflated 65%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/ (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/keras_class_head_tf2_test.py (deflated 82%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/keras_mask_head_tf2_test.py (deflated 84%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/keypoint_head_tf1_test.py (deflated 56%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/keras_mask_head.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/mask_head.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/keypoint_head.py (deflated 64%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/keras_class_head.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/class_head.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/class_head_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/keras_box_head.py (deflated 78%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/box_head.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/mask_head_tf1_test.py (deflated 80%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/box_head_tf1_test.py (deflated 73%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/head.py (deflated 57%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/heads/keras_box_head_tf2_test.py (deflated 81%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor.py (deflated 63%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/rfcn_keras_box_predictor.py (deflated 70%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor_tf2_test.py (deflated 75%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/rfcn_box_predictor_tf1_test.py (deflated 60%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/rfcn_box_predictor.py (deflated 68%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/convolutional_box_predictor.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/convolutional_keras_box_predictor_tf2_test.py (deflated 92%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/mask_rcnn_box_predictor_tf1_test.py (deflated 76%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/__init__.py (stored 0%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/rfcn_keras_box_predictor_tf2_test.py (deflated 60%)\n","  adding: content/models-master/research/build/lib/object_detection/predictors/convolutional_keras_box_predictor.py (deflated 77%)\n","  adding: content/models-master/research/build/lib/object_detection/exporter_main_v2.py (deflated 68%)\n","  adding: content/models-master/research/build/lib/object_detection/exporter_tf1_test.py (deflated 90%)\n","  adding: content/models-master/research/lfads/ (stored 0%)\n","  adding: content/models-master/research/lfads/plot_lfads.py (deflated 69%)\n","  adding: content/models-master/research/lfads/run_lfads.py (deflated 69%)\n","  adding: content/models-master/research/lfads/README.md (deflated 66%)\n","  adding: content/models-master/research/lfads/synth_data/ (stored 0%)\n","  adding: content/models-master/research/lfads/synth_data/generate_labeled_rnn_data.py (deflated 65%)\n","  adding: content/models-master/research/lfads/synth_data/trained_itb/ (stored 0%)\n","  adding: content/models-master/research/lfads/synth_data/trained_itb/model-65000.meta (deflated 93%)\n","  adding: content/models-master/research/lfads/synth_data/trained_itb/model-65000.index (deflated 32%)\n","  adding: content/models-master/research/lfads/synth_data/trained_itb/model-65000.data-00000-of-00001 (deflated 8%)\n","  adding: content/models-master/research/lfads/synth_data/generate_itb_data.py (deflated 67%)\n","  adding: content/models-master/research/lfads/synth_data/generate_chaotic_rnn_data.py (deflated 63%)\n","  adding: content/models-master/research/lfads/synth_data/synthetic_data_utils.py (deflated 63%)\n","  adding: content/models-master/research/lfads/synth_data/run_generate_synth_data.sh (deflated 73%)\n","  adding: content/models-master/research/lfads/distributions.py (deflated 73%)\n","  adding: content/models-master/research/lfads/utils.py (deflated 71%)\n","  adding: content/models-master/research/lfads/lfads.py (deflated 78%)\n","  adding: content/models-master/research/delf/ (stored 0%)\n","  adding: content/models-master/research/delf/EXTRACTION_MATCHING.md (deflated 58%)\n","  adding: content/models-master/research/delf/README.md (deflated 67%)\n","  adding: content/models-master/research/delf/DETECTION.md (deflated 53%)\n","  adding: content/models-master/research/delf/delf/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/__init__.py (deflated 61%)\n","  adding: content/models-master/research/delf/delf/protos/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/protos/datum.proto (deflated 59%)\n","  adding: content/models-master/research/delf/delf/protos/aggregation_config.proto (deflated 59%)\n","  adding: content/models-master/research/delf/delf/protos/delf_config.proto (deflated 67%)\n","  adding: content/models-master/research/delf/delf/protos/__init__.py (stored 0%)\n","  adding: content/models-master/research/delf/delf/protos/box.proto (deflated 44%)\n","  adding: content/models-master/research/delf/delf/protos/feature.proto (deflated 48%)\n","  adding: content/models-master/research/delf/delf/python/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/feature_io_test.py (deflated 71%)\n","  adding: content/models-master/research/delf/delf/python/training/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/training/matched_images_demo.png (deflated 1%)\n","  adding: content/models-master/research/delf/delf/python/training/download_dataset.sh (deflated 67%)\n","  adding: content/models-master/research/delf/delf/python/training/README.md (deflated 66%)\n","  adding: content/models-master/research/delf/delf/python/training/install_delf.sh (deflated 67%)\n","  adding: content/models-master/research/delf/delf/python/training/model/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/training/model/delf_model.py (deflated 70%)\n","  adding: content/models-master/research/delf/delf/python/training/model/export_local_and_global_model.py (deflated 67%)\n","  adding: content/models-master/research/delf/delf/python/training/model/export_global_model.py (deflated 69%)\n","  adding: content/models-master/research/delf/delf/python/training/model/resnet50.py (deflated 75%)\n","  adding: content/models-master/research/delf/delf/python/training/model/export_model_utils.py (deflated 77%)\n","  adding: content/models-master/research/delf/delf/python/training/model/resnet50_test.py (deflated 54%)\n","  adding: content/models-master/research/delf/delf/python/training/model/delf_model_test.py (deflated 64%)\n","  adding: content/models-master/research/delf/delf/python/training/model/__init__.py (deflated 53%)\n","  adding: content/models-master/research/delf/delf/python/training/model/delg_model.py (deflated 69%)\n","  adding: content/models-master/research/delf/delf/python/training/model/export_local_model.py (deflated 62%)\n","  adding: content/models-master/research/delf/delf/python/training/train.py (deflated 73%)\n","  adding: content/models-master/research/delf/delf/python/training/__init__.py (deflated 47%)\n","  adding: content/models-master/research/delf/delf/python/training/datasets/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/training/datasets/googlelandmarks.py (deflated 65%)\n","  adding: content/models-master/research/delf/delf/python/training/datasets/__init__.py (deflated 47%)\n","  adding: content/models-master/research/delf/delf/python/training/build_image_dataset.py (deflated 72%)\n","  adding: content/models-master/research/delf/delf/python/utils_test.py (deflated 75%)\n","  adding: content/models-master/research/delf/delf/python/feature_aggregation_extractor.py (deflated 77%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/extract_index_boxes_and_features.py (deflated 64%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/cluster_delf_features.py (deflated 62%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/image_reranking.py (deflated 71%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/perform_retrieval.py (deflated 72%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/extract_query_features.py (deflated 61%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/dataset_test.py (deflated 78%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/delf_gld_config.pbtxt (deflated 53%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/aggregation_extraction.py (deflated 68%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/DETECT_TO_RETRIEVE_INSTRUCTIONS.md (deflated 73%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/dataset.py (deflated 74%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/query_aggregation_config.pbtxt (deflated 32%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/boxes_and_features_extraction.py (deflated 67%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/__init__.py (deflated 51%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/extract_aggregation.py (deflated 61%)\n","  adding: content/models-master/research/delf/delf/python/detect_to_retrieve/index_aggregation_config.pbtxt (deflated 34%)\n","  adding: content/models-master/research/delf/delf/python/feature_aggregation_similarity_test.py (deflated 77%)\n","  adding: content/models-master/research/delf/delf/python/box_io.py (deflated 72%)\n","  adding: content/models-master/research/delf/delf/python/feature_extractor_test.py (deflated 59%)\n","  adding: content/models-master/research/delf/delf/python/delg/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/delg/r50delg_gldv2clean_config.pbtxt (deflated 54%)\n","  adding: content/models-master/research/delf/delf/python/delg/r50delg_gld_config.pbtxt (deflated 55%)\n","  adding: content/models-master/research/delf/delf/python/delg/perform_retrieval.py (deflated 71%)\n","  adding: content/models-master/research/delf/delf/python/delg/DELG_INSTRUCTIONS.md (deflated 68%)\n","  adding: content/models-master/research/delf/delf/python/delg/r101delg_gldv2clean_config.pbtxt (deflated 54%)\n","  adding: content/models-master/research/delf/delf/python/delg/r101delg_gld_config.pbtxt (deflated 54%)\n","  adding: content/models-master/research/delf/delf/python/delg/extract_features.py (deflated 64%)\n","  adding: content/models-master/research/delf/delf/python/delg/measure_latency.py (deflated 58%)\n","  adding: content/models-master/research/delf/delf/python/datum_io_test.py (deflated 68%)\n","  adding: content/models-master/research/delf/delf/python/examples/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/examples/detection_example_1.jpg (deflated 3%)\n","  adding: content/models-master/research/delf/delf/python/examples/match_images.py (deflated 62%)\n","  adding: content/models-master/research/delf/delf/python/examples/delf_config_example.pbtxt (deflated 53%)\n","  adding: content/models-master/research/delf/delf/python/examples/extractor.py (deflated 75%)\n","  adding: content/models-master/research/delf/delf/python/examples/detector.py (deflated 52%)\n","  adding: content/models-master/research/delf/delf/python/examples/matched_images_example.jpg (deflated 0%)\n","  adding: content/models-master/research/delf/delf/python/examples/detection_example_2.jpg (deflated 2%)\n","  adding: content/models-master/research/delf/delf/python/examples/extract_boxes.py (deflated 64%)\n","  adding: content/models-master/research/delf/delf/python/examples/extract_features.py (deflated 60%)\n","  adding: content/models-master/research/delf/delf/python/examples/__init__.py (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/feature_aggregation_similarity.py (deflated 74%)\n","  adding: content/models-master/research/delf/delf/python/box_io_test.py (deflated 62%)\n","  adding: content/models-master/research/delf/delf/python/datum_io.py (deflated 73%)\n","  adding: content/models-master/research/delf/delf/python/feature_io.py (deflated 77%)\n","  adding: content/models-master/research/delf/delf/python/__init__.py (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/feature_aggregation_extractor_test.py (deflated 89%)\n","  adding: content/models-master/research/delf/delf/python/utils.py (deflated 60%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/ (stored 0%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/dataset_file_io_test.py (deflated 78%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/dataset_file_io.py (deflated 69%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/compute_recognition_metrics.py (deflated 66%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/README.md (deflated 64%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/compute_retrieval_metrics.py (deflated 68%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/metrics_test.py (deflated 79%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/metrics.py (deflated 75%)\n","  adding: content/models-master/research/delf/delf/python/google_landmarks_dataset/rn101_af_gldv2clean_config.pbtxt (deflated 35%)\n","  adding: content/models-master/research/delf/delf/python/feature_extractor.py (deflated 68%)\n","  adding: content/models-master/research/delf/setup.py (deflated 47%)\n","  adding: content/models-master/research/delf/INSTALL_INSTRUCTIONS.md (deflated 64%)\n","  adding: content/models-master/research/delf/.gitignore (deflated 20%)\n","  adding: content/models-master/research/cognitive_planning/ (stored 0%)\n","  adding: content/models-master/research/cognitive_planning/string_int_label_map_pb2.py (deflated 73%)\n","  adding: content/models-master/research/cognitive_planning/viz_active_vision_dataset_main.py (deflated 69%)\n","  adding: content/models-master/research/cognitive_planning/label_map_util.py (deflated 66%)\n","  adding: content/models-master/research/cognitive_planning/tasks.py (deflated 77%)\n","  adding: content/models-master/research/cognitive_planning/command (deflated 46%)\n","  adding: content/models-master/research/cognitive_planning/README.md (deflated 63%)\n","  adding: content/models-master/research/cognitive_planning/BUILD (deflated 40%)\n","  adding: content/models-master/research/cognitive_planning/visualization_utils.py (deflated 76%)\n","  adding: content/models-master/research/cognitive_planning/preprocessing/ (stored 0%)\n","  adding: content/models-master/research/cognitive_planning/preprocessing/lenet_preprocessing.py (deflated 52%)\n","  adding: content/models-master/research/cognitive_planning/preprocessing/preprocessing_factory.py (deflated 67%)\n","  adding: content/models-master/research/cognitive_planning/preprocessing/vgg_preprocessing.py (deflated 73%)\n","  adding: content/models-master/research/cognitive_planning/preprocessing/cifarnet_preprocessing.py (deflated 71%)\n","  adding: content/models-master/research/cognitive_planning/preprocessing/inception_preprocessing.py (deflated 73%)\n","  adding: content/models-master/research/cognitive_planning/preprocessing/__init__.py (stored 0%)\n","  adding: content/models-master/research/cognitive_planning/embedders.py (deflated 74%)\n","  adding: content/models-master/research/cognitive_planning/label_map.txt (deflated 78%)\n","  adding: content/models-master/research/cognitive_planning/train_supervised_active_vision.sh (deflated 48%)\n","  adding: content/models-master/research/cognitive_planning/__init__.py (stored 0%)\n","  adding: content/models-master/research/cognitive_planning/policies.py (deflated 72%)\n","  adding: content/models-master/research/cognitive_planning/standard_fields.py (deflated 74%)\n","  adding: content/models-master/research/cognitive_planning/train_supervised_active_vision.py (deflated 69%)\n","  adding: content/models-master/research/cognitive_planning/envs/ (stored 0%)\n","  adding: content/models-master/research/cognitive_planning/envs/active_vision_dataset_env.py (deflated 74%)\n","  adding: content/models-master/research/cognitive_planning/envs/configs/ (stored 0%)\n","  adding: content/models-master/research/cognitive_planning/envs/configs/active_vision_config.gin (deflated 64%)\n","  adding: content/models-master/research/cognitive_planning/envs/task_env.py (deflated 66%)\n","  adding: content/models-master/research/cognitive_planning/envs/__init__.py (stored 0%)\n","  adding: content/models-master/research/cognitive_planning/envs/util.py (deflated 53%)\n","  adding: content/models-master/research/a3c_blogpost/ (stored 0%)\n","  adding: content/models-master/research/a3c_blogpost/README.md (deflated 35%)\n","  adding: content/models-master/research/a3c_blogpost/a3c_cartpole.py (deflated 71%)\n","  adding: content/models-master/research/setup.py (deflated 39%)\n","  adding: content/models-master/research/lstm_object_detection/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/model_builder_test.py (deflated 81%)\n","  adding: content/models-master/research/lstm_object_detection/export_tflite_lstd_graph_lib.py (deflated 72%)\n","  adding: content/models-master/research/lstm_object_detection/inputs/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/inputs/tf_sequence_example_decoder_test.py (deflated 70%)\n","  adding: content/models-master/research/lstm_object_detection/inputs/seq_dataset_builder_test.py (deflated 74%)\n","  adding: content/models-master/research/lstm_object_detection/inputs/tf_sequence_example_decoder.py (deflated 72%)\n","  adding: content/models-master/research/lstm_object_detection/inputs/seq_dataset_builder.py (deflated 73%)\n","  adding: content/models-master/research/lstm_object_detection/inputs/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/model_builder.py (deflated 74%)\n","  adding: content/models-master/research/lstm_object_detection/README.md (deflated 49%)\n","  adding: content/models-master/research/lstm_object_detection/metrics/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/metrics/coco_evaluation_all_frames.py (deflated 71%)\n","  adding: content/models-master/research/lstm_object_detection/metrics/coco_evaluation_all_frames_test.py (deflated 82%)\n","  adding: content/models-master/research/lstm_object_detection/metrics/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/train.py (deflated 66%)\n","  adding: content/models-master/research/lstm_object_detection/models/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor_test.py (deflated 70%)\n","  adding: content/models-master/research/lstm_object_detection/models/lstm_ssd_interleaved_mobilenet_v2_feature_extractor.py (deflated 72%)\n","  adding: content/models-master/research/lstm_object_detection/models/mobilenet_defs_test.py (deflated 79%)\n","  adding: content/models-master/research/lstm_object_detection/models/mobilenet_defs.py (deflated 72%)\n","  adding: content/models-master/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor.py (deflated 69%)\n","  adding: content/models-master/research/lstm_object_detection/models/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/models/lstm_ssd_interleaved_mobilenet_v2_feature_extractor_test.py (deflated 80%)\n","  adding: content/models-master/research/lstm_object_detection/lstm/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/lstm/utils_test.py (deflated 82%)\n","  adding: content/models-master/research/lstm_object_detection/lstm/rnn_decoder_test.py (deflated 84%)\n","  adding: content/models-master/research/lstm_object_detection/lstm/rnn_decoder.py (deflated 71%)\n","  adding: content/models-master/research/lstm_object_detection/lstm/lstm_cells_test.py (deflated 90%)\n","  adding: content/models-master/research/lstm_object_detection/lstm/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/lstm/lstm_cells.py (deflated 79%)\n","  adding: content/models-master/research/lstm_object_detection/lstm/utils.py (deflated 73%)\n","  adding: content/models-master/research/lstm_object_detection/configs/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/configs/lstm_ssd_interleaved_mobilenet_v2_imagenet.config (deflated 67%)\n","  adding: content/models-master/research/lstm_object_detection/configs/lstm_ssd_mobilenet_v1_imagenet.config (deflated 66%)\n","  adding: content/models-master/research/lstm_object_detection/builders/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/builders/graph_rewriter_builder_test.py (deflated 71%)\n","  adding: content/models-master/research/lstm_object_detection/builders/graph_rewriter_builder.py (deflated 65%)\n","  adding: content/models-master/research/lstm_object_detection/builders/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/utils/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/utils/config_util.py (deflated 70%)\n","  adding: content/models-master/research/lstm_object_detection/utils/config_util_test.py (deflated 71%)\n","  adding: content/models-master/research/lstm_object_detection/utils/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/meta_architectures/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch.py (deflated 74%)\n","  adding: content/models-master/research/lstm_object_detection/meta_architectures/lstm_ssd_meta_arch_test.py (deflated 76%)\n","  adding: content/models-master/research/lstm_object_detection/meta_architectures/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/evaluator.py (deflated 71%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/WORKSPACE (deflated 67%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/mobile_ssd_tflite_client.h (deflated 61%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/BUILD (deflated 77%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/mobile_lstd_tflite_client.h (deflated 61%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/mobile_ssd_tflite_client.cc (deflated 76%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/file_utils.h (deflated 53%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/conversion_utils_test.cc (deflated 79%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/BUILD (deflated 71%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/ssd_utils.h (deflated 72%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/conversion_utils.cc (deflated 62%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/ssd_utils.cc (deflated 80%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/conversion_utils.h (deflated 52%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/utils/file_utils.cc (deflated 54%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/mobile_ssd_client.cc (deflated 70%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/protos/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/protos/labelmap.proto (deflated 52%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/protos/box_encodings.proto (deflated 67%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/protos/mobile_ssd_client_options.proto (deflated 60%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/protos/BUILD (deflated 78%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/protos/detections.proto (deflated 49%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/protos/proto_config.asciipb (deflated 12%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/protos/anchor_generation_options.proto (deflated 56%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/mobile_ssd_client.h (deflated 65%)\n","  adding: content/models-master/research/lstm_object_detection/tflite/mobile_lstd_tflite_client.cc (deflated 77%)\n","  adding: content/models-master/research/lstm_object_detection/export_tflite_lstd_model.py (deflated 56%)\n","  adding: content/models-master/research/lstm_object_detection/g3doc/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/g3doc/lstm_ssd_intro.png (deflated 1%)\n","  adding: content/models-master/research/lstm_object_detection/g3doc/exporting_models.md (deflated 63%)\n","  adding: content/models-master/research/lstm_object_detection/g3doc/Interleaved_Intro.png (deflated 1%)\n","  adding: content/models-master/research/lstm_object_detection/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/eval.py (deflated 64%)\n","  adding: content/models-master/research/lstm_object_detection/protos/ (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/protos/input_reader_google.proto (deflated 51%)\n","  adding: content/models-master/research/lstm_object_detection/protos/__init__.py (stored 0%)\n","  adding: content/models-master/research/lstm_object_detection/protos/pipeline.proto (deflated 61%)\n","  adding: content/models-master/research/lstm_object_detection/protos/quant_overrides.proto (deflated 58%)\n","  adding: content/models-master/research/lstm_object_detection/trainer.py (deflated 70%)\n","  adding: content/models-master/research/lstm_object_detection/export_tflite_lstd_graph.py (deflated 64%)\n","  adding: content/models-master/research/lstm_object_detection/test_tflite_model.py (deflated 52%)\n","  adding: content/models-master/research/deeplab/ (stored 0%)\n","  adding: content/models-master/research/deeplab/deprecated/ (stored 0%)\n","  adding: content/models-master/research/deeplab/deprecated/segmentation_dataset.py (deflated 63%)\n","  adding: content/models-master/research/deeplab/deprecated/__init__.py (stored 0%)\n","  adding: content/models-master/research/deeplab/convert_to_tflite.py (deflated 60%)\n","  adding: content/models-master/research/deeplab/common_test.py (deflated 64%)\n","  adding: content/models-master/research/deeplab/core/ (stored 0%)\n","  adding: content/models-master/research/deeplab/core/nas_network.py (deflated 73%)\n","  adding: content/models-master/research/deeplab/core/xception_test.py (deflated 84%)\n","  adding: content/models-master/research/deeplab/core/utils_test.py (deflated 69%)\n","  adding: content/models-master/research/deeplab/core/resnet_v1_beta_test.py (deflated 88%)\n","  adding: content/models-master/research/deeplab/core/dense_prediction_cell.py (deflated 72%)\n","  adding: content/models-master/research/deeplab/core/resnet_v1_beta.py (deflated 85%)\n","  adding: content/models-master/research/deeplab/core/preprocess_utils_test.py (deflated 85%)\n","  adding: content/models-master/research/deeplab/core/nas_cell.py (deflated 70%)\n","  adding: content/models-master/research/deeplab/core/nas_network_test.py (deflated 62%)\n","  adding: content/models-master/research/deeplab/core/preprocess_utils.py (deflated 71%)\n","  adding: content/models-master/research/deeplab/core/conv2d_ws_test.py (deflated 86%)\n","  adding: content/models-master/research/deeplab/core/conv2d_ws.py (deflated 70%)\n","  adding: content/models-master/research/deeplab/core/xception.py (deflated 81%)\n","  adding: content/models-master/research/deeplab/core/__init__.py (stored 0%)\n","  adding: content/models-master/research/deeplab/core/dense_prediction_cell_test.py (deflated 75%)\n","  adding: content/models-master/research/deeplab/core/dense_prediction_cell_branch5_top1_cityscapes.json (deflated 71%)\n","  adding: content/models-master/research/deeplab/core/utils.py (deflated 67%)\n","  adding: content/models-master/research/deeplab/core/nas_genotypes.py (deflated 54%)\n","  adding: content/models-master/research/deeplab/core/feature_extractor.py (deflated 79%)\n","  adding: content/models-master/research/deeplab/testing/ (stored 0%)\n","  adding: content/models-master/research/deeplab/testing/info.md (deflated 35%)\n","  adding: content/models-master/research/deeplab/testing/pascal_voc_seg/ (stored 0%)\n","  adding: content/models-master/research/deeplab/testing/pascal_voc_seg/val-00000-of-00001.tfrecord (deflated 0%)\n","  adding: content/models-master/research/deeplab/README.md (deflated 62%)\n","  adding: content/models-master/research/deeplab/evaluation/ (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/base_metric.py (deflated 66%)\n","  adding: content/models-master/research/deeplab/evaluation/streaming_metrics.py (deflated 77%)\n","  adding: content/models-master/research/deeplab/evaluation/README.md (deflated 64%)\n","  adding: content/models-master/research/deeplab/evaluation/panoptic_quality_test.py (deflated 82%)\n","  adding: content/models-master/research/deeplab/evaluation/eval_coco_format.py (deflated 70%)\n","  adding: content/models-master/research/deeplab/evaluation/parsing_covering.py (deflated 68%)\n","  adding: content/models-master/research/deeplab/evaluation/eval_coco_format_test.py (deflated 78%)\n","  adding: content/models-master/research/deeplab/evaluation/test_utils_test.py (deflated 62%)\n","  adding: content/models-master/research/deeplab/evaluation/g3doc/ (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/g3doc/img/ (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/g3doc/img/equation_pq.png (deflated 5%)\n","  adding: content/models-master/research/deeplab/evaluation/g3doc/img/equation_pc.png (deflated 8%)\n","  adding: content/models-master/research/deeplab/evaluation/__init__.py (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/test_utils.py (deflated 62%)\n","  adding: content/models-master/research/deeplab/evaluation/parsing_covering_test.py (deflated 73%)\n","  adding: content/models-master/research/deeplab/evaluation/panoptic_quality.py (deflated 70%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/ (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_pred.json (deflated 82%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_pred/ (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_pred/team.png (deflated 0%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_pred/congress.png (deflated 12%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_pred/cat.png (deflated 2%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_pred/bird.png (deflated 0%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/cat_gt.png (deflated 9%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_gt/ (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_gt/team.png (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_gt/congress.png (deflated 6%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_gt/cat.png (deflated 1%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_gt/bird.png (deflated 1%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/cat_pred_class.png (deflated 18%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/README.md (deflated 48%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/team_pred_instance.png (deflated 2%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/bird_pred_instance.png (deflated 1%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/bird_pred_class.png (deflated 1%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/coco_gt.json (deflated 82%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/bird_gt.png (stored 0%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/cat_pred_instance.png (deflated 12%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/team_pred_class.png (deflated 8%)\n","  adding: content/models-master/research/deeplab/evaluation/testdata/team_gt_instance.png (deflated 1%)\n","  adding: content/models-master/research/deeplab/evaluation/streaming_metrics_test.py (deflated 86%)\n","  adding: content/models-master/research/deeplab/train.py (deflated 70%)\n","  adding: content/models-master/research/deeplab/utils/ (stored 0%)\n","  adding: content/models-master/research/deeplab/utils/save_annotation.py (deflated 58%)\n","  adding: content/models-master/research/deeplab/utils/get_dataset_colormap_test.py (deflated 69%)\n","  adding: content/models-master/research/deeplab/utils/train_utils.py (deflated 71%)\n","  adding: content/models-master/research/deeplab/utils/get_dataset_colormap.py (deflated 72%)\n","  adding: content/models-master/research/deeplab/utils/__init__.py (stored 0%)\n","  adding: content/models-master/research/deeplab/deeplab_demo.ipynb (deflated 70%)\n","  adding: content/models-master/research/deeplab/vis.py (deflated 68%)\n","  adding: content/models-master/research/deeplab/model.py (deflated 78%)\n","  adding: content/models-master/research/deeplab/g3doc/ (stored 0%)\n","  adding: content/models-master/research/deeplab/g3doc/img/ (stored 0%)\n","  adding: content/models-master/research/deeplab/g3doc/img/image_info.txt (deflated 37%)\n","  adding: content/models-master/research/deeplab/g3doc/img/image3.jpg (deflated 0%)\n","  adding: content/models-master/research/deeplab/g3doc/img/image2.jpg (deflated 0%)\n","  adding: content/models-master/research/deeplab/g3doc/img/vis2.png (deflated 1%)\n","  adding: content/models-master/research/deeplab/g3doc/img/vis3.png (deflated 0%)\n","  adding: content/models-master/research/deeplab/g3doc/img/vis1.png (deflated 1%)\n","  adding: content/models-master/research/deeplab/g3doc/img/image1.jpg (deflated 0%)\n","  adding: content/models-master/research/deeplab/g3doc/pascal.md (deflated 68%)\n","  adding: content/models-master/research/deeplab/g3doc/cityscapes.md (deflated 67%)\n","  adding: content/models-master/research/deeplab/g3doc/export_model.md (deflated 48%)\n","  adding: content/models-master/research/deeplab/g3doc/quantize.md (deflated 63%)\n","  adding: content/models-master/research/deeplab/g3doc/installation.md (deflated 56%)\n","  adding: content/models-master/research/deeplab/g3doc/model_zoo.md (deflated 71%)\n","  adding: content/models-master/research/deeplab/g3doc/ade20k.md (deflated 58%)\n","  adding: content/models-master/research/deeplab/g3doc/faq.md (deflated 53%)\n","  adding: content/models-master/research/deeplab/__init__.py (stored 0%)\n","  adding: content/models-master/research/deeplab/eval.py (deflated 67%)\n","  adding: content/models-master/research/deeplab/datasets/ (stored 0%)\n","  adding: content/models-master/research/deeplab/datasets/build_ade20k_data.py (deflated 62%)\n","  adding: content/models-master/research/deeplab/datasets/download_and_convert_ade20k.sh (deflated 56%)\n","  adding: content/models-master/research/deeplab/datasets/build_data.py (deflated 66%)\n","  adding: content/models-master/research/deeplab/datasets/download_and_convert_voc2012.sh (deflated 56%)\n","  adding: content/models-master/research/deeplab/datasets/convert_cityscapes.sh (deflated 52%)\n","  adding: content/models-master/research/deeplab/datasets/data_generator.py (deflated 67%)\n","  adding: content/models-master/research/deeplab/datasets/data_generator_test.py (deflated 59%)\n","  adding: content/models-master/research/deeplab/datasets/build_cityscapes_data.py (deflated 62%)\n","  adding: content/models-master/research/deeplab/datasets/remove_gt_colormap.py (deflated 61%)\n","  adding: content/models-master/research/deeplab/datasets/__init__.py (stored 0%)\n","  adding: content/models-master/research/deeplab/datasets/build_voc2012_data.py (deflated 63%)\n","  adding: content/models-master/research/deeplab/local_test.sh (deflated 64%)\n","  adding: content/models-master/research/deeplab/common.py (deflated 69%)\n","  adding: content/models-master/research/deeplab/model_test.py (deflated 69%)\n","  adding: content/models-master/research/deeplab/export_model.py (deflated 65%)\n","  adding: content/models-master/research/deeplab/input_preprocess.py (deflated 68%)\n","  adding: content/models-master/research/deeplab/local_test_mobilenetv2.sh (deflated 61%)\n","  adding: content/models-master/research/deep_speech/ (stored 0%)\n","  adding: content/models-master/research/deep_speech/decoder.py (deflated 58%)\n","  adding: content/models-master/research/deep_speech/requirements.txt (deflated 13%)\n","  adding: content/models-master/research/deep_speech/run_deep_speech.sh (deflated 63%)\n","  adding: content/models-master/research/deep_speech/data/ (stored 0%)\n","  adding: content/models-master/research/deep_speech/data/vocabulary.txt (deflated 27%)\n","  adding: content/models-master/research/deep_speech/data/featurizer.py (deflated 58%)\n","  adding: content/models-master/research/deep_speech/data/dataset.py (deflated 67%)\n","  adding: content/models-master/research/deep_speech/data/__init__.py (stored 0%)\n","  adding: content/models-master/research/deep_speech/data/download.py (deflated 66%)\n","  adding: content/models-master/research/deep_speech/README.md (deflated 57%)\n","  adding: content/models-master/research/deep_speech/deep_speech_model.py (deflated 65%)\n","  adding: content/models-master/research/deep_speech/deep_speech.py (deflated 67%)\n","  adding: content/models-master/research/deep_speech/__init__.py (stored 0%)\n","  adding: content/models-master/research/dist/ (stored 0%)\n","  adding: content/models-master/research/dist/object_detection-0.1-py3.6.egg (deflated 4%)\n","  adding: content/models-master/orbit/ (stored 0%)\n","  adding: content/models-master/orbit/README.md (deflated 40%)\n","  adding: content/models-master/orbit/standard_runner.py (deflated 73%)\n","  adding: content/models-master/orbit/controller_test.py (deflated 86%)\n","  adding: content/models-master/orbit/standard_runner_test.py (deflated 65%)\n","  adding: content/models-master/orbit/utils/ (stored 0%)\n","  adding: content/models-master/orbit/utils/tpu_summaries_test.py (deflated 70%)\n","  adding: content/models-master/orbit/utils/common_test.py (deflated 48%)\n","  adding: content/models-master/orbit/utils/tpu_summaries.py (deflated 63%)\n","  adding: content/models-master/orbit/utils/loop_fns.py (deflated 63%)\n","  adding: content/models-master/orbit/utils/__init__.py (deflated 52%)\n","  adding: content/models-master/orbit/utils/summary_manager.py (deflated 64%)\n","  adding: content/models-master/orbit/utils/epoch_helper.py (deflated 60%)\n","  adding: content/models-master/orbit/utils/common.py (deflated 57%)\n","  adding: content/models-master/orbit/runner.py (deflated 60%)\n","  adding: content/models-master/orbit/LICENSE (deflated 65%)\n","  adding: content/models-master/orbit/__init__.py (deflated 55%)\n","  adding: content/models-master/orbit/controller.py (deflated 71%)\n","  adding: content/models-master/AUTHORS (deflated 34%)\n","  adding: content/models-master/LICENSE (deflated 65%)\n","  adding: content/models-master/CONTRIBUTING.md (deflated 36%)\n","  adding: content/models-master/.gitignore (deflated 44%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JEExq3aHkekT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608066667200,"user_tz":-330,"elapsed":6559,"user":{"displayName":"Samyak Jain","photoUrl":"","userId":"08021580289275006991"}},"outputId":"7819b413-1d0a-4a02-e210-066624ae6953"},"source":["!cd /content/drive/MyDrive/new_graph\r\n","!tflite_convert --graph_def_file=/content/drive/MyDrive/new_graph/tflite_graph.pb --output_file=/content/drive/MyDrive/new_graph/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --allow_custom_ops"],"execution_count":40,"outputs":[{"output_type":"stream","text":["2020-12-15 21:11:04.640820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-12-15 21:11:04.675228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.675839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 21:11:04.676110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 21:11:04.677713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 21:11:04.679267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 21:11:04.679585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 21:11:04.681369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 21:11:04.682356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 21:11:04.686000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 21:11:04.686140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.686806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.687322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 21:11:04.692742: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n","2020-12-15 21:11:04.692946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d52a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-12-15 21:11:04.692976: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-12-15 21:11:04.800821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.801493: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d52bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-12-15 21:11:04.801523: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-12-15 21:11:04.801713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.802322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-12-15 21:11:04.802376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 21:11:04.802404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-12-15 21:11:04.802425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-12-15 21:11:04.802445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-12-15 21:11:04.802469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-12-15 21:11:04.802487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-12-15 21:11:04.802509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-12-15 21:11:04.802578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.803203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.803757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-12-15 21:11:04.803815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-12-15 21:11:04.804869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-12-15 21:11:04.804896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-12-15 21:11:04.804908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-12-15 21:11:04.805014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.805601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-12-15 21:11:04.806171: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-12-15 21:11:04.806230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E_PbbGYZPJlI"},"source":[""],"execution_count":null,"outputs":[]}]}